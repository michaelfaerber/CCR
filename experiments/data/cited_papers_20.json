{"1601.00670": ["[CLS]  mystyle commentstyle=, numberstyle=, stringstyle=, basicstyle=, breakatwhitespace=false, breaklines=true, captionpos=b, keepspaces=true, numbers=none, numbersep=5pt, showspaces=false, showstringspaces=false, showtabs=false, tabsize=2  citecolor=Violet linkcolor=black urlcolor=MidnightBlue KLklKullback-Leibler ELBOelboevidence lower bound EMemexpectation maximization MCMCmcmcMarkov chain Monte Carlo MCmcMonte Carlo EPepexpectation propagation VIvivariational inference MFVImfvimean-field variational inference SVIsvistochastic variational inference CAVIcavicoordinate ascent variational inference [SEP]\n", "[CLS] ADadautomatic differentiation ADVIadviautomatic differentiation variational inference ADVIDIAGadvi-diagautomatic differentiation variational inference diagonal ADSVIadsviautomatic differentiation stochastic variational inference RMSPROPrmsproprmsprop GMMgmmGaussian mixture model LDAldalatent Dirichlet allocation ARDardautomatic relevance determination SGAsgastochastic gradient ascent MLEmlemaximum likelihood estimate Variational Inference: A Review for StatisticiansDavid M.\u00a0BleiDepartment of Computer Science and StatisticsColumbia UniversityAlp KucukelbirDepartment of Computer Science Columbia [SEP]\n", "[CLS] UniversityJon D.\u00a0McAuliffe Department of StatisticsUniversity of California, Berkeley2020/09/16 02:49:51 [SEP]\n", "[CLS] One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. [SEP]\n", "[CLS] This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. [SEP]\n", "[CLS] In this paper, we review VI, a method from machine learning that approximates probability densities through optimization. [SEP]\n", "[CLS] VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. [SEP]\n", "[CLS] The idea behind VI is to first posit a family of densities and then to find the member of that family which is close to the target. [SEP]\n", "[CLS] Closeness is measured by Kullback-Leibler divergence. [SEP]\n", "[CLS] We review the ideas behind mean-field variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. [SEP]\n", "[CLS] We discuss modern research in VI and highlight important open problems. [SEP]\n", "[CLS] VI is powerful, but it is not yet well understood. [SEP]\n", "[CLS] Our hope in writing this paper is to catalyze statistical research on this class of algorithms.   [SEP]\n", "[CLS] Keywords: Algorithms; Statistical Computing; Computationally Intensive Methods.   [SEP]\n", "[CLS] Introduction One of the core problems of modern statistics is to approximate difficult-to-compute probability densities. [SEP]\n", "[CLS] This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation about the posterior. [SEP]\n", "[CLS] Modern Bayesian statistics relies on models for which the posterior is not easy to compute and corresponding algorithms for approximating them. [SEP]\n", "[CLS] In this paper, we review VI, a method from machine learning for approximating probability densities\u00a0{{cite:fe7cad8f-3b9d-4d8c-91d7-3ecd2141df10}}, {{cite:949e3650-fc19-4029-80eb-0e8e66d78e58}}. [SEP]\n", "[CLS] Variational inference is widely used to approximate posterior densities for Bayesian models, an alternative strategy to MCMC sampling. [SEP]\n", "[CLS] Compared to MCMC, variational inference tends to be faster and easier to scale to large data\u2014it has been applied to problems such as large-scale document analysis, computational neuroscience, and computer vision. [SEP]\n", "[CLS] But variational inference has been studied less rigorously than MCMC, and its statistical properties are less well understood. [SEP]\n", "[CLS] In writing this paper, our hope is to catalyze statistical research on variational inference. [SEP]\n", "[CLS] First, we set up the general problem. [SEP]\n", "[CLS] Consider a joint density of latent variables FORMULA  and observations FORMULA , FORMULA    [SEP]\n", "[CLS] In Bayesian models, the latent variables help govern the distribution of the data. [SEP]\n", "[CLS] A Bayesian model draws the latent variables from a prior density FORMULA  and then relates them to the observations through the likelihood FORMULA . [SEP]\n", "[CLS] Inference in a Bayesian model amounts to conditioning on data and computing the posterior FORMULA . [SEP]\n", "[CLS] In complex Bayesian models, this computation often requires approximate inference. [SEP]\n", "[CLS] For decades, the dominant paradigm for approximate inference has been MCMC\u00a0{{cite:c99a58b0-9290-4561-b858-981664e91f27}}, {{cite:31a39dc9-f0cc-4c1e-b5f9-5d9632a9d2ca}}. [SEP]\n", "[CLS] In MCMC, we first construct an ergodic Markov chain on FORMULA   [SEP]\n", "[CLS] whose stationary distribution is the posterior FORMULA . [SEP]\n", "[CLS] Then, we sample from the chain to collect samples from the stationary distribution. [SEP]\n", "[CLS] Finally, we approximate the posterior with an empirical estimate constructed from (a subset of) the collected samples. [SEP]\n", "[CLS] MCMC sampling has evolved into an indispensable tool to the modern Bayesian statistician. [SEP]\n", "[CLS] Landmark developments include the Metropolis-Hastings algorithm {{cite:8dd4bf8a-d897-4385-8cd2-b52626588308}}, {{cite:c99a58b0-9290-4561-b858-981664e91f27}}, the Gibbs sampler {{cite:b7f385ac-6c99-443d-a35e-95f09dd8e784}} and its application to Bayesian statistics {{cite:31a39dc9-f0cc-4c1e-b5f9-5d9632a9d2ca}}. [SEP]\n", "[CLS] MCMC algorithms are under active investigation. [SEP]\n", "[CLS] They have been widely studied, extended, and applied; see {{cite:a05a6d03-6435-4356-a767-aae5b16f1091}} for a perspective. [SEP]\n", "[CLS] However, there are problems for which we cannot easily use this approach. [SEP]\n", "[CLS] These arise particularly when we need an approximate conditional faster than a simple MCMC algorithm can produce, such as when data sets are large or models are very complex. [SEP]\n", "[CLS] In these settings, variational inference provides a good alternative approach to approximate Bayesian inference. [SEP]\n", "[CLS] Rather than use sampling, the main idea behind variational inference is to use optimization. [SEP]\n", "[CLS] First, we posit a family of approximate densities FORMULA . [SEP]\n", "[CLS] This is a set of densities over the latent variables. [SEP]\n", "[CLS] Then, we try to find the member of that family that minimizes the KL divergence to the exact posterior, FORMULA    [SEP]\n", "[CLS] Finally, we approximate the posterior with the optimized member of the family FORMULA . [SEP]\n", "[CLS] Variational inference thus turns the inference problem into an optimization problem, and the reach of the family FORMULA  manages the complexity of this optimization. [SEP]\n", "[CLS] One of the key ideas behind variational inference is to choose FORMULA  to be flexible enough to capture a density close to FORMULA , but simple enough for efficient optimization. [SEP]\n", "[CLS] We focus here on FORMULA -based optimization, also called Kullback Leibler variational inference\u00a0{{cite:4442222f-0fbf-40d7-96ed-1a773b14e881}}. [SEP]\n", "[CLS] {{cite:949e3650-fc19-4029-80eb-0e8e66d78e58}} emphasize that any procedure which uses optimization to approximate a density can be termed \u201cvariational inference.\u201d [SEP]\n", "[CLS] This includes methods like expectation propagation\u00a0{{cite:6823d9ea-22c9-48a3-a1b9-13c77f84a78b}}, belief propagation\u00a0{{cite:e3f3360b-e995-4b83-ad33-5d6630275d26}}, or even the Laplace approximation. [SEP]\n", "[CLS] We briefly discuss alternative divergence measures in Section\u00a0. [SEP]\n", "[CLS] We emphasize that MCMC and variational inference are different approaches to solving the same problem. [SEP]\n", "[CLS] MCMC algorithms sample a Markov chain; variational algorithms solve an optimization problem. [SEP]\n", "[CLS] MCMC algorithms approximate the posterior with samples from the chain; variational algorithms approximate the posterior with the result of the optimization. [SEP]\n", "[CLS] Comparing variational inference and MCMC. [SEP]\n", "[CLS] \u00a0 When should a statistician use MCMC and when should she use variational inference? [SEP]\n", "[CLS] We will offer some guidance. [SEP]\n", "[CLS] MCMC methods tend to be more computationally intensive than variational inference but they also provide guarantees of producing (asymptotically) exact samples from the target density {{cite:a05a6d03-6435-4356-a767-aae5b16f1091}}. [SEP]\n", "[CLS] Variational inference does not enjoy such guarantees\u2014it can only find a density close to the target\u2014but tends to be faster than MCMC. [SEP]\n", "[CLS] Because it rests on optimization, variational inference easily takes advantage of methods like stochastic optimization\u00a0{{cite:51665fa3-19b9-4f4c-b91e-d8ab8e35f92e}}, {{cite:ad7ffa6b-7adb-44fb-a8a9-334936b4f183}} and distributed optimization (though some MCMC methods can also exploit these innovations\u00a0{{cite:f45739ea-428f-4bf6-90dc-1b474eacb213}}, {{cite:3f8cca96-8b99-4819-a14f-c5acdfd954b2}}). [SEP]\n", "[CLS] Thus, variational inference is suited to large data sets and scenarios where we want to quickly explore many models; MCMC is suited to smaller data sets and scenarios where we happily pay a heavier computational cost for more precise samples. [SEP]\n", "[CLS] For example, we might use MCMC in a setting where we spent 20 years collecting a small but expensive data set, where we are confident that our model is appropriate, and where we require precise inferences. [SEP]\n", "[CLS] We might use variational inference when fitting a probabilistic model of text to one billion text documents and where the inferences will be used to serve search results to a large population of users. [SEP]\n", "[CLS] In this scenario, we can use distributed computation and stochastic optimization to scale and speed up inference, and we can easily explore many different models of the data. [SEP]\n", "[CLS] Data set size is not the only consideration. [SEP]\n", "[CLS] Another factor is the geometry of the posterior distribution. [SEP]\n", "[CLS] For example, the posterior of a mixture model admits multiple modes, each corresponding label permutations of the components. [SEP]\n", "[CLS] Gibbs sampling, if the model permits, is a powerful approach to sampling from such target distributions; it quickly focuses on one of the modes. [SEP]\n", "[CLS] For mixture models where Gibbs sampling is not an option, variational inference may perform better than a more general MCMC technique (e.g.,\u00a0Hamiltonian Monte Carlo), even for small datasets {{cite:de6dbb02-df68-4e27-b0e8-851b5948d5be}}. [SEP]\n", "[CLS] Exploring the interplay between model complexity and inference (and between variational inference and MCMC) is an exciting avenue for future research (see Section\u00a0REF ). [SEP]\n", "[CLS] The relative accuracy of variational inference and MCMC is still unknown. [SEP]\n", "[CLS] We do know that variational inference generally underestimates the variance of the posterior density; this is a consequence of its objective function. [SEP]\n", "[CLS] But, depending on the task at hand, underestimating the variance may be acceptable. [SEP]\n", "[CLS] Several lines of empirical research have shown that variational inference does not necessarily suffer in accuracy, e.g., in terms of posterior predictive densities\u00a0{{cite:b9d95572-a8f1-4873-a24e-416d965905ce}}, {{cite:7c538023-885f-42ee-b9cc-c91ec5eb4063}}, {{cite:e0277160-fe65-49ed-9588-106a52a0bd9f}}; other research focuses on where variational inference falls short, especially around the posterior variance, and tries to more closely match the inferences made by MCMC {{cite:cef830c5-f260-433b-ada6-2ea7e9c49d6a}}. [SEP]\n", "[CLS] In general, a statistical theory and understanding around variational inference is an important open area of research (see Section\u00a0REF ). [SEP]\n", "[CLS] We can envision future results that outline which classes of models are particularly suited to each algorithm and perhaps even theory that bounds their accuracy. [SEP]\n", "[CLS] More broadly, variational inference is a valuable tool, alongside MCMC, in the statistician's toolbox. [SEP]\n", "[CLS] It might appear to the reader that variational inference is only relevant to Bayesian analysis. [SEP]\n", "[CLS] Indeed, both variational inference and MCMC have had a significant impact on applied Bayesian computation and we will be focusing on Bayesian models here. [SEP]\n", "[CLS] We emphasize, however, that these techniques also apply more generally to computation about intractable densities. [SEP]\n", "[CLS] MCMC is a tool for simulating from densities and variational inference is a tool for approximating densities. [SEP]\n", "[CLS] One need not be a Bayesian to have use for variational inference. [SEP]\n", "[CLS] Research on variational inference. [SEP]\n", "[CLS] \u00a0 The development of variational techniques for Bayesian inference followed two parallel, yet separate, tracks. [SEP]\n", "[CLS] {{cite:2e8b000c-a618-485b-aa69-c77106efaa31}} is arguably the first variational procedure for a particular model: a neural network. [SEP]\n", "[CLS] This paper, along with insights from statistical mechanics {{cite:8e9f1fbb-e4e8-4b9a-99a1-dbe0b41242bf}}, led to a flurry of variational inference procedures for a wide class of models {{cite:b969a8cd-fd5b-441d-aab5-1c679536a353}}, {{cite:058b5b7f-6183-4c34-9c1b-d1175dcd441a}}, {{cite:b448a758-55e0-4a8f-b174-6064ee835ef6}}, {{cite:f63c7221-0167-422e-a3ce-375f7cc2a27c}}, {{cite:fe7cad8f-3b9d-4d8c-91d7-3ecd2141df10}}. [SEP]\n", "[CLS] In parallel, {{cite:8f2a39a7-129c-4242-959f-6ec21f0ef030}} proposed a variational algorithm for a similar neural network model. [SEP]\n", "[CLS] {{cite:2cc20958-4b81-46e2-bc4e-396f72a4e3bb}} (first published in 1993) made important connections to the EM algorithm\u00a0{{cite:cf8481fb-5ef4-4162-9ac4-6ebe8c309c6f}}, which then led to a variety of variational inference algorithms for other types of models {{cite:99ae043f-6da3-45d8-92dd-5783e0ce1840}}, {{cite:3a64edd7-2873-4150-90d9-dd636da6bc11}}. [SEP]\n", "[CLS] Modern research on variational inference focuses on several aspects: tackling Bayesian inference problems that involve massive data; using improved optimization methods for solving Equation\u00a0(REF ) (which is usually subject to local minima); developing generic variational inference, algorithms that are easy to apply to a wide class of models; and increasing the accuracy of variational inference, e.g., by stretching the boundaries of FORMULA  while managing complexity in optimization. [SEP]\n", "[CLS] Organization of this paper. [SEP]\n", "[CLS] \u00a0 Section\u00a0 describes the basic ideas behind the simplest approach to variational inference: mean-field inference and coordinate-ascent optimization. [SEP]\n", "[CLS] Section\u00a0 works out the details for a Bayesian mixture of Gaussians, an example model familiar to many readers. [SEP]\n", "[CLS] Sections\u00a0REF  and\u00a0REF  describe variational inference for the class of models where the joint density of the latent and observed variables are in the exponential family\u2014this includes many intractable models from modern Bayesian statistics and reveals deep connections between variational inference and the Gibbs sampler of\u00a0{{cite:31a39dc9-f0cc-4c1e-b5f9-5d9632a9d2ca}}. [SEP]\n", "[CLS] Section\u00a0REF  expands on this algorithm to describe stochastic variational inference\u00a0{{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}}, which scales variational inference to massive data using stochastic optimization\u00a0{{cite:51665fa3-19b9-4f4c-b91e-d8ab8e35f92e}}. [SEP]\n", "[CLS] Finally, with these foundations in place, Section\u00a0 gives a perspective on the field\u2014applications in the research literature, a survey of theoretical results, and an overview of some open problems. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Variational inference The goal of variational inference is to approximate a conditional density of latent variables given observed variables. [SEP]\n", "[CLS] The key idea is to solve this problem with optimization. [SEP]\n", "[CLS] We use a family of densities over the latent variables, parameterized by free \u201cvariational parameters.\u201d [SEP]\n", "[CLS] The optimization finds the member of this family, i.e., the setting of the parameters, that is closest in KL divergence to the conditional of interest. [SEP]\n", "[CLS] The fitted variational density then serves as a proxy for the exact conditional density. [SEP]\n", "[CLS] (All vectors defined below are column vectors, unless stated otherwise.) [SEP]\n", "[CLS] The problem of approximate inference Let FORMULA  be a set of observed variables and FORMULA  be a set of latent variables, with joint density FORMULA . [SEP]\n", "[CLS] We omit constants, such as hyperparameters, from the notation. [SEP]\n", "[CLS] The inference problem is to compute the conditional density of the latent variables given the observations, FORMULA . [SEP]\n", "[CLS] This conditional can be used to produce point or interval estimates of the latent variables, form predictive densities of new data, and more. [SEP]\n", "[CLS] We can write the conditional density as FORMULA   The denominator contains the marginal density of the observations, also called the evidence. [SEP]\n", "[CLS] We calculate it by marginalizing out the latent variables from the joint density, FORMULA   For many models, this evidence integral is unavailable in closed form or requires exponential time to compute. [SEP]\n", "[CLS] The evidence is what we need to compute the conditional from the joint; this is why inference in such models is hard. [SEP]\n", "[CLS] Note we assume that all unknown quantities of interest are represented as latent random variables. [SEP]\n", "[CLS] This includes parameters that might govern all the data, as found in Bayesian models, and latent variables that are \u201clocal\u201d to individual data points. [SEP]\n", "[CLS] Bayesian mixture of Gaussians. [SEP]\n", "[CLS] \u00a0 Consider a Bayesian mixture of unit-variance univariate Gaussians. [SEP]\n", "[CLS] There are FORMULA  mixture components, corresponding to FORMULA   [SEP]\n", "[CLS] Gaussian distributions with means FORMULA . [SEP]\n", "[CLS] The mean parameters are drawn independently from a common prior FORMULA , which we assume to be a Gaussian FORMULA ; the prior variance FORMULA  is a hyperparameter. [SEP]\n", "[CLS] To generate an observation FORMULA  from the model, we first choose a cluster assignment FORMULA . [SEP]\n", "[CLS] It indicates which latent cluster FORMULA  comes from and is drawn from a categorical distribution over FORMULA . [SEP]\n", "[CLS] (We encode FORMULA  as an indicator FORMULA -vector, all zeros except for a one in the position corresponding to FORMULA 's cluster.) [SEP]\n", "[CLS] We then draw FORMULA  from the corresponding Gaussian FORMULA . [SEP]\n", "[CLS] The full hierarchical model is FORMULA   For a sample of size FORMULA , the joint density of latent and observed variables is FORMULA    [SEP]\n", "[CLS] The latent variables are FORMULA , the FORMULA  class means and FORMULA  class assignments. [SEP]\n", "[CLS] Here, the evidence is FORMULA    [SEP]\n", "[CLS] The integrand in\u00a0Equation\u00a0(REF ) does not contain a separate factor for each FORMULA . [SEP]\n", "[CLS] (Indeed, each FORMULA  appears in all FORMULA  factors of the integrand.) [SEP]\n", "[CLS] Thus, the integral in\u00a0Equation\u00a0(REF ) does not reduce to a product of one-dimensional integrals over the FORMULA 's. [SEP]\n", "[CLS] The time complexity of numerically evaluating the FORMULA -dimensional integral is FORMULA . [SEP]\n", "[CLS] If we distribute the product over the sum in\u00a0(REF ) and rearrange, we can write the evidence as a sum over all possible configurations FORMULA  of cluster assignments, FORMULA    [SEP]\n", "[CLS] Here each individual integral is computable, thanks to the conjugacy between the Gaussian prior on the components and the Gaussian likelihood. [SEP]\n", "[CLS] But there are FORMULA  of them, one for each configuration of the cluster assignments. [SEP]\n", "[CLS] Computing the evidence remains exponential in FORMULA , hence intractable.   [SEP]\n", "[CLS] The evidence lower bound In variational inference, we specify a family FORMULA  of densities over the latent variables. [SEP]\n", "[CLS] Each FORMULA  is a candidate approximation to the exact conditional. [SEP]\n", "[CLS] Our goal is to find the best candidate, the one closest in KL divergence to the exact conditional. [SEP]\n", "[CLS] The KL divergence is an information-theoretic measure of proximity between two densities. [SEP]\n", "[CLS] It is asymmetric\u2014that is, FORMULA \u2014and nonnegative. [SEP]\n", "[CLS] It is minimized when FORMULA . [SEP]\n", "[CLS] Inference now amounts to solving the following optimization problem, FORMULA   Once found, FORMULA  is the best approximation of the conditional, within the family FORMULA . [SEP]\n", "[CLS] The complexity of the family determines the complexity of this optimization. [SEP]\n", "[CLS] However, this objective is not computable because it requires computing the evidence FORMULA  in Equation\u00a0(REF ). [SEP]\n", "[CLS] (That the evidence is hard to compute is why we appeal to approximate inference in the first place.) To see why, recall that KL divergence is FORMULA   where all expectations are taken with respect to FORMULA . [SEP]\n", "[CLS] Expand the conditional, FORMULA    [SEP]\n", "[CLS] This reveals its dependence on FORMULA . [SEP]\n", "[CLS] Because we cannot compute the KL, we optimize an alternative objective that is equivalent to the KL up to an added constant, FORMULA    [SEP]\n", "[CLS] This function is called the ELBO. [SEP]\n", "[CLS] The ELBO is the negative KL divergence of Equation\u00a0(REF ) plus FORMULA , which is a constant with respect to FORMULA . [SEP]\n", "[CLS] Maximizing the ELBO is equivalent to minimizing the KL divergence. [SEP]\n", "[CLS] Examining the ELBO gives intuitions about the optimal variational density. [SEP]\n", "[CLS] We rewrite the ELBO as a sum of the expected log likelihood of the data and the KL divergence between the prior FORMULA  and FORMULA , FORMULA   Which values of FORMULA  will this objective encourage FORMULA  to place its mass on? [SEP]\n", "[CLS] The first term is an expected likelihood; it encourages densities that place their mass on configurations of the latent variables that explain the observed data. [SEP]\n", "[CLS] The second term is the negative divergence between the variational density and the prior; it encourages densities close to the prior. [SEP]\n", "[CLS] Thus the variational objective mirrors the usual balance between likelihood and prior. [SEP]\n", "[CLS] Another property of the ELBO is that it lower-bounds the (log) evidence, FORMULA  for any FORMULA . [SEP]\n", "[CLS] This explains the name. [SEP]\n", "[CLS] To see this notice that Equations\u00a0(REF ) and\u00a0(REF ) give the following expression of the evidence, FORMULA    [SEP]\n", "[CLS] The bound then follows from the fact that FORMULA \u00a0{{cite:8ba2afb1-5289-428d-8136-df7e4fbc6616}}. [SEP]\n", "[CLS] In the original literature on variational inference, this was derived through Jensen's inequality\u00a0{{cite:fe7cad8f-3b9d-4d8c-91d7-3ecd2141df10}}. [SEP]\n", "[CLS] The relationship between the ELBO and FORMULA  has led to using the variational bound as a model selection criterion. [SEP]\n", "[CLS] This has been explored for mixture models {{cite:2ed0acf8-8927-4cb5-a5cb-3e0467241da6}}, {{cite:f953d886-b908-427d-8b30-b0d66f5fd202}} and more generally\u00a0{{cite:fd68c0d6-a82d-4405-8aa6-ff17f0cf452a}}. [SEP]\n", "[CLS] The premise is that the bound is a good approximation of the marginal likelihood, which provides a basis for selecting a model. [SEP]\n", "[CLS] Though this sometimes works in practice, selecting based on a bound is not justified in theory. [SEP]\n", "[CLS] Other research has used variational approximations in the log predictive density to use VI in cross-validation based model selection\u00a0{{cite:3a30c077-c669-44e5-a872-cb37c1cb970f}}. [SEP]\n", "[CLS] Finally, many readers will notice that the first term of the ELBO in Equation\u00a0(REF ) is the expected complete log-likelihood, which is optimized by the EM algorithm\u00a0{{cite:cf8481fb-5ef4-4162-9ac4-6ebe8c309c6f}}. [SEP]\n", "[CLS] The EM algorithm was designed for finding maximum likelihood estimates in models with latent variables. [SEP]\n", "[CLS] It uses the fact that the ELBO is equal to the log likelihood FORMULA  (i.e., the log evidence) when FORMULA . [SEP]\n", "[CLS] EM alternates between computing the expected complete log likelihood according to FORMULA  (the E step) and optimizing it with respect to the model parameters (the M step). [SEP]\n", "[CLS] Unlike variational inference, EM assumes the expectation under FORMULA  is computable and uses it in otherwise difficult parameter estimation problems. [SEP]\n", "[CLS] Unlike EM, variational inference does not estimate fixed model parameters\u2014it is often used in a Bayesian setting where classical parameters are treated as latent variables. [SEP]\n", "[CLS] Variational inference applies to models where we cannot compute the exact conditional of the latent variables. [SEP]\n", "[CLS] Two notes: (a) Variational EM is the EM algorithm with a variational E-step, i.e., a computation of an approximate conditional. [SEP]\n", "[CLS] (b) The coordinate ascent algorithm of Section\u00a0REF  can look like the EM algorithm. [SEP]\n", "[CLS] The \u201cE step\u201d computes approximate conditionals of local latent variables; the \u201cM step\u201d computes a conditional of the global latent variables. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The mean-field variational family We described the ELBO, the variational objective function in the optimization of Equation\u00a0(REF ). [SEP]\n", "[CLS] We now describe a variational family FORMULA , to complete the specification of the optimization problem. [SEP]\n", "[CLS] The complexity of the family determines the complexity of the optimization; it is more difficult to optimize over a complex family than a simple family. [SEP]\n", "[CLS] In this review we focus on the mean-field variational family, where the latent variables are mutually independent and each governed by a distinct factor in the variational density. [SEP]\n", "[CLS] A generic member of the mean-field variational family is FORMULA    [SEP]\n", "[CLS] Each latent variable FORMULA  is governed by its own variational factor, the density FORMULA . [SEP]\n", "[CLS] In optimization, these variational factors are chosen to maximize the ELBO of\u00a0Equation\u00a0(REF ). [SEP]\n", "[CLS] We emphasize that the variational family is not a model of the observed data\u2014indeed, the data FORMULA  does not appear in Equation\u00a0(REF ). [SEP]\n", "[CLS] Instead, it is the ELBO, and the corresponding KL minimization problem, that connects the fitted variational density to the data and model. [SEP]\n", "[CLS] Notice we have not specified the parametric form of the individual variational factors. [SEP]\n", "[CLS] In principle, each can take on any parametric form appropriate to the corresponding random variable. [SEP]\n", "[CLS] For example, a continuous variable might have a Gaussian factor; a categorical variable will typically have a categorical factor. [SEP]\n", "[CLS] We will see in Sections\u00a0, REF  and\u00a0REF  that there are many models for which properties of the model determine optimal forms of the mean-field variational factors FORMULA . [SEP]\n", "[CLS] Finally, though we focus on mean-field inference in this review, researchers have also studied more complex families. [SEP]\n", "[CLS] One way to expand the family is to add dependencies between the variables\u00a0{{cite:3b4a3d9e-1237-425d-a924-cc65c4f92c7b}}, {{cite:bb4d89fe-3e45-4eee-8fdd-676a870dc22f}}; this is called structured variational inference. [SEP]\n", "[CLS] Another way to expand the family is to consider mixtures of variational densities, i.e., additional latent variables within the variational family\u00a0{{cite:a6990839-665a-4725-9b1c-ca48befff73d}}. [SEP]\n", "[CLS] Both of these methods potentially improve the fidelity of the approximation, but there is a trade off. [SEP]\n", "[CLS] Structured and mixture-based variational families come with a more difficult-to-solve variational optimization problem. [SEP]\n", "[CLS] Bayesian mixture of Gaussians (continued). [SEP]\n", "[CLS] \u00a0 Consider again the Bayesian mixture of Gaussians. [SEP]\n", "[CLS] The mean-field variational family contains approximate posterior densities of the form FORMULA    [SEP]\n", "[CLS] Following the mean-field recipe, each latent variable is governed by its own variational factor. [SEP]\n", "[CLS] The factor FORMULA  is a Gaussian distribution on the FORMULA th mixture component's mean parameter; its mean is FORMULA  and its variance is FORMULA . [SEP]\n", "[CLS] The factor FORMULA  is a distribution on the FORMULA th observation's mixture assignment; its assignment probabilities are a FORMULA -vector FORMULA . [SEP]\n", "[CLS] Here we have asserted parametric forms for these factors: the mixture components are Gaussian with variational parameters (mean and variance) specific to the FORMULA th cluster; the cluster assignments are categorical with variational parameters (cluster probabilities) specific to the FORMULA th data point. [SEP]\n", "[CLS] In fact, these are the optimal forms of the mean-field variational density for the mixture of Gaussians. [SEP]\n", "[CLS] With the variational family in place, we have completely specified the variational inference problem for the mixture of Gaussians. [SEP]\n", "[CLS] The ELBO is defined by the model definition in Equation\u00a0(REF ) and the mean-field family in Equation\u00a0(REF ). [SEP]\n", "[CLS] The corresponding variational optimization problem maximizes the ELBO with respect to the variational parameters, i.e., the Gaussian parameters for each mixture component and the categorical parameters for each cluster assignment. [SEP]\n", "[CLS] We will see this example through in Section\u00a0. [SEP]\n", "[CLS] Visualizing the mean-field approximation. [SEP]\n", "[CLS] \u00a0  [SEP]\n", "[CLS] The mean-field family is expressive because it can capture any marginal density of the latent variables. [SEP]\n", "[CLS] However, it cannot capture correlation between them. [SEP]\n", "[CLS] Seeing this in action reveals some of the intuitions and limitations of mean-field variational inference. [SEP]\n", "[CLS] Consider a two dimensional Gaussian distribution, shown in violet in Figure REF . [SEP]\n", "[CLS] This density is highly correlated, which defines its elongated shape. [SEP]\n", "[CLS] The optimal mean-field variational approximation to this posterior is a product of two Gaussian distributions. [SEP]\n", "[CLS] Figure\u00a0REF  shows the mean-field variational density after maximizing the ELBO. [SEP]\n", "[CLS] While the variational approximation has the same mean as the original density, its covariance structure is, by construction, decoupled. [SEP]\n", "[CLS] Further, the marginal variances of the approximation under-represent those of the target density. [SEP]\n", "[CLS] This is a common effect in mean-field variational inference and, with this example, we can see why. [SEP]\n", "[CLS] The KL divergence from the approximation to the posterior is in Equation\u00a0(REF ). [SEP]\n", "[CLS] It penalizes placing mass in FORMULA  on areas where FORMULA  has little mass, but penalizes less the reverse. [SEP]\n", "[CLS] In this example, in order to successfully match the marginal variances, the circular FORMULA  would have to expand into territory where FORMULA  has little mass. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Coordinate ascent mean-field variational inference Using the ELBO and the mean-field family, we have cast approximate conditional inference as an optimization problem. [SEP]\n", "[CLS] In this section, we describe one of the most commonly used algorithms for solving this optimization problem, CAVI\u00a0{{cite:0b57a9d1-ed0c-4663-912a-0e699836184b}}. [SEP]\n", "[CLS] CAVI iteratively optimizes each factor of the mean-field variational density, while holding the others fixed. [SEP]\n", "[CLS] It climbs the ELBO to a local optimum. [SEP]\n", "[CLS] The algorithm. [SEP]\n", "[CLS] \u00a0 We first state a result. [SEP]\n", "[CLS] Consider the FORMULA th latent variable FORMULA . [SEP]\n", "[CLS] The complete conditional of FORMULA  is its conditional density given all of the other latent variables in the model and the observations, FORMULA . [SEP]\n", "[CLS] Fix the other variational factors FORMULA , FORMULA . [SEP]\n", "[CLS] The optimal FORMULA  is then proportional to the exponentiated expected log of the complete conditional, FORMULA    [SEP]\n", "[CLS] The expectation in Equation\u00a0(REF ) is with respect to the (currently fixed) variational density over FORMULA , that is, FORMULA . [SEP]\n", "[CLS] Equivalently, Equation\u00a0(REF ) is proportional to the exponentiated log of the joint, FORMULA   Because of the mean-field family assumption\u2014that all the latent variables are independent\u2014the expectations on the right hand side do not involve the FORMULA th variational factor. [SEP]\n", "[CLS] Thus this is a valid coordinate update. [SEP]\n", "[CLS] These equations underlie the CAVI algorithm, presented as Algorithm\u00a0REF . [SEP]\n", "[CLS] We maintain a set of variational factors FORMULA . [SEP]\n", "[CLS] We iterate through them, updating FORMULA  using Equation\u00a0(REF ). [SEP]\n", "[CLS] CAVI goes uphill on the ELBO of Equation\u00a0(REF ), eventually finding a local optimum. [SEP]\n", "[CLS] As examples we show CAVI for a mixture of Gaussians in Section\u00a0 and for a nonconjugate linear regression in Appendix\u00a0. [SEP]\n", "[CLS] CAVI can also be seen as a \u201cmessage passing\u201d algorithm\u00a0{{cite:8a3a6198-a75c-4230-9247-a3d4d311e240}}, iteratively updating each random variable's variational parameters based on the variational parameters of the variables in its Markov blanket. [SEP]\n", "[CLS] This perspective enabled the design of automated software for a large class of models\u00a0{{cite:605f6a7f-bf89-4df7-9cb2-9ba08b7dcc55}}, {{cite:803fa59c-288f-4ee2-b26a-993cbf7909b2}}. [SEP]\n", "[CLS] Variational message passing connects variational inference to the classical theories of graphical models and probabilistic inference\u00a0{{cite:80e8172d-e609-460e-86c3-8f026d2aa731}}, {{cite:b21a0b93-9ba5-4587-a407-6154e2d6d269}}. [SEP]\n", "[CLS] It has been extended to nonconjugate models\u00a0{{cite:ab7957ce-b8fe-4f54-a94b-563e14968911}} and generalized via factor graphs\u00a0{{cite:45aa6331-74e0-4969-8c6a-754cd31e180e}}. [SEP]\n", "[CLS] Finally, CAVI is closely related to Gibbs sampling\u00a0{{cite:b7f385ac-6c99-443d-a35e-95f09dd8e784}}, {{cite:31a39dc9-f0cc-4c1e-b5f9-5d9632a9d2ca}}, the classical workhorse of approximate inference. [SEP]\n", "[CLS] The Gibbs sampler maintains a realization of the latent variables and iteratively samples from each variable's complete conditional. [SEP]\n", "[CLS] Equation\u00a0(REF ) uses the same complete conditional. [SEP]\n", "[CLS] It takes the expected log, and uses this quantity to iteratively set each variable's variational factor. [SEP]\n", "[CLS] Many readers will know that we can significantly speed up the Gibbs sampler by marginalizing out some of the latent variables; this is called collapsed Gibbs sampling. [SEP]\n", "[CLS] We can speed up variational inference with similar reasoning; this is called collapsed variational inference. [SEP]\n", "[CLS] It has been developed for the same class of models described here\u00a0{{cite:90157fc3-1e0a-4744-9cdc-2250095488ae}}, {{cite:9d6d98f7-95c7-44a1-9a9b-b67faad77901}}. [SEP]\n", "[CLS] These ideas are outside the scope of our review. [SEP]\n", "[CLS] CAVI [t] 1.25 A model FORMULA , a data set FORMULA   [SEP]\n", "[CLS] A variational density FORMULA   [SEP]\n", "[CLS] Initialize: Variational factors  FORMULA the ELBO has not converged  FORMULA   Set  FORMULA   [SEP]\n", "[CLS] Compute FORMULA   FORMULA   [SEP]\n", "[CLS] CAVI Derivation. [SEP]\n", "[CLS] \u00a0 We now derive the coordinate update in Equation\u00a0(REF ). [SEP]\n", "[CLS] The idea appears in\u00a0{{cite:0b57a9d1-ed0c-4663-912a-0e699836184b}}, but the argument there uses gradients, which we do not. [SEP]\n", "[CLS] Rewrite the ELBO of Equation\u00a0(REF ) as a function of the FORMULA th variational factor FORMULA , absorbing into a constant the terms that do not depend on it, FORMULA    [SEP]\n", "[CLS] We have rewritten the first term of the ELBO using iterated expectation. [SEP]\n", "[CLS] The second term we have decomposed, using the independence of the variables (i.e., the mean-field assumption) and retaining only the term that depends on FORMULA . [SEP]\n", "[CLS] Up to an added constant, the objective function in Equation\u00a0(REF ) is equal to the negative KL divergence between FORMULA  and FORMULA  from Equation\u00a0(REF ). [SEP]\n", "[CLS] Thus we maximize the ELBO with respect to FORMULA  when we set FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Practicalities Here, we highlight a few things to keep in mind when implementing and using variational inference in practice. [SEP]\n", "[CLS] Initialization. [SEP]\n", "[CLS] \u00a0  [SEP]\n", "[CLS] The ELBO is (generally) a non-convex objective function. [SEP]\n", "[CLS] CAVI only guarantees convergence to a local optimum, which can be sensitive to initialization. [SEP]\n", "[CLS] Figure\u00a0REF  shows the ELBO trajectory for 10 random initializations using the Gaussian mixture model. [SEP]\n", "[CLS] The means of the variational factors were randomly initialized by drawing from a factorized Gaussian calibrated to the empirical mean and variance of the dataset. [SEP]\n", "[CLS] (This inference is on images; see Section\u00a0REF .) Each initialization reaches a different value, indicating the presence of many local optima in the ELBO. [SEP]\n", "[CLS] In terms of FORMULA , better local optima give variational densities that are closer to the exact posterior. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] This is not always a disadvantage. [SEP]\n", "[CLS] Some models, such as the mixture of Gaussians (Section\u00a0 and\u00a0appendix\u00a0) and mixed-membership model (Appendix\u00a0), exhibit many posterior modes due to label switching: swapping cluster assignment labels induces many symmetric posterior modes. [SEP]\n", "[CLS] Representing one of these modes is sufficient for exploring latent clusters or predicting new observations. [SEP]\n", "[CLS] Assessing convergence. [SEP]\n", "[CLS] \u00a0 Monitoring the ELBO in CAVI is simple; we typically assess convergence once the change in ELBO has fallen below some small threshold. [SEP]\n", "[CLS] However, computing the ELBO of the full dataset may be undesirable. [SEP]\n", "[CLS] Instead, we suggest computing the average log predictive of a small held-out dataset. [SEP]\n", "[CLS] Monitoring changes here is a proxy to monitoring the ELBO of the full data. [SEP]\n", "[CLS] (Unlike the full ELBO, held-out predictive probability is not guaranteed to monotonically increase across iterations of CAVI.) [SEP]\n", "[CLS] Numerical stability. [SEP]\n", "[CLS] \u00a0 Probabilities are constrained to live within FORMULA . [SEP]\n", "[CLS] Precisely manipulating and performing arithmetic of small numbers requires additional care. [SEP]\n", "[CLS] When possible, we recommend working with logarithms of probabilities. [SEP]\n", "[CLS] One useful identity is the \u201clog-sum-exp\u201d trick, FORMULA    [SEP]\n", "[CLS] The constant FORMULA  is typically set to FORMULA . [SEP]\n", "[CLS] This provides numerical stability to common computations in variational inference procedures. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A complete example: Bayesian mixture of Gaussians As an example, we return to the simple mixture of Gaussians model of Section\u00a0REF . [SEP]\n", "[CLS] To review, consider FORMULA  mixture components and FORMULA  real-valued data points FORMULA . [SEP]\n", "[CLS] The latent variables are FORMULA  real-valued mean parameters FORMULA  and FORMULA  latent-class assignments FORMULA . [SEP]\n", "[CLS] The assignment FORMULA  indicates which latent cluster FORMULA  comes from. [SEP]\n", "[CLS] In detail, FORMULA  is an indicator FORMULA -vector, all zeros except for a one in the position corresponding to FORMULA 's cluster. [SEP]\n", "[CLS] There is a fixed hyperparameter FORMULA , the variance of the normal prior on the FORMULA 's. [SEP]\n", "[CLS] We assume the observation variance is one and take a uniform prior over the mixture components. [SEP]\n", "[CLS] The joint density of the latent and observed variables is in Equation\u00a0(REF ). [SEP]\n", "[CLS] The variational family is in Equation\u00a0(REF ). [SEP]\n", "[CLS] Recall that there are two types of variational parameters\u2014categorical parameters FORMULA  for approximating the posterior cluster assignment of the FORMULA th data point and Gaussian parameters FORMULA  and FORMULA  for approximating the posterior of the FORMULA th mixture component. [SEP]\n", "[CLS] We combine the joint and the mean-field family to form the ELBO for the mixture of Gaussians. [SEP]\n", "[CLS] It is a function of the variational parameters FORMULA }, FORMULA , and FORMULA , FORMULA    [SEP]\n", "[CLS] In each term, we have made explicit the dependence on the variational parameters. [SEP]\n", "[CLS] Each expectation can be computed in closed form. [SEP]\n", "[CLS] The CAVI algorithm updates each variational parameter in turn. [SEP]\n", "[CLS] We first derive the update for the variational cluster assignment factor; we then derive the update for the variational mixture component factor. [SEP]\n", "[CLS] The variational density of the mixture assignments We first derive the variational update for the cluster assignment FORMULA . [SEP]\n", "[CLS] Using Equation\u00a0(REF ), FORMULA    [SEP]\n", "[CLS] The terms in the exponent are the components of the joint density that depend on FORMULA . [SEP]\n", "[CLS] The expectation in the second term is over the mixture components FORMULA . [SEP]\n", "[CLS] The first term of Equation\u00a0(REF ) is the log prior of FORMULA . [SEP]\n", "[CLS] It is the same for all possible values of FORMULA , FORMULA . [SEP]\n", "[CLS] The second term is the expected log of the FORMULA th Gaussian density. [SEP]\n", "[CLS] Recalling that FORMULA  is an indicator vector, we can write FORMULA   [SEP]\n", "[CLS] We use this to compute the expected log probability, FORMULA    [SEP]\n", "[CLS] In each line we remove terms that are constant with respect to FORMULA . [SEP]\n", "[CLS] This calculation requires FORMULA  and FORMULA  for each mixture component, both computable from the variational Gaussian on the FORMULA th mixture component. [SEP]\n", "[CLS] Thus the variational update for the FORMULA th cluster assignment is FORMULA    [SEP]\n", "[CLS] Notice it is only a function of the variational parameters for the mixture components. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The variational density of the mixture-component means We turn to the variational density FORMULA  of the FORMULA th mixture component. [SEP]\n", "[CLS] Again we use Equation\u00a0(REF ) and write down the joint density up to a normalizing constant, FORMULA   We now calculate the unnormalized log of this coordinate-optimal FORMULA . [SEP]\n", "[CLS] Recall FORMULA  is the probability that the FORMULA th observation comes from the FORMULA th cluster. [SEP]\n", "[CLS] Because FORMULA  is an indicator vector, we see that FORMULA . [SEP]\n", "[CLS] Now FORMULA    [SEP]\n", "[CLS] This calculation reveals that the coordinate-optimal variational density of FORMULA  is an exponential family with sufficient statistics FORMULA  and natural parameters FORMULA , i.e., a Gaussian. [SEP]\n", "[CLS] Expressed in terms of the variational mean and variance, the updates for FORMULA  are FORMULA   [SEP]\n", "[CLS] These updates relate closely to the complete conditional density of the FORMULA th component in the mixture model. [SEP]\n", "[CLS] The complete conditional is a posterior Gaussian given the data assigned to the FORMULA th component. [SEP]\n", "[CLS] The variational update is a weighted complete conditional, where each data point is weighted by its variational probability of being assigned to component FORMULA . [SEP]\n", "[CLS] [t] 1.25 Data FORMULA , number of components FORMULA , prior variance of component means  FORMULA Variational densities FORMULA   [SEP]\n", "[CLS] (Gaussian) and FORMULA  (FORMULA -categorical) Initialize: Variational parameters FORMULA , FORMULA , and  FORMULA the ELBO has not converged  FORMULA   Set  FORMULA   FORMULA FORMULA     [SEP]\n", "[CLS] Compute FORMULA   FORMULA  CAVI for a Gaussian mixture model   [SEP]\n", "[CLS] CAVI for the mixture of Gaussians Algorithm\u00a0REF  presents coordinate-ascent variational inference for the Bayesian mixture of Gaussians. [SEP]\n", "[CLS] It combines the variational updates in Equation\u00a0(REF ) and Equation\u00a0(REF ). [SEP]\n", "[CLS] The algorithm requires computing the ELBO of Equation\u00a0(REF ). [SEP]\n", "[CLS] We use the ELBO to track the progress of the algorithm and assess when it has converged. [SEP]\n", "[CLS] Once we have a fitted variational density, we can use it as we would use the posterior. [SEP]\n", "[CLS] For example, we can obtain a posterior decomposition of the data. [SEP]\n", "[CLS] We assign points to their most likely mixture assignment FORMULA  and estimate cluster means with their variational means FORMULA . [SEP]\n", "[CLS] We can also use the fitted variational density to approximate the predictive density of new data. [SEP]\n", "[CLS] This approximate predictive is a mixture of Gaussians, FORMULA   where FORMULA  is a Gaussian with mean FORMULA  and unit variance. [SEP]\n", "[CLS]  Empirical study [SEP]\n", "[CLS] We present two analyses to demonstrate the mixture of Gaussians algorithm in action. [SEP]\n", "[CLS] The first is a simulation study; the second is an analysis of a data set of natural images. [SEP]\n", "[CLS] Simulation study. [SEP]\n", "[CLS] \u00a0 Consider two-dimensional real-valued data FORMULA . [SEP]\n", "[CLS] We simulate FORMULA   [SEP]\n", "[CLS] Gaussians with random means, covariances, and mixture assignments. [SEP]\n", "[CLS] Figure\u00a0REF  shows the data; each point is colored according to its true cluster. [SEP]\n", "[CLS] Figure\u00a0REF  also illustrates the initial variational density of the mixture components\u2014each is a Gaussian, nearly centered, and with a wide variance; the subpanels plot the variational density of the components as the CAVI algorithm progresses. [SEP]\n", "[CLS] The progression of the ELBO tells a story. [SEP]\n", "[CLS] We highlight key points where the ELBO develops \u201celbows\u201d, phases of the maximization where the variational approximation changes its shape. [SEP]\n", "[CLS] These \u201celbows\u201d arise because the ELBO is not a convex function in terms of the variational parameters; CAVI iteratively reaches better plateaus. [SEP]\n", "[CLS] Finally, we plot the logarithm of the Bayesian predictive density as approximated by the variational density. [SEP]\n", "[CLS] Here we report the average across held-out data. [SEP]\n", "[CLS] Note this plot is smoother than the ELBO. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Image analysis. [SEP]\n", "[CLS] \u00a0 We now turn to an experimental study. [SEP]\n", "[CLS] Consider the task of grouping images according to their color profiles. [SEP]\n", "[CLS] One approach is to compute the color histogram of the images. [SEP]\n", "[CLS] Figure\u00a0REF  shows the red, green, and blue channel histograms of two images from the imageclef data {{cite:db51a5ec-a9a8-4e45-880b-8e5027c64193}}. [SEP]\n", "[CLS] Each histogram is a vector of length 192; concatenating the three color histograms gives a 576-dimensional representation of each image, regardless of its original size in pixel-space. [SEP]\n", "[CLS] We use CAVI to fit a Gaussian mixture model with thirty clusters to image histograms. [SEP]\n", "[CLS] We randomly select two sets of ten thousand images from the imageclef collection to serve as training and testing datasets. [SEP]\n", "[CLS] Figure\u00a0REF  shows similarly colored images assigned to four randomly chosen clusters. [SEP]\n", "[CLS] Figure\u00a0REF  shows the average log predictive accuracy of the testing set as a function of time. [SEP]\n", "[CLS] We compare CAVI to an implementation in Stan {{cite:007c2129-c55b-4bc4-97c4-4dbbf46b3f17}}, which uses a Hamiltonian Monte Carlo-based sampler {{cite:5b017b3d-9efb-478e-b8b6-6b7430f2bc52}}. [SEP]\n", "[CLS] (Details are in Appendix\u00a0.) CAVI is orders of magnitude faster than this sampling algorithm. [SEP]\n", "[CLS] This is not a definitive comparison between variational inference and MCMC. [SEP]\n", "[CLS] Other samplers, such as a collapsed Gibbs sampler, may perform better than Hamiltonian Monte Carlo sampling. [SEP]\n", "[CLS] FIGURE  FIGURE  FIGURE   Variational inference with exponential families We described mean-field variational inference and derived CAVI, a general coordinate-ascent algorithm for optimizing the ELBO. [SEP]\n", "[CLS] We demonstrated this approach on a simple mixture of Gaussians, where each coordinate update was available in closed form. [SEP]\n", "[CLS] The mixture of Gaussians is one member of the important class of models where each complete conditional is in the exponential family. [SEP]\n", "[CLS] This includes a number of widely used models, such as Bayesian mixtures of exponential families, factorial mixture models, matrix factorization models, certain hierarchical regression models (e.g., linear regression, probit regression, Poisson regression), stochastic blockmodels of networks, hierarchical mixtures of experts, and a variety of mixed-membership models (which we will discuss below). [SEP]\n", "[CLS] Working in this family simplifies variational inference: it is easier to derive the corresponding CAVI algorithm, and it enables variational inference to scale up to massive data. [SEP]\n", "[CLS] In Section\u00a0REF , we develop the general case. [SEP]\n", "[CLS] In Section\u00a0REF , we discuss conditionally conjugate models, i.e., the common Bayesian application where some latent variables are \u201clocal\u201d to a data point and others, usually identified with parameters, are \u201cglobal\u201d to the entire data set. [SEP]\n", "[CLS] Finally, in Section\u00a0REF , we describe stochastic variational inference\u00a0{{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}}, a stochastic optimization algorithm that scales up variational inference in this setting. [SEP]\n", "[CLS] Complete conditionals in the exponential family Consider the generic model FORMULA  of Section\u00a0REF  and suppose each complete conditional is in the exponential family: FORMULA   where FORMULA  is its own sufficient statistic, FORMULA  is a base measure, and FORMULA  is the log normalizer\u00a0{{cite:757b09de-e439-4ebf-ba58-58ed74b9bafd}}. [SEP]\n", "[CLS] Because this is a conditional density, the parameter FORMULA  is a function of the conditioning set. [SEP]\n", "[CLS] Consider mean-field variational inference for this class of models, where we fit FORMULA . [SEP]\n", "[CLS] The exponential family assumption simplifies the coordinate update of Equation\u00a0(REF ), FORMULA    [SEP]\n", "[CLS] This update reveals the parametric form of the optimal variational factors. [SEP]\n", "[CLS] Each one is in the same exponential family as its corresponding complete conditional. [SEP]\n", "[CLS] Its parameter has the same dimension and it has the same base measure FORMULA  and log normalizer FORMULA . [SEP]\n", "[CLS] Having established their parametric forms, let FORMULA  denote the variational parameter for the FORMULA th variational factor. [SEP]\n", "[CLS] When we update each factor, we set its parameter equal to the expected parameter of the complete conditional, FORMULA    [SEP]\n", "[CLS] This expression facilitates deriving CAVI algorithms for many complex models. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conditional conjugacy and Bayesian models One important special case of exponential family models are conditionally conjugate models with local and global variables. [SEP]\n", "[CLS] Models like this come up frequently in Bayesian statistics and statistical machine learning, where the global variables are the \u201cparameters\u201d and the local variables are per-data-point latent variables. [SEP]\n", "[CLS] Conditionally conjugate models. [SEP]\n", "[CLS] \u00a0 Let FORMULA  be a vector of global latent variables, which potentially govern any of the data. [SEP]\n", "[CLS] Let FORMULA  be a vector of local latent variables, whose FORMULA th component only governs data in the FORMULA th \u201ccontext.\u201d [SEP]\n", "[CLS] The joint density is FORMULA    [SEP]\n", "[CLS] The mixture of Gaussians of Section\u00a0 is an example. [SEP]\n", "[CLS] The global variables are the mixture components; the FORMULA th local variable is the cluster assignment for data point FORMULA . [SEP]\n", "[CLS] We will assume that the modeling terms of\u00a0Equation\u00a0(REF ) are chosen to ensure each complete conditional is in the exponential family. [SEP]\n", "[CLS] In detail, we first assume the joint density of each FORMULA  pair, conditional on FORMULA , has an exponential family form, FORMULA   where FORMULA  is the sufficient statistic. [SEP]\n", "[CLS] Next, we take the prior on the global variables to be the corresponding conjugate prior\u00a0{{cite:98007ced-66e3-4bb8-a7b1-eefb88ae808d}}, {{cite:be269954-934e-4d0c-8e8b-362b7d556de3}}, FORMULA    [SEP]\n", "[CLS] This prior has natural (hyper)parameter FORMULA , a column vector, and sufficient statistics that concatenate the global variable and its log normalizer in the density of the local variables. [SEP]\n", "[CLS] With the conjugate prior, the complete conditional of the global variables is in the same family. [SEP]\n", "[CLS] Its natural parameter is FORMULA  Turn now to the complete conditional of the local variable FORMULA . [SEP]\n", "[CLS] Given FORMULA  and FORMULA , the local variable FORMULA  is conditionally independent of the other local variables FORMULA  and other data FORMULA . [SEP]\n", "[CLS] This follows from the form of the joint density in Equation\u00a0(REF ). [SEP]\n", "[CLS] Thus FORMULA   We further assume that this density is in an exponential family, FORMULA    [SEP]\n", "[CLS] This is a property of the local likelihood term FORMULA  from\u00a0Equation\u00a0(REF ). [SEP]\n", "[CLS] For example, in the mixture of Gaussians, the complete conditional of the local variable is a categorical. [SEP]\n", "[CLS] Variational inference in conditionally conjugate models. [SEP]\n", "[CLS] \u00a0 We now describe CAVI for this general class of models. [SEP]\n", "[CLS] Write FORMULA  for the variational posterior approximation on FORMULA ; we call FORMULA  the \u201cglobal variational parameter\u201d. [SEP]\n", "[CLS] It indexes the same exponential family density as the prior. [SEP]\n", "[CLS] Similarly, let the variational posterior FORMULA  on each local variable FORMULA  be governed by a \u201clocal variational parameter\u201d FORMULA . [SEP]\n", "[CLS] It indexes the same exponential family density as the local complete conditional. [SEP]\n", "[CLS] CAVI iterates between updating each local variational parameter and updating the global variational parameter. [SEP]\n", "[CLS] The local variational update is FORMULA    [SEP]\n", "[CLS] This is an application of Equation\u00a0(REF ), where we take the expectation of the natural parameter of the complete conditional in Equation\u00a0(REF ). [SEP]\n", "[CLS] The global variational update applies the same technique. [SEP]\n", "[CLS] It is FORMULA    [SEP]\n", "[CLS] Here we take the expectation of the natural parameter in Equation\u00a0(REF ). [SEP]\n", "[CLS] CAVI optimizes the ELBO by iterating between local updates of each local parameter and global updates of the global parameters. [SEP]\n", "[CLS] To assess convergence we can compute the ELBO at each iteration (or at some lag), up to a constant that does not depend on the variational parameters, FORMULA    [SEP]\n", "[CLS] This is the ELBO in Equation\u00a0(REF ) applied to the joint in Equation\u00a0(REF ) and the corresponding mean-field variational density; we have omitted terms that do not depend on the variational parameters. [SEP]\n", "[CLS] The last term is FORMULA   CAVI for the mixture of Gaussians model (Algorithm\u00a0REF ) is an instance of this method. [SEP]\n", "[CLS] Appendix\u00a0 presents another example of CAVI for LDA, a probabilistic topic model. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Stochastic variational inference Modern applications of probability models often require analyzing massive data. [SEP]\n", "[CLS] However, most posterior inference algorithms do not easily scale. [SEP]\n", "[CLS] CAVI is no exception, particularly in the conditionally conjugate setting of Section\u00a0REF . [SEP]\n", "[CLS] The reason is that the coordinate ascent structure of the algorithm requires iterating through the entire data set at each iteration. [SEP]\n", "[CLS] As the data set size grows, each iteration becomes more computationally expensive. [SEP]\n", "[CLS] An alternative to coordinate ascent is gradient-based optimization, which climbs the ELBO by computing and following its gradient at each iteration. [SEP]\n", "[CLS] This perspective is the key to scaling up variational inference using SVI\u00a0{{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}}, a method that combines natural gradients\u00a0{{cite:2ebd439f-fb78-4f8e-8d2e-b35af8dbc49e}} and stochastic optimization\u00a0{{cite:51665fa3-19b9-4f4c-b91e-d8ab8e35f92e}}. [SEP]\n", "[CLS] SVI focuses on optimizing the global variational parameters FORMULA  of a conditionally conjugate model. [SEP]\n", "[CLS] The flow of computation is simple. [SEP]\n", "[CLS] The algorithm maintains a current estimate of the global variational parameters. [SEP]\n", "[CLS] It repeatedly (a) subsamples a data point from the full data set; (b) uses the current global parameters to compute the optimal local parameters for the subsampled data point; and (c) adjusts the current global parameters in an appropriate way. [SEP]\n", "[CLS] SVI is detailed in Algorithm\u00a0REF . [SEP]\n", "[CLS] We now show why it is a valid algorithm for optimizing the ELBO. [SEP]\n", "[CLS] The natural gradient of the ELBO. [SEP]\n", "[CLS] \u00a0  [SEP]\n", "[CLS] In gradient-based optimization, the natural gradient accounts for the geometric structure of probability parameters\u00a0{{cite:f92124cf-4104-44f7-83c7-a5a83fe33e5e}}, {{cite:2ebd439f-fb78-4f8e-8d2e-b35af8dbc49e}}. [SEP]\n", "[CLS] Specifically, natural gradients warp the parameter space in a sensible way, so that moving the same distance in different directions amounts to equal change in symmetrized KL divergence. [SEP]\n", "[CLS] The usual Euclidean gradient does not enjoy this property. [SEP]\n", "[CLS] In exponential families, we find the natural gradient with respect to the parameter by premultiplying the usual gradient by the inverse covariance of the sufficient statistic, FORMULA . [SEP]\n", "[CLS] This is the inverse Riemannian metric and the inverse Fisher information matrix\u00a0{{cite:f92124cf-4104-44f7-83c7-a5a83fe33e5e}}. [SEP]\n", "[CLS] Conditionally conjugate models enjoy simple natural gradients of the ELBO. [SEP]\n", "[CLS] We focus on gradients with respect to the global parameter FORMULA . [SEP]\n", "[CLS] {{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}} derive the Euclidean gradient of the ELBO, FORMULA   where FORMULA  is in Equation\u00a0(REF ). [SEP]\n", "[CLS] Premultiplying by the inverse Fisher information gives the natural gradient FORMULA , FORMULA    [SEP]\n", "[CLS] It is the difference between the coordinate updates FORMULA  and the variational parameters FORMULA  at which we are evaluating the gradient. [SEP]\n", "[CLS] In addition to enjoying good theoretical properties, the natural gradient is easier to calculate than the Euclidean gradient. [SEP]\n", "[CLS] For more on natural gradients and variational inference see\u00a0{{cite:81e3e4bb-9a5a-472b-a51d-d4685c39495a}} and {{cite:b15fc517-347e-4280-b82a-6466ed45db47}}. [SEP]\n", "[CLS] We can use this natural gradient in a gradient-based optimization algorithm. [SEP]\n", "[CLS] At each iteration, we update the global parameters, FORMULA   where FORMULA  is a step size. [SEP]\n", "[CLS] Substituting Equation\u00a0(REF ) into the second term reveals a special structure, FORMULA    [SEP]\n", "[CLS] Notice this does not require additional types of calculations other than those for coordinate ascent updates. [SEP]\n", "[CLS] At each iteration, we first compute the coordinate update. [SEP]\n", "[CLS] We then adjust the current estimate to be a weighted combination of the update and the current variational parameter. [SEP]\n", "[CLS] Though easy to compute, using the natural gradient has the same cost as the coordinate update in Equation\u00a0(REF ); it requires summing over the entire data set and computing the optimal local variational parameters for each data point. [SEP]\n", "[CLS] With massive data, this is prohibitively expensive. [SEP]\n", "[CLS] Stochastic optimization of the ELBO. [SEP]\n", "[CLS] \u00a0 Stochastic variational inference solves this problem by using the natural gradient in a stochastic optimization algorithm. [SEP]\n", "[CLS] Stochastic optimization algorithms follow noisy but cheap-to-compute gradients to reach the optimum of an objective function. [SEP]\n", "[CLS] (In the case of the ELBO, stochastic optimization will reach a local optimum.) [SEP]\n", "[CLS] In their seminal paper, {{cite:51665fa3-19b9-4f4c-b91e-d8ab8e35f92e}} proved results implying that optimization algorithms can successfully use noisy, unbiased gradients, as long as the step size sequence satisfies certain conditions. [SEP]\n", "[CLS] This idea has blossomed\u00a0{{cite:7ece99ce-697f-4188-a1b0-ae713b88cf1b}}, {{cite:ad7ffa6b-7adb-44fb-a8a9-334936b4f183}}. [SEP]\n", "[CLS] Stochastic optimization has enabled modern machine learning to scale to massive data\u00a0{{cite:d00f20e8-2022-43f4-a055-c9fba29b1838}}. [SEP]\n", "[CLS] Our aim is to construct a cheaply computed, noisy, unbiased natural gradient. [SEP]\n", "[CLS] We expand the natural gradient in Equation\u00a0(REF ) using Equation\u00a0(REF ) FORMULA   where FORMULA  indicates that we consider the optimized local variational parameters (at fixed global parameters FORMULA ) in Equation\u00a0(REF ). [SEP]\n", "[CLS] We construct a noisy natural gradient by sampling an index from the data and then rescaling the second term, FORMULA    [SEP]\n", "[CLS] The noisy natural gradient FORMULA  is unbiased: FORMULA . [SEP]\n", "[CLS] And it is cheap to compute\u2014it only involves a single sampled data point and only one set of optimized local parameters. [SEP]\n", "[CLS] (This immediately extends to minibatches, where we sample FORMULA  data points and rescale appropriately.) Again, the noisy gradient only requires calculations from the coordinate ascent algorithm. [SEP]\n", "[CLS] The first two terms of Equation\u00a0(REF ) are equivalent to the coordinate update in a model with FORMULA  replicates of the sampled data point. [SEP]\n", "[CLS] Finally, we set the step size sequence. [SEP]\n", "[CLS] It must follow the conditions of\u00a0{{cite:51665fa3-19b9-4f4c-b91e-d8ab8e35f92e}}, FORMULA    [SEP]\n", "[CLS] Many sequences will satisfy these conditions, for example FORMULA  for FORMULA . [SEP]\n", "[CLS] The full SVI algorithm is in Algorithm\u00a0REF . [SEP]\n", "[CLS] We emphasize that SVI requires no new derivation beyond what is needed for CAVI. [SEP]\n", "[CLS] Any implementation of CAVI can be immediately scaled up to a stochastic algorithm. [SEP]\n", "[CLS] Probabilistic topic models. [SEP]\n", "[CLS] \u00a0 We demonstrate SVI with a probabilistic topic model. [SEP]\n", "[CLS] Probabilistic topic models are mixed-membership models of text, used to uncover the latent \u201ctopics\u201d that run through a collection of documents. [SEP]\n", "[CLS] Topic models have become a popular technique for exploratory data analysis of large collections\u00a0{{cite:0fa7c300-28d3-4726-ba76-c175ac5841c3}}. [SEP]\n", "[CLS] In detail, each latent topic is a distribution over terms in a vocabulary and each document is a collection of words that comes from a mixture of the topics. [SEP]\n", "[CLS] The topics are shared across the collection, but each document mixes them with different proportions. [SEP]\n", "[CLS] (This is the hallmark of a mixed-membership model.) [SEP]\n", "[CLS] Thus topic modeling casts topic discovery as a posterior inference problem. [SEP]\n", "[CLS] Posterior estimates of the topics and topic proportions can be used to summarize, visualize, explore, and form predictions about the documents. [SEP]\n", "[CLS] One motivation for topic modeling is to get a handle on massive collections of documents. [SEP]\n", "[CLS] Early inference algorithms were based on coordinate ascent variational inference\u00a0{{cite:0d5f2195-64d4-4d40-95f2-e6250bd775c8}} and analyzed collections in the thousands or tens of thousands of documents. [SEP]\n", "[CLS] (Appendix\u00a0 presents this algorithm). [SEP]\n", "[CLS] With SVI, topic models scale up to millions of documents; the details of the algorithm are in\u00a0{{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}}. [SEP]\n", "[CLS] Figure\u00a0REF  illustrates topics inferred using the latent Dirichlet allocation model\u00a0{{cite:0d5f2195-64d4-4d40-95f2-e6250bd775c8}} from 1.8M articles from the New York Times. [SEP]\n", "[CLS] This analysis would not have been possible without SVI. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] [t] 1.25 Model FORMULA , data FORMULA , and step size sequence FORMULA   [SEP]\n", "[CLS] Global variational densities FORMULA   [SEP]\n", "[CLS] Initialize: Variational parameters  FORMULA TRUE [SEP]\n", "[CLS] Choose a data point uniformly at random,  FORMULA Optimize its local variational parameters  FORMULA Compute the coordinate update as though FORMULA  was repeated FORMULA  times, FORMULA   [SEP]\n", "[CLS] Update the global variational parameter,  FORMULA  FORMULA  SVI for conditionally conjugate models   [SEP]\n", "[CLS] Discussion We described variational inference, a method that uses optimization to make probabilistic computations. [SEP]\n", "[CLS] The goal is to approximate the conditional density of latent variables FORMULA  given observed variables FORMULA , FORMULA . [SEP]\n", "[CLS] The idea is to posit a family of densities FORMULA  and then to find the member FORMULA  that is closest in KL divergence to the conditional of interest. [SEP]\n", "[CLS] Minimizing the KL divergence is the optimization problem, and its complexity is governed by the complexity of the approximating family. [SEP]\n", "[CLS] We then described the mean-field family, i.e., the family of fully factorized densities of the latent variables. [SEP]\n", "[CLS] Using this family, variational inference is particularly amenable to coordinate-ascent optimization, which iteratively optimizes each factor. [SEP]\n", "[CLS] (This approach closely connects to the classical Gibbs sampler\u00a0{{cite:b7f385ac-6c99-443d-a35e-95f09dd8e784}}, {{cite:31a39dc9-f0cc-4c1e-b5f9-5d9632a9d2ca}}.) We showed how to use mean-field VI to approximate the posterior density of a Bayesian mixture of Gaussians, discussed the special case of exponential families and conditional conjugacy, and described the extension to stochastic variational inference\u00a0{{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}}, which scales mean-field variational inference to massive data. [SEP]\n", "[CLS] Applications Researchers in many fields have used variational inference to solve real problems. [SEP]\n", "[CLS] Here we focus on example applications of mean-field variational inference and structured variational inference based on the KL divergence. [SEP]\n", "[CLS] This discussion is not exhaustive; our intention is to outline the diversity of applications of variational inference. [SEP]\n", "[CLS] Computational biology. [SEP]\n", "[CLS] \u00a0 VI is widely used in computational biology, where probabilistic models provide important building blocks for analyzing genetic data. [SEP]\n", "[CLS] For example, VI has been used in genome-wide association studies\u00a0{{cite:66dafe42-366b-4c2b-acb2-88ab7c7a4a79}}, {{cite:cec12459-dc3a-4bfc-ad07-dc9b3176a364}}, regulatory network analysis\u00a0{{cite:c0e0a7e4-c1a1-4dc2-bfaf-9b480fa96dc9}}, motif detection\u00a0{{cite:9bd27bd3-e79d-439f-a7ae-ca4b78c0e313}}, phylogenetic hidden Markov models\u00a0{{cite:ea651f16-6953-477f-b516-853d4f00b21c}}, [SEP]\n", "[CLS] population genetics\u00a0{{cite:7ef1ef87-04be-460c-9a5c-68fd6db462e6}}, and gene expression analysis\u00a0{{cite:ff0aa78f-3379-4b6c-a916-473c4e526fc0}}. [SEP]\n", "[CLS] Computer vision and robotics. [SEP]\n", "[CLS] \u00a0 Since its inception, variational inference has been important to computer vision. [SEP]\n", "[CLS] Vision researchers frequently analyze large and high-dimensional data sets of images, and fast inference is important to successfully deploy a vision system. [SEP]\n", "[CLS] Some of the earliest examples included inferring non-linear image manifolds\u00a0{{cite:772ecb04-bdd2-4fb9-90d8-19fd795ac6cc}} and finding layers of images in videos\u00a0{{cite:ef24d095-9376-4057-8cb6-60254d0c50d5}}. [SEP]\n", "[CLS] As other examples, variational inference is important to probabilistic models of videos\u00a0{{cite:36dd3c1d-8d27-4e62-846f-2fc09c6c5b98}}, {{cite:6fff2494-368f-495a-b876-8b1b744f4bad}}, image denoising\u00a0{{cite:21d70467-6aca-486b-a6b8-3258f90fa2d8}}, tracking\u00a0{{cite:5dc40fae-edb0-4e5c-a25a-21570db88629}}, {{cite:3a03a917-1543-4ba8-a12e-1a2c443081c0}}, place recognition and mapping for robotics\u00a0{{cite:9d80403f-8878-43d0-89f0-d4a9791082c4}}, {{cite:dbc58f36-0d0b-4387-8cca-47dfab1de50c}}, and image segmentation with Bayesian nonparametrics\u00a0{{cite:6fa0c808-48cf-4936-973c-f8032316b847}}. [SEP]\n", "[CLS] {{cite:214ce28e-a220-4ae1-a447-43b281865e80}} uses variational inference in a probabilistic model to combine the tasks of segmentation, clustering, and annotation. [SEP]\n", "[CLS] Computational neuroscience. [SEP]\n", "[CLS] \u00a0 Modern neuroscience research also requires analyzing very large and high-dimensional data sets, such as high-frequency time series data or high-resolution functional magnetic imaging data. [SEP]\n", "[CLS] There have been many applications of variational inference to neuroscience, especially for autoregressive processes\u00a0{{cite:606c9252-0930-4767-a95e-7e693857ef7d}}, {{cite:49219e8a-ef27-48e6-8f6c-7606b193fca7}}, {{cite:13ddf20f-6fb5-45ba-a203-308ee254ef30}}, {{cite:9a3203d5-c1f6-47a2-b182-a3b3e5faa8d3}}, {{cite:9cd766fd-b64c-4f07-9155-9aa6b1785ebf}}. [SEP]\n", "[CLS] Other applications of variational inference to neuroscience include hierarchical models of multiple subjects\u00a0{{cite:15d4aa52-8a0e-4960-a4fa-e18e89300d80}}, spatial models\u00a0{{cite:c3989d07-3836-45f5-9d8e-7e3d8c6acd74}}, {{cite:aea8f008-e3cc-4a0b-bb33-7ce942e19b8d}}, {{cite:d739ab16-3bb6-4da2-9894-9f7911d13400}}, {{cite:9e45c3d1-602b-44ad-8031-bd13e1335a4f}}, {{cite:bf65ffeb-cf02-4226-8e48-085ffff6bbc3}}, {{cite:1223edbe-d06a-468e-9553-d61f6092d5f8}}, brain-computer interfaces\u00a0{{cite:431fb1ce-b207-4e3b-8c96-58902973cafc}}, and factor models\u00a0{{cite:7e72aa01-50bc-4ccc-be0e-e65f4fa45deb}}, {{cite:c12ff2bd-7d33-4aef-a644-9629df56cc9c}}. [SEP]\n", "[CLS] There is a software toolbox that uses variational methods for solving neuroscience and psychology research problems\u00a0{{cite:1360bfc8-8e38-4b96-8909-b8f4ebd6a378}}. [SEP]\n", "[CLS] Natural language processing and speech recognition. [SEP]\n", "[CLS] \u00a0  [SEP]\n", "[CLS] In natural language processing, variational inference has been used for solving problems such as parsing\u00a0{{cite:b8e5c233-b858-4fbe-90b8-afc0c62989f6}}, {{cite:1242e893-c5e4-4e4f-8965-8560c0efa1ad}}, grammar induction\u00a0{{cite:ab26ebed-000c-4b1e-83e3-27360ee96026}}, {{cite:8208cc19-9024-4f63-b16a-5de57b284442}}, {{cite:68f8f97d-03e8-4e8a-8755-f400647a8bd8}}, models of streaming text\u00a0{{cite:56e9fe66-0c14-4aa9-a2fb-c36f7dcff2dd}}, topic modeling\u00a0{{cite:0d5f2195-64d4-4d40-95f2-e6250bd775c8}}, and hidden Markov models and part-of-speech tagging\u00a0{{cite:2349afdd-c861-43cd-8952-8b3733ee8e70}}. [SEP]\n", "[CLS] In speech recognition, variational inference has been used to fit complex coupled hidden Markov models\u00a0{{cite:889806c2-d217-4922-871c-d3158c45d51f}} and switching dynamic systems\u00a0{{cite:81a5eac2-0e5d-4c80-b1bd-308d4a1d65ab}}. [SEP]\n", "[CLS] Other applications. [SEP]\n", "[CLS] \u00a0 There have been many other applications of variational inference. [SEP]\n", "[CLS] Fields in which it has been used include marketing\u00a0{{cite:7c538023-885f-42ee-b9cc-c91ec5eb4063}}, optimal control and reinforcement learning\u00a0{{cite:0daebc7a-acb2-4d0c-823a-80c7e2215d1e}}, {{cite:daf7d120-6051-48c0-8f95-1375a71c233f}}, statistical network analysis\u00a0{{cite:c2b881d6-f901-439a-b1f0-e901d720ed01}}, {{cite:50dd9a43-259f-4c05-a112-35cc2acccb42}}, astrophysics\u00a0{{cite:52295cbc-1b42-48ce-9c80-e58521b63543}}, and the social sciences\u00a0{{cite:ee7d00d9-b21e-4e8a-8075-4ec150da1bc1}}, {{cite:bf19e2c4-7693-4906-aa6d-3f3a54704c41}}. [SEP]\n", "[CLS] General variational inference algorithms have been developed for a variety of classes of models, including shrinkage models\u00a0{{cite:d1eab559-eab7-4360-b55f-0114b3d0ea9e}}, {{cite:0c359cfd-0bae-43cc-99cf-80c38a7e19bd}}, {{cite:6bbd222c-2a06-4712-8075-5562b6a6ecb6}}, general time-series models\u00a0{{cite:4d64ef2c-dbe2-4c14-8b4f-9d3a887d109f}}, {{cite:8e1072ee-6304-4e5b-a134-680f8a0b603c}}, {{cite:c84f8162-9226-4f24-b14e-19c701ed07d8}}, {{cite:215bbcfd-d5ea-41f9-b1fa-29a7fae826c8}}, {{cite:cfd3176b-a863-4cba-944e-4a3581d2ab69}}, {{cite:7e097add-a44f-43ab-b396-8ef58e61b045}}, robust models\u00a0{{cite:e09a7ee8-481d-4327-9b57-06bfea8ee31d}}, {{cite:7e73d62c-01d5-4c14-bf88-a28d93313187}}, and Gaussian process models\u00a0{{cite:9674275d-cfdb-4d21-be3a-c4f96c8715f2}}, {{cite:33837f78-2302-4060-82c3-02fbecc56772}}, {{cite:4dd5f35d-4998-4776-a181-4a71e6c43ce2}}.   [SEP]\n", "[CLS] Theory [SEP]\n", "[CLS] Though researchers have not developed much theory around variational inference, there are several threads of research about theoretical guarantees of variational approximations. [SEP]\n", "[CLS] As we mentioned in the introduction, one of our purposes for writing this paper is to catalyze research on the statistical theory around variational inference. [SEP]\n", "[CLS] Below, we summarize a variety of results. [SEP]\n", "[CLS] In general, they are all of the following type: treat VI posterior means as point estimates (or use m-step estimates from variational EM) and confirm that they have the usual frequentist asymptotics. [SEP]\n", "[CLS] (Sometimes the research finds that they do not enjoy the same asymptotics.) Each result revolves around a single model and a single family of variational approximations. [SEP]\n", "[CLS] {{cite:b821303b-03b2-4459-a0d1-5f34755bffae}} study the variational posterior for a classical Bayesian linear model. [SEP]\n", "[CLS] They put a normal prior on the coefficients and an inverse gamma prior on the response variance. [SEP]\n", "[CLS] They find that, under standard regularity conditions, the mean-field variational posterior mean of the parameters are consistent in the frequentist sense. [SEP]\n", "[CLS] {{cite:0b3d43e2-4303-42f1-ae3c-6dcc46933b05}} build on their earlier work with a spike-and-slab prior on the coefficients and find similar consistency results. [SEP]\n", "[CLS] {{cite:476cf94d-1330-405f-a9a7-796fd1eaeab4}}, {{cite:3896bf3d-506e-497e-a331-40763d770687}} examine a simple Poisson mixed-effects model, one with a single predictor and a random intercept. [SEP]\n", "[CLS] They use a Gaussian variational approximation and estimate parameters with variational EM. [SEP]\n", "[CLS] They prove consistency of these estimates at the parametric rate and show asymptotic normality with asymptotically valid standard errors. [SEP]\n", "[CLS] {{cite:3690f87d-1db5-4605-be6b-29c0a0841767}} and {{cite:d1e4507a-edcb-4de1-8d8b-1588785d7ff5}} analyze network data using stochastic blockmodels. [SEP]\n", "[CLS] They show asymptotic normality of parameter estimates obtained using a mean-field variational approximation. [SEP]\n", "[CLS] They highlight the computational advantages and theoretical guarantees of the variational approach over maximum likelihood for dense, sparse, and restricted variants of the stochastic blockmodel. [SEP]\n", "[CLS] {{cite:d026d89b-725c-4605-bf27-89d34bcecc2f}} study the consistency of VI through a connection to M-estimation. [SEP]\n", "[CLS] They focus on a broader class of models (with posterior support in real coordinate space) and analyze an automated VI technique that uses a Gaussian variational approximation {{cite:de6dbb02-df68-4e27-b0e8-851b5948d5be}}. [SEP]\n", "[CLS] They derive an asymptotic covariance matrix estimator of the variational approximation and show its robustness to model misspecification. [SEP]\n", "[CLS] Finally, {{cite:56d53f4c-2e2f-41f2-8e3b-0032903bed42}} analyze variational approximations to mixtures of Gaussians. [SEP]\n", "[CLS] Specifically, they consider Bayesian mixtures with conjugate priors, the mean-field variational approximation, and an estimator that is the variational posterior mean. [SEP]\n", "[CLS] They confirm that CAVI converges to a local optimum, that the VI estimator is consistent, and that the VI estimate and MLE approach each other at a rate of FORMULA . [SEP]\n", "[CLS] In {{cite:55b33be4-8598-4063-ac70-6c5de1458bea}}, they show that the asymptotic variational posterior covariance matrix is \u201ctoo small\u201d\u2014it differs from the MLE covariance (i.e., the inverse Fisher information) by a positive-definite matrix. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Beyond conditional conjugacy We focused on models where the complete conditional is in the exponential family. [SEP]\n", "[CLS] Many models, however, do not enjoy this property. [SEP]\n", "[CLS] A simple example is Bayesian logistic regression, FORMULA   where FORMULA  is the logistic function. [SEP]\n", "[CLS] The posterior density of the coefficients is not in an exponential family and we cannot apply the variational inference methods we discussed above. [SEP]\n", "[CLS] Specifically, we cannot compute the expectations in the first term of the ELBO in Equation\u00a0(REF ) or the coordinate update in Equation\u00a0(REF ). [SEP]\n", "[CLS] Exploring variational methods for such models has been a fruitful area of research. [SEP]\n", "[CLS] An early example is {{cite:b448a758-55e0-4a8f-b174-6064ee835ef6}}, {{cite:e3579510-f7c1-40f3-8887-9ce8fde7b36d}}, who developed a variational bound tailored to logistic regression. [SEP]\n", "[CLS] {{cite:836f432e-0fed-4dd9-a2be-d1e205b97f15}} later adapted their idea to nonconjugate topic models, and researchers have continued to improve the original bound {{cite:cd0d90d9-daad-418f-82c6-666652e1b86e}}, {{cite:c0ccf231-6ca0-427c-be07-27093c4d6542}}, {{cite:12e41914-1c8d-4da7-b759-d2c64a18444e}}. [SEP]\n", "[CLS] In other work, {{cite:7c538023-885f-42ee-b9cc-c91ec5eb4063}} derived a variational inference algorithm for the discrete choice model, which also lies outside of the class of conditionally conjugate models. [SEP]\n", "[CLS] They developed a delta method to approximate the difficult-to-compute expectations. [SEP]\n", "[CLS] Finally, {{cite:605f6a7f-bf89-4df7-9cb2-9ba08b7dcc55}} use auxiliary variable methods, quadrature, and mixture approximations to handle a variety of likelihood terms that fall outside of the exponential family. [SEP]\n", "[CLS] More recently, researchers have generalized nonconjugate inference, seeking recipes that can be used across many models. [SEP]\n", "[CLS] {{cite:59eeafe1-164b-49db-82a1-d982dcc70381}} adapted Laplace approximations and the delta method to this end, improving inference in nonconjugate generalized linear models and topic models; this approach is also used by {{cite:8279f5db-ac0e-4044-b014-49adef9258d9}} for semi-parametric regression. [SEP]\n", "[CLS] {{cite:ab7957ce-b8fe-4f54-a94b-563e14968911}} generalized the {{cite:b448a758-55e0-4a8f-b174-6064ee835ef6}}, {{cite:e3579510-f7c1-40f3-8887-9ce8fde7b36d}} bound in a message-passing algorithm and {{cite:34fa79d1-63aa-4037-a0b6-e8124c256f65}} further simplified and extended their approach. [SEP]\n", "[CLS] {{cite:bde80f0d-3be5-4f6e-8da8-01513e6643cd}}, {{cite:a0a81391-e75e-4628-a240-083cde25a104}} applied these message-passing methods to generalized linear mixed models (and also combined them with SVI). [SEP]\n", "[CLS] {{cite:14cc25a9-6e1b-4dbe-98aa-f706d7af0adc}} unified many of these algorithmic developments and provided practical insights into their numerical implementations. [SEP]\n", "[CLS] Finally, there has been a flurry of research on optimizing difficult variational objectives with MC estimates of the gradient. [SEP]\n", "[CLS] The idea is to write the gradient of the ELBO as an expectation, compute MC estimates of it, and then use stochastic optimization with repeated MC gradients. [SEP]\n", "[CLS] This first appeared independently in several papers\u00a0{{cite:9dbfad47-8281-4697-a370-02d3a70e1989}}, {{cite:3a30c077-c669-44e5-a872-cb37c1cb970f}}, {{cite:16da7eb7-0669-4064-9655-9e6687df140b}}, {{cite:cb661a4e-cfd4-491c-953f-5f9dd5e88242}}. [SEP]\n", "[CLS] The newest approaches avoid any model-specific derivations, and are termed \u201cblack box\u201d inference methods. [SEP]\n", "[CLS] As examples, see\u00a0{{cite:f452ed74-c293-418c-b749-3a00e5a00609}}, {{cite:566928dd-482d-44a7-9ed5-37a1757c8081}}, {{cite:8cbdd476-967e-4d3a-8088-c7bd2da65f57}}, {{cite:c473112b-580c-4e8a-b457-cc8e53110fa1}}, {{cite:0f2a20e0-a42e-4439-a78b-f772c0b803e2}}, {{cite:0a4c4d69-aa90-44c7-a105-a5449af882ad}}, and {{cite:8d83d30c-090f-4079-bb20-7c31f5981281}}. [SEP]\n", "[CLS] {{cite:e0277160-fe65-49ed-9588-106a52a0bd9f}} leverage these ideas toward an automatic VI technique that works on any model written in the probabilistic programming system Stan {{cite:007c2129-c55b-4bc4-97c4-4dbbf46b3f17}}. [SEP]\n", "[CLS] This is a step towards a derivation-free, easy-to-use VI algorithm. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Open problems There are many open avenues for statistical research in variational inference. [SEP]\n", "[CLS] We focused on optimizing FORMULA  as the variational objective function. [SEP]\n", "[CLS] A promising avenue of research is to develop variational inference methods that optimize other measures, such as FORMULA -divergence measures. [SEP]\n", "[CLS] As one example, expectation propagation\u00a0{{cite:6823d9ea-22c9-48a3-a1b9-13c77f84a78b}} is inspired by the KL divergence \u201cin the other direction,\u201d between FORMULA  and FORMULA . [SEP]\n", "[CLS] Other work has developed divergences based on lower bounds that are tighter than the ELBO\u00a0{{cite:865a5510-fbc5-4b7b-adc6-45cb7b4a9356}}, {{cite:5205930b-663f-4ec5-b299-6862a337ceae}}. [SEP]\n", "[CLS] While alternative divergences may be difficult to optimize, they may give better approximations\u00a0{{cite:45aa6331-74e0-4969-8c6a-754cd31e180e}}, {{cite:8827349d-c1a3-4306-9f64-c1cfdfead2cf}}. [SEP]\n", "[CLS] Though it is flexible, the mean-field family makes strong independence assumptions. [SEP]\n", "[CLS] These assumptions help with scalable optimization, but they limit the expressibility of the variational family. [SEP]\n", "[CLS] Further, they can exacerbate issues with local optima of the objective and underestimating posterior variances; see Figure\u00a0REF . [SEP]\n", "[CLS] A second avenue of research is to develop better approximations while maintaining efficient optimization. [SEP]\n", "[CLS] As we mentioned above, structured variational inference has its roots in the early days of the method\u00a0{{cite:3b4a3d9e-1237-425d-a924-cc65c4f92c7b}}, {{cite:bb4d89fe-3e45-4eee-8fdd-676a870dc22f}}. [SEP]\n", "[CLS] More recently, {{cite:df210deb-bb8c-42fe-be9e-9dadaeead2d5}} use generic structured variational inference in a stochastic optimization algorithm; {{cite:e0277160-fe65-49ed-9588-106a52a0bd9f}}, {{cite:a953f2cd-70cb-4d02-a87f-24b405a928c2}}, and {{cite:1c9f2d61-0919-4aae-b379-fe0ddba65436}} take advantage of Gaussian variational families with non-diagonal covariance; {{cite:cef830c5-f260-433b-ada6-2ea7e9c49d6a}} post-process the mean-field parameters to correct for underestimating the variance; and {{cite:c473112b-580c-4e8a-b457-cc8e53110fa1}} embed the mean-field parameters themselves in a hierarchical model to induce variational dependencies between latent variables. [SEP]\n", "[CLS] The interface between variational inference and MCMC remains relatively unexplored. [SEP]\n", "[CLS] {{cite:c5c89e0d-f9da-4a20-a7ce-3fcb2d4d4e91}} used fitted variational distributions as a component of a proposal distribution for Metropolis-Hastings. [SEP]\n", "[CLS] {{cite:05908bf4-4935-452e-bcb7-90ae98583d93}} and {{cite:df210deb-bb8c-42fe-be9e-9dadaeead2d5}} studied MCMC as a method of approximating coordinate updates, e.g., to include structure in the variational family. [SEP]\n", "[CLS] {{cite:9bbe0c14-debd-4bd5-bab4-4054eef101bd}} propose a variational approximation to the MCMC chain; their method enables an explicit trade off between computational accuracy and speed. [SEP]\n", "[CLS] Understanding how to combine these two strategies for approximate inference is a ripe area for future research. [SEP]\n", "[CLS] A principled analysis of when to use (and combine) variational inference and MCMC would have both theoretical and practical impact in the field. [SEP]\n", "[CLS] Finally, the statistical properties of variational inference are not yet well understood, especially in contrast to the wealth of analysis of MCMC techniques. [SEP]\n", "[CLS] There has been some progress; see Section\u00a0REF . [SEP]\n", "[CLS] A final open research problem is to understand variational inference as an estimator and to understand its statistical profile relative to the exact posterior. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Bayesian Linear Regression with Automatic RelevanceDetermination Consider a dataset of FORMULA  outputs and FORMULA  FORMULA -dimensional inputs, where each FORMULA . [SEP]\n", "[CLS] A linear regression model assumes a linear relationship between the inputs and the conditional mean of the output given the inputs. [SEP]\n", "[CLS] The latent variable FORMULA  is a vector of the regression coefficients. [SEP]\n", "[CLS] ARD assigns a separate prior for each regression coefficient; the idea is to automatically shrink irrelevant coefficients during inference {{cite:501190a2-966e-4241-8fa7-6fea4bd21ff9}}, {{cite:fbfc48fe-da02-47bb-a2ce-ce4cfd934243}}, {{cite:d19058eb-abab-4748-9ffc-0eee72a3da56}}, {{cite:348f5d3c-f70a-4605-b04f-15d71efcfbe3}}. [SEP]\n", "[CLS] ARD works by pairing the prior precision of each regression coefficient with its own latent variable FORMULA . [SEP]\n", "[CLS] The hyper-prior on these relevance variables FORMULA  encourages small values; this, in turn, selects relevant regression coefficients. [SEP]\n", "[CLS] Here we present a conditionally conjugate Bayesian linear regression model with an ARD prior, based on {{cite:c50f9fd2-4822-44cd-b25a-82e3b57b4bd4}}. [SEP]\n", "[CLS] All Gaussian distributions below follow the precision parameterization. [SEP]\n", "[CLS] Define a Gaussian likelihood with precision parameter FORMULA  as FORMULA   [SEP]\n", "[CLS] ARD then posits the following hierarchical prior FORMULA   where FORMULA  is a FORMULA -dimensional relevance variable FORMULA   Here FORMULA  and FORMULA  are fixed hyper-parameters. [SEP]\n", "[CLS] The latent variable FORMULA  determines the relevance of each regression coefficient. [SEP]\n", "[CLS] The posterior FORMULA  is not available in closed form. [SEP]\n", "[CLS] A simpler model that does not include FORMULA  admits a closed form posterior because the normal-gamma distribution is conjugate to a normal likelihood with unknown mean and precision. [SEP]\n", "[CLS] We derive a CAVI algorithm for this model. [SEP]\n", "[CLS] First, factorize the variational approximation as FORMULA    [SEP]\n", "[CLS] Here we consider FORMULA  and FORMULA  in a single factor. [SEP]\n", "[CLS] Begin by applying Equation\u00a0(REF ) to identify the optimal form of FORMULA  as FORMULA    [SEP]\n", "[CLS] The optimal variational approximation to the regression coefficients and the precision is thus a normal-gamma with the following parameters: FORMULA   [SEP]\n", "[CLS] Next consider the optimal form of the relevance variables FORMULA . [SEP]\n", "[CLS] Again, apply Equation\u00a0(REF ) to identify the optimal form of FORMULA  as FORMULA    [SEP]\n", "[CLS] The optimal variational approximation to the relevance variable is thus a Gamma with the following parameters: FORMULA   Finally, compute the expectations as FORMULA   where FORMULA  indicates the FORMULA th diagonal entry of a matrix. [SEP]\n", "[CLS] Iteratively updating FORMULA  and FORMULA  defines CAVI for this model. [SEP]\n", "[CLS] These quantities also define the ELBO; {{cite:c50f9fd2-4822-44cd-b25a-82e3b57b4bd4}} presents the additional algebra that computes the ELBO. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Gaussian Mixture Model of Image Histograms We present a multivariate (FORMULA -dimensional), diagonal covariance GMM. [SEP]\n", "[CLS] Denote a dataset of FORMULA  observations as FORMULA , where each FORMULA . [SEP]\n", "[CLS] Assume FORMULA  mixture components. [SEP]\n", "[CLS] The cluster assignment latent variables are FORMULA  where each FORMULA  is a FORMULA -indicator vector. [SEP]\n", "[CLS] The cluster assignments depend on the mixing vector latent variable FORMULA , which lives in a FORMULA -simplex. [SEP]\n", "[CLS] The mean latent variables are FORMULA , where each FORMULA , and the precision latent variables are FORMULA , where each FORMULA . [SEP]\n", "[CLS] The joint density of the model factorizes as FORMULA   [SEP]\n", "[CLS] The likelihood is Gaussian with precision parameterization FORMULA   [SEP]\n", "[CLS] The marginal over cluster assignments is a categorical distribution, FORMULA   [SEP]\n", "[CLS] The prior over the mixing vector is a Dirichlet distribution with fixed hyperparameters FORMULA , FORMULA   [SEP]\n", "[CLS] The prior over mean and precision parameters is a normal-gamma distribution with hyperparameters FORMULA , FORMULA , FORMULA , FORMULA , FORMULA   [SEP]\n", "[CLS] We use the following values for the hyperparameters FORMULA  {{cite:0b57a9d1-ed0c-4663-912a-0e699836184b}} derives a CAVI algorithm for this model. [SEP]\n", "[CLS] Figure\u00a0REF  presents Stan code that implements this model. [SEP]\n", "[CLS] Since Stan does not support discrete latent variables, we marginalize over the assignment variables. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Latent Dirichlet Allocation Probabilistic topic models are mixed-membership models of text, used to uncover the latent \u201ctopics\u201d that run through a collection of documents. [SEP]\n", "[CLS] Topic models have become a popular technique for exploratory data analysis of large collections\u00a0{{cite:0fa7c300-28d3-4726-ba76-c175ac5841c3}}. [SEP]\n", "[CLS] LDA LDA {{cite:0d5f2195-64d4-4d40-95f2-e6250bd775c8}} is a conditionally conjugate topic model (Section\u00a0REF ). [SEP]\n", "[CLS] It treats documents as containing multiple topics, where a topic is a distribution over words in a vocabulary. [SEP]\n", "[CLS] Following the notation of {{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}}, let FORMULA  be a specific number of topics and FORMULA   [SEP]\n", "[CLS] the size of the vocabulary. [SEP]\n", "[CLS] LDA defines the following generative process:  For each topic in FORMULA ,  draw a distribution over words FORMULA . [SEP]\n", "[CLS]    [SEP]\n", "[CLS] For each document in FORMULA ,  draw a vector of topic proportions FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] For each word in FORMULA ,  draw a topic assignment FORMULA , then  draw a word FORMULA . [SEP]\n", "[CLS]     [SEP]\n", "[CLS] Here FORMULA  is a fixed parameter of the symmetric Dirichlet prior on the topics FORMULA , and FORMULA  are fixed parameters of the Dirichlet prior on the topic proportions for each document. [SEP]\n", "[CLS] Similar to the GMM example in Section\u00a0, we encode categorical variables as indicator vectors. [SEP]\n", "[CLS] Thus FORMULA  is a FORMULA -vector where FORMULA  indicates the FORMULA th word in document FORMULA  is assigned to the FORMULA th topic. [SEP]\n", "[CLS] Similarly, FORMULA  is a FORMULA -vector where FORMULA  indicates that the FORMULA th word in document FORMULA  is the FORMULA th word in the vocabulary. [SEP]\n", "[CLS] We occasionally abuse these indicator vectors as indices\u2014for example, if FORMULA , then FORMULA  is the FORMULA th topic, denoted by FORMULA . [SEP]\n", "[CLS] The posterior FORMULA  is not available in closed form. [SEP]\n", "[CLS] While the topic assignments FORMULA  and their proportions FORMULA  enjoy a conjugate relationship, the introduction of the topics FORMULA  renders this posterior analytically intractable. [SEP]\n", "[CLS] We derive a CAVI algorithm for this model, based on {{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}}. [SEP]\n", "[CLS] Posit a mean-field variational family FORMULA   Since LDA is a conditionally conjugate model, we can directly identify the family of each factor (Section\u00a0REF ). [SEP]\n", "[CLS] Begin with the complete conditional of the topic assignment. [SEP]\n", "[CLS] This is a multinomial, FORMULA    [SEP]\n", "[CLS] The variational approximation to the topic assignments is also a multinomial distribution, with parameters FORMULA . [SEP]\n", "[CLS] Follow with the complete conditional of the topic proportions. [SEP]\n", "[CLS] This is a FORMULA -dimensional Dirichlet FORMULA    [SEP]\n", "[CLS] The variational approximation to the topic proportions is also a FORMULA -dimensional [SEP]\n", "[CLS] Dirichlet with parameters FORMULA . [SEP]\n", "[CLS] End with the complete conditional of the topics. [SEP]\n", "[CLS] This is a FORMULA -dimensional Dirichlet FORMULA    [SEP]\n", "[CLS] In words, the FORMULA th element of the FORMULA th topic is a Dirichlet with parameter equal to the sum of the fixed scalar FORMULA  and the number of times term FORMULA  (denoted by FORMULA ) was assigned to topic FORMULA  (denoted by FORMULA ). [SEP]\n", "[CLS] The variational approximation to the topic proportions is a FORMULA -dimensional [SEP]\n", "[CLS] Dirichlet with parameters FORMULA . [SEP]\n", "[CLS] The CAVI updates for the topic assignment and topic proportions require iterating over the following for each word within each document until convergence: FORMULA    [SEP]\n", "[CLS] This is a direct application of Equation\u00a0(REF ) to the complete conditionals above. [SEP]\n", "[CLS] The updates for FORMULA  and FORMULA  depend on the variational parameters for the topics FORMULA . [SEP]\n", "[CLS] The update for the topics, in turn, depends on the variational parameters for the topic proportions. [SEP]\n", "[CLS] That update is FORMULA    [SEP]\n", "[CLS] This update only depends on the variational parameter for the topic assignments FORMULA . [SEP]\n", "[CLS] Algorithm\u00a0 presents the full CAVI algorithm for LDA. [SEP]\n", "[CLS] A similar computation defines the ELBO for LDA; {{cite:0dcf83fe-30a3-4532-bb59-3309086d12b5}} present the additional algebra for the ELBO. [SEP]\n", "[CLS] [!hbtp] 1.25 LDA model and a set of words in documents FORMULA . [SEP]\n", "[CLS] Variational parameters FORMULA . [SEP]\n", "[CLS] Initialize: Variational parameters FORMULA  randomly. [SEP]\n", "[CLS] the ELBO has not converged FORMULA  and FORMULA  have converged  each document FORMULA   each word FORMULA    [SEP]\n", "[CLS] Compute updates to FORMULA  and FORMULA  via Equations\u00a0(REF ) and\u00a0(). [SEP]\n", "[CLS]    Compute update to FORMULA  via Equation\u00a0(REF ). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] CAVI for LDA [SEP]\n"], "1612.05970": ["[CLS]  Adversarial Deep Structural Networks for Mammographic Mass Segmentation Adversarial Deep Structural Networks for Mammographic Mass Segmentation. [SEP]\n", "[CLS] Wentao Zhu Xiang Xiang Trac\u00a0D.\u00a0Tran Xiaohui Xie W. Zhu et al. University of California, Irvine and Johns Hopkins University {wentaoz1, xhx}@ics.uci.edu, {xxiang, trac}@jhu.edu Lecture Notes in Computer Science Authors' Instructions   [SEP]\n", "[CLS] Mass segmentation is an important task in mammogram analysis, providing effective morphological features and regions of interest (ROI) for mass detection and classification. [SEP]\n", "[CLS] Inspired by the success of using deep convolutional features for natural image analysis and conditional random fields (CRF) for structural learning, we propose an end-to-end network for mammographic mass segmentation. [SEP]\n", "[CLS] The network employs a fully convolutional network (FCN) to model a potential function, followed by a CRF to perform structured learning. [SEP]\n", "[CLS] Because the mass distribution varies greatly with pixel position, the FCN is combined with a position priori. [SEP]\n", "[CLS] Due to the small size of mammogram datasets, we use adversarial training to control over-fitting. [SEP]\n", "[CLS] Four models with different convolutional kernels are further fused to improve the segmentation results. [SEP]\n", "[CLS] Experimental results on two public datasets, INBreast and DDSM-BCRP, demonstrate that our end-to-end network achieves the state-of-the-art results. [SEP]\n", "[CLS] Code: https://github.com/wentaozhu/adversarial-deep-structural-networks.git. [SEP]\n", "[CLS] Adversarial deep structure networks, segmentation, adversarial fully convolutional network, adversarial training Introduction According to the American Cancer Society, breast cancer is the most frequently diagnosed solid cancer and the second leading cause of cancer death among U.S. women\u00a0{{cite:b83e85cf-3d4f-4d01-afe1-14bdfd67cdeb}}. [SEP]\n", "[CLS] Mammogram screening has been demonstrated to be an effective way for early detection and diagnosis, which can significantly decrease breast cancer mortality {{cite:19144a7c-5874-47c6-90d8-46ffc6d9d9ee}}. [SEP]\n", "[CLS] Mass segmentation provides morphological features, which play crucial roles for diagnosis. [SEP]\n", "[CLS] Traditional studies on mass segmentation rely heavily on elaborate human designed features. [SEP]\n", "[CLS] Model-based methods build classifiers and learn the features from the mass {{cite:2f4a4b54-5238-48ae-9055-75f9cdbc299a}}, {{cite:40706688-d917-43d5-8142-95ff9711b8b4}}. [SEP]\n", "[CLS] There are few works using deep networks to process the mammogram\u00a0{{cite:9cb0ac5d-ec77-474b-b4de-cc8d3b65b34b}}, {{cite:6643545d-cfe7-4927-ae46-a8148e59fbe3}}, {{cite:e0e8b7b4-00d0-436c-b20e-858a8aefda3f}}. [SEP]\n", "[CLS] Dhungel et al. employed multiple deep belief networks (DBNs), GMM classifier and a priori as potential functions, and structural SVM to perform segmentation {{cite:ac665279-6e81-435f-a043-a50ff7c90ae7}}. [SEP]\n", "[CLS] They also used CRF with tree re-weighted belief propagation to boost the segmentation results {{cite:4ce7a388-7207-4299-9f5a-c48f1dfb17c8}}. [SEP]\n", "[CLS] A recent work used the output from a CNN as a complimentary potential function, yielding the state-of-the-art performance\u00a0{{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}}. [SEP]\n", "[CLS] However, the two-stage training used in these methods produces potential functions that can easily over-fit training data. [SEP]\n", "[CLS] Inspired by the power of deep networks\u00a0{{cite:2bf35cfa-5f51-492a-9cd6-e20449adb1b6}}, {{cite:6310df00-79fb-4f1c-b78c-a4b8c7a77cf7}}, we propose an end-to-end trained adversarial deep structural network to perform mass segmentation (Fig. REF (a)). [SEP]\n", "[CLS] The proposed network is designed to robustly learn from a small dataset with poor contrast mammographic images. [SEP]\n", "[CLS] Specifically, an end-to-end trained fully convolution network (FCN) with CRF is applied. [SEP]\n", "[CLS] Adversarial training is introduced into the network to learn robustly from scarce mammographic images. [SEP]\n", "[CLS] To further explore statistical property of mass regions, the spatial priori with categorical distributions considering the positions are added into FCN. [SEP]\n", "[CLS] We validate our adversarial deep structural network on two public mammographic mass segmentation datasets. [SEP]\n", "[CLS] The proposed network is demonstrated to consistently outperform other algorithms for mass segmentation. [SEP]\n", "[CLS] Our main contributions in this paper are: (1) It is the first time to apply adversarial training to medical imaging. [SEP]\n", "[CLS] Integrating CNN+CRF and adversarial training into a unified end-to-end training framework has not been attempted before. [SEP]\n", "[CLS] Both components are essential and necessary for achieving the state-of-the-art performance. [SEP]\n", "[CLS] (2) We employ an end-to-end trained network to do the mass segmentation while previous works needed a lot of hand-designed features or multi-stage training, such as calculating potential functions independently. [SEP]\n", "[CLS] (3) Our model achieves state-of-the-art results on two commonly used mammographic mass segmentation datasets. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Fully Convolution Network-CRF Network Fully convolutional network (FCN) is a successful model for image segmentation, which preserves the spatial structure of predictions\u00a0{{cite:8cc762e9-b9bc-4a02-8163-b81537569227}}. [SEP]\n", "[CLS] FCN consists of convolution, de-convolution {{cite:e4653336-b553-4080-acbc-8ababf164f2d}}, or max-pooling in each layer. [SEP]\n", "[CLS] For training, the FCN optimizes maximum likelihood loss function FORMULA , where FORMULA  is the label of FORMULA th pixel in the FORMULA th image FORMULA , FORMULA  is the number of training mammograms, FORMULA  is the number of pixels in the image, and FORMULA  is the parameter of FCN. [SEP]\n", "[CLS] Here the size of images is fixed to FORMULA  and FORMULA  is 1,600. [SEP]\n", "[CLS] CRF is a commonly used method for structural learning, well suited for image segmentation. [SEP]\n", "[CLS] It models pixel labels as random variables in a Markov random field conditioned on an observed input image. [SEP]\n", "[CLS] To make the annotation consistent, we use FORMULA  to denote the random variables of pixel labels in an image, where FORMULA . [SEP]\n", "[CLS] The zero denotes pixel belonging to background, and one denotes it belonging to mass region. [SEP]\n", "[CLS] The Gibbs energy of fully connected pairwise CRF {{cite:970a782d-009b-4a6c-9792-8d33c5f85955}} is FORMULA , where unary potential function FORMULA  is the loss of FCN in our case, pairwise potential function FORMULA  defines the cost of labeling pair FORMULA . [SEP]\n", "[CLS] The pairwise potential function FORMULA  can be defined as FORMULA  where label compatibility function FORMULA  is given by the Potts model in our case, FORMULA  is the Gaussian kernel applied to feature vectors {{cite:970a782d-009b-4a6c-9792-8d33c5f85955}}, FORMULA  is the learned weight. [SEP]\n", "[CLS] Pixel values FORMULA  and positions FORMULA  can be used as the feature vector FORMULA . [SEP]\n", "[CLS] Efficient inference algorithm can be obtained by mean field approximation FORMULA  {{cite:970a782d-009b-4a6c-9792-8d33c5f85955}}. [SEP]\n", "[CLS] The update rule is FORMULA  where the first line is the message passing from label of pixel FORMULA  to label of pixel FORMULA , the second line is re-weighting with the learned weights FORMULA , the third line is compatibility transform, the fourth line is adding unary potentials, and the last step is normalization operator. [SEP]\n", "[CLS] Here FORMULA  denotes background or mass. [SEP]\n", "[CLS] The initialization of inference employs unary potential function as FORMULA . [SEP]\n", "[CLS] The above mean field approximation can be interpreted as a recurrent neural network (RNN) in Fig. [SEP]\n", "[CLS] \u00a0REF (b){{cite:2d20ba12-6254-4c02-970c-5f094c1951ff}}. [SEP]\n", "[CLS]  Adversarial FCN-CRF Network Shape and the appearance priori play an important role in mammogram mass segmentation {{cite:18465ef5-a1ef-48eb-b521-1a483f90b8be}}, {{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}}. [SEP]\n", "[CLS] The distribution of labels varies greatly with a position in the mammographic mass segmentation. [SEP]\n", "[CLS] From observation, most of the mass is located in the center of ROI, and the boundary of ROI is more likely to be background (Fig. REF (a)). [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The conventional FCN provides predictions for pixels independently. [SEP]\n", "[CLS] It only considers global class distribution difference corresponding to the number of filters (channels) in the last layer. [SEP]\n", "[CLS] Here we take the categorical priori of different positions into consideration and add it into the FCN as FORMULA , where FORMULA  is the categorical priori distribution varied with the pixel position FORMULA , and FORMULA  is the output of conventional FCN. [SEP]\n", "[CLS] In the implementation, we assigned the bias of last layer as the average image to train network. [SEP]\n", "[CLS] The FORMULA  is used as the unary potential function for FORMULA  in the CRF as RNN. [SEP]\n", "[CLS] For multiple FCNs as potential functions, the potential function is defined as FORMULA , where FORMULA  is the learned weight for unary potential function, FORMULA  is the potential function provided by one FCN. [SEP]\n", "[CLS] Adversarial training provides strong regularization for deep networks {{cite:fca877ef-fd95-4f59-9c91-89aabfdf847c}}. [SEP]\n", "[CLS] The idea of adversarial training is that if the model is robust enough, it should be invariant to small perturbations of training examples that yield the largest increase in the loss (adversarial examples {{cite:4c731b2d-0540-4748-87df-7643eb4fd46b}}). [SEP]\n", "[CLS] The perturbation FORMULA  for adversarial example can be obtained as FORMULA . [SEP]\n", "[CLS] In general, the calculation of exact FORMULA  is intractable because the exact minimization is not solvable w.r.t. [SEP]\n", "[CLS] FORMULA , especially for complicated models such as deep networks. [SEP]\n", "[CLS] The linear approximation and FORMULA  norm box constraint can be used for the calculation of perturbation {{cite:fca877ef-fd95-4f59-9c91-89aabfdf847c}} as FORMULA , where FORMULA . [SEP]\n", "[CLS] For adversarial fully convolutional network, the network predicts label of each pixel independently as FORMULA . [SEP]\n", "[CLS] For adversarial CRF as RNN, the prediction of network relies on mean field approximation inference as FORMULA . [SEP]\n", "[CLS] The adversarial training forces the model to fit examples with the worst perturbation as well. [SEP]\n", "[CLS] The adversarial loss is defined as FORMULA  In training, the total loss is defined as the sum of adversarial loss and the empirical loss based on training samples as FORMULA  where FORMULA  is the regularization factor used to avoid over-fitting, FORMULA  is either prediction in the enhanced FCN or posteriori approximated by mean field inference in the CRF as RNN for the FORMULA th image FORMULA . [SEP]\n", "[CLS] The FORMULA  regularization term is used only for the parameters in CRF.   [SEP]\n", "[CLS] Experiments We validate the proposed model on two publicly and most frequently used mammographic mass segmentation datasets: INBreast dataset {{cite:98c96701-22ad-4ce8-bd04-a67070beacfb}} and DDSM-BCRP dataset {{cite:5fd884ff-481a-4e4f-b25d-78ef8da9b4c0}}. [SEP]\n", "[CLS] We use the same ROI extraction and re-size principle as {{cite:ac665279-6e81-435f-a043-a50ff7c90ae7}}, {{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}}, {{cite:4ce7a388-7207-4299-9f5a-c48f1dfb17c8}}. [SEP]\n", "[CLS] Due to the low contrast of mammographic images, image enhancement technique is used on the extracted ROI images as the first 9 steps of enhancement {{cite:6d37ebed-6a7d-414a-bbb8-2fca51429f70}}, followed by pixel position dependent normalization. [SEP]\n", "[CLS] The preprocessing makes training converge quickly. [SEP]\n", "[CLS] We further augment each training set by flipping horizontally, flipping vertically, flipping horizontally and vertically, which makes the training set 4 times larger than the original training set. [SEP]\n", "[CLS] For consistent comparison, the Dice index metric is used for the segmentation results and is defined FORMULA . [SEP]\n", "[CLS] For a fair comparison, we also validate the Deep Structure Learning + CNN {{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}} on our processed data, and obtain similar result (Dice index FORMULA ) on the INBreast dataset. [SEP]\n", "[CLS] To investigate the impact of each component in our model, we conduct extensive experiments under different configurations. [SEP]\n", "[CLS] FCN is the network integrating a position priori into FCN (structure denoted as FCN 1 in Tab. [SEP]\n", "[CLS] 1). [SEP]\n", "[CLS] We use the enhanced FCN rather than the conventional FCN in all experiments. [SEP]\n", "[CLS] Adversarial FCN is FCN with adversarial training. [SEP]\n", "[CLS] Jointly Trained FCN-CRF is the FCN followed by CRF as RNN with an end-to-end training scheme. [SEP]\n", "[CLS] Jointly Trained Adversarial FCN-CRF is the Jointly Trained FCN-CRF with end-to-end adversarial training. [SEP]\n", "[CLS] Multi-FCN, Adversarial Multi-FCN, Jointly Trained Multi-FCN-CRF, Jointly Trained Adversarial Multi-FCN-CRF are those networks with 4 FCNs. [SEP]\n", "[CLS] The configuration of FCN and other used three subnetworks in the Multi-FCN are in Table\u00a0REF . [SEP]\n", "[CLS] The last layers of the four networks are all two FORMULA  deconvolutional filters with softmax activation function. [SEP]\n", "[CLS] We use hyperbolic tangent activation function in middle layers. [SEP]\n", "[CLS] The parameters of FCNs are set such that the number of each layer's parameters is almost the same as that of CNN used in the work {{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}}. [SEP]\n", "[CLS] For optimization, we use Adam algorithm {{cite:9b62dcfb-5038-4a71-b2ec-8fee0f8b7d74}} with learning rate 0.003. [SEP]\n", "[CLS] The FORMULA  used for weights of CRF as RNN is FORMULA  in the two datasets. [SEP]\n", "[CLS] The FORMULA  used in adversarial training are FORMULA  and FORMULA  for INBreast and DDSM-BCRP datasets respectively, because the boundaries of masses on the DDSM-BCRP dataset are smoother than those on the INbreast dataset. [SEP]\n", "[CLS] For mean field approximation or the CRF as RNN, we use 5 iterations/time steps in the training and 10 iterations/time steps in the test phase. [SEP]\n", "[CLS] TABLE  TABLE   [SEP]\n", "[CLS] The INBreast dataset is a recently released mammographic mass analysis dataset, which provides more accurate contours of lesion region and the mammograms are of high quality. [SEP]\n", "[CLS] For mass segmentation, the dataset contains 116 mass regions. [SEP]\n", "[CLS] We use the first 58 masses for training and the rest for test, which is of the same protocol used in these works {{cite:ac665279-6e81-435f-a043-a50ff7c90ae7}}, {{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}}, {{cite:4ce7a388-7207-4299-9f5a-c48f1dfb17c8}}. [SEP]\n", "[CLS] The DDSM-BCRP dataset contains 39 cases (156 images) for training and 40 cases (160 images) for testing\u00a0{{cite:5fd884ff-481a-4e4f-b25d-78ef8da9b4c0}}. [SEP]\n", "[CLS] After ROI extraction, there are 84 ROIs for training, and 87 ROIs for test. [SEP]\n", "[CLS] We compare our schemes with other recently published mammographic mass segmentation methods {{cite:40706688-d917-43d5-8142-95ff9711b8b4}}, {{cite:ac665279-6e81-435f-a043-a50ff7c90ae7}}, {{cite:4ce7a388-7207-4299-9f5a-c48f1dfb17c8}}, {{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}} in Table REF . [SEP]\n", "[CLS] Table REF  shows that the successfully used CNN features in natural image provide superior performance on medical image analysis, outperforming hand-crafted feature based methods {{cite:40706688-d917-43d5-8142-95ff9711b8b4}}, {{cite:2f4a4b54-5238-48ae-9055-75f9cdbc299a}}. [SEP]\n", "[CLS] Our enhanced FCN achieves 0.25% Dice index improvement than the traditional FCN on the INBreast dataset. [SEP]\n", "[CLS] The adversarial training yields 0.4% improvement on average. [SEP]\n", "[CLS] Incorporating the spatially structural constraint further produces 0.3% improvement. [SEP]\n", "[CLS] Using model average or multiple potential functions contributes the most to segmentation results which is consistent with work showing that the best model requires five different unary potential functions {{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}}. [SEP]\n", "[CLS] Combining all the components together achieves the best performance with relative 9.7%, 13% improvement on INBreast, DDSM-BCRP datasets respectively. [SEP]\n", "[CLS] In our experiment, the FCN overfits heavily on the training set and can even achieve above 98.60% Dice index. [SEP]\n", "[CLS] It might explains why the two-stage training cannot boost the performance too much. [SEP]\n", "[CLS] The adversarial training works effectively as a regularization to reduce the overfitting. [SEP]\n", "[CLS] We believe that the overfitting is mainly caused by the small training set size and we strongly support the creation of a large mammographic analysis dataset to accelerate mammogram analysis research. [SEP]\n", "[CLS] We calculate the p-value of McNemar\u2019s Chi-Square Test to compare our model with the method\u00a0{{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}} on the INBreast dataset. [SEP]\n", "[CLS] The total number of pixels is 92,800. [SEP]\n", "[CLS] The numbers of pixels classified right and wrong for both models are 76,130 and 8,805, respectively. [SEP]\n", "[CLS] The number of pixels classified right by only using our model is 4,595. [SEP]\n", "[CLS] The number of pixels classified right by using model\u00a0{{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}} is 3,270. [SEP]\n", "[CLS] We obtain p-value FORMULA , which shows our model is significantly better than model\u00a0{{cite:28e4ccd4-5808-49bd-9de7-78e227fbe34e}}. [SEP]\n", "[CLS] To further understand the adversarial training, we visualize segmentation results in Fig. REF . [SEP]\n", "[CLS] We observe that segmentations in the first row have vague borders and many outliers within the predicted borders. [SEP]\n", "[CLS] The segmentations in the second row have fewer vague borders and fewer outliers than the predictions in the first row. [SEP]\n", "[CLS] The results in the last two rows have sharper and more accurate borders than the first two rows. [SEP]\n", "[CLS] It demonstrates that the CRF based methods achieves better segmentations on the test sets. [SEP]\n", "[CLS] The structural learning using CRF eliminates outliers within borders effectively, which makes better segmentation results and more accurately predicted borders. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] We further employ the metric based on the trimap to specifically evaluate segmentation accuracy in boundaries {{cite:c015412a-88b4-4974-8aab-2353257c97d2}}. [SEP]\n", "[CLS] We calculate the accuracies within trimap surrounding the actual mass boundaries (groundtruth) in Fig. REF . [SEP]\n", "[CLS] Trimaps on the DDSM-BCRP dataset is visualized in Fig. [SEP]\n", "[CLS] \u00a0REF (b). [SEP]\n", "[CLS] From the figure, accuracies of FCN-CRF with Adversarial Training are 2-3 % higher than those of FCN-CRF on average and the accuracies of FCN with Adversarial Training are better than those of FCN. [SEP]\n", "[CLS] The results demonstrate that the adversarial training regularization improves the FCN and FCN-CRF both in the whole image (Dice Index metric) and around the boundaries. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Conclusion [SEP]\n", "[CLS] In this paper, we propose an end-to-end trained adversarial FCN-CRF network for mammographic mass segmentation. [SEP]\n", "[CLS] To integrate the priori distribution of masses and fully explore the power of FCN, a position priori is added to the network. [SEP]\n", "[CLS] Furthermore, adversarial training is used to handle the small size of training data by reducing over-fitting and increasing robustness. [SEP]\n", "[CLS] Experimental results demonstrate the state-of-the-art performance of our model on the two most used public mammogram datasets. [SEP]\n", "[CLS]   [SEP]\n"], "1511.04491": ["[CLS]    Deeply-Recursive Convolutional Network for Image Super-ResolutionJiwon Kim, Jung Kwon Lee and Kyoung Mu LeeDepartment of ECE, ASRI, Seoul National University, Korea{j.kim, deruci, kyoungmu}@snu.ac.kr 2020/09/15 [SEP]\n", "[CLS] 18:01:15We propose an image super-resolution method (SR) using a deeply-recursive convolutional network (DRCN). [SEP]\n", "[CLS] Our network has a very deep recursive layer (up to 16 recursions). [SEP]\n", "[CLS] Increasing recursion depth can improve performance without introducing new parameters for additional convolutions. [SEP]\n", "[CLS] Albeit advantages, learning a DRCN is very hard with a standard gradient descent method due to exploding/vanishing gradients. [SEP]\n", "[CLS] To ease the difficulty of training, we propose two extensions: recursive-supervision and skip-connection. [SEP]\n", "[CLS] Our method outperforms previous methods by a large margin. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Introduction For image super-resolution (SR), receptive field of a convolutional network determines the amount of contextual information that can be exploited to infer missing high-frequency components. [SEP]\n", "[CLS] For example, if there exists a pattern with smoothed edges contained in a receptive field, it is plausible that the pattern is recognized and edges are appropriately sharpened. [SEP]\n", "[CLS] As SR is an ill-posed inverse problem, collecting and analyzing more neighbor pixels can possibly give more clues on what may be lost by downsampling. [SEP]\n", "[CLS] Deep convolutional networks (DCN) succeeding in various computer vision tasks often use very large receptive fields (224x224 common in ImageNet classification {{cite:0a72f29f-401c-4bff-a641-53c6b94be7e7}}, {{cite:7ac5797c-d07e-4f76-9bdf-75d29fe5eb14}}). [SEP]\n", "[CLS] Among many approaches to widen the receptive field, increasing network depth is one possible way: a convolutional (conv.) layer with filter size larger than a FORMULA  or a pooling (pool.) layer that reduces the dimension of intermediate representation can be used. [SEP]\n", "[CLS] Both approaches have drawbacks: a conv. [SEP]\n", "[CLS] layer introduces more parameters and a pool. [SEP]\n", "[CLS] layer typically discards some pixel-wise information. [SEP]\n", "[CLS] For image restoration problems such as super-resolution and denoising, image details are very important. [SEP]\n", "[CLS] Therefore, most deep-learning approaches for such problems do not use pooling. [SEP]\n", "[CLS] Increasing depth by adding a new weight layer basically introduces more parameters. [SEP]\n", "[CLS] Two problems can arise. [SEP]\n", "[CLS] First, overfitting is highly likely. [SEP]\n", "[CLS] More data are now required. [SEP]\n", "[CLS] Second, the model becomes too huge to be stored and retrieved. [SEP]\n", "[CLS] To resolve these issues, we use a deeply-recursive convolutional network (DRCN). [SEP]\n", "[CLS] DRCN repeatedly applies the same convolutional layer as many times as desired. [SEP]\n", "[CLS] The number of parameters do not increase while more recursions are performed. [SEP]\n", "[CLS] Our network has the receptive field of 41 by 41 and this is relatively large compared to SRCNN {{cite:d6f71a5c-0576-46e2-8506-9d1aa4d219ef}} (13 by 13). [SEP]\n", "[CLS] While DRCN has good properties, we find that DRCN optimized with the widely-used stochastic gradient descent method does not easily converge. [SEP]\n", "[CLS] This is due to exploding/vanishing gradients {{cite:d77be775-82aa-41a7-bf69-be325b312fb6}}. [SEP]\n", "[CLS] Learning long-range dependencies between pixels with a single weight layer is very difficult. [SEP]\n", "[CLS] We propose two approaches to ease the difficulty of training (Figure REF (a)). [SEP]\n", "[CLS] First, all recursions are supervised. [SEP]\n", "[CLS] Feature maps after each recursion are used to reconstruct the target high-resolution image (HR). [SEP]\n", "[CLS] Reconstruction method (layers dedicated to reconstruction) is the same for all recursions. [SEP]\n", "[CLS] As each recursion leads to a different HR prediction, we combine all predictions resulting from different levels of recursions to deliver a more accurate final prediction. [SEP]\n", "[CLS] The second proposal is to use a skip-connection from input to the reconstruction layer. [SEP]\n", "[CLS] In SR, a low-resolution image (input) and a high-resolution image (output) share the same information to a large extent. [SEP]\n", "[CLS] Exact copy of input, however, is likely to be attenuated during many forward passes. [SEP]\n", "[CLS] We explicitly connect the input to the layers for output reconstruction. [SEP]\n", "[CLS] This is particularly effective when input and output are highly correlated. [SEP]\n", "[CLS] Contributions In summary, we propose an image super-resolution method deeply recursive in nature. [SEP]\n", "[CLS] It utilizes a very large context compared to previous SR methods with only a single recursive layer. [SEP]\n", "[CLS] We improve the simple recursive network in two ways: recursive-supervision and skip-connection. [SEP]\n", "[CLS] Our method demonstrates state-of-the-art performance in common benchmarks. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Related Work Single-Image Super-Resolution We apply DRCN to single-image super-resolution (SR) {{cite:f1331c0a-a36f-42b2-a6ba-0ec6946f9381}}, {{cite:6788bcf6-c5a5-47a5-affa-ed0206f017e4}}, {{cite:ff009d69-cc73-4d66-919c-e3cd0cb565e7}}. [SEP]\n", "[CLS] Many SR methods have been proposed in the computer vision community. [SEP]\n", "[CLS] Early methods use very fast interpolations but yield poor results. [SEP]\n", "[CLS] Some of the more powerful methods utilize statistical image priors {{cite:29fca67a-a2a4-43a7-993b-f3fee49f994b}}, {{cite:4fdb9578-9a15-4791-80e3-9380d436f212}} or internal patch recurrence {{cite:ff009d69-cc73-4d66-919c-e3cd0cb565e7}}, {{cite:354787a0-c034-42b9-b591-4048edeeb420}}. [SEP]\n", "[CLS] Recently, sophisticated learning methods have been widely used to model a mapping from LR to HR patches. [SEP]\n", "[CLS] Many methods have paid attention to find better regression functions from LR to HR images. [SEP]\n", "[CLS] This is achieved with various techniques: neighbor embedding {{cite:4e02e57f-24c9-4776-b0ca-b0d7aef65d05}}, {{cite:2be44df9-afa7-4c33-a013-31b154c838a0}}, sparse coding {{cite:865d60a8-5474-47b9-bd37-40bdb69c9719}}, {{cite:28343bcd-c4fd-4a9b-82ea-a5100ee04ac6}}, {{cite:5e281652-6323-4492-bc94-a79c65ab223e}}, {{cite:f7510290-aa1d-4815-9b4b-a0307c5092da}}, convolutional neural network (CNN) {{cite:d6f71a5c-0576-46e2-8506-9d1aa4d219ef}} and random forest {{cite:717ee24b-159c-4646-a45b-dcdfce82aa01}}. [SEP]\n", "[CLS] Among several recent learning-based successes, convolutional neural network (SRCNN) {{cite:d6f71a5c-0576-46e2-8506-9d1aa4d219ef}} demonstrated the feasibility of an end-to-end approach to SR. [SEP]\n", "[CLS] One possibility to improve SRCNN is to simply stack more weight layers as many times as possible. [SEP]\n", "[CLS] However, this significantly increases the number of parameters and requires more data to prevent overfitting. [SEP]\n", "[CLS] In this work, we seek to design a convolutional network that models long-range pixel dependencies with limited capacity. [SEP]\n", "[CLS] Our network recursively widens the receptive field without increasing model capacity. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Recursive Neural Network in Computer Vision Recursive neural networks, suitable for temporal and sequential data, have seen limited use on algorithms operating on a single static image. [SEP]\n", "[CLS] Socher et al. {{cite:6de3d075-2229-4f4a-a6ff-bc1da992f7a9}} used a convolutional network in a separate stage to first learn features on RGB-Depth data, prior to hierarchical merging. [SEP]\n", "[CLS] In these models, the input dimension is twice that of the output and recursive convolutions are applied only two times. [SEP]\n", "[CLS] Similar dimension reduction occurs in the recurrent convolutional neural networks used for semantic segmentation {{cite:c16aaa28-90a3-4bd2-a2a0-12446e9380bc}}. [SEP]\n", "[CLS] As SR methods predict full-sized images, dimension reduction is not allowed. [SEP]\n", "[CLS] In Eigen et al. {{cite:ee406dd7-3be7-47ef-88dc-2f4fb11cea61}}, recursive layers have the same input and output dimension, but recursive convolutions resulted in worse performances than a single convolution due to overfitting. [SEP]\n", "[CLS] To overcome overfitting, Liang and Hu {{cite:3d28b4cb-d46b-463d-af5c-87c9ad78002a}} uses a recurrent layer that takes feed-forward inputs into all unfolded layers. [SEP]\n", "[CLS] They show that performance increases up to three convolutions. [SEP]\n", "[CLS] Their network structure, designed for object recognition, is the same as the existing CNN architectures. [SEP]\n", "[CLS] Our network is similar to the above in the sense that recursive or recurrent layers are used with convolutions. [SEP]\n", "[CLS] We further increase the recursion depth and demonstrate that very deep recursions can significantly boost the performance for super-resolution. [SEP]\n", "[CLS] We apply the same convolution up to 16 times (the previous maximum is three). [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] FIGURE   Proposed Method Basic Model [SEP]\n", "[CLS] Our first model, outlined in Figure REF , consists of three sub-networks: embedding, inference and reconstruction networks. [SEP]\n", "[CLS] The embedding net is used to represent the given image as feature maps ready for inference. [SEP]\n", "[CLS] Next, the inference net solves the task. [SEP]\n", "[CLS] Once inference is done, final feature maps in the inference net are fed into the reconstruction net to generate the output image. [SEP]\n", "[CLS] The embedding net takes the input image (grayscale or RGB) and represents it as a set of feature maps. [SEP]\n", "[CLS] Intermediate representation used to pass information to the inference net largely depends on how the inference net internally represent its feature maps in its hidden layers. [SEP]\n", "[CLS] Learning this representation is done end-to-end altogether with learning other sub-networks. [SEP]\n", "[CLS] Inference net is the main component that solves the task of super-resolution. [SEP]\n", "[CLS] Analyzing a large image region is done by a single recursive layer. [SEP]\n", "[CLS] Each recursion applies the same convolution followed by a rectified linear unit (Figure REF ). [SEP]\n", "[CLS] With convolution filters larger than FORMULA , the receptive field is widened with every recursion. [SEP]\n", "[CLS] While feature maps from the final application of the recursive layer represent the high-resolution image, transforming them (multi-channel) back into the original image space (1 or 3-channel) is necessary. [SEP]\n", "[CLS] This is done by the reconstruction net. [SEP]\n", "[CLS] We have a single hidden layer for each sub-net. [SEP]\n", "[CLS] Only the layer for the inference net is recursive. [SEP]\n", "[CLS] Other sub-nets are vastly similar to the standard mutilayer perceptrons (MLP) with a single hidden layer. [SEP]\n", "[CLS] For MLP, full connection of FORMULA  neurons is equivalent to a convolution with FORMULA . [SEP]\n", "[CLS] In our sub-nets, we use FORMULA  filters. [SEP]\n", "[CLS] For embedding net, we use FORMULA  filters because image gradients are more informative than the raw intensities for super-resolution. [SEP]\n", "[CLS] For inference net, FORMULA  convolutions imply that hidden states are passed to adjacent pixels only. [SEP]\n", "[CLS] Reconstruction net also takes direct neighbors into account. [SEP]\n", "[CLS] Mathematical Formulation The network takes an interpolated input image (to the desired size) as input FORMULA  and predicts the target image FORMULA  as in SRCNN {{cite:d6f71a5c-0576-46e2-8506-9d1aa4d219ef}}. [SEP]\n", "[CLS] Our goal is to learn a model FORMULA  that predicts values FORMULA , where FORMULA  is its estimate of ground truth output FORMULA . [SEP]\n", "[CLS] Let FORMULA  denote sub-net functions: embedding, inference and reconstruction, respectively. [SEP]\n", "[CLS] Our model is the composition of three functions: [SEP]\n", "[CLS]  FORMULA Embedding net FORMULA  takes the input vector FORMULA  and computes the matrix output FORMULA , which is an input to the inference net FORMULA . [SEP]\n", "[CLS] Hidden layer values are denoted by FORMULA . [SEP]\n", "[CLS] The formula for embedding net is as follows: FORMULA   where the operator FORMULA  denotes a convolution and FORMULA  corresponds to a ReLU. [SEP]\n", "[CLS] Weight and bias matrices are FORMULA  and FORMULA . [SEP]\n", "[CLS] Inference net FORMULA  takes the input matrix FORMULA  and computes the matrix output FORMULA . [SEP]\n", "[CLS] Here, we use the same weight and bias matrices FORMULA  and FORMULA  for all operations. [SEP]\n", "[CLS] Let FORMULA  denote the function modeled by a single recursion of the recursive layer: FORMULA . [SEP]\n", "[CLS] The recurrence relation is FORMULA  for FORMULA . [SEP]\n", "[CLS] Inference net FORMULA  is equivalent to the composition of the same elementary function FORMULA : FORMULA  where the operator FORMULA  denotes a function composition and FORMULA  denotes the FORMULA -fold product of FORMULA . [SEP]\n", "[CLS] Reconstruction net FORMULA  takes the input hidden state FORMULA  and outputs the target image (high-resolution). [SEP]\n", "[CLS] Roughly speaking, reconstruction net is the inverse operation of embedding net. [SEP]\n", "[CLS] The formula is as follows: FORMULA   [SEP]\n", "[CLS] Model Properties Now we have all components for our model. [SEP]\n", "[CLS] The recursive model has pros and cons. [SEP]\n", "[CLS] While the recursive model is simple and powerful, we find training a deeply-recursive network very difficult. [SEP]\n", "[CLS] This is in accordance with the limited success of previous methods using at most three recursions so far {{cite:3d28b4cb-d46b-463d-af5c-87c9ad78002a}}. [SEP]\n", "[CLS] Among many reasons, two severe problems are vanishing and exploding gradients {{cite:d77be775-82aa-41a7-bf69-be325b312fb6}}, {{cite:c4c4258f-f75a-4b16-ae26-6b872b5cec2f}}. [SEP]\n", "[CLS] Exploding gradients refer to the large increase in the norm of the gradient during training. [SEP]\n", "[CLS] Such events are due to the multiplicative nature of chained gradients. [SEP]\n", "[CLS] Long term components can grow exponentially for deep recursions. [SEP]\n", "[CLS] The vanishing gradients problem refers to the opposite behavior. [SEP]\n", "[CLS] Long term components approach exponentially fast to the zero vector. [SEP]\n", "[CLS] Due to this, learning the relation between distant pixels is very hard. [SEP]\n", "[CLS] Another known issue is that storing an exact copy of information through many recursions is not easy. [SEP]\n", "[CLS] In SR, output is vastly similar to input and recursive layer needs to keep the exact copy of input image for many recursions. [SEP]\n", "[CLS] These issues are also observed when we train our basic recursive model and we did not succeed in training a deeply-recursive network. [SEP]\n", "[CLS] In addition to gradient problems, there exists an issue with finding the optimal number of recursions. [SEP]\n", "[CLS] If recursions are too deep for a given task, we need to reduce the number of recursions. [SEP]\n", "[CLS] Finding the optimal number requires training many networks with different recursion depths. [SEP]\n", "[CLS]  Advanced Model Recursive-Supervision To resolve the gradient and optimal recursion issues, we propose an improved model. [SEP]\n", "[CLS] We supervise all recursions in order to alleviate the effect of vanishing/exploding gradients. [SEP]\n", "[CLS] As we have assumed that the same representation can be used again and again during convolutions in the inference net, the same reconstruction net is used to predict HR images for all recursions. [SEP]\n", "[CLS] Our reconstruction net now outputs FORMULA   [SEP]\n", "[CLS] predictions [SEP]\n", "[CLS] and all predictions are simultaneously supervised during training (Figure REF  (a)). [SEP]\n", "[CLS] We use all FORMULA  intermediate predictions to compute the final output. [SEP]\n", "[CLS] All predictions are averaged during testing. [SEP]\n", "[CLS] The optimal weights are automatically learned during training. [SEP]\n", "[CLS] A similar but a different concept of supervising intermediate layers for a convolutional network is used in Lee et al {{cite:9921ca1d-30e3-473c-be80-ee22efaed4f2}}. [SEP]\n", "[CLS] Their method simultaneously minimizes classification error while improving the directness and transparency of the hidden layer learning process. [SEP]\n", "[CLS] There are two significant differences between our recursive-supervision and deep-supervision proposed in Lee et al. {{cite:9921ca1d-30e3-473c-be80-ee22efaed4f2}}. [SEP]\n", "[CLS] They associate a unique classifier for each hidden layer. [SEP]\n", "[CLS] For each additional layer, a new classifier has to be introduced, as well as new parameters. [SEP]\n", "[CLS] If this approach is used, our modified network would resemble that of Figure REF (b). [SEP]\n", "[CLS] We would then need FORMULA  different reconstruction networks. [SEP]\n", "[CLS] This is against our original purpose of using recursive networks, which is avoid introducing new parameters while stacking more layers. [SEP]\n", "[CLS] In addition, using different reconstruction nets no longer effectively regularizes the network. [SEP]\n", "[CLS] The second difference is that Lee et al. {{cite:9921ca1d-30e3-473c-be80-ee22efaed4f2}} discards all intermediate classifiers during testing. [SEP]\n", "[CLS] However, an ensemble of all intermediate predictions significantly boosts the performance. [SEP]\n", "[CLS] The final output from the ensemble is also supervised. [SEP]\n", "[CLS] Our recursive-supervision naturally eases the difficulty of training recursive networks. [SEP]\n", "[CLS] Backpropagation goes through a small number of layers if supervising signal goes directly from loss layer to early recursion. [SEP]\n", "[CLS] Summing all gradients backpropagated from different prediction losses gives a smoothing effect. [SEP]\n", "[CLS] The adversarial effect of vanishing/exploding gradients along one backpropagation path is alleviated. [SEP]\n", "[CLS] Moreover, the importance of picking the optimal number of recursions is reduced as our supervision enables utilizing predictions from all intermediate layers. [SEP]\n", "[CLS] If recursions are too deep for the given task, we expect the weight for late predictions to be low while early predictions receive high weights. [SEP]\n", "[CLS] By looking at weights of predictions, we can figure out the marginal gain from additional recursions. [SEP]\n", "[CLS] We present an expanded CNN structure of our model for illustration purposes in Figure REF (c). [SEP]\n", "[CLS] If parameters are not allowed to be shared and CNN chains vary their depths, the number of free parameters grows fast (quadratically). [SEP]\n", "[CLS] Skip-Connection Now we describe our second extension: skip-connection. [SEP]\n", "[CLS] For SR, input and output images are highly correlated. [SEP]\n", "[CLS] Carrying most if not all of input values until the end of the network is inevitable but very inefficient. [SEP]\n", "[CLS] Due to gradient problems, exactly learning a simple linear relation between input and output is very difficult if many recursions exist in between them. [SEP]\n", "[CLS] We add a layer skip {{cite:3c312829-ca1b-43ef-9a5e-08ecb0f88033}} from input to the reconstruction net. [SEP]\n", "[CLS] Adding layer skips is successfully used for a semantic segmentation network {{cite:9f9adb5f-b4fe-4347-809c-a11e479f270c}} and we employ a similar idea. [SEP]\n", "[CLS] Now input image is directly fed into the reconstruction net whenever it is used during recursions. [SEP]\n", "[CLS] Our skip-connection has two advantages. [SEP]\n", "[CLS] First, network capacity to store the input signal during recursions is saved. [SEP]\n", "[CLS] Second, the exact copy of input signal can be used during target prediction. [SEP]\n", "[CLS] Our skip-connection is simple yet very effective. [SEP]\n", "[CLS] In super-resolution, LR and HR images are vastly similar. [SEP]\n", "[CLS] In most regions, differences are zero and only small number of locations have non-zero values. [SEP]\n", "[CLS] For this reason, several super-resolution methods {{cite:5e281652-6323-4492-bc94-a79c65ab223e}}, {{cite:f7510290-aa1d-4815-9b4b-a0307c5092da}}, {{cite:2be44df9-afa7-4c33-a013-31b154c838a0}}, {{cite:5aecd405-7493-4f77-be91-7076bf953019}} predict image details only. [SEP]\n", "[CLS] Similarly, we find that this domain-specific knowledge significantly improves our learning procedure. [SEP]\n", "[CLS] Mathematical Formulation [SEP]\n", "[CLS] Each intermediate prediction under recursive-supervision (Figure REF (a)) is FORMULA  for FORMULA , where FORMULA  now takes two inputs, one from skip-connection. [SEP]\n", "[CLS] Reconstruction net with skip-connection can take various functional forms. [SEP]\n", "[CLS] For example, input can be concatenated to the feature maps FORMULA . [SEP]\n", "[CLS] As the input is an interpolated input image (roughly speaking, FORMULA ), we find FORMULA  is enough for our purpose. [SEP]\n", "[CLS] More sophisticated functions for merging two inputs to FORMULA  will be explored in the future. [SEP]\n", "[CLS] Now, the final output is the weighted average of all intermediate predictions: FORMULA  where FORMULA  denotes the weights of predictions reconstructed from each intermediate hidden state during recursion. [SEP]\n", "[CLS] These weights are learned during training. [SEP]\n", "[CLS] TABLE  FIGURE  FIGURE  FIGURE  FIGURE   Training Objective We now describe the training objective used to find optimal parameters of our model. [SEP]\n", "[CLS] Given a training dataset FORMULA , our goal is to find the best model FORMULA  that accurately predicts values FORMULA . [SEP]\n", "[CLS] In the least-squares regression setting, typical in SR, the mean squared error FORMULA  averaged over the training set is minimized. [SEP]\n", "[CLS] This favors high Peak Signal-to-Noise Ratio (PSNR), a widely-used evaluation criteria. [SEP]\n", "[CLS] With recursive-supervision, we have FORMULA  objectives to minimize: supervising FORMULA  outputs from recursions and the final output. [SEP]\n", "[CLS] For intermediate outputs, we have the loss function FORMULA  where FORMULA  denotes the parameter set and FORMULA  is the output from the FORMULA -th recursion. [SEP]\n", "[CLS] For the final output, we have FORMULA   [SEP]\n", "[CLS] Now we give the final loss function FORMULA . [SEP]\n", "[CLS] The training is regularized by weight decay (FORMULA  penalty multiplied by FORMULA ). [SEP]\n", "[CLS] FORMULA  where FORMULA  denotes the importance of the companion objective on the intermediate outputs and FORMULA  denotes the multiplier of weight decay. [SEP]\n", "[CLS] Setting FORMULA  high makes the training procedure stable as early recursions easily converge. [SEP]\n", "[CLS] As training progresses, FORMULA  decays to boost the performance of the final output. [SEP]\n", "[CLS] Training is carried out by optimizing the regression objective using mini-batch gradient descent based on back-propagation (LeCun et al. {{cite:ca5ac04b-fff5-4040-aaf2-1d247f738ec8}}). [SEP]\n", "[CLS] We implement our model using the MatConvNet http://www.vlfeat.org/matconvnet/ package {{cite:4280dc92-1d7b-4b46-8b08-99de4a14c717}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Experimental Results In this section, we evaluate the performance of our method on several datasets. [SEP]\n", "[CLS] We first describe datasets used for training and testing our method. [SEP]\n", "[CLS] Next, our training setup is given. [SEP]\n", "[CLS] We give several experiments for understanding our model properties. [SEP]\n", "[CLS] The effect of increasing the number of recursions is investigated. [SEP]\n", "[CLS] Finally, we compare our method with several state-of-the-art methods. [SEP]\n", "[CLS] Datasets For training, we use 91 images proposed in Yang et al. {{cite:865d60a8-5474-47b9-bd37-40bdb69c9719}} for all experiments. [SEP]\n", "[CLS] For testing, we use four datasets. [SEP]\n", "[CLS] Datasets Set5 {{cite:2be44df9-afa7-4c33-a013-31b154c838a0}} and Set14 {{cite:28343bcd-c4fd-4a9b-82ea-a5100ee04ac6}} are often used for benchmark {{cite:f7510290-aa1d-4815-9b4b-a0307c5092da}}, {{cite:5e281652-6323-4492-bc94-a79c65ab223e}}, {{cite:d6f71a5c-0576-46e2-8506-9d1aa4d219ef}}. [SEP]\n", "[CLS] Dataset B100 consists of natural images in the Berkeley Segmentation Dataset {{cite:2e656df2-1ac7-4910-a21e-0d9f1dd7495a}}. [SEP]\n", "[CLS] Finally, dataset Urban100, urban images recently provided by Huang et al. {{cite:354787a0-c034-42b9-b591-4048edeeb420}}, is very interesting as it contains many challenging images failed by existing methods. [SEP]\n", "[CLS] FIGURE  FIGURE    [SEP]\n", "[CLS] Training Setup [SEP]\n", "[CLS] We use 16 recursions unless stated otherwise. [SEP]\n", "[CLS] When unfolded, the longest chain from the input to the output passes 20 conv. [SEP]\n", "[CLS] layers (receptive field of 41 by 41). [SEP]\n", "[CLS] We set the momentum parameter to 0.9 and weight decay to 0.0001. [SEP]\n", "[CLS] We use 256 filters of the size FORMULA  for all weight layers. [SEP]\n", "[CLS] Training images are split into 41 by 41 patches with stride 21 and 64 patches are used as a mini-batch for stochastic gradient descent. [SEP]\n", "[CLS] For initializing weights in non-recursive layers, we use the method described in He et al. {{cite:387d666d-4c64-4e09-90f6-0ca8f9d216b5}}. [SEP]\n", "[CLS] For recursive convolutions, we set all weights to zero except self-connections (connection to the same neuron in the next layer) {{cite:47c07f02-f46b-4eb1-a021-75cb6fa15a2c}}, {{cite:7d9f6ca7-619b-4a83-a3fc-409ff7227b90}}. [SEP]\n", "[CLS] Biases are set to zero. [SEP]\n", "[CLS] Learning rate is initially set to 0.01 and then decreased by a factor of 10 if the validation error does not decrease for 5 epochs. [SEP]\n", "[CLS] If learning rate is less than FORMULA , the procedure is terminated. [SEP]\n", "[CLS] Training roughly takes 6 days on a machine using one Titan X GPU.   [SEP]\n", "[CLS] Study of Deep Recursions We study the effect of increasing recursion depth. [SEP]\n", "[CLS] We trained four models with different numbers of recursions: 1, 6, 11, and 16. [SEP]\n", "[CLS] Four models use the same number of parameters except the weights used for ensemble. [SEP]\n", "[CLS] In Figure 8, it is shown that as more recursions are performed, PSNR measures increase. [SEP]\n", "[CLS] Increasing recursion depth with a larger image context and more nonlinearities boosts performance. [SEP]\n", "[CLS] The effect of ensemble is also investigated. [SEP]\n", "[CLS] We first evaluate intermediate predictions made from recursions (Figure REF ). [SEP]\n", "[CLS] The ensemble output significantly improves performances of individual predictions. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Comparisons with State-of-the-Art Methods We provide quantitative and qualitative comparisons. [SEP]\n", "[CLS] For benchmark, we use public code for A+ {{cite:f7510290-aa1d-4815-9b4b-a0307c5092da}}, SRCNN {{cite:d6f71a5c-0576-46e2-8506-9d1aa4d219ef}}, RFL {{cite:717ee24b-159c-4646-a45b-dcdfce82aa01}} and SelfEx {{cite:354787a0-c034-42b9-b591-4048edeeb420}}. [SEP]\n", "[CLS] We deal with luminance components only as similarly done in other methods because human vision is much more sensitive to details in intensity than in color. [SEP]\n", "[CLS] As some methods such as A+ {{cite:f7510290-aa1d-4815-9b4b-a0307c5092da}} and RFL {{cite:717ee24b-159c-4646-a45b-dcdfce82aa01}} do not predict image boundary, they require cropping pixels near borders. [SEP]\n", "[CLS] For our method, this procedure is unnecessary as our network predicts the full-sized image. [SEP]\n", "[CLS] For fair comparison, however, we also crop pixels to the same amount. [SEP]\n", "[CLS] PSNRs can be slightly different from original papers as existing methods use slightly different evaluation frameworks. [SEP]\n", "[CLS] We use the public evaluation code used in {{cite:354787a0-c034-42b9-b591-4048edeeb420}}. [SEP]\n", "[CLS] In Table REF , we provide a summary of quantitative evaluation on several datasets. [SEP]\n", "[CLS] Our method outperforms all existing methods in all datasets and scale factors (both PSNR and SSIM). [SEP]\n", "[CLS] In Figures REF , REF , REF  and REF , example images are given. [SEP]\n", "[CLS] Our method produces relatively sharp edges respective to patterns. [SEP]\n", "[CLS] In contrast, edges in other images are blurred. [SEP]\n", "[CLS] Our method takes a second to process a FORMULA  image on a GPU Titan X.   [SEP]\n", "[CLS] Conclusion [SEP]\n", "[CLS] In this work, we have presented a super-resolution method using a deeply-recursive convolutional network. [SEP]\n", "[CLS] Our network efficiently reuses weight parameters while exploiting a large image context. [SEP]\n", "[CLS] To ease the difficulty of training the model, we use recursive-supervision and skip-connection. [SEP]\n", "[CLS] We have demonstrated that our method outperforms existing methods by a large margin on benchmarked images. [SEP]\n", "[CLS] In the future, one can try more recursions in order to use image-level context. [SEP]\n", "[CLS] We believe our approach is readily applicable to other image restoration problems such as denoising and compression artifact removal. [SEP]\n"], "1603.01025": ["[CLS]   [SEP]\n", "[CLS] Convolutional Neural Networks using Logarithmic Data Representation [ Convolutional Neural Networks using Logarithmic Data Representation Daisuke Miyashitadaisukem@stanford.edu Stanford University, Stanford, CA 94305 USA Toshiba, Kawasaki, Japan Edward H. Leeedhlee@stanford.edu Stanford University, Stanford, CA 94305 USA Boris Murmannmurmann@stanford.edu Stanford University, Stanford, CA 94305 USA deep learning, convolutional neural network, machine learning ] Recent advances in convolutional neural networks have considered model complexity and hardware efficiency to enable deployment onto embedded systems and mobile devices. [SEP]\n", "[CLS] For example, it is now well-known that the arithmetic operations of deep networks can be encoded down to 8-bit fixed-point without significant deterioration in performance. [SEP]\n", "[CLS] However, further reduction in precision down to as low as 3-bit fixed-point results in significant losses in performance. [SEP]\n", "[CLS] In this paper we propose a new data representation that enables state-of-the-art networks to be encoded to 3 bits with negligible loss in classification performance. [SEP]\n", "[CLS] To perform this, we take advantage of the fact that the weights and activations in a trained network naturally have non-uniform distributions. [SEP]\n", "[CLS] Using non-uniform, base-2 logarithmic representation to encode weights, communicate activations, and perform dot-products enables networks to 1) achieve higher classification accuracies than fixed-point at the same resolution and 2) eliminate bulky digital multipliers. [SEP]\n", "[CLS] Finally, we propose an end-to-end training procedure that uses FORMULA  representation at 5-bits, which achieves higher final test accuracy than linear at 5-bits. [SEP]\n", "[CLS] Introduction Deep convolutional neural networks (CNN) have demonstrated state-of-the-art performance in image classification {{cite:4b7430ee-7f60-46e6-bd7a-13b7069ff179}}, {{cite:d1dc862e-ba0a-4bf8-b238-5f429585c2a9}}, {{cite:a2767084-5cc6-467d-a377-db7700412bef}} but have steadily grown in computational complexity. [SEP]\n", "[CLS] For example, the Deep Residual Learning {{cite:a2767084-5cc6-467d-a377-db7700412bef}} set a new record in image classification accuracy at the expense of FORMULA  billion floating-point multiply-and-add operations per forward-pass of an image and 230 MB of memory to store the weights in its 152-layer network. [SEP]\n", "[CLS] In order for these large networks to run in real-time applications such as for mobile or embedded platforms, it is often necessary to use low-precision arithmetic and apply compression techniques. [SEP]\n", "[CLS] Recently, many researchers have successfully deployed networks that compute using 8-bit fixed-point representation {{cite:6100842d-31ba-4376-bc4b-8929047c370c}}, {{cite:cbab1779-81c1-4db1-a11d-22e8ab2aaab7}} and have successfully trained networks with 16-bit fixed point {{cite:d28b7eac-3fe6-4c5e-a807-c23d6a6d8177}}. [SEP]\n", "[CLS] This work in particular is built upon the idea that algorithm-level noise tolerance of the network can motivate simplifications in hardware complexity. [SEP]\n", "[CLS] Interesting directions point towards matrix factorization {{cite:46888da3-658b-4806-9527-6b350f2018d5}} and tensorification {{cite:814c28fd-8bf5-4c05-b42c-b8a1f9474ecc}} by leveraging structure of the fully-connected (FC) layers. [SEP]\n", "[CLS] Another promising area is to prune the FC layer before mapping this to sparse matrix-matrix routines in GPUs {{cite:4db2f2fa-3cc2-40d0-8510-571c392e522b}}. [SEP]\n", "[CLS] However, many of these inventions aim at systems that meet some required and specific criteria such as networks that have many, large FC layers or accelerators that handle efficient sparse matrix-matrix arithmetic. [SEP]\n", "[CLS] And with network architectures currently pushing towards increasing the depth of convolutional layers by settling for fewer dense FC layers {{cite:a2767084-5cc6-467d-a377-db7700412bef}}, {{cite:ef1eddc2-bc11-4f60-8729-d6822e0a4992}}, there are potential problems in motivating a one-size-fits-all solution to handle these computational and memory demands. [SEP]\n", "[CLS] We propose a general method of representing and computing the dot products in a network that can allow networks with minimal constraint on the layer properties to run more efficiently in digital hardware. [SEP]\n", "[CLS] In this paper we explore the use of communicating activations, storing weights, and computing the atomic dot-products in the binary logarithmic (base-2 logarithmic) domain for both inference and training. [SEP]\n", "[CLS] The motivations for moving to this domain are the following:  Training networks with weight decay leads to final weights that are distributed non-uniformly around 0. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Similarly, activations are also highly concentrated near 0. [SEP]\n", "[CLS] Our work uses rectified Linear Units (ReLU) as the non-linearity. [SEP]\n", "[CLS]  Logarithmic representations can encode data with very large dynamic range in fewer bits than can fixed-point representation {{cite:dce227c6-79fd-4e28-8b85-9c7e9f7b87d5}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Data representation in FORMULA -domain is naturally encoded in digital hardware (as shown in Section REF ). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Our contributions are listed:  we show that networks obtain higher classification accuracies with logarithmic quantization than linear quantization using traditional fixed-point at equivalent resolutions. [SEP]\n", "[CLS]  we show that activations are more robust to quantization than weights. [SEP]\n", "[CLS] This is because the number of activations tend to be larger than the number of weights which are reused during convolutions. [SEP]\n", "[CLS]  we apply our logarithmic data representation on state-of-the-art networks, allowing activations and weights to use only 3b with almost no loss in classification performance. [SEP]\n", "[CLS]  we generalize base-2 arithmetic to handle different base. [SEP]\n", "[CLS] In particular, we show that a base-FORMULA  enables the ability to capture large dynamic ranges of weights and activations but also finer precisions across the encoded range of values as well.   [SEP]\n", "[CLS] we develop logarithmic backpropagation for efficient training. [SEP]\n", "[CLS]   Related work Reduced-precision computation. [SEP]\n", "[CLS] {{cite:fe8b7ea0-cafe-43ff-b5b9-bae4f67b0839}}, {{cite:4af0ed70-9692-44e1-8c3a-daaf04d41b51}}, {{cite:6100842d-31ba-4376-bc4b-8929047c370c}}, {{cite:6d7b2199-a2c7-4a71-b16e-c5e74e7741f4}} analyzed the effects of quantizing the trained weights for inference. [SEP]\n", "[CLS] For example, {{cite:4db2f2fa-3cc2-40d0-8510-571c392e522b}} shows that convolutional layers in AlexNet {{cite:4b7430ee-7f60-46e6-bd7a-13b7069ff179}} can be encoded to as little as 5 bits without a significant accuracy penalty. [SEP]\n", "[CLS] There has also been recent work in training using low precision arithmetic. [SEP]\n", "[CLS] {{cite:d28b7eac-3fe6-4c5e-a807-c23d6a6d8177}} propose a stochastic rounding scheme to help train networks using 16-bit fixed-point. [SEP]\n", "[CLS] {{cite:84a56b92-86fc-40d6-9d45-4ad52c8c4e04}} propose quantized back-propagation and ternary connect. [SEP]\n", "[CLS] This method reduces the number of floating-point multiplications by casting these operations into powers-of-two multiplies, which are easily realized with bitshifts in digital hardware. [SEP]\n", "[CLS] They apply this technique on MNIST and CIFAR10 with little loss in performance. [SEP]\n", "[CLS] However, their method does not completely eliminate all multiplications end-to-end. [SEP]\n", "[CLS] During test-time the network uses the learned full resolution weights for forward propagation. [SEP]\n", "[CLS] Training with reduced precision is motivated by the idea that high-precision gradient updates is unnecessary for the stochastic optimization of networks {{cite:917e1436-cf5b-454a-bc8d-01785d1a2bba}}, {{cite:ed264e12-e3ec-4daa-b31e-de02dcc9aceb}}, {{cite:f1d995da-551b-41c9-945b-ad20146c1262}}. [SEP]\n", "[CLS] In fact, there are some studies that show that gradient noise helps convergence. [SEP]\n", "[CLS] For example, {{cite:81c522dd-776f-43af-b63f-93f9cff4b866}} empirically finds that gradient noise can also encourage faster exploration and annealing of optimization space, which can help network generalization performance. [SEP]\n", "[CLS] Hardware implementations. [SEP]\n", "[CLS] There have been a few but significant advances in the development of specialized hardware of large networks. [SEP]\n", "[CLS] For example {{cite:1448b7b9-99be-4eb1-9b5b-8c7e463320d2}} developed Field-Programmable Gate Arrays (FPGA) to perform real-time forward propagation. [SEP]\n", "[CLS] These groups have also performed a comprehensive study of classification performance and energy efficiency as function of resolution. [SEP]\n", "[CLS] {{cite:8bb2bc9f-f405-4484-9f7f-3a9de7e8fef1}} have also explored the design of convolutions in the context of memory versus compute management under the RoofLine model. [SEP]\n", "[CLS] Other works focus on specialized, optimized kernels for general purpose GPUs {{cite:044a755c-3fc1-4a37-bad5-b6697967b049}}. [SEP]\n", "[CLS]  Concept and Motivation FIGURE   [SEP]\n", "[CLS] Each convolutional and fully-connected layer of a network performs matrix operations that distills down to dot products FORMULA , where FORMULA  is the input, FORMULA  the weights, and FORMULA  the activations before being transformed by the non-linearity (e.g. ReLU). [SEP]\n", "[CLS] Using conventional digital hardware, this operation is performed using FORMULA  multiply-and-add operations using floating or fixed point representation as shown in Figure\u00a0REF (a). [SEP]\n", "[CLS] However, this dot product can also be computed in the FORMULA -domain as shown in Figure\u00a0REF (b,c). [SEP]\n", "[CLS] Proposed Method 1. [SEP]\n", "[CLS] The first proposed method as shown in Figure\u00a0REF (b) is to transform one operand to its FORMULA  representation, convert the resulting transformation back to the linear domain, and multiply this by the other operand. [SEP]\n", "[CLS] This is simply FORMULA  where FORMULA , FORMULA  quantizes FORMULA  to an integer, and FORMULA  is the function that bitshifts a value FORMULA  by an integer FORMULA  in fixed-point arithmetic. [SEP]\n", "[CLS] In floating-point, this operation is simply an addition of FORMULA  with the exponent part of FORMULA . [SEP]\n", "[CLS] Taking advantage of the FORMULA  operator to perform multiplication obviates the need for expensive digital multipliers. [SEP]\n", "[CLS] Quantizing the activations and weights in the FORMULA -domain (FORMULA  and FORMULA ) instead of FORMULA  and FORMULA  is also motivated by leveraging structure of the non-uniform distributions of FORMULA  and FORMULA . [SEP]\n", "[CLS] A detailed treatment is shown in the next section. [SEP]\n", "[CLS] In order to quantize, we propose two hardware-friendly flavors. [SEP]\n", "[CLS] The first option is to simply floor the input. [SEP]\n", "[CLS] This method computes FORMULA  by returning the position of the first 1 bit seen from the most significant bit (MSB). [SEP]\n", "[CLS] The second option is to round to the nearest integer, which is more precise than the first option. [SEP]\n", "[CLS] With the latter option, after computing the integer part, the fractional part is computed in order to assert the rounding direction. [SEP]\n", "[CLS] This method of rounding is summarized as follows. [SEP]\n", "[CLS] Pick FORMULA  bits followed by the leftmost 1 and consider it as a fixed point number FORMULA  with 0 integer bit and FORMULA  fractional bits. [SEP]\n", "[CLS] Then, if FORMULA , round FORMULA  up to the nearest integer and otherwise round it down to the nearest integer. [SEP]\n", "[CLS]  Proposed Method 2. [SEP]\n", "[CLS] The second proposed method as shown in Figure\u00a0REF (c) is to extend the first method to compute dot products in the FORMULA -domain for both operands. [SEP]\n", "[CLS] Additions in linear-domain map to sums of exponentials in the FORMULA -domain and multiplications in linear become FORMULA -addition. [SEP]\n", "[CLS] The resulting dot-product is FORMULA  where the FORMULA -domain weights are FORMULA  and FORMULA -domain inputs are FORMULA . [SEP]\n", "[CLS] By transforming both the weights and inputs, we compute the original dot product by bitshifting 1 by an integer result FORMULA  and summing over all FORMULA . [SEP]\n", "[CLS]  Accumulation in FORMULA  domain [SEP]\n", "[CLS] Although Fig.\u00a0REF (b,c) indicates a logarithm-to-linear converter between layers where the actual accumulation is performed in the linear domain, this accumulation is able to be performed in the FORMULA -domain using the approximation FORMULA  for FORMULA . [SEP]\n", "[CLS] For example, let FORMULA , FORMULA , and FORMULA . [SEP]\n", "[CLS] When FORMULA , FORMULA  and for FORMULA  in general, FORMULA   [SEP]\n", "[CLS] Note that FORMULA  preserves the fractional part of the word during accumulation. [SEP]\n", "[CLS] Both accumulation in linear domain and accumulation in FORMULA  domain have its pros and cons. [SEP]\n", "[CLS] Accumulation in linear domain is simpler but requires larger bit widths to accommodate large dynamic range numbers. [SEP]\n", "[CLS] Accumulation in FORMULA  in (REF ) and (REF ) appears to be more complicated, but is in fact simply computed using bit-wise operations in digital hardware.   [SEP]\n", "[CLS] Experiments of Proposed Methods Here we evaluate our methods as detailed in Sections \u00a0REF  and \u00a0REF  on the classification task of ILSVRC-2012 {{cite:1411b890-5842-4bfe-bc04-6365ce1954a4}} using Chainer \u00a0{{cite:e8092a34-8f8b-4fd2-aef1-a54fc233c2e6}}. [SEP]\n", "[CLS] We evaluate method 1 (Section \u00a0REF ) on inference (forward pass) in Section\u00a0REF . [SEP]\n", "[CLS] Similarly, we evaluate method 2 (Section \u00a0REF ) on inference in Sections \u00a0REF  and \u00a0REF . [SEP]\n", "[CLS] For those experiments, we use published models (AlexNet {{cite:4b7430ee-7f60-46e6-bd7a-13b7069ff179}}, VGG16 {{cite:d1dc862e-ba0a-4bf8-b238-5f429585c2a9}}) from the caffe model zoo ({{cite:5feb97e0-a2f1-4acb-9b71-be4ea225ea43}}) without any fine tuning (or extra retraining). [SEP]\n", "[CLS] Finally, we evaluate method 2 on training in Section \u00a0REF . [SEP]\n", "[CLS] Logarithmic Representation of Activations TABLE  TABLE   [SEP]\n", "[CLS] This experiment evaluates the classification accuracy using logarithmic activations and floating point 32b for the weights. [SEP]\n", "[CLS] In similar spirit to that of {{cite:d28b7eac-3fe6-4c5e-a807-c23d6a6d8177}}, we describe the logarithmic quantization layer LogQuant that performs the element-wise operation as follows: FORMULA  where FORMULA   [SEP]\n", "[CLS] These layers perform the logarithmic quantization and computation as detailed in Section \u00a0REF . [SEP]\n", "[CLS] Tables\u00a0REF  and \u00a0REF  illustrate the addition of these layers to the models. [SEP]\n", "[CLS] The quantizer has a specified full scale range, and this range in linear scale is FORMULA , where we express this as simply FORMULA  throughout this paper for notational convenience. [SEP]\n", "[CLS] The FORMULA  values for each layer are shown in Tables\u00a0REF  and \u00a0REF ; they show FORMULA  added by an offset parameter. [SEP]\n", "[CLS] This offset parameter is chosen to properly handle the variation of activation ranges from layer to layer using 100 images from the training set. [SEP]\n", "[CLS] The FORMULA  is a parameter which is global to the network and is tuned to perform the experiments to measure the effect of FORMULA  on classification accuracy. [SEP]\n", "[CLS] The FORMULA  is the number of bits required to represent a number after quantization. [SEP]\n", "[CLS] Note that since we assume applying quantization after ReLU function, FORMULA  is 0 or positive [SEP]\n", "[CLS] and then we use unsigned format without sign bit for activations. [SEP]\n", "[CLS] In order to evaluate our logarithmic representation, we detail an equivalent linear quantization layer described as FORMULA  and where FORMULA   [SEP]\n", "[CLS] Figure\u00a0REF  illustrates the effect of the quantizer on activations following the conv2_2 layer used in VGG16. [SEP]\n", "[CLS] The pre-quantized distribution tends to 0 exponentially, and the FORMULA -quantized distribution illustrates how the FORMULA -encoded activations are uniformly equalized across many output bins which is not prevalent in the linear case. [SEP]\n", "[CLS] Many smaller activation values are more finely represented by FORMULA  quantization compared to linear quantization. [SEP]\n", "[CLS] The total quantization error FORMULA , where FORMULA  is FORMULA  or FORMULA , FORMULA  is the vectorized activations of size FORMULA , is less for the FORMULA -quantized case than for linear. [SEP]\n", "[CLS] This result is illustrated in Figure REF . [SEP]\n", "[CLS] Using linear quantization with step size of 1024, we obtain a distribution of quantization errors that are highly concentrated in the region where FORMULA . [SEP]\n", "[CLS] However, FORMULA  quantization with the FORMULA  as linear results in a significantly lower number of quantization errors in the region FORMULA . [SEP]\n", "[CLS] This comes at the expense of a slight increase in errors in the region FORMULA . [SEP]\n", "[CLS] Nonetheless, the quantization errors FORMULA  for FORMULA  and FORMULA  for linear. [SEP]\n", "[CLS] FIGURE  FIGURE  FIGURE   [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] We run the models as described in Tables\u00a0REF  and \u00a0REF  and test on the validation set without data augmentation. [SEP]\n", "[CLS] We evaluate it with variable FORMULA s and FORMULA s for both quantizer layers. [SEP]\n", "[CLS] Figure\u00a0REF  illustrates the results of AlexNet. [SEP]\n", "[CLS] Using only 3 bits to represent the activations for both logarithmic and linear quantizations, the top-5 accuracy is still very close to that of the original, unquantized model encoded at floating-point 32b. [SEP]\n", "[CLS] However, logarithmic representations tolerate a large dynamic range of FORMULA s. For example, using 4b FORMULA , we can obtain 3 order of magnitude variations in the full scale without a significant loss of top-5 accuracy. [SEP]\n", "[CLS] We see similar results for VGG16 as shown in Figure\u00a0REF . [SEP]\n", "[CLS] Table\u00a0REF  lists the classification accuracies with the optimal FORMULA s for each case. [SEP]\n", "[CLS] There are some interesting observations. [SEP]\n", "[CLS] First, 3b FORMULA  performs FORMULA  worse than 3b linear for AlexNet but FORMULA  better for VGG16, which is a higher capacity network than AlexNet. [SEP]\n", "[CLS] Second, by encoding the activations in 3b FORMULA , we achieve the same top-5 accuracy compared to that achieved by 4b linear for VGG16. [SEP]\n", "[CLS] Third, with 4b FORMULA , there is no loss in top-5 accuracy from the original float32 representation. [SEP]\n", "[CLS] TABLE   Logarithmic Representation of Weights of Fully Connected Layers [SEP]\n", "[CLS] The FC weights are quantized using the same strategies as those in Section \u00a0REF , except that they have sign bit. [SEP]\n", "[CLS] We evaluate the classification performance using FORMULA  data representation for both FC weights and activations jointly using method 2 in Section \u00a0REF . [SEP]\n", "[CLS] For comparison, we use linear for FC weights and FORMULA  for activations as reference. [SEP]\n", "[CLS] For both methods, we use optimal 4b FORMULA  for activations that were computed in Section \u00a0REF . [SEP]\n", "[CLS] Table\u00a0REF  compares the mentioned approaches along with floating point. [SEP]\n", "[CLS] We observe a small FORMULA  win for FORMULA  over linear for AlexNet but a FORMULA  decrease for VGG16. [SEP]\n", "[CLS] Nonetheless, FORMULA  computation is performed without the use of multipliers. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] An added benefit to quantization is a reduction of the model size. [SEP]\n", "[CLS] By quantizing down to 4b FORMULA  including sign bit, we compress the FC weights for free significantly from FORMULA   [SEP]\n", "[CLS] Gb to FORMULA   [SEP]\n", "[CLS] Gb for AlexNet and FORMULA   [SEP]\n", "[CLS] Gb to FORMULA   [SEP]\n", "[CLS] Gb for VGG16. [SEP]\n", "[CLS] This is because the dense FC layers occupy FORMULA  and FORMULA  of the total model size for AlexNet and VGG16 respectively. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Logarithmic Representation of Weights of Convolutional Layers We now represent the convolutional layers using the same procedure. [SEP]\n", "[CLS] We keep the representation of activations at 4b FORMULA  and the representation of weights of FC layers at 4b FORMULA , and compare our FORMULA  method with the linear reference and ideal floating point. [SEP]\n", "[CLS] We also perform the dot products using two different bases: FORMULA . [SEP]\n", "[CLS] Note that there is no additional overhead for FORMULA  base-FORMULA  as it is computed with the same equation shown in Equation REF . [SEP]\n", "[CLS] Table\u00a0REF  shows the classification results. [SEP]\n", "[CLS] The results illustrate an approximate FORMULA  drop in performance from floating point down to 5b base-2 but a relatively minor FORMULA  drop for 5b base-FORMULA . [SEP]\n", "[CLS] They includes sign bit. [SEP]\n", "[CLS] There are also some important observations here. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] We first observe that the weights of the convolutional layers for AlexNet and VGG16 are more sensitive to quantization than are FC weights. [SEP]\n", "[CLS] Each FC weight is used only once per image (batch size of 1) whereas convolutional weights are reused many times across the layer's input activation map. [SEP]\n", "[CLS] Because of this, the quantization error of each weight now influences the dot products across the entire activation volume. [SEP]\n", "[CLS] Second, we observe that by moving from 5b base-2 to a finer granularity such as 5b base-FORMULA , we allow the network to 1) be robust to quantization errors and degradation in classification performance and 2) retain the practical features of FORMULA -domain arithmetic. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The distributions of quantization errors for both 5b base-2 and 5b base-FORMULA  are shown in Figure \u00a0REF . [SEP]\n", "[CLS] The total quantization error on the weights, FORMULA , where FORMULA  is the vectorized weights of size FORMULA , is FORMULA  smaller for base-FORMULA  than for base-2. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Training with Logarithmic Representation We incorporate FORMULA  representation during the training phase. [SEP]\n", "[CLS] This entire algorithm can be computed using Method 2 in Section \u00a0REF . [SEP]\n", "[CLS] Table\u00a0REF  illustrates the networks that we compare. [SEP]\n", "[CLS] The proposed FORMULA  and linear networks are trained at the same resolution using 4-bit unsigned activations and 5-bit signed weights and gradients using Algorithm \u00a0REF  on the CIFAR10 dataset with simple data augmentation described in {{cite:a2767084-5cc6-467d-a377-db7700412bef}}. [SEP]\n", "[CLS] Note that unlike BinaryNet {{cite:cfe1e15c-ec7d-4baf-8b26-cc7350f38721}}, we quantize the backpropagated gradients to train FORMULA -net. [SEP]\n", "[CLS] This enables end-to-end training using logarithmic representation at the 5-bit level. [SEP]\n", "[CLS] For linear quantization however, we found it necessary to keep the gradients in its unquantized floating-point precision form in order to achieve good convergence. [SEP]\n", "[CLS] Furthermore, we include the training curve for BinaryNet, which uses unquantized gradients. [SEP]\n", "[CLS] Fig. \u00a0REF  illustrates the training results of FORMULA , linear, and BinaryNet. [SEP]\n", "[CLS] Final test accuracies for FORMULA -5b, linear-5b, and BinaryNet are FORMULA , FORMULA , FORMULA  respectively where linear-5b and BinaryNet use unquantized gradients. [SEP]\n", "[CLS] The test results indicate that even with quantized gradients, our proposed network with FORMULA  representation still outperforms the others that use unquantized gradients. [SEP]\n", "[CLS] [ht]  a minibatch of inputs and targets FORMULA , previous weights FORMULA . [SEP]\n", "[CLS] updated weights  FORMULA 1. [SEP]\n", "[CLS] Computing the parameters' gradient: 1.1. [SEP]\n", "[CLS] Forward propagation: FORMULA  to FORMULA  FORMULA  FORMULA   FORMULA 1.2. [SEP]\n", "[CLS] Backward propagation: Compute FORMULA  knowing FORMULA  and FORMULA  FORMULA  to 1 FORMULA  FORMULA   FORMULA 2. [SEP]\n", "[CLS] Accumulating the parameters' gradient: FORMULA  to FORMULA  FORMULA   Training a CNN with base-2 logarithmic representation. [SEP]\n", "[CLS] FORMULA  is the softmax loss for each minibatch. [SEP]\n", "[CLS] LogQuant(x) quantizes FORMULA  in base-2 FORMULA -domain. [SEP]\n", "[CLS] The optimization step Update(FORMULA ,FORMULA ) updates the weights FORMULA  based on backpropagated gradients FORMULA . [SEP]\n", "[CLS] We use the SGD with momentum and Adam rule. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Conclusion [SEP]\n", "[CLS] In this paper, we describe a method to represent the weights and activations with low resolution in the FORMULA -domain, which eliminates bulky digital multipliers. [SEP]\n", "[CLS] This method is also motivated by the non-uniform distributions of weights and activations, making FORMULA  representation more robust to quantization as compared to linear. [SEP]\n", "[CLS] We evaluate our methods on the classification task of ILSVRC-2012 using pretrained models (AlexNet and VGG16). [SEP]\n", "[CLS] We also offer extensions that incorporate end-to-end training using FORMULA  representation including gradients. [SEP]\n", "[CLS] TABLE   [SEP]\n"], "1701.08230": ["[CLS]  2017 2017 acmlicensed KDD '17August 13-17, 2017Halifax, NS, Canada15.0010.1145/3097983.3098095 978-1-4503-4887-4/17/08 Algorithmic decision making and the cost of fairness Sam Corbett-Davies  Stanford University   [SEP]\n", "[CLS] scorbett@stanford.edu [SEP]\n", "[CLS] Emma Pierson  Stanford University  emmap1@stanford.edu Avi Feller  Univ. of California, Berkeley   [SEP]\n", "[CLS] afeller@berkeley.edu [SEP]\n", "[CLS] Sharad Goel   [SEP]\n", "[CLS] Stanford University  scgoel@stanford.edu [SEP]\n", "[CLS] Aziz Huq  University of Chicago   [SEP]\n", "[CLS] huq@uchicago.edu Algorithms are now regularly used to decide whether defendants awaiting trial are too dangerous to be released back into the community. [SEP]\n", "[CLS] In some cases, black defendants are substantially more likely than white defendants to be incorrectly classified as high risk. [SEP]\n", "[CLS] To mitigate such disparities, several techniques have recently been proposed to achieve algorithmic fairness. [SEP]\n", "[CLS] Here we reformulate algorithmic fairness as constrained optimization: the objective is to maximize public safety while satisfying formal fairness constraints designed to reduce racial disparities. [SEP]\n", "[CLS] We show that for several past definitions of fairness, the optimal algorithms that result require detaining defendants above race-specific risk thresholds. [SEP]\n", "[CLS] We further show that the optimal unconstrained algorithm requires applying a single, uniform threshold to all defendants. [SEP]\n", "[CLS] The unconstrained algorithm thus maximizes public safety while also satisfying one important understanding of equality: that all individuals are held to the same standard, irrespective of race. [SEP]\n", "[CLS] Because the optimal constrained and unconstrained algorithms generally differ, there is tension between improving public safety and satisfying prevailing notions of algorithmic fairness. [SEP]\n", "[CLS] By examining data from Broward County, Florida, we show that this trade-off can be large in practice. [SEP]\n", "[CLS] We focus on algorithms for pretrial release decisions, but the principles we discuss apply to other domains, and also to human decision makers carrying out structured decision rules. [SEP]\n", "[CLS] <ccs2012> <concept> <conceptid>10003456.10003462</conceptid> <conceptdesc>Social and professional topics\u00a0Computing / technology policy</conceptdesc> <conceptsignificance>500</conceptsignificance> </concept> <concept> <conceptid>10010405.10010455</conceptid> <conceptdesc>Applied computing\u00a0Law, social and behavioral sciences</conceptdesc> <conceptsignificance>500</conceptsignificance> </concept> <concept> <conceptid>10010405.10010481.10010484</conceptid> <conceptdesc> [SEP]\n", "[CLS] Applied computing\u00a0Decision analysis</conceptdesc> <conceptsignificance>500</conceptsignificance> </concept> </ccs2012> Introduction Judges nationwide use algorithms to help decide whether defendants should be detained or released while awaiting trial\u00a0{{cite:0b7a0cda-75f7-4b77-977b-24ac9a58aa61}}, {{cite:724cad2c-56e6-4eb9-baf0-ae117c916332}}. [SEP]\n", "[CLS] One such algorithm, called COMPAS, assigns defendants risk scores between 1 and 10 that indicate how likely they are to commit a violent crime based on more than 100 factors, including age, sex and criminal history. [SEP]\n", "[CLS] For example, defendants with scores of 7 reoffend at twice the rate as those with scores of 3. [SEP]\n", "[CLS] Accordingly, defendants classified as high risk are much more likely to be detained while awaiting trial than those classified as low risk. [SEP]\n", "[CLS] These algorithms do not explicitly use race as an input. [SEP]\n", "[CLS] Nevertheless, an analysis of defendants in Broward County, Florida {{cite:bc53b066-cd8f-4f0c-91e9-df64da0837a4}} revealed that black defendants are substantially more likely to be classified as high risk. [SEP]\n", "[CLS] Further, among defendants who ultimately did not reoffend, blacks were more than twice as likely as whites to be labeled as risky. [SEP]\n", "[CLS] Even though these defendants did not go on to commit a crime, being classified as high risk meant they were subjected to harsher treatment by the courts. [SEP]\n", "[CLS] To reduce racial disparities of this kind, several authors recently have proposed a variety of fair decision algorithms\u00a0{{cite:69f39463-d097-4c53-a16c-fa8692b58fd3}}, {{cite:b8f39a8a-f505-4884-bb90-e771408d21cc}}, {{cite:3a596328-4d78-4ac2-aba6-c60834fbafee}}, {{cite:4f4ea7ff-7218-42ae-8e35-808f750299dd}}, {{cite:1520e5de-071a-4cd9-ac33-8146b27e8ee9}}, {{cite:90bcb3c9-f9e3-45ee-b907-1d44257dbfde}}.We consider racial disparities because they have been at the center of many recent debates in criminal justice, but the same logic applies across a range of possible attributes, including gender. [SEP]\n", "[CLS] Here we reformulate algorithmic fairness as constrained optimization: the objective is to maximize public safety while satisfying formal fairness constraints. [SEP]\n", "[CLS] We show that for several past definitions of fairness, the optimal algorithms that result require applying multiple, race-specific thresholds to individuals' risk scores. [SEP]\n", "[CLS] One might, for example, detain white defendants who score above 4, but detain black defendants only if they score above 6. [SEP]\n", "[CLS] We further show that the optimal unconstrained algorithm requires applying a single, uniform threshold to all defendants. [SEP]\n", "[CLS] This safety-maximizing rule thus satisfies one important understanding of equality: that all individuals are held to the same standard, irrespective of race. [SEP]\n", "[CLS] Since the optimal constrained and unconstrained algorithms in general differ, there is tension between reducing racial disparities and improving public safety. [SEP]\n", "[CLS] By examining data from Broward County, we demonstrate that this tension is more than theoretical. [SEP]\n", "[CLS] Adhering to past fairness definitions can substantially decrease public safety; conversely, optimizing for public safety alone can produce stark racial disparities. [SEP]\n", "[CLS] We focus here on the problem of designing algorithms for pretrial release decisions, but the principles we discuss apply to other domains, and also to human decision makers carrying out structured decision rules. [SEP]\n", "[CLS] We emphasize at the outset that algorithmic decision making does not preclude additional, or alternative, policy interventions. [SEP]\n", "[CLS] For example, one might provide released defendants with robust social services aimed at reducing recidivism, or conclude that it is more effective and equitable to replace pretrial detention with non-custodial supervision. [SEP]\n", "[CLS] Moreover, regardless of the algorithm used, human discretion may be warranted in individual cases. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Background Defining algorithmic fairness Existing approaches to algorithmic fairness typically proceed in two steps. [SEP]\n", "[CLS] First, a formal criterion of fairness is defined; then, a decision rule is developed to satisfy that measure, either exactly or approximately. [SEP]\n", "[CLS] To formally define past fairness measures, we introduce a general notion of (randomized) decision rules. [SEP]\n", "[CLS] Suppose we have a vector FORMULA  that we interpret as the visible attributes of individual FORMULA . [SEP]\n", "[CLS] For example, FORMULA  might represent a defendant's age, gender, race, and criminal history. [SEP]\n", "[CLS] We consider binary decisions (e.g., FORMULA  and FORMULA ), and define a decision algorithm, or a decision rule, to be any function FORMULA  that specifies which action is taken for each individual. [SEP]\n", "[CLS] To allow for probabilistic decisions, we require only that FORMULA . [SEP]\n", "[CLS] [Decision rule] A decision rule is any measurable function FORMULA , where we interpret FORMULA  as the probability that action FORMULA  is taken for an individual with visible attributes FORMULA . [SEP]\n", "[CLS] Before defining algorithmic fairness, we need three additional concepts. [SEP]\n", "[CLS] First, we define the group membership of each individual to take a value from the set FORMULA . [SEP]\n", "[CLS] In most cases, we imagine these groups indicate an individual's race, but they might also represent gender or other protected attributes. [SEP]\n", "[CLS] We assume an individual's racial group can be inferred from their vector of observable attributes FORMULA , and so denote FORMULA 's group by FORMULA . [SEP]\n", "[CLS] For example, if we encode race as a coordinate in the vector FORMULA , then FORMULA  is simply a projection onto this coordinate. [SEP]\n", "[CLS] Second, for each individual, we suppose there is a quantity FORMULA  that specifies the benefit of taking action FORMULA  relative to action FORMULA . [SEP]\n", "[CLS] For simplicity, we assume FORMULA  is binary and normalized to take values 0 and 1, but many of our results can be extended to the more general case. [SEP]\n", "[CLS] For example, in the pretrial setting, it is beneficial to detain a defendant who would have committed a violent crime if released. [SEP]\n", "[CLS] Thus, we might have FORMULA  for those defendants who would have committed a violent crime if released, and FORMULA  otherwise. [SEP]\n", "[CLS] Importantly, FORMULA  is not known exactly to the decision maker, who at the time of the decision has access only to information encoded in the visible features FORMULA . [SEP]\n", "[CLS] Finally, we define random variables FORMULA  and FORMULA  that take on values FORMULA  and FORMULA  for an individual drawn randomly from the population of interest (e.g., the population of defendants for whom pretrial decisions must be made). [SEP]\n", "[CLS] With this setup, we now describe three popular definitions of algorithmic fairness. [SEP]\n", "[CLS]  Statistical parity means that an equal proportion of defendants are detained in each race group\u00a0{{cite:f92bd2d9-6e6f-4020-abdf-bc115113ed65}}, {{cite:69f39463-d097-4c53-a16c-fa8692b58fd3}}, {{cite:ac7281ce-1548-4e73-b92b-57653b27e02c}}, {{cite:7ac2d0a3-4e60-413c-b6cf-fcad9d5cc750}}. [SEP]\n", "[CLS] For example, white and black defendants are detained at equal rates. [SEP]\n", "[CLS] Formally, statistical parity means, FORMULA    [SEP]\n", "[CLS] Conditional statistical parity means that controlling for a limited set of \u201clegitimate\u201d risk factors, an equal proportion of defendants are detained within each race group\u00a0{{cite:b8f39a8a-f505-4884-bb90-e771408d21cc}}, {{cite:793316f4-e7b1-459f-8cd5-c53b55744ed5}}.Conditional statistical parity is closely related to the idea of fairness through blindness, in which one attempts to create fair algorithms by prohibiting use of protected attributes, such as race. [SEP]\n", "[CLS] However, as frequently noted, it is difficult to restrict to \u201clegitimate\u201d features that do not at least partially correlate with race and other protected attributes, and so one cannot be completely \u201cblind\u201d to the sensitive information\u00a0{{cite:793316f4-e7b1-459f-8cd5-c53b55744ed5}}. [SEP]\n", "[CLS] Moreover, unlike the other definitions of fairness, this one does not necessarily reduce racial disparities. [SEP]\n", "[CLS] Conditional statistical parity mitigates these limitations of the blindness approach while preserving its intuitive appeal. [SEP]\n", "[CLS] For example, among defendants who have the same number of prior convictions, black and white defendants are detained at equal rates. [SEP]\n", "[CLS] Suppose FORMULA  is a projection of FORMULA  to factors considered legitimate. [SEP]\n", "[CLS] Then conditional statistical parity means, FORMULA   Predictive equality means that the accuracy of decisions is equal across race groups, as measured by false positive rate (FPR)\u00a0{{cite:3a596328-4d78-4ac2-aba6-c60834fbafee}}, {{cite:ae4a106b-7752-403a-a143-6f445e9d2bd3}}, {{cite:1d5c7663-11ee-400a-8889-6e6b9344575b}}. [SEP]\n", "[CLS] This condition means that among defendants who would not have gone on to commit a violent crime if released, detention rates are equal across race groups. [SEP]\n", "[CLS] Formally, predictive equality means, FORMULA   [SEP]\n", "[CLS] As noted above, a major criticism of COMPAS is that the rate of false positives is higher among blacks than whites\u00a0{{cite:bc53b066-cd8f-4f0c-91e9-df64da0837a4}}. [SEP]\n", "[CLS]   Related work The literature on designing fair algorithms is extensive and interdisciplinary. [SEP]\n", "[CLS] {{cite:199e32aa-be5d-4648-8fee-d8eae48227bb}} and {{cite:32557c06-2ff0-4782-91c2-e8d0843dc17e}} survey various measures of fairness in decision making. [SEP]\n", "[CLS] Here we focus on algorithmic decision making in the criminal justice system, and briefly discuss several interrelated strands of past empirical and theoretical work. [SEP]\n", "[CLS] Statistical risk assessment has been used in criminal justice for nearly one hundred years, dating back to parole decisions in the 1920s. [SEP]\n", "[CLS] Several empirical studies have measured the effects of adopting such decision aids. [SEP]\n", "[CLS] In a randomized controlled trial, the Philadelphia Adult Probation and Parole Department evaluated the effectiveness of a risk assessment tool developed by Berk et al.\u00a0{{cite:6a27a792-d9b5-41d4-8a8a-e5789b3834b6}}, and found the tool reduced the burden on parolees without significantly increasing rates of re-offense\u00a0{{cite:0fe76286-dcf6-4754-9d43-186c2c45587a}}. [SEP]\n", "[CLS] In a study by Danner et al.\u00a0{{cite:4c8ac012-7d12-4c82-b421-520225fc06a7}}, pretrial services agencies in Virginia were randomly chosen to adopt supervision guidelines based on a risk assessment tool. [SEP]\n", "[CLS] Defendants processed by the chosen agencies were nearly twice as likely to be released, and these released defendants were on average less risky than those released by agencies not using the tool. [SEP]\n", "[CLS] We note that despite such aggregate benefits, some have argued that statistical tools do not provide sufficiently precise estimates of individual recidivism risk to ethically justify their use\u00a0{{cite:3426f42a-602b-4954-aee6-d8da9fade110}}.Eric Holder, former Attorney General of the United States, has been similarly critical of risk assessment tools, arguing that \u201c[e]qual justice can only mean individualized justice, with charges, convictions, and sentences befitting the conduct of each defendant and the particular crime he or she commits\u201d\u00a0{{cite:ccbe06cb-d1c3-4e8d-9a19-44d42f24f7d6}}. [SEP]\n", "[CLS] Several authors have developed algorithms that guarantee formal definitions of fairness are satisfied. [SEP]\n", "[CLS] To ensure statistical parity, {{cite:69f39463-d097-4c53-a16c-fa8692b58fd3}} propose \u201crepairing\u201d attributes or risk scores by converting them to within-group percentiles. [SEP]\n", "[CLS] For example, a black defendant riskier than 90% of black defendants would receive the same transformed score as a white defendant riskier than 90% of white defendants. [SEP]\n", "[CLS] A single decision threshold applied to the transformed scores would then result in equal detention rates across groups. [SEP]\n", "[CLS] {{cite:b8f39a8a-f505-4884-bb90-e771408d21cc}} propose a similar method (called \u201clocal massaging\u201d) to achieve conditional statistical parity. [SEP]\n", "[CLS] Given a set of decisions, they stratify the population by \u201clegitimate\u201d factors (such as number of prior convictions), and then alter decisions within each stratum so that: (1) the overall proportion of people detained within each stratum remains unchanged; and (2) the detention rates in the stratum are equal across race groups. [SEP]\n", "[CLS] In their context, they consider human decisions, rather than algorithmic ones, but the same procedure can be applied to any rule. [SEP]\n", "[CLS] Finally, {{cite:3a596328-4d78-4ac2-aba6-c60834fbafee}} propose a method for constructing randomized decision rules that ensure true positive and false positive rates are equal across race groups, a criterion of fairness that they call equalized odds; they further study the case in which only true positive rates must be equal, which they call equal opportunity. [SEP]\n", "[CLS] The definitions of algorithmic fairness discussed above assess the fairness of decisions; in contrast, some authors consider the fairness of risk scores, like those produced by COMPAS. [SEP]\n", "[CLS] The dominant fairness criterion in this case is calibration. [SEP]\n", "[CLS] Calibration is sometimes called predictive parity; we use \u201ccalibration\u201d here to distinguish it from predictive equality, meaning equal false positive rates. [SEP]\n", "[CLS] Calibration means that among defendants with a given risk score, the proportion who reoffend is the same across race groups. [SEP]\n", "[CLS] Formally, given risk scores FORMULA , calibration means, FORMULA   [SEP]\n", "[CLS] Several researchers have pointed out that many notions of fairness are in conflict; {{cite:b7fd7e84-2fb1-4a34-97c9-9440f82292e2}} survey various fairness measures and their incompatibilities. [SEP]\n", "[CLS] Most importantly, {{cite:1d5c7663-11ee-400a-8889-6e6b9344575b}} prove that except in degenerate cases, no algorithm can simultaneously satisfy the following three properties: (1) calibration; (2) balance for the negative class, meaning that among defendants who would not commit a crime if released, average risk score is equal across race group; and (3) balance for the positive class, meaning that among defendants who would commit a crime if released, average risk score is equal across race group. [SEP]\n", "[CLS] {{cite:5e99b90e-14e2-4244-97cf-d6da970bf32f}} similarly considers the tension between calibration and alternative definitions of fairness. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Optimal decision rules Policymakers wishing to satisfy a particular definition of fairness are necessarily restricted in the set of decision rules that they can apply. [SEP]\n", "[CLS] In general, however, multiple rules satisfy any given fairness criterion, and so one must still decide which rule to adopt from among those satisfying the constraint. [SEP]\n", "[CLS] In making this choice, we assume policymakers seek to maximize a specific notion of utility, which we detail below. [SEP]\n", "[CLS] In the pretrial setting, one must balance two factors: the benefit of preventing violent crime committed by released defendants on the one hand, and the social and economic costs of detention on the other. [SEP]\n", "[CLS] Some jurisdictions consider flight risk, but safety is typically the dominant concern. [SEP]\n", "[CLS] To capture these costs and benefits, we define the immediate utility of a decision rule as follows. [SEP]\n", "[CLS] [Immediate utility] For FORMULA  a constant such that FORMULA , the immediate utility of a decision rule FORMULA  is  u(d, c)  = E[ Yd(X) - cd(X) ]  = E [SEP]\n", "[CLS] [ Yd(X) ] - cE[ d(X) ]. [SEP]\n", "[CLS] The first term in Eq.\u00a0() is the expected benefit of the decision rule, and the second term its costs. [SEP]\n", "[CLS] We could equivalently define immediate utility in terms of the relative costs of false positives and false negatives, but we believe our formulation better reflects the concrete trade-offs policymakers face. [SEP]\n", "[CLS] For pretrial decisions, the first term is proportional to the expected number of violent crimes prevented under FORMULA , and the second term is proportional to the expected number of people detained. [SEP]\n", "[CLS] The constant FORMULA  is the cost of detention in units of crime prevented. [SEP]\n", "[CLS] We call this immediate utility to clarify that it reflects only the proximate costs and benefits of decisions. [SEP]\n", "[CLS] It does not, for example, consider the long-term, systemic effects of a decision rule. [SEP]\n", "[CLS] We can rewrite immediate utility as  u(d, c)  = E [SEP]\n", "[CLS] [ E[ Yd(X) - cd(X) X ] ]  = E [SEP]\n", "[CLS] [ pY|X d(X) - cd(X) ]   [SEP]\n", "[CLS] = E[ d(X) (pY|X - c) ]   where FORMULA . [SEP]\n", "[CLS] This latter expression shows that it is beneficial to detain an individual precisely when FORMULA , and is a convenient reformulation for our derivations below. [SEP]\n", "[CLS] Our definition of immediate utility implicitly encodes two important assumptions. [SEP]\n", "[CLS] First, since FORMULA  is binary, all violent crime is assumed to be equally costly. [SEP]\n", "[CLS] Second, the cost of detaining every individual is assumed to be FORMULA , without regard to personal characteristics. [SEP]\n", "[CLS] Both of these restrictions can be relaxed without significantly affecting our formal results. [SEP]\n", "[CLS] In practice, however, it is often difficult to approximate individualized costs and benefits of detention, and so we proceed with this framing of the problem. [SEP]\n", "[CLS] Among the rules that satisfy a chosen fairness criterion, we assume policymakers would prefer the one that maximizes immediate utility. [SEP]\n", "[CLS] For example, if policymakers wish to ensure statistical parity, they might first consider all decision rules that guarantee statistical parity is satisfied, and then adopt the utility-maximizing rule among this subset. [SEP]\n", "[CLS] For the three fairness definitions we consider (statistical parity, conditional statistical parity, and predictive equality) we show next that the optimal algorithms that result are simple, deterministic threshold rules based on FORMULA . [SEP]\n", "[CLS] For statistical parity and predictive equality, the optimal algorithms detain defendants when FORMULA  exceeds a group-specific threshold. [SEP]\n", "[CLS] For example, black defendants might be detained if FORMULA , and white defendants detained if FORMULA . [SEP]\n", "[CLS] The exact thresholds for statistical parity differ from those for predictive equality. [SEP]\n", "[CLS] For conditional statistical parity, the thresholds in the optimal decision rule depend on both group membership and the \u201clegitimate\u201d factors FORMULA . [SEP]\n", "[CLS] Finally, we show that the unconstrained utility-maximizing algorithm applies a single, uniform threshold to all individuals, irrespective of group membership. [SEP]\n", "[CLS] Importantly, since the optimal constrained algorithms differ from the optimal unconstrained algorithm, fairness has a cost. [SEP]\n", "[CLS] To prove these results, we require one more technical criterion: that the distribution of FORMULA  has a strictly positive density on FORMULA . [SEP]\n", "[CLS] Intuitively, FORMULA  is the risk score for a randomly selected individual with visible attributes FORMULA . [SEP]\n", "[CLS] Having a density means that the distribution of FORMULA  does not have any point masses: for example, the probability that FORMULA  exactly equals 0.1 is zero. [SEP]\n", "[CLS] Positivity means that in any sub-interval, there is non-zero (though possibly small) probability an individual has risk score in that interval. [SEP]\n", "[CLS] From an applied perspective, this is a relatively weak condition, since starting from any risk distribution we can achieve this property by smoothing the distribution by an arbitrarily small amount. [SEP]\n", "[CLS] But the criterion serves two important technical purposes. [SEP]\n", "[CLS] First, with this assumption, there are always deterministic decision rules that satisfy each fairness definition; and second, it implies that the optimal decision rules are unique. [SEP]\n", "[CLS] We now state our main theoretical result. [SEP]\n", "[CLS] Suppose FORMULA  has positive density on FORMULA . [SEP]\n", "[CLS] The optimal decision rules FORMULA  that maximize FORMULA  under various fairness conditions have the following form, and are unique up to a set of probability zero. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The unconstrained optimum is FORMULA    [SEP]\n", "[CLS] Among rules satisfying statistical parity, the optimum is FORMULA  where FORMULA  are constants that depend only on group membership. [SEP]\n", "[CLS] The optimal rule satisfying predictive equality takes the same form, though the values of the group-specific thresholds are different.   [SEP]\n", "[CLS] Additionally suppose FORMULA  has positive density on FORMULA . [SEP]\n", "[CLS] Among rules satisfying conditional statistical parity, the optimum is FORMULA  where FORMULA  are constants that depend on group membership and \u201clegitimate\u201d attributes.   [SEP]\n", "[CLS] Before presenting the formal proof of Theorem\u00a0, we sketch out the argument. [SEP]\n", "[CLS] From Eq.\u00a0(), it follows immediately that (unconstrained) utility is maximized for a rule that deterministically detains defendants if and only if FORMULA . [SEP]\n", "[CLS] The optimal rule satisfying statistical parity necessarily detains the same proportion FORMULA  of defendants in each group; it is thus clear that utility is maximized by setting the thresholds so that the riskiest proportion FORMULA  of defendants is detained in each group. [SEP]\n", "[CLS] Similar logic establishes the result for conditional statistical parity. [SEP]\n", "[CLS] (In both cases, our assumption on the distribution of the risk scores ensures these thresholds exist.) The predictive equality constraint is the most complicated to analyze. [SEP]\n", "[CLS] Starting from any non-threshold rule FORMULA  satisfying predictive equality, we show that one can derive a rule FORMULA  satisfying predictive equality such that FORMULA ; this in turn implies a threshold rule is optimal. [SEP]\n", "[CLS] We construct FORMULA  in three steps. [SEP]\n", "[CLS] First, we show that under the original rule FORMULA  there must exist some low-risk defendants that are detained while some relatively high-risk defendants are released. [SEP]\n", "[CLS] Next, we show that if FORMULA  has the same false positive rate as FORMULA , then FORMULA  if and only if more defendants are detained under FORMULA . [SEP]\n", "[CLS] This is because having equal false positive rates means that FORMULA  and FORMULA  detain the same number of people who would not have committed a violent crime if released; under this restriction, detaining more people means detaining more people who would have committed a violent crime, which improves utility. [SEP]\n", "[CLS] Finally, we show that one can preserve false positive rates by releasing the low-risk individuals and detaining an even greater number of the high-risk individuals; this last statement follows because releasing low-risk individuals decreases the false positive rate faster than detaining high-risk individuals increases it. [SEP]\n", "[CLS] As described above, it is clear that threshold rules are optimal absent fairness constraints, and also in the case of statistical parity and conditional statistical parity. [SEP]\n", "[CLS] We now establish the result for predictive equality; we then prove the uniqueness of these rules. [SEP]\n", "[CLS] Suppose FORMULA  is a decision rule satisfying equal false positive rates and which is not equivalent to a multiple-threshold rule. [SEP]\n", "[CLS] We shall construct a new decision rule FORMULA  satisfying equal false positive rates, and such that FORMULA . [SEP]\n", "[CLS] Since this construction shows any non-multiple-threshold rule can be improved, the optimal rule must be a multiple-threshold rule. [SEP]\n", "[CLS] Because FORMULA  is not equivalent to a multiple-threshold rule, there exist relatively low-risk individuals that are detained and relatively high-risk individuals that are released. [SEP]\n", "[CLS] To see this, define FORMULA  to be the threshold that detains the same proportion of group FORMULA  as FORMULA  does: FORMULA   [SEP]\n", "[CLS] Such thresholds exist by our assumption on the distribution of FORMULA . [SEP]\n", "[CLS] Since FORMULA  is not equivalent to a multiple-threshold rule, there must be a group FORMULA  for which, in expectation, some defendants below FORMULA  will be detained and an equal proportion of defendants above FORMULA  released. [SEP]\n", "[CLS] Let FORMULA  equal the proportion of defendants \u201cmisclassified\" (with respect to FORMULA ) in this way:  = E[1{pY|X ta*}(1-d(X)) g(X)=a [SEP]\n", "[CLS] *] = E[1{pY|X< ta*}d(X) g(X)=a*] >0,  where we note that FORMULA . [SEP]\n", "[CLS] For FORMULA , define the rule FORMULA   [SEP]\n", "[CLS] This rule detains  2(t1,t2)=E[1{pY|Xt2}(1-d(X)) g(X)=a [SEP]\n", "[CLS] *]  defendants above the threshold who were released under FORMULA . [SEP]\n", "[CLS] Further,  2(t1,t2) =E[ 1{pY|Xt2}(1-d(X))(1-pY|X) g(X)=a [SEP]\n", "[CLS] *] (1-t2)2(t1,t2)  defendants are newly detained and \u201cinnocent\u201d (i.e., would not have gone on to commit a violent crime). [SEP]\n", "[CLS] Similarly, FORMULA  releases  1(t1,t2)=E[1{pY|X< t1}d(X) g(X)=a [SEP]\n", "[CLS] *]  defendants below the threshold that were detained under FORMULA , resulting in  1(t1,t2) =E [SEP]\n", "[CLS] [ 1{pY|X< t1}d(X)(1-pY|X) g(X)=a [SEP]\n", "[CLS] *] (1-t1)1(t1,t2)  fewer innocent detainees. [SEP]\n", "[CLS] Now choose FORMULA  such that FORMULA   [SEP]\n", "[CLS] Such thresholds exist because: FORMULA , FORMULA , and the functions FORMULA  are continuous in each coordinate. [SEP]\n", "[CLS] Then, FORMULA  and FORMULA , so FORMULA . [SEP]\n", "[CLS] This inequality implies that FORMULA  releases more innocent low-risk people than it detains innocent high-risk people (compared to FORMULA ). [SEP]\n", "[CLS] To equalize false positive rates between FORMULA  and FORMULA  we must equalize FORMULA  and FORMULA , and so we need to decrease FORMULA  in order to release fewer low-risk people. [SEP]\n", "[CLS] Note that FORMULA  is continuous in each coordinate, FORMULA , and FORMULA  depends only on its second coordinate. [SEP]\n", "[CLS] There thus exists FORMULA  such that FORMULA . [SEP]\n", "[CLS] Further, since FORMULA , FORMULA . [SEP]\n", "[CLS] Consequently, FORMULA  has the same false positive rate as FORMULA  but detains more people. [SEP]\n", "[CLS] Finally, since false positive rates are equal, detaining extra people means detaining more people who go on to commit a violent crime. [SEP]\n", "[CLS] As a result FORMULA  has strictly higher immediate utility than FORMULA :  u(d't1',t2,c)-u(d,c)  =E[d't1',t2(X)(pY|X - c)] - E[d(X)(pY|X - c)] = E[d't1',t2(X)(1 - c)] - E[d't1',t2(X)(1 - pY|X)] \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0- E[d(X)(1 - c)] + E[d(X)(1 - pY|X)] = (1-c)( E[d't1',t2(X)]-E[d(X)]) = (1-c)[2(t1',t2)-1(t1',t2)] >0. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The second-to-last equality follows from the fact that FORMULA  and FORMULA  have equal false positive rates, which in turn implies that  E[d't1',t2(X)(1 - pY|X )] = E[d(X)(1 - pY|X )]. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Thus, starting from an arbitrary non-threshold rule satisfying predictive equality, we have constructed a threshold rule with strictly higher utility that also satisfies predictive equality; as a consequence, threshold rules are optimal. [SEP]\n", "[CLS] We now establish uniqueness of the optimal rules for each fairness constraint. [SEP]\n", "[CLS] Optimality for the unconstrained algorithm is clear, and so we consider only the constrained rules, starting with statistical parity. [SEP]\n", "[CLS] Denote by FORMULA   [SEP]\n", "[CLS] the rule that detains the riskiest proportion FORMULA  of individuals in each group [SEP]\n", "[CLS] ; this rule is the unique optimum among those with detention rate FORMULA  satisfying statistical parity. [SEP]\n", "[CLS] Define  f() = u(d, c) = E[d(X)pY|X] - c . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The first term of FORMULA  is strictly concave, because FORMULA  detains progressively less risky people as FORMULA  increases. [SEP]\n", "[CLS] The second term of FORMULA  is linear. [SEP]\n", "[CLS] Consequently, FORMULA  is strictly concave and has a unique maximizer. [SEP]\n", "[CLS] A similar argument shows uniqueness of the optimal rule for conditional statistical parity. [SEP]\n", "[CLS] To establish uniqueness in the case of predictive equality, we first restrict to the set of threshold rules, since we showed above that non-threshold rules are suboptimal. [SEP]\n", "[CLS] Let FORMULA  be the unique, optimal threshold rule having false positive rate FORMULA  in each group. [SEP]\n", "[CLS] Now let FORMULA  be the detention rate under FORMULA . [SEP]\n", "[CLS] Since FORMULA  is strictly increasing, there is a unique, optimal threshold rule FORMULA  that satisfies predictive equality and detains a proportion FORMULA  of defendants: namely, FORMULA . [SEP]\n", "[CLS] Uniqueness now follows by the same argument we gave for statistical parity. [SEP]\n", "[CLS] Theorem\u00a0 shows that threshold rules maximize immediate utility when the three fairness criteria we consider hold exactly. [SEP]\n", "[CLS] Threshold rules are also optimal if we only require the constraints hold approximately. [SEP]\n", "[CLS] For example, a threshold rule maximizes immediate utility under the requirement that false positive rates differ by at most a constant FORMULA  across groups. [SEP]\n", "[CLS] To see this, note that our construction in Theorem\u00a0 preserves false positive rates. [SEP]\n", "[CLS] Thus, starting from a non-threshold rule that satisfies the (relaxed) constraint, one can construct a threshold rule that satisfies the constraint and strictly improves immediate utility, establishing the optimality of threshold rules. [SEP]\n", "[CLS] Threshold rules have been proposed previously to achieve the various fairness criteria we analyze\u00a0{{cite:69f39463-d097-4c53-a16c-fa8692b58fd3}}, {{cite:b8f39a8a-f505-4884-bb90-e771408d21cc}}, {{cite:3a596328-4d78-4ac2-aba6-c60834fbafee}}. [SEP]\n", "[CLS] We note two important distinctions between our work and past research. [SEP]\n", "[CLS] First, the optimality of such algorithms has not been previously established, and indeed previously proposed decision rules are not always optimal. [SEP]\n", "[CLS] Feldman et al.'s\u00a0{{cite:69f39463-d097-4c53-a16c-fa8692b58fd3}} algorithm for achieving statistical parity [SEP]\n", "[CLS] is optimal only if one \u201crepairs\u201d risk scores FORMULA  rather than individual attributes. [SEP]\n", "[CLS] Applying Kamiran et. [SEP]\n", "[CLS] al's local massaging algorithm\u00a0{{cite:b8f39a8a-f505-4884-bb90-e771408d21cc}} for achieving conditional statistical parity yields a non-optimal multiple-threshold rule, even if one starts with the optimal single threshold rule. [SEP]\n", "[CLS] {{cite:3a596328-4d78-4ac2-aba6-c60834fbafee}} hint at the optimality of their algorithm for achieving predictive equality\u2014and in fact their algorithm is optimal\u2014but they do not provide a proof. [SEP]\n", "[CLS] Second, our results clarify the need for race-specific decision thresholds to achieve prevailing notions of algorithmic fairness. [SEP]\n", "[CLS] We thus identify an inherent tension between satisfying common fairness constraints and treating all individuals equally, irrespective of race. [SEP]\n", "[CLS] Our definition of immediate utility does not put a hard cap on the number of people detained, but rather balances detention rates with public safety benefits via the constant FORMULA . [SEP]\n", "[CLS] Proposition\u00a0 below shows that one can equivalently view the optimization problem as maximizing public safety while detaining a specified number of individuals. [SEP]\n", "[CLS] As a consequence, the results in Theorem\u00a0\u2014where immediate utility is maximized under a fairness constraint\u2014also hold when public safety is optimized under constraints on both fairness and the proportion of defendants detained. [SEP]\n", "[CLS] This reformulation is useful for our empirical analysis in Section\u00a0. [SEP]\n", "[CLS] Suppose FORMULA  is the set of decision rules satisfying statistical parity, conditional statistical parity, predictive equality, or the full set of all decision rules. [SEP]\n", "[CLS] There is a bijection FORMULA  on the interval FORMULA  such that FORMULA  where the equivalence of the maximizers in (REF ) is defined up to a set of probability zero. [SEP]\n", "[CLS] Let FORMULA , where FORMULA  is the unique maximizer of FORMULA  under the constraint FORMULA . [SEP]\n", "[CLS] For a fixed FORMULA , if a decision rule maximizes the right-hand side of (REF ) then it is straightforward to see that it also maximizes the left-hand side. [SEP]\n", "[CLS] By uniqueness of the solution to the left-hand side, the solution to the right-hand side is also unique. [SEP]\n", "[CLS] The equality in Eq.\u00a0(REF ) thus holds for all FORMULA . [SEP]\n", "[CLS] It remains to be shown that FORMULA  is a bijection. [SEP]\n", "[CLS] For fixed FORMULA  and FORMULA , the proof of Theorem\u00a0 established that there is a unique, utility-maximizing threshold rule FORMULA  that detains a fraction FORMULA  of individuals. [SEP]\n", "[CLS] Let FORMULA . [SEP]\n", "[CLS] Now,  g'() =  E[Yd(X)-cd(X)] =  (E[Yd(X)]-c)  and so FORMULA  is maximized at FORMULA  such that FORMULA   [SEP]\n", "[CLS] In other words, the optimal detention rate FORMULA  is such that the marginal person detained has probability FORMULA  of reoffending. [SEP]\n", "[CLS] Thus, as FORMULA  decreases, the optimal detention threshold decreases, and the proportion detained increases. [SEP]\n", "[CLS] Consequently, if FORMULA  then FORMULA , and so FORMULA  is injective. [SEP]\n", "[CLS] To show that FORMULA  is surjective, note that FORMULA  and FORMULA ; the result now follows from continuity of FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The cost of fairness As shown above, the optimal algorithms under past notions of fairness differ from the unconstrained solution. [SEP]\n", "[CLS] One can construct examples in which the group-specific thresholds coincide, leading to a single threshold, but it is unlikely for the thresholds to be exactly equal in practice. [SEP]\n", "[CLS] We discuss this possibility further in Section\u00a0. [SEP]\n", "[CLS] Consequently, satisfying common definitions of fairness means one must in theory sacrifice some degree of public safety. [SEP]\n", "[CLS] We turn next to the question of how great this public safety loss might be in practice. [SEP]\n", "[CLS] We use data from Broward County, Florida originally compiled by ProPublica\u00a0{{cite:62147ad9-afea-4c7c-8872-368f7a3567a0}}. [SEP]\n", "[CLS] Following their analysis, we only consider black and white defendants who were assigned COMPAS risk scores within 30 days of their arrest, and were not arrested for an ordinary traffic crime. [SEP]\n", "[CLS] We further restrict to only those defendants who spent at least two years (after their COMPAS evaluation) outside a correctional facility without being arrested for a violent crime, or were arrested for a violent crime within this two-year period. [SEP]\n", "[CLS] Following standard practice, we use this two-year violent recidivism metric to approximate the benefit FORMULA  of detention: we set FORMULA  for those who reoffended, and FORMULA  for those who did not. [SEP]\n", "[CLS] For the 3,377 defendants satisfying these criteria, the dataset includes race, age, sex, number of prior convictions, and COMPAS violent crime risk score (a discrete score between 1 and 10). [SEP]\n", "[CLS] The COMPAS scores may not be the most accurate estimates of risk, both because the scores are discretized and because they are not trained specifically for Broward County. [SEP]\n", "[CLS] Therefore, to estimate FORMULA  we re-train a risk assessment model that predicts two-year violent recidivism using FORMULA -regularized logistic regression followed by Platt scaling\u00a0{{cite:2a9e1f6c-2de7-4879-b957-c3122817b4bd}}. [SEP]\n", "[CLS] The model is based on all available features for each defendant, excluding race. [SEP]\n", "[CLS] Our risk scores achieve higher AUC on a held-out set of defendants than the COMPAS scores (0.75 vs. 0.73). [SEP]\n", "[CLS] We note that adding race to this model does not improve performance, as measured by AUC on the test set. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] We investigate the three past fairness definitions previously discussed: statistical parity, conditional statistical parity, and predictive equality. [SEP]\n", "[CLS] For each definition, we find the set of thresholds that produce a decision rule that: (1) satisfies the fairness definition; (2) detains 30% of defendants; and (3) maximizes expected public safety subject to (1) and (2). [SEP]\n", "[CLS] The proportion of defendants detained is chosen to match the fraction of defendants classified as medium or high risk by COMPAS (scoring 5 or greater). [SEP]\n", "[CLS] Conditional statistical parity requires that one define the \u201clegitimate\u201d factors FORMULA , and this choice significantly impacts results. [SEP]\n", "[CLS] For example, if all variables are deemed legitimate, then this fairness condition imposes no constraint on the algorithm. [SEP]\n", "[CLS] In our application, we consider only a defendant's number of prior convictions to be legitimate; to deal with sparsity in the data, we partition prior convictions into four bins: 0, 1\u20132, 3\u20134, and 5 or more. [SEP]\n", "[CLS] We estimate two quantities for each decision rule: the increase in violent crime committed by released defendants, relative to a rule that optimizes for public safety alone, ignoring formal fairness requirements; and the proportion of detained defendants that are low risk (i.e., would be released if we again considered only public safety). [SEP]\n", "[CLS] We compute these numbers on 100 random train-test splits of the data. [SEP]\n", "[CLS] On each iteration, we train the risk score model and find the optimal thresholds using 70% of the data, and then calculate the two statistics on the remaining 30%. [SEP]\n", "[CLS] Ties are broken randomly when they occur, and we report results averaged over all runs. [SEP]\n", "[CLS] For each fairness constraint, Table\u00a0REF  shows that violent recidivism increases while low risk defendants are detained. [SEP]\n", "[CLS] For example, when we enforce statistical parity, 17% of detained defendants are relatively low risk. [SEP]\n", "[CLS] An equal number of high-risk defendants are thus released (because we hold fixed the number of individuals detained), leading to an estimated 9% increase in violent recidivism among released defendants. [SEP]\n", "[CLS] There are thus tangible costs to satisfying popular notions of algorithmic fairness. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The cost of public safety A decision rule constrained to satisfy statistical parity, conditional statistical parity, or predictive equality reduces public safety. [SEP]\n", "[CLS] However, a single-threshold rule that maximizes public safety generally violates all of these fairness definitions. [SEP]\n", "[CLS] For example, in the Broward County data, optimally detaining 30% of defendants with a single-threshold rule means that 40% of black defendants are detained, compared to 18% of white defendants, violating statistical parity. [SEP]\n", "[CLS] And among defendants who ultimately do not go on to commit a violent crime, 14% of whites are detained compared to 32% of blacks, violating predictive equality. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The reason for these disparities is that white and black defendants in Broward County have different distributions of risk, FORMULA , as shown in Figure 1. [SEP]\n", "[CLS] In particular, a greater fraction of black defendants have relatively high risk scores, in part because black defendants are more likely to have prior arrests, which is a strong indicator of reoffending. [SEP]\n", "[CLS] Importantly, while an algorithm designer can choose different decision rules based on these risk scores, the algorithm cannot alter the risk scores themselves, which reflect underlying features of the population of Broward County. [SEP]\n", "[CLS] Once a decision threshold is specified, these risk distributions determine the statistical properties of the decision rule, including the group-specific detention and false positive rates. [SEP]\n", "[CLS] In theory, it is possible that these distributions line up in a way that achieves statistical parity or predictive equality, but in practice that is unlikely. [SEP]\n", "[CLS] Consequently, any decision rule that guarantees these various fairness criteria are met will in practice deviate from the unconstrained optimum. [SEP]\n", "[CLS] {{cite:1d5c7663-11ee-400a-8889-6e6b9344575b}} establish the incompatibility of different fairness measures when the overall risk FORMULA  differs between groups FORMULA . [SEP]\n", "[CLS] However, the tension we identify between maximizing public safety and satisfying various notions of algorithmic fairness typically persists even if groups have the same overall risk. [SEP]\n", "[CLS] To demonstrate this phenomenon, Figure\u00a0REF  shows risk score distributions for two hypothetical populations with equal average risk. [SEP]\n", "[CLS] Even though their means are the same, the tail of the red distribution is heavier than the tail of the blue distribution, resulting in higher detention and false positive rates in the red group. [SEP]\n", "[CLS] That a single decision threshold can, and generally does, result in racial disparities is closely related to the notion of infra-marginality in the econometric literature on taste-based discrimination\u00a0{{cite:d211952d-1b6e-40ec-8b0c-bf6e892e1c2a}}, {{cite:1bc386b3-e44c-426b-a27f-6155c83ee531}}, {{cite:e4ce830f-ea86-474d-b3ae-7afb34d3ce35}}, {{cite:2e1c8b6b-806f-4edd-ad6b-f824f63de9b5}}. [SEP]\n", "[CLS] In that work, taste-based discrimination\u00a0{{cite:e3f02ec0-a5f8-405d-afdd-2e40ba335866}} is equated with applying decision thresholds that differ by race. [SEP]\n", "[CLS] Their setting is human, not algorithmic, decision making, and so one cannot directly observe the thresholds being applied; the goal is thus to infer the thresholds from observable statistics. [SEP]\n", "[CLS] Though intuitively appealing, detention rates and false positive rates are poor proxies for the thresholds: these infra-marginal statistics consider average risk above the thresholds, and so can differ even if the thresholds are identical (as shown in Figure\u00a0REF ). [SEP]\n", "[CLS] In the algorithmic setting, past fairness measures notably focus on these infra-marginal statistics, even though the thresholds themselves are directly observable. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Detecting discrimination [SEP]\n", "[CLS] The algorithms we have thus far considered output a decision FORMULA  for each individual. [SEP]\n", "[CLS] In practice, however, algorithms like COMPAS typically output a score FORMULA  that is claimed to indicate a defendant's risk FORMULA ; decision makers then use these risk estimates to select an action (e.g., release or detain). [SEP]\n", "[CLS] In some cases, neither the procedure nor the data used to generate these scores is disclosed, prompting worry that the scores are themselves discriminatory. [SEP]\n", "[CLS] To address this concern, researchers often examine whether scores are calibrated\u00a0{{cite:1d5c7663-11ee-400a-8889-6e6b9344575b}}, as defined by Eq.\u00a0(REF ).Some [SEP]\n", "[CLS] researchers also check whether the AUC of scores is similar across race groups\u00a0{{cite:bf8f9be6-6fbd-4a22-a4a1-77f76b7ef9ef}}. [SEP]\n", "[CLS] The theoretical motivation for examining AUC is less clear, since the true risk distributions might have different AUCs, a pattern that would be reproduced in scores that approximate these probabilities. [SEP]\n", "[CLS] In practice, however, one might expect the true risk distributions to yield similar AUCs across race groups\u2014and indeed this is the case for the Broward County data. [SEP]\n", "[CLS] Since the true probabilities FORMULA  are necessarily calibrated, it is reasonable to expect risk estimates that approximate these probabilities to be calibrated as well. [SEP]\n", "[CLS] Figure\u00a0REF  shows that the COMPAS scores indeed satisfy this property. [SEP]\n", "[CLS] For example, among defendants who scored a seven on the COMPAS scale, 60% of white defendants reoffended, which is nearly identical to the 61% percent of black defendants who reoffended. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] However, given only scores FORMULA  and outcomes FORMULA , it is impossible to determine whether the scores are accurate estimates of FORMULA  or have been strategically designed to produce racial disparities. [SEP]\n", "[CLS] {{cite:3a596328-4d78-4ac2-aba6-c60834fbafee}} make a similar observation in their discussion of \u201coblivious\u201d measures. [SEP]\n", "[CLS] Consider a hypothetical situation where a malicious decision maker wants to release all white defendants, even if they are high risk. [SEP]\n", "[CLS] To shield himself from claims of discrimination, he applies a facially neutral 30% threshold to defendants regardless of race. [SEP]\n", "[CLS] Suppose that 20% of blacks recidivate, and the decision-maker's algorithm uses additional information, such as prior arrests, to partition blacks into three risk categories: low risk (10% chance of reoffending), average risk (20% chance), and high risk (40% chance). [SEP]\n", "[CLS] Further suppose that whites are just as risky as blacks overall (20% of them reoffend), but the decision maker ignores individual characteristics and labels every white defendant average risk. [SEP]\n", "[CLS] This algorithm is calibrated, as both whites and blacks labeled average risk reoffend 20% of the time. [SEP]\n", "[CLS] However, all white defendants fall below the decision threshold, so none are detained. [SEP]\n", "[CLS] By systematically ignoring information that could be used to distinguish between white defendants, the decision maker has succeeded in discriminating while using a single threshold applied to calibrated scores. [SEP]\n", "[CLS] Figure\u00a0REF  illustrates a general method for constructing such discriminatory scores from true risk estimates. [SEP]\n", "[CLS] We start by adding noise to the true scores (black curve) of the group that we wish to treat favorably\u2014in the figure we use FORMULA  noise. [SEP]\n", "[CLS] We then use the perturbed scores to predict the outcomes FORMULA  via a logistic regression model. [SEP]\n", "[CLS] The resulting model predictions (red curve) are more tightly clustered around their mean, since adding noise removes information. [SEP]\n", "[CLS] Consequently, under the transformed scores, no one in the group lies above the decision threshold, indicated by the vertical line. [SEP]\n", "[CLS] The key point is that the red curve is a perfectly plausible distribution of risk: without further information, one cannot determine whether the risk model was fit on input data that were truly noisy, or whether noise was added to the inputs to produce disparities. [SEP]\n", "[CLS] These examples relate to the historical practice of redlining, in which lending decisions were intentionally based only on coarse information\u2014usually neighborhood\u2014in order to deny loans to well-qualified minorities\u00a0{{cite:fb2731fd-9a86-464c-8e9f-2c72b7bf9b92}}. [SEP]\n", "[CLS] Since even creditworthy minorities often resided in neighborhoods with low average income, lenders could deny their applications by adhering to a facially neutral policy of not serving low-income areas. [SEP]\n", "[CLS] In the case of redlining, one discriminates by ignoring information about the disfavored group; in the pretrial setting, one ignores information about the favored group. [SEP]\n", "[CLS] Both strategies, however, operate under the same general principle. [SEP]\n", "[CLS] There is no evidence to suggest that organizations have intentionally ignored relevant information when constructing risk scores. [SEP]\n", "[CLS] Similar effects, however, may also arise through negligence or unintentional oversights. [SEP]\n", "[CLS] Indeed, we found in Section\u00a0 that we could improve the predictive power of the Broward County COMPAS scores with a standard statistical model. [SEP]\n", "[CLS] To ensure an algorithm is equitable, it is thus important to inspect the algorithm itself and not just the decisions it produces. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Discussion Maximizing public safety requires detaining all individuals deemed sufficiently likely to commit a violent crime, regardless of race. [SEP]\n", "[CLS] However, to satisfy common metrics of fairness, one must set multiple, race-specific thresholds. [SEP]\n", "[CLS] There is thus an inherent tension between minimizing expected violent crime and satisfying common notions of fairness. [SEP]\n", "[CLS] This tension is real: by analyzing data from Broward County, we find that optimizing for public safety yields stark racial disparities; conversely, satisfying past fairness definitions means releasing more high-risk defendants, adversely affecting public safety. [SEP]\n", "[CLS] Policymakers face a difficult and consequential choice, and it is ultimately unclear what course of action is best in any given situation. [SEP]\n", "[CLS] We note, however, one important consideration: with race-specific thresholds, a black defendant may be released while an equally risky white defendant is detained. [SEP]\n", "[CLS] Such racial classifications would likely trigger strict scrutiny\u00a0{{cite:2d08b03d-cd5b-49cd-be76-23cd2a0a820d}}, the most stringent standard of judicial review used by U.S. courts under the Equal Protection Clause of the Fourteenth Amendment. [SEP]\n", "[CLS] A single-threshold rule thus maximizes public safety while satisfying a core constitutional law rule, bolstering the case in its favor. [SEP]\n", "[CLS] To some extent, concerns embodied by past fairness definitions can be addressed while still adopting a single-threshold rule. [SEP]\n", "[CLS] For example, by collecting more data and accordingly increasing the accuracy of risk estimates, one can lower error rates. [SEP]\n", "[CLS] Further, one could raise the threshold for detaining defendants, reducing the number of people erroneously detained from all race groups. [SEP]\n", "[CLS] Finally, one could change the decision such that classification errors are less costly. [SEP]\n", "[CLS] For example, rather than being held in jail, risky defendants might be required to participate in community supervision programs. [SEP]\n", "[CLS] When evaluating policy options, it is important to consider how well risk scores capture the salient costs and benefits of the decision. [SEP]\n", "[CLS] For example, though we might want to minimize violent crime conducted by defendants awaiting trial, we typically only observe crime that results in an arrest. [SEP]\n", "[CLS] But arrests are an imperfect proxy. [SEP]\n", "[CLS] Heavier policing in minority neighborhoods might lead to black defendants being arrested more often than whites who commit the same crime\u00a0{{cite:35a4d632-d7a5-4ea0-8cd0-040d993e1336}}. [SEP]\n", "[CLS] Poor outcome data might thus cause one to systematically underestimate the risk posed by white defendants. [SEP]\n", "[CLS] This concern is mitigated when the outcome FORMULA  is serious crime\u2014rather than minor offenses\u2014since such incidents are less susceptible to biased observation. [SEP]\n", "[CLS] In particular, {{cite:bf8f9be6-6fbd-4a22-a4a1-77f76b7ef9ef}} note that the racial distribution of individuals arrested for violent offenses is in line with the racial distribution of offenders inferred from victim reports and also in line with self-reported offending data. [SEP]\n", "[CLS] One might similarly worry that the features FORMULA  are biased in the sense that factors are not equally predictive across race groups, a phenomenon known as subgroup validity\u00a0{{cite:d211952d-1b6e-40ec-8b0c-bf6e892e1c2a}}. [SEP]\n", "[CLS] For example, housing stability might be less predictive of recidivism for minorities than for whites. [SEP]\n", "[CLS] If the vector of features FORMULA  includes race, an individual's risk score FORMULA  is in theory statistically robust to this issue, and for this reason some have argued race should be included in risk models\u00a0{{cite:f53d3b27-1d10-4a16-8e05-f7877e4250db}}. [SEP]\n", "[CLS] However, explicitly including race as an input feature raises legal and policy complications, and as such it is common to simply exclude features with differential predictive power\u00a0{{cite:4c8ac012-7d12-4c82-b421-520225fc06a7}}. [SEP]\n", "[CLS] While perhaps a reasonable strategy in practice, we note that discarding information may inadvertently lead to the redlining effects we discuss in Section\u00a0. [SEP]\n", "[CLS] Risk scores might also fail to accurately capture costs in specific, idiosyncratic cases. [SEP]\n", "[CLS] Detaining a defendant who is the sole caretaker of her children arguably incurs higher social costs than detaining a defendant without children. [SEP]\n", "[CLS] Discretionary consideration of individual cases might thus be justified, provided that such discretion does not also introduce bias. [SEP]\n", "[CLS] Further, the immediate utility of a decision rule might be a poor measure of its long-term costs and benefits. [SEP]\n", "[CLS] For example, in the context of credit extensions, offering loans preferentially to minorities might ultimately lead to a more productive distribution of wealth, combating harms from historical under-investment in minority communities. [SEP]\n", "[CLS] Finally, we note that some decisions are better thought of as group rather than individual choices, limiting the applicability of the framework we have been considering. [SEP]\n", "[CLS] For example, when universities admit students, they often aim to select the best group, not simply the best individual candidates, and may thus decide to deviate from a single-threshold rule in order to create diverse communities with varied perspectives and backgrounds {{cite:b8a5a305-2d59-4321-a8d8-51417663a758}}. [SEP]\n", "[CLS] Experts increasingly rely on algorithmic decision aids in diverse settings, including law enforcement, education, employment, and medicine\u00a0{{cite:e5ff3a4b-608c-4985-8443-c70cd135c4ed}}, {{cite:e091f10e-eca5-49bc-bae5-757188498607}}, {{cite:05252478-cb20-48f3-8b08-960dcf7efc25}}, {{cite:7d968e4f-6cbe-48ef-9f32-0e0f1da8deb0}}, {{cite:2fc83edd-5e0c-4853-896e-8bfc602e2d1a}}. [SEP]\n", "[CLS] Algorithms have the potential to improve the efficiency and equity of decisions, but their design and application raise complex questions for researchers and policymakers. [SEP]\n", "[CLS] By clarifying the implications of competing notions of algorithmic fairness, we hope our analysis fosters discussion and informs policy. [SEP]\n", "[CLS] We thank Imanol Arrieta Ibarra, Ang\u00e8le Christin, Alexander Gelber, Andrew Gelman, Jan Overgoor, Ravi Shroff, and Jennifer Skeem for their helpful comments. [SEP]\n", "[CLS] This work was supported in part by the John S. and James L. Knight Foundation, and by the Hellman Fellows Fund. [SEP]\n", "[CLS] Data and code to reproduce our results are available at https://github.com/5harad/cost-of-fairness. [SEP]\n"], "1811.06817": ["[CLS]   [SEP]\n", "[CLS] Evaluating Uncertainty Quantification in End-to-End Autonomous Driving Control Rhiannon Michelmore1, Marta Kwiatkowska1, Yarin Gal1 1University of Oxford, UK 1firstname.lastname@cs.ox.ac.uk A rise in popularity of Deep Neural Networks (DNNs), attributed to more powerful GPUs and widely available datasets, has seen them being increasingly used within safety-critical domains. [SEP]\n", "[CLS] One such domain, self-driving, has benefited from significant performance improvements, with millions of miles having been driven with no human intervention. [SEP]\n", "[CLS] Despite this, crashes and erroneous behaviours still occur, in part due to the complexity of verifying the correctness of DNNs and a lack of safety guarantees. [SEP]\n", "[CLS] In this paper, we demonstrate how quantitative measures of uncertainty can be extracted in real-time, and their quality evaluated in end-to-end controllers for self-driving cars. [SEP]\n", "[CLS] To this end we utilise a recent method for gathering approximate uncertainty information from DNNs without changing the network's architecture. [SEP]\n", "[CLS] We propose evaluation techniques for the uncertainty on two separate architectures which use the uncertainty to predict crashes up to five seconds in advance. [SEP]\n", "[CLS] We find that mutual information, a measure of uncertainty in classification networks, is a promising indicator of forthcoming crashes. [SEP]\n", "[CLS] Introduction Deep learning, and in particular Deep Neural Networks (DNNs), have seen a surge in popularity over the past decade, and their use has become widespread in many fields. [SEP]\n", "[CLS] This increase in popularity, attributed to (i) more powerful GPU implementations and (ii) the availability of large amounts of data, has led to significant performance gains. [SEP]\n", "[CLS] DNNs are now being deployed in safety-critical systems such as medical diagnosis and, in particular, autonomous cars. [SEP]\n", "[CLS] The latter are computationally efficient and have driven millions of miles without human intervention {{cite:188a2811-e049-4b8f-b892-08623066b75c}}, {{cite:9f4b68f0-8c25-45ff-9806-983d8375d66c}}, but offer few safety guarantees. [SEP]\n", "[CLS] Our lack of understanding of how DNNs work {{cite:dca57292-a48d-4e9d-b215-9b5703eb9d53}}, paired with the prohibitive difficulty of verifying the correctness of DNNs of this magnitude {{cite:ae44696f-5265-4dd8-b866-36e797e09895}}, has led to erroneous edge-case behaviours and unforeseen consequences. [SEP]\n", "[CLS] Most notably, there have been crashes involving autonomous cars that were a direct result of the self-driving system malfunctioning. [SEP]\n", "[CLS] In May 2016, the autopilot feature of a Tesla Model S caused a fatal accident when it failed to distinguish the white side of a truck against the bright sky {{cite:c2f85fa7-ec74-46a4-a7d8-3c8499e906c6}}. [SEP]\n", "[CLS] It is clear that, although DNNs are said to perform as well as humans, there are still erroneous edge-case behaviours which need to be detected, analysed and ultimately eliminated. [SEP]\n", "[CLS] In this paper, we focus on end-to-end controllers for self-driving cars, that is, DNNs mapping raw pixels from a front-facing camera directly to steering instructions. [SEP]\n", "[CLS] End-to-end learning-based approaches have been used in several existing autonomous vehicle control systems, including the DARPA Autonomous Vehicle (DAVE) project {{cite:c2d80cbf-4725-42bd-af22-6e8e7389b9db}}, and more recently in NVIDIA's PilotNet (formally known as DAVE-2) {{cite:52ae3c8b-1d66-4c45-9f49-09634009d648}}. [SEP]\n", "[CLS] The motivation for using an end-to-end controller is to remove the need for complex, specifically coded scenarios, instead allowing the network to define its own features based on training. [SEP]\n", "[CLS] When the entire control system is an end-to-end controller (a DNN), as opposed to a collection of subsystems, techniques such as uncertainty estimation can be employed to more accurately assess the controllers confidence in the decisions {{cite:3556c54b-fb7d-44cc-b424-3d01618376b0}}. [SEP]\n", "[CLS] Model uncertainty is a measure of how unsure a DNN model is in its prediction, and can be used to understand if a model is under- or over-confident, as well as to determine regions of input where more training data is required {{cite:3d2aaf98-4614-4a6e-ac6e-a2ac84a4b235}}. [SEP]\n", "[CLS] With certain DNN activation functions such as ReLU, model uncertainty increases as the input moves further from the training data; this information can be used to augment the training data accordingly. [SEP]\n", "[CLS] A recent technique from Gal and Ghahramani {{cite:fa6d83cb-dfa4-47c7-9460-221ff2522ef1}} provides a simple, real-time method to extract an estimation of model uncertainty using any stochastic regularisation technique, which are a common feature of modern DNN models. [SEP]\n", "[CLS] This technique, and dropout, our stochastic regularisation technique of choice, will be explained in detail in Section\u00a0REF . [SEP]\n", "[CLS] The motivation behind modelling uncertainty is to improve safety by creating systems that take into account the confidence of the model at each stage to avoid error propagation {{cite:3556c54b-fb7d-44cc-b424-3d01618376b0}}. [SEP]\n", "[CLS] A meaningful measure of system uncertainty can be used as a basis for safe decisions. [SEP]\n", "[CLS] This paper proposes quantitative evaluations of uncertainty for use within end-to-end controllers for self-driving cars. [SEP]\n", "[CLS] The key contributions are:   [SEP]\n", "[CLS] We demonstrate how quantitative measures of uncertainty can be extracted in real-time from end-to-end controllers. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We show how uncertainty thresholds can be chosen and used to alert the operator to areas of low model confidence. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We evaluate the techniques on two modified PilotNet {{cite:9a3ed274-1b9a-4268-aa24-764b79688aca}} architectures, for both regression and classification settings, within a driving simulator. [SEP]\n", "[CLS] We demonstrate how to train these networks and how to select hyper-parameters. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We present preliminary results that show significant changes in uncertainty, specifically mutual information, up to five seconds before crashes. [SEP]\n", "[CLS]   Related Work With the exception of {{cite:e8d7118e-e3a5-4200-8e45-07b6e32c2051}}, {{cite:78b73f5f-147c-49eb-879e-1310ed2a5119}}, DNN-based approaches for autonomous driving do not often consider model uncertainty. [SEP]\n", "[CLS] Recent work by Yang et al {{cite:818a348c-7f84-4bac-87f6-f127c5111b06}} has seen the addition of discrete speed control prediction, along with steering angle prediction, to end-to-end controllers for self-driving cars. [SEP]\n", "[CLS] Their work aims to make DNN-based controllers more viable, as steering angle alone is not sufficient for vehicle control. [SEP]\n", "[CLS] The resulting multi-modal multi-task network was shown to predict both steering angle and speed commands accurately, but does not include the use of uncertainty for any means. [SEP]\n", "[CLS] Kendall et al's paper on pixel-wise semantic segmentation {{cite:e8d7118e-e3a5-4200-8e45-07b6e32c2051}} utilised model uncertainty to improve segmentation performance. [SEP]\n", "[CLS] In addition to this, they were able to show that the highest areas of uncertainty occurred on class boundaries. [SEP]\n", "[CLS] These results were reinforced by Kampffmeyer et al {{cite:3540c01c-aa7a-413a-bfa3-3f5b10c850ff}} which considers several other methods and also concludes that uncertainty maps are a good measure of uncertainty in segmented images. [SEP]\n", "[CLS] In 2016, Kendall and Cipolla {{cite:78b73f5f-147c-49eb-879e-1310ed2a5119}} developed tools for the localisation of a car given a forward facing photo. [SEP]\n", "[CLS] They found that model uncertainty correlated to positional error; test photos with strong occlusion resulted in high uncertainty and the uncertainty displayed a linearly increasing trend with the distance from the training set.   [SEP]\n", "[CLS] Background End-to-end controllers for self-driving An end-to-end controller is a controller in which the end-to-end process, from sensors to actuation, involves a single DNN without modularisation. [SEP]\n", "[CLS] In the context of self-driving, the sensors might include camera input, infrared (IR) sensors, light detection and range sensors (LiDAR), or a combination of these in addition to many others. [SEP]\n", "[CLS] The outputs are typically steering angle, braking and acceleration values. [SEP]\n", "[CLS] In this paper, we focus on up to three camera inputs, placed on the front of the car facing forwards. [SEP]\n", "[CLS] The input to the network is therefore up to three images, and the output is the desired steering angle. [SEP]\n", "[CLS] A typical feed-forward DNN consists of layers of neurons; these neurons are connected via edges to neurons in different layers. [SEP]\n", "[CLS] Each edge has a corresponding weight and each neuron sums together the product of each input FORMULA  and edge weight FORMULA , then applies a non-linear activation function FORMULA  over the result: FORMULA . [SEP]\n", "[CLS] Common choices for activation functions include the sigmoid function {{cite:45dab253-baf2-4bf3-8052-eb5160f4e85a}} and the Rectified Linear Unit (ReLU) {{cite:2bf8c6a9-3a75-4e45-85e0-e1bddabfe07f}}. [SEP]\n", "[CLS] Networks intended for regression tasks have one output per continuous value to be predicted, and a common loss function for optimisation is the mean squared loss. [SEP]\n", "[CLS] Classification problems, in general, have as many neurons in the output layer as classes, and the final layer's activation function is a \u201csoftmax\u201d function (see Equation\u00a0REF ). [SEP]\n", "[CLS] The most common loss function for classification is the cross-entropy loss. [SEP]\n", "[CLS] For more detail, we refer the interested reader to {{cite:31f7d979-28eb-40f6-97d0-7018f10d1384}}. [SEP]\n", "[CLS] FORMULA   [SEP]\n", "[CLS] Convolutional neural networks (CNNs) are commonly used in self-driving and other image recognition tasks as they reduce the number of network parameters, reduce training time and prevent overfitting {{cite:31f7d979-28eb-40f6-97d0-7018f10d1384}}. [SEP]\n", "[CLS] CNNs differ from DNNs in that they include convolution layer(s). [SEP]\n", "[CLS] The output of a neuron in a convolution layer is computed using only a small region (window) of the layer before it is combined using a convolution kernel. [SEP]\n", "[CLS] This closely resembles the human visual system, suggesting that CNNs are well suited for vision based tasks {{cite:31f7d979-28eb-40f6-97d0-7018f10d1384}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Bayesian uncertainty estimation [SEP]\n", "[CLS] In many fields, uncertainty is used to determine the dependability of a model. [SEP]\n", "[CLS] In self-driving, if the training set of a model consisted of only images from highways and the model was then given an image of a dirt track, the model would return a steering angle but we would ideally require the model to have high uncertainty as it would not have seen this type of image before. [SEP]\n", "[CLS] In classification problems, the softmax probabilities are not enough to indicate whether the model is confident in its prediction, as a standard model would pass the predictive mean (a point estimate) through the softmax rather than the whole predictive distribution {{cite:0ab4efda-09ba-4429-8f92-41187fc3b82e}}. [SEP]\n", "[CLS] This leads to high probabilities (confidence) on points far from the training data. [SEP]\n", "[CLS] The above was an example of out-of-distribution test data. [SEP]\n", "[CLS] Other examples of sources of uncertainty include noisy data, and situations where many models explain the same dataset equally (model parameter uncertainty). [SEP]\n", "[CLS] Noisy data is an example of aleatoric uncertainty, whereas model parameter uncertainty is an example of model uncertainty (or epistemic uncertainty) {{cite:3d2aaf98-4614-4a6e-ac6e-a2ac84a4b235}}, the confidence the model has in its prediction, which is what this paper focuses on. [SEP]\n", "[CLS] A recent technique from Gal and Ghahramani {{cite:fa6d83cb-dfa4-47c7-9460-221ff2522ef1}} allows the gathering of approximate uncertainty information from DNNs without changing the architecture (given that some stochastic regularisation technique such as dropout has been used). [SEP]\n", "[CLS] Dropout is a regularisation technique that sets 1-p proportion of the dropout layers' input to be 0, where p is the dropout probability {{cite:149c16c5-20a4-4db5-b2e5-cceb1e2962ae}}. [SEP]\n", "[CLS] The dropped weights are often scaled by 1/p to maintain constant output magnitude. [SEP]\n", "[CLS] It has been shown that a network that uses dropout is an approximation to a Gaussian process {{cite:fa6d83cb-dfa4-47c7-9460-221ff2522ef1}}. [SEP]\n", "[CLS] Equation\u00a0REF  shows how a prediction can be performed with a Gaussian process, where f is the space of functions, X is the training data and Y is the training outputs. [SEP]\n", "[CLS] The expectation of y* is called the predictive mean of the model and the variance is the predictive uncertainty. [SEP]\n", "[CLS] FORMULA   [SEP]\n", "[CLS] For a regression network, Equations REF  and REF  are used to obtain an approximation of the predictive mean and variance of the Gaussian process that the network is an approximation of. [SEP]\n", "[CLS] FORMULA  FORMULA   [SEP]\n", "[CLS] The set FORMULA  of size FORMULA  is the results from FORMULA  stochastic forward passes through the network. [SEP]\n", "[CLS] It is important that the non-determinism from dropout is retained at prediction time to ensure different units will be dropped per pass through. [SEP]\n", "[CLS] Relating back to the Gaussian process, these are empirical samples from the approximate predictive distribution seen in Equation\u00a0REF . [SEP]\n", "[CLS] FORMULA  relates to the precision of the Gaussian process model, and is used in the calculation of the predictive variance. [SEP]\n", "[CLS] FORMULA  can be calculated as seen in Equation\u00a0REF , where FORMULA  is a user-defined length scale, FORMULA  is the probability of units not being dropped, FORMULA  is the number of training samples and FORMULA  is multiplier used in the L2 regularisation of the network. [SEP]\n", "[CLS] FORMULA   [SEP]\n", "[CLS] A small length-scale (corresponding to high frequency data) with high FORMULA  (corresponding to small observation noise) will lead to a small weight-decay, which might mean the model fits the data well but generalises badly. [SEP]\n", "[CLS] Conversely, a large length-scale and low FORMULA  will lead to strong regularisation. [SEP]\n", "[CLS] There is a trade-off between length-scale and model precision. [SEP]\n", "[CLS] In practice, the model precision FORMULA  is often found by grid searching over the weight decay FORMULA  to minimise validation error, choosing a length-scale that correctly describes the data, and then putting the values into Equation\u00a0REF . [SEP]\n", "[CLS] It can also be found by grid searching over FORMULA  values directly. [SEP]\n", "[CLS] For classification tasks, there are several methods of obtaining uncertainty information. [SEP]\n", "[CLS] As previously mentioned, softmax probabilities are a poor indicator as they are the result of a single deterministic pass of a point estimate through the network, which can lead to high confidence on points far from the training data {{cite:3d2aaf98-4614-4a6e-ac6e-a2ac84a4b235}}. [SEP]\n", "[CLS] The three approaches used in this paper to summarise classification uncertainty are variation ratios {{cite:93d324b1-47ab-48b3-b946-b4ada4271602}}, predictive entropy {{cite:fde7939c-be8d-4ee6-8175-b40c9c0d1180}} and mutual information {{cite:fde7939c-be8d-4ee6-8175-b40c9c0d1180}}. [SEP]\n", "[CLS] Variation ratio is a measure of dispersion, its value is high when classes are more equally likely and low when there is a clear winner. [SEP]\n", "[CLS] Variation ratio, as with predictive uncertainty in regression tasks, requires FORMULA  stochastic forward passes through the network for a test input FORMULA . [SEP]\n", "[CLS] A set of FORMULA  labels FORMULA  is collected, where FORMULA  is the class with the highest softmax output of that pass through. [SEP]\n", "[CLS] The mode of the distribution FORMULA  and the number of times it was sampled FORMULA  can then be used to obtain the variation ratio. [SEP]\n", "[CLS] These calculations can be seen in Equations REF , REF  and REF . [SEP]\n", "[CLS] FORMULA  FORMULA  FORMULA   [SEP]\n", "[CLS] Predictive entropy captures the average amount of information present in the predictive distribution, FORMULA . [SEP]\n", "[CLS] In our setting the predictive entropy can be approximated by collecting the softmax probability vectors over FORMULA  stochastic forward passes, and for each class, averaging the softmax probability and multiplying it by the log of that average. [SEP]\n", "[CLS] This can be seen in Equations\u00a0REF  and REF , where FORMULA  is the network with model parameters FORMULA . [SEP]\n", "[CLS] FORMULA  FORMULA   [SEP]\n", "[CLS] The final measure is mutual information, FORMULA . [SEP]\n", "[CLS] Test points that maximise mutual information are points on which the model is uncertain on average, but there are model parameters that erroneously produce high confidence predictions. [SEP]\n", "[CLS] Mutual information is calculated similarly to predictive entropy, but with an extra term as seen in Equation\u00a0REF . [SEP]\n", "[CLS] FORMULA   [SEP]\n", "[CLS] Variation ratios and predictive entropy are both measures of predictive uncertainty, whereas mutual information is a measure of the model's confidence in its output. [SEP]\n", "[CLS] Further information on this can be found in {{cite:3d2aaf98-4614-4a6e-ac6e-a2ac84a4b235}}. [SEP]\n", "[CLS] Having multiple measures of uncertainty is arguably more powerful than the sole measure available for regression tasks, as it allows for different types of uncertainty to be captured and gives us more information about the performance of the model. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Methodology To investigate evaluation techniques of uncertainty in end-to-end controllers for self-driving, we must (i) explore the different types of uncertainty available from different network architectures, (ii) assess the suitability of each network architecture as a function of accuracy and uncertainty type, (iii) calibrate thresholds for these uncertainties, and (iv) study uncertainty levels in real-time in a simulator. [SEP]\n", "[CLS] Network setup As mentioned above, the inputs in our scenario are images, of size 66x200x3 (RGB colour channels are retained), from the Udacity self-driving car simulator {{cite:aa3e8377-af93-4a27-b7ab-36a01dc9f6cc}}. [SEP]\n", "[CLS] Our desired output is a steering angle. [SEP]\n", "[CLS] The simulator only allows for angles between -25 and +25 degrees so the network is limited to this range of values. [SEP]\n", "[CLS] We use two networks in this work, one that treats the problem of predicting a steering angle as a regression problem and one that treats it as a classification problem. [SEP]\n", "[CLS] Traditionally, steering angle prediction has been treated as a regression problem. [SEP]\n", "[CLS] However, it has been shown that posing regression tasks as classification tasks often shows improvement over direct regression training {{cite:d979df6b-8365-4b40-ba68-60461dbd6b74}}. [SEP]\n", "[CLS] In addition to this, although theoretically continuous, steering angle in the real-world is commonly a discrete variable due to mechanical limitations. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The architecture of our regression network. [SEP]\n", "[CLS] ReLU is used as the activation function, and dropout is applied after every layer but the first and last with probability FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Both architectures are heavily based on NVIDIA's end-to-end self-driving controller PilotNet {{cite:9a3ed274-1b9a-4268-aa24-764b79688aca}}. [SEP]\n", "[CLS] The architecture of the regression network, seen in Figure\u00a0REF , has additional dropout layers after every layer but the first and last, with probability FORMULA . [SEP]\n", "[CLS] An L2 regularizer with scale factor FORMULA  was used on every layer but the final, and the ReLU activation function (FORMULA ) was used throughout. [SEP]\n", "[CLS] The loss function used was mean square error. [SEP]\n", "[CLS] In calculating FORMULA , the value FORMULA  was selected after a grid search experiment, because it, along with the value selected for FORMULA , produced the highest accuracy out of the values searched over and matched values used in similar experiments {{cite:fa6d83cb-dfa4-47c7-9460-221ff2522ef1}}. [SEP]\n", "[CLS] In order to frame the problem of predicting steering angles as a classification problem, the training angles were bucketed into one of two-hundred intervals (classes). [SEP]\n", "[CLS] As the simulator has a limit of -25 degrees to +25 degrees, each bucket has a precision of 0.25 degrees. [SEP]\n", "[CLS] The architecture of the classification network can be seen in Figure\u00a0REF ; it also uses ReLU activation functions, but has a softmax final layer and uses the categorical cross-entropy loss function. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The architecture of our classification network. [SEP]\n", "[CLS]   Network training Both networks were trained on a dataset of 24,496 images taken from the front centre of the car, with a random 20% reserved for testing. [SEP]\n", "[CLS] 8037 of these images came from the training dataset included in the Udacity self-driving car challenge {{cite:aa3e8377-af93-4a27-b7ab-36a01dc9f6cc}}, the rest from data collected by the authors. [SEP]\n", "[CLS] The data was then augmented by mirroring each image horizontally and multiplying the steering angles by -1. [SEP]\n", "[CLS] For the classification task, the steering angles were further bucketed into their closest 0.25 degree interval. [SEP]\n", "[CLS] The speed of the car in both data collection and testing was around 15mph. [SEP]\n", "[CLS] Further data augmentation can be done, as the simulator produces images from cameras at the left and right of the car, as well as the front centre. [SEP]\n", "[CLS] These additional images can be used with the original steering angle +/- a small correction resulting from the deviation from the centre of the car to the camera. [SEP]\n", "[CLS] It was found that, in this case, adding the extra images did not change the accuracy of the network sufficiently enough to include them so they were omitted. [SEP]\n", "[CLS] Both networks were trained for 50 epochs with batch size 128. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Uncertainty extraction At test time, each image FORMULA  was copied FORMULA  times into an array FORMULA  which was passed to the network for prediction. [SEP]\n", "[CLS] Non-determinism was retained by running the network in training mode. [SEP]\n", "[CLS] Higher FORMULA  increases processing time but returns a more accurate representation of the predictive distribution. [SEP]\n", "[CLS] The value of FORMULA  used here was 128 to match a single batch size; this provides a good trade-off between processing time and accuracy. [SEP]\n", "[CLS] For regression, this resulted in a 128 length vector where the returned prediction was the mean (as in Equation\u00a0REF ) and the variance was calculated according to Equation\u00a0REF . [SEP]\n", "[CLS] The value of FORMULA  was 0.00328. [SEP]\n", "[CLS] For classification, this resulted in a 128x200 matrix where each of the 128 rows represents the softmax output for that particular pass through the network. [SEP]\n", "[CLS] The mode of the maximum value in each row was taken to be the steering angle prediction, and the three types of uncertainty defined in Section\u00a0REF  were calculated as seen in Equations REF , REF  and REF . [SEP]\n", "[CLS] We found that extracting uncertainty information in real-time was achievable if the number of stochastic forward passes was limited to a single batch size. [SEP]\n", "[CLS] The simulator sends an average of 6 frames per second to the receiver and we were able to consistently match this rate on a desktop PC with an Intel Core i5-6600 processor and 16GB RAM. [SEP]\n", "[CLS]  Uncertainty evaluations [SEP]\n", "[CLS] In order for uncertainty information to be useful, we examined two scenarios: whether any uncertainty measure is significantly higher in places where the predicted angle is visually incorrect, and whether any uncertainty measure is significantly higher before a crash. [SEP]\n", "[CLS] These two scenarios define our evaluation metrics. [SEP]\n", "[CLS] Evaluation Metric One [SEP]\n", "[CLS] For the first of the two investigations, manually labelled ground truth data was collected by writing a program to overlay the networks' predicted angles on the input images. [SEP]\n", "[CLS] It was then possible to manually decide whether the angle was \u201csafe\u201d or would lead to a crash, which was recorded to disk. [SEP]\n", "[CLS] The criterion for \u201csafe\u201d was if, at the end of a straight line from the centre of the car at the predicted angle, the car did not deviate from the road (see Figure\u00a0REF ). [SEP]\n", "[CLS] The length of the straight line represents roughly 3 seconds of travel in the same direction but this will vary as the simulator car does not always travel at a constant speed and this cannot be controlled (only throttle value can be specified). [SEP]\n", "[CLS] Another criterion for \u201csafe\u201d was briefly explored, where a curved line was drawn, to represent the car continuing to turn at the specified steering angle. [SEP]\n", "[CLS] [] FIGURE   [SEP]\n", "[CLS] [] FIGURE  (a) An image generated by the manual labelling program and classification network that was marked \u201csafe\u201d. [SEP]\n", "[CLS] (b) An image marked \u201cunsafe\u201d. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] After manually labelling a set of 200 randomly selected images from the test set, ROC curves comparing the true and false positive rates for a range of uncertainty thresholds were generated. [SEP]\n", "[CLS] If the uncertainty for an \u201cunsafe\u201d image was above the threshold, it was marked as a true positive, whereas if the uncertainty was above the threshold for a \u201csafe\u201d image it was marked as a false positive. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Evaluation Metric Two [SEP]\n", "[CLS] In the second scenario, evaluating whether uncertainty was significantly higher before a crash, involved running the simulator and recording uncertainty until a crash occurred. [SEP]\n", "[CLS] At that point, the uncertainty value from FORMULA  seconds before the crash was recorded, for FORMULA , and paired with a \u201ccrashed\u201d label. [SEP]\n", "[CLS] Additional \u201cnot crashed\u201d data was recorded, where uncertainty from FORMULA  seconds before a normal driving state was paired with a \u201cnot crashed\u201d label. [SEP]\n", "[CLS] This data, for each FORMULA , was used to generate ROC curves to determine both the best threshold for uncertainty to predict \u201ccrashed\u201d states that will occur in FORMULA  seconds, and to determine the most informative time FORMULA  before a crash. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Results Network performance The best version of the regression network achieved an RMSE of 0.1107 when using the predictive mean, a slight improvement over 0.1211 when predicting deterministically. [SEP]\n", "[CLS] In the simulator, the network drove around the track with an average of two crashes per loop, but its movement was jerky. [SEP]\n", "[CLS] For classification, the best iteration of the network achieved an accuracy of 67% (and did not change when using the mode of predictive distribution). [SEP]\n", "[CLS] This low accuracy could be explained by the fact that the steering angles needed to be converted to classes for classification, therefore losing some granularity. [SEP]\n", "[CLS] It is also worth noting that wrong predictions were frequently only a few classes away, so the predicted angle may still have been classified as \u201csafe\u201d. [SEP]\n", "[CLS] Despite this accuracy, the car consistently drove around the simulator track with an average of zero to one crash per loop, and although still jerky, it was smoother than the regression network. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Incorrect angle prediction The ROC curve for the regression network can be seen in the first graph in Figure\u00a0REF . [SEP]\n", "[CLS] Using predictive variance to judge safe and unsafe road situations is only a slight improvement on random guessing (AUC = 0.64 versus 0.5). [SEP]\n", "[CLS] The ROC curves for each of the different uncertainty measures for classification can also be seen in Figure\u00a0REF . [SEP]\n", "[CLS] It is clear that mutual information is most promising, with a high AUC value of 0.77. [SEP]\n", "[CLS] The most important value to minimise in self-driving and crash prediction is false negatives (labelling unsafe situations as safe) as these will lead to crashes. [SEP]\n", "[CLS] With this in mind, a threshold with a high true positive rate was chosen to minimise this value. [SEP]\n", "[CLS] The threshold for mutual information was chosen as 0.612 which has a true positive rate of 0.81 and a false positive rate of 0.28. [SEP]\n", "[CLS] The threshold for entropy was chosen as 3.51 and the threshold for variation ratio was 0.75. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The ROC curves for uncertainty in regression (top left) and classification (remaining plots) for incorrect angle prediction. [SEP]\n", "[CLS]   Crash prediction FIGURE   [SEP]\n", "[CLS] The different uncertainty measures a number of frames before a crash occurs. [SEP]\n", "[CLS] The red dashed line indicates the frame at which the crash occurred. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The graphs in Figure\u00a0REF  show the value of uncertainty for both regression and classification over the time period leading to one of the crashes; the red line indicates the frame at which the crash happened. [SEP]\n", "[CLS] Mutual information was once again the strongest indicator of incorrect behaviour, in this case meaning the car crashing. [SEP]\n", "[CLS] The mutual information in this graph peaks at around 27 frames, or 4.5 seconds, before the crash. [SEP]\n", "[CLS] Over the recorded crashes, the same uncertainty peak can be seen from between 7-31 frames, 1.17-5.17 seconds, before the crash. [SEP]\n", "[CLS] Table\u00a0REF  shows for the first five crashes, the number of frames before the crash that the threshold was first passed, and the location of the most defined peak of mutual information before the crash. [SEP]\n", "[CLS] Figure\u00a0REF  shows the ROC curves for mutual information for 2, 3, 4 and 5 seconds before the \u201ccrashed\u201d or \u201cnot crashed\u201d event occurred, including values 0.25s either side (i.e. \u201c2 seconds before\u201d encompasses from 1.75s to 2.25s). [SEP]\n", "[CLS] Three seconds after a high mutual information value was recorded was the most likely time for a crash to occur, and the threshold for mutual information for this time step was set to be 0.501, which had a true positive rate of 73% and a false positive rate of 28%. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The ROC curves 2,3,4,5 seconds before a \u201ccrashed\u201d or \u201cnot crashed\u201d event for mutual information. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] This allows us to conclude that mutual information is a promising indicator of incorrect behaviour in real-time, and a time from highest peak to crash of 3 seconds could be sufficient to take an appropriate action. [SEP]\n", "[CLS] Distance in frames and seconds from crash. [SEP]\n", "[CLS] 0.5XXXXX 1XCrash #  2>XDistance to first threshold breach  2>XDistance to defined peak  (frames)  (seconds)  (frames)  (seconds) 1  21 3.5  18 3 2  45 7.5  31 5.17 3  42 7  16 2.7 4  39 6.5  7 1.17 5  40 6.7  27 4.5    Conclusion [SEP]\n", "[CLS] In this paper, we explored the use of uncertainty in end-to-end controllers for self-driving cars and suggested new evaluations for it. [SEP]\n", "[CLS] We studied two separate architectures, one for regression and one for classification, along with the tools to retrieve different types of uncertainty information from them. [SEP]\n", "[CLS] We tested those architectures in the Udacity self-driving car simulator and found that mutual information, above all other uncertainty measures, is a promising predictor for erroneous behaviour (crashes). [SEP]\n", "[CLS] All of the above runs in real-time and we thus believe that uncertainty information could play a major role in improving end-to-end controllers and in bringing them up to speed with more traditional and better performing modular controllers. [SEP]\n", "[CLS] Planned future work includes varying the speed of the car to determine whether any uncertainty measure is viable at higher speeds, as well as modifying the simulator to include a top down view and the ability to set the car speed directly, and finally exploring a wider range of network architectures. [SEP]\n", "[CLS] It would also be interesting to evaluate the techniques on real data. [SEP]\n"], "1609.05807": ["[CLS]  same verbose,letterpaper,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in positioning,decorations.pathmorphing,shapes,decorations.pathreplacing Inherent Trade-Offs in the Fair Determination of [SEP]\n", "[CLS] Risk ScoresJon Kleinberg Cornell University Sendhil Mullainathan Harvard University Manish Raghavan Cornell University Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. [SEP]\n", "[CLS] We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. [SEP]\n", "[CLS] Moreover, even satisfying all three conditions approximately requires that the data lie in an approximate version of one of the constrained special cases identified by our theorem. [SEP]\n", "[CLS] These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-offs between them. [SEP]\n", "[CLS] Introduction There are many settings in which a sequence of people comes before a decision-maker, who must make a judgment about each based on some observable set of features. [SEP]\n", "[CLS] Across a range of applications, these judgments are being carried out by an increasingly wide spectrum of approaches ranging from human expertise to algorithmic and statistical frameworks, as well as various combinations of these approaches. [SEP]\n", "[CLS] Along with these developments, a growing line of work has asked how we should reason about issues of bias and discrimination in settings where these algorithmic and statistical techniques, trained on large datasets of past instances, play a significant role in the outcome. [SEP]\n", "[CLS] Let us consider three examples where such issues arise, both to illustrate the range of relevant contexts, and to surface some of the challenges. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A set of example domains. [SEP]\n", "[CLS] First, at various points in the criminal justice system, including decisions about bail, sentencing, or parole, an officer of the court may use quantitative risk tools to assess a defendant's probability of recidivism \u2014 future arrest \u2014 based on their past history and other attributes. [SEP]\n", "[CLS] Several recent analyses have asked whether such tools are mitigating or exacerbating the sources of bias in the criminal justice system; in one widely-publicized report, Angwin et al. analyzed a commonly used statistical method for assigning risk scores in the criminal justice system \u2014 the COMPAS risk tool \u2014 and argued that it was biased against African-American defendants {{cite:5b7e0330-db52-4c96-99ca-3769c51beecf}}, {{cite:58259c89-b636-4f3f-ab84-ba5980c485fd}}. [SEP]\n", "[CLS] One of their main contentions was that the tool's errors were asymmetric: African-American defendants were more likely to be incorrectly labeled as higher-risk than they actually were, while white defendants were more likely to be incorrectly labeled as lower-risk than they actually were. [SEP]\n", "[CLS] Subsequent analyses raised methodological objections to this report, and also observed that despite the COMPAS risk tool's errors, its estimates of the probability of recidivism are equally well calibrated to the true outcomes for both African-American and white defendants {{cite:5db7867c-023c-4934-b99b-1bd5d2ffd2e7}}, {{cite:82d9de7d-ecef-430c-8f2d-86f4d1b3f39e}}, {{cite:7510899a-fe95-4d7d-a144-61a8f1987310}}, {{cite:9d0eb2e0-f229-4b7d-bb37-29fe92b7cc1d}}. [SEP]\n", "[CLS] Second, in a very different domain, researchers have begun to analyze the ways in which different genders and racial groups experience advertising and commercial content on the Internet differently {{cite:ef48820b-7800-42de-8a0e-c03072d17ea8}}, {{cite:03b3d0dc-a49a-4857-b493-1873cf338a93}}. [SEP]\n", "[CLS] We could ask, for example: if a male user and female user are equally interested in a particular product, does it follow that they're equally likely to be shown an ad for it? [SEP]\n", "[CLS] Sometimes this concern may have broader implications, for example if women in aggregate are shown ads for lower-paying jobs. [SEP]\n", "[CLS] Other times, it may represent a clash with a user's leisure interests: if a female user interacting with an advertising platform is interested in an activity that tends to have a male-dominated viewership, like professional football, is the platform as likely to show her an ad for football as it is to show such an ad to an interested male user? [SEP]\n", "[CLS] A third domain, again quite different from the previous two, is medical testing and diagnosis. [SEP]\n", "[CLS] Doctors making decisions about a patient's treatment may rely on tests providing probability estimates for different diseases and conditions. [SEP]\n", "[CLS] Here too we can ask whether such decision-making is being applied uniformly across different groups of patients {{cite:4ff540c0-f2b0-4da2-beeb-4fd184113692}}, {{cite:dcdc455f-92e7-49ef-9b17-42267468435a}}, and in particular how medical tests may play a differential role for conditions that vary widely in frequency between these groups. [SEP]\n", "[CLS]    [SEP]\n", "[CLS] Providing guarantees for decision procedures. [SEP]\n", "[CLS] One can raise analogous questions in many other domains of fundamental importance, including decisions about hiring, lending, or school admissions {{cite:b064f320-eb34-4a0a-b0cd-375adf3764f9}}, but we will focus on the three examples above for the purposes of this discussion. [SEP]\n", "[CLS] In these three example domains, a few structural commonalities stand out. [SEP]\n", "[CLS] First, the algorithmic estimates are often being used as \u201cinput\u201d to a larger framework that makes the overall decision \u2014 a risk score provided to a human expert in the legal and medical instances, and the output of a machine-learning algorithm provided to a larger advertising platform in the case of Internet ads. [SEP]\n", "[CLS] Second, the underlying task is generally about classifying whether people possess some relevant property: recidivism, a medical condition, or interest in a product. [SEP]\n", "[CLS] We will refer to people as being positive instances if they truly possess the property, and negative instances if they do not. [SEP]\n", "[CLS] Finally, the algorithmic estimates being provided for these questions are generally not pure yes-no decisions, but instead probability estimates about whether people constitute positive or negative instances. [SEP]\n", "[CLS] Let us suppose that we are concerned about how our decision procedure might operate differentially between two groups of interest (such as African-American and white defendants, or male and female users of an advertising system). [SEP]\n", "[CLS] What sorts of guarantees should we ask for as protection against potential bias? [SEP]\n", "[CLS] A first basic goal in this literature is that the probability estimates provided by the algorithm should be well-calibrated: if the algorithm identifies a set of people as having a probability FORMULA  of constituting positive instances, then approximately a FORMULA  fraction of this set should indeed be positive instances {{cite:496233fc-94cd-4e14-acdf-cdc60b8dd4ca}}, {{cite:b14ec098-b1d0-476b-ade0-c81d7114f640}}. [SEP]\n", "[CLS] Moreover, this condition should hold when applied separately in each group as well {{cite:7510899a-fe95-4d7d-a144-61a8f1987310}}. [SEP]\n", "[CLS] For example, if we are thinking in terms of potential differences between outcomes for men and women, this means requiring that a FORMULA  fraction of men and a FORMULA  fraction of women assigned a probability FORMULA  should possess the property in question. [SEP]\n", "[CLS] A second goal focuses on the people who constitute positive instances (even if the algorithm can only imperfectly recognize them): the average score received by people constituting positive instances should be the same in each group. [SEP]\n", "[CLS] We could think of this as balance for the positive class, since a violation of it would mean that people constituting positive instances in one group receive consistently lower probability estimates than people constituting positive instances in another group. [SEP]\n", "[CLS] In our initial criminal justice example, for instance, one of the concerns raised was that white defendants who went on to commit future crimes were assigned risk scores corresponding to lower probability estimates in aggregate; this is a violation of the condition here. [SEP]\n", "[CLS] There is a completely analogous property with respect to negative instances, which we could call balance for the negative class. [SEP]\n", "[CLS] These balance conditions can be viewed as generalizations of the notions that both groups should have equal false negative and false positive rates. [SEP]\n", "[CLS] It is important to note that balance for the positive and negative classes, as defined here, is distinct in crucial ways from the requirement that the average probability estimate globally over all members of the two groups be equal. [SEP]\n", "[CLS] This latter global requirement is a version of statistical parity {{cite:cbcc69f5-644d-4a2b-9329-27920454f480}}, {{cite:cea0db1f-09ea-4f42-9a13-0ca2d122cbf2}}, {{cite:4213c57e-61e5-4ee4-aef1-d8a66db3fb56}}, {{cite:264ea123-597f-4a83-bb5a-c823dd73c733}}. [SEP]\n", "[CLS] In some cases statistical parity is a central goal (and in some it is legally mandated), but the examples considered so far suggest that classification and risk assessment are much broader activities where statistical parity is often neither feasible nor desirable. [SEP]\n", "[CLS] Balance for the positive and negative classes, however, is a goal that can be discussed independently of statistical parity, since these two balance conditions simply ask that once we condition on the \u201ccorrect\u201d answer for a person, the chance of making a mistake on them should not depend on which group they belong to. [SEP]\n", "[CLS]    [SEP]\n", "[CLS] The present work: Trade-offs among the guarantees. [SEP]\n", "[CLS] Despite their different formulations, the calibration condition and the balance conditions for the positive and negative classes intuitively all seem to be asking for variants of the same general goal \u2014 that our probability estimates should have the same effectiveness regardless of group membership. [SEP]\n", "[CLS] One might therefore hope that it would be feasible to achieve all of them simultaneously. [SEP]\n", "[CLS] Our main result, however, is that these conditions are in general incompatible with each other; they can only be simultaneously satisfied in certain highly constrained cases. [SEP]\n", "[CLS] Moreover, this incompatibility applies to approximate versions of the conditions as well. [SEP]\n", "[CLS] In the remainder of this section we formulate this main result precisely, as a theorem building on a model that makes the discussion thus far more concrete.   [SEP]\n", "[CLS] Formulating the Goal Let's start with some basic definitions. [SEP]\n", "[CLS] As above, we have a collection of people each of whom constitutes either a positive instance or a negative instance of the classification problem. [SEP]\n", "[CLS] We'll say that the positive class consists of the people who constitute positive instances, and the negative class consists of the people who constitute negative instances. [SEP]\n", "[CLS] For example, for criminal defendants, the positive class could consist of those defendants who will be arrested again within some fixed time window, and the negative class could consist of those who will not. [SEP]\n", "[CLS] The positive and negative classes thus represent the \u201ccorrect\u201d answer to the classification problem; our decision procedure does not know them, but is trying to estimate them. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Feature vectors. [SEP]\n", "[CLS] Each person has an associated feature vector FORMULA , representing the data that we know about them. [SEP]\n", "[CLS] Let FORMULA  denote the fraction of people with feature vector FORMULA  who belong to the positive class. [SEP]\n", "[CLS] Conceptually, we will picture that while there is variation within the set of people who have feature vector FORMULA , this variation is invisible to whatever decision procedure we apply; all people with feature vector FORMULA  are indistinguishable to the procedure. [SEP]\n", "[CLS] Our model will assume that the value FORMULA  for each FORMULA  is known to the procedure. [SEP]\n", "[CLS] Clearly the case in which the value of FORMULA  is unknown is an important version of the problem as well; however, since our main results establish strong limitations on what is achievable, these limitations are only stronger because they apply even to the case of known FORMULA . [SEP]\n", "[CLS]   Groups. [SEP]\n", "[CLS] Each person also belongs to one of two groups, labeled 1 or 2, and we would like our decisions to be unbiased with respect to the members of these two groups. [SEP]\n", "[CLS] We focus on the case of two groups for simplicity of exposition, but it is straightforward to extend all of our definitions to the case of more than two groups. [SEP]\n", "[CLS] In our examples, the two groups could correspond to different races or genders, or other cases where we want to look for the possibility of bias between them. [SEP]\n", "[CLS] The two groups have different distributions over feature vectors: a person of group FORMULA  has a probability FORMULA  of exhibiting the feature vector FORMULA . [SEP]\n", "[CLS] However, people of each group have the same probability FORMULA  of belonging to the positive class provided their feature vector is FORMULA . [SEP]\n", "[CLS] In this respect, FORMULA  contains all the relevant information available to us about the person's future behavior; once we know FORMULA , we do not get any additional information from knowing their group as well. [SEP]\n", "[CLS] As we will discuss in more detail below, the assumption that the group provides no additional information beyond FORMULA  does not restrict the generality of the model, since we can always consider instances in which people of different groups never have the same feature vector FORMULA , and hence FORMULA  implicitly conveys perfect information about a person's group. [SEP]\n", "[CLS]   Risk Assignments. [SEP]\n", "[CLS] We say that an instance of our problem is specified by the parameters above: a feature vector and a group for each person, with a value FORMULA  for each feature vector, and distributions FORMULA  giving the frequency of the feature vectors in each group. [SEP]\n", "[CLS] Informally, risk assessments are ways of dividing people up into sets based on their feature vectors FORMULA  (potentially using randomization), and then assigning each set a probability estimate that the people in this set belong to the positive class. [SEP]\n", "[CLS] Thus, we define a risk assignment to consist of a set of \u201cbins\u201d (the sets), where each bin is labeled with a score FORMULA  that we intend to use as the probability for everyone assigned to bin FORMULA . [SEP]\n", "[CLS] We then create a rule for assigning people to bins based on their feature vector FORMULA ; we allow the rule to divide people with a fixed feature vector FORMULA  across multiple bins (reflecting the possible use of randomization). [SEP]\n", "[CLS] Thus, the rule is specified by values FORMULA : a fraction FORMULA  of all people with feature vector FORMULA  are assigned to bin FORMULA . [SEP]\n", "[CLS] Note that the rule does not have access to the group FORMULA  of the person being considered, only their feature vector FORMULA . [SEP]\n", "[CLS] (As we will see, this does not mean that the rule is incapable of exhibiting bias between the two groups.) In summary, a risk assignment is specified by a set of bins, a score for each bin, and values FORMULA  that define a mapping from people with feature vectors to bins. [SEP]\n", "[CLS]   Fairness Properties for Risk Assignments. [SEP]\n", "[CLS] Within the model, we now express the three conditions discussed at the outset, each reflecting a potentially different notion of what it means for the risk assignment to be \u201cfair.\u201d [SEP]\n", "[CLS] (A) Calibration within groups requires that for each group FORMULA , and each bin FORMULA  with associated score FORMULA , the expected number of people from group FORMULA  in FORMULA  who belong to the positive class should be a FORMULA  fraction of the expected number of people from group FORMULA  assigned to FORMULA . [SEP]\n", "[CLS] (B) Balance for the negative class requires that the average score assigned to people of group 1 who belong to the negative class should be the same as the average score assigned to people of group 2 who belong to the negative class. [SEP]\n", "[CLS] In other words, the assignment of scores shouldn't be systematically more inaccurate for negative instances in one group than the other. [SEP]\n", "[CLS] (C) Balance for the positive class symmetrically requires that the average score assigned to people of group 1 who belong to the positive class should be the same as the average score assigned to people of group 2 who belong to the positive class. [SEP]\n", "[CLS]    Why Do These Conditions Correspond to Notions of Fairness?. [SEP]\n", "[CLS] All of these are natural conditions to impose on a risk assignment; and as indicated by the discussion above, all of them have been proposed as versions of fairness. [SEP]\n", "[CLS] The first one essentially asks that the scores mean what they claim to mean, even when considered separately in each group. [SEP]\n", "[CLS] In particular, suppose a set of scores lack the first property for some bin FORMULA , and these scores are given to a decision-maker; then if people of two different groups both belong to bin FORMULA , the decision-maker has a clear incentive to treat them differently, since the lack of calibration within groups on bin FORMULA  means that these people have different aggregate probabilities of belonging to the positive class. [SEP]\n", "[CLS] Another way of stating the property of calibration within groups is to say that, conditioned on the bin to which an individual is assigned, the likelihood that the individual is a member of the positive class is independent of the group to which the individual belongs. [SEP]\n", "[CLS] This means we are justified in treating people with the same score comparably with respect to the outcome, rather than treating people with the same score differently based on the group they belong to. [SEP]\n", "[CLS] The second and third ask that if two individuals in different groups exhibit comparable future behavior (negative or positive), they should be treated comparably by the procedure. [SEP]\n", "[CLS] In other words, a violation of, say, the second condition would correspond to the members of the negative class in one group receiving consistently higher scores than the members of the negative class in the other group, despite the fact that the members of the negative class in the higher-scoring group have done nothing to warrant these higher scores. [SEP]\n", "[CLS] We can also interpret some of the prior work around our earlier examples through the lens of these conditions. [SEP]\n", "[CLS] For example, in the analysis of the COMPAS risk tool for criminal defendants, the critique by Angwin et al. focused on the risk tool's violation of conditions (B) and (C); the counter-arguments established that it satisfies condition (A). [SEP]\n", "[CLS] While it is clearly crucial for a risk tool to satisfy (A), it may still be important to know that it violates (B) and (C). [SEP]\n", "[CLS] Similarly, to think in terms of the example of Internet advertising, with male and female users as the two groups, condition (A) as before requires that our estimates of ad-click probability mean the same thing in aggregate for men and women. [SEP]\n", "[CLS] Conditions (B) and (C) are distinct; condition (C), for example, says that a female user who genuinely wants to see a given ad should be assigned the same probability as a male user who wants to see the ad. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Determining What is Achievable: A Characterization Theorem When can conditions (A), (B), and (C) be simultaneously achieved? [SEP]\n", "[CLS] We begin with two simple cases where it's possible. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Perfect prediction. [SEP]\n", "[CLS] Suppose that for each feature vector FORMULA , we have either FORMULA  or FORMULA . [SEP]\n", "[CLS] This means that we can achieve perfect prediction, since we know each person's class label (positive or negative) for certain. [SEP]\n", "[CLS] In this case, we can assign all feature vectors FORMULA  with FORMULA  to a bin FORMULA  with score FORMULA , and all FORMULA  with FORMULA  to a bin FORMULA  with score FORMULA . [SEP]\n", "[CLS] It is easy to check that all three of the conditions (A), (B), and (C) are satisfied by this risk assignment. [SEP]\n", "[CLS]  Equal base rates. [SEP]\n", "[CLS] Suppose, alternately, that the two groups have the same fraction of members in the positive class; that is, the average value of FORMULA  is the same for the members of group 1 and group 2. [SEP]\n", "[CLS] (We can refer to this as the base rate of the group with respect to the classification problem.) In this case, we can create a single bin FORMULA  with score equal to this average value of FORMULA , and we can assign everyone to bin FORMULA . [SEP]\n", "[CLS] While this is not a particularly informative risk assignment, it is again easy to check that it satisfies fairness conditions (A), (B), and (C). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Our first main result establishes that these are in fact the only two cases in which a risk assignment can achieve all three fairness guarantees simultaneously. [SEP]\n", "[CLS] Theorem 1.1 Consider an instance of the problem in which there is a risk assignment satisfying fairness conditions (A), (B), and (C). [SEP]\n", "[CLS] Then the instance must either allow for perfect prediction (with FORMULA  equal to 0 or 1 for all FORMULA ) or have equal base rates.   [SEP]\n", "[CLS] Thus, in every instance that is more complex than the two cases noted above, there will be some natural fairness condition that is violated by any risk assignment. [SEP]\n", "[CLS] Moreover, note that this result applies regardless of how the risk assignment is computed; since our framework considers risk assignments to be arbitrary functions from feature vectors to bins labeled with probability estimates, it applies independently of the method \u2014 algorithmic or otherwise \u2014 that is used to construct the risk assignment. [SEP]\n", "[CLS] The conclusions of the first theorem can be relaxed in a continuous fashion when the fairness conditions are only approximate. [SEP]\n", "[CLS] In particular, for any FORMULA  we can define FORMULA -approximate versions of each of conditions (A), (B), and (C) (specified precisely in the next section), each of which requires that the corresponding equalities between groups hold only to within an error of FORMULA . [SEP]\n", "[CLS] For any FORMULA , we can also define a FORMULA -approximate version of the equal base rates condition (requiring that the base rates of the two groups be within an additive FORMULA  of each other) and a FORMULA -approximate version of the perfect prediction condition (requiring that in each group, the average of the expected scores assigned to members of the positive class is at least FORMULA ; by the calibration condition, this can be shown to imply a complementary bound on the average of the expected scores assigned to members of the negative class). [SEP]\n", "[CLS] In these terms, our approximate version of Theorem\u00a0REF  is the following. [SEP]\n", "[CLS] Theorem 1.2 [SEP]\n", "[CLS] There is a continuous function FORMULA , with FORMULA  going to 0 as FORMULA  goes to 0, so that the following holds. [SEP]\n", "[CLS] For all FORMULA , and any instance of the problem with a risk assignment satisfying the FORMULA -approximate versions of fairness conditions (A), (B), and (C), the instance must satisfy either the FORMULA -approximate version of perfect prediction or the FORMULA -approximate version of equal base rates.   [SEP]\n", "[CLS] Thus, anything that approximately satisfies the fairness constraints must approximately look like one of the two simple cases identified above. [SEP]\n", "[CLS] Finally, in connection to Theorem REF , we note that when the two groups have equal base rates, then one can ask for the most accurate risk assignment that satisfies all three fairness conditions (A), (B), and (C) simultaneously. [SEP]\n", "[CLS] Since the risk assignment that gives the same score to everyone satisfies the three conditions, we know that at least one such risk assignment exists; hence, it is natural to seek to optimize over the set of all such assignments. [SEP]\n", "[CLS] We consider this algorithmic question in the final technical section of the paper. [SEP]\n", "[CLS] To reflect a bit further on our main theorems and what they suggest, we note that our intention in the present work isn't to make a recommendation on how conflicts between different definitions of fairness should be handled. [SEP]\n", "[CLS] Nor is our intention to analyze which definitions of fairness are violated in particular applications or datasets. [SEP]\n", "[CLS] Rather, our point is to establish certain unavoidable trade-offs between the definitions, regardless of the specific context and regardless of the method used to compute risk scores. [SEP]\n", "[CLS] Since each of the definitions reflect (and have been proposed as) natural notions of what it should mean for a risk score to be fair, these trade-offs suggest a striking implication: that outside of narrowly delineated cases, any assignment of risk scores can in principle be subject to natural criticisms on the grounds of bias. [SEP]\n", "[CLS] This is equally true whether the risk score is determined by an algorithm or by a system of human decision-makers. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Special Cases of the Model. [SEP]\n", "[CLS] Our main results, which place strong restrictions on when the three fairness conditions can be simultaneously satisfied, have more power when the underlying model of the input is more general, since it means that the restrictions implied by the theorems apply in greater generality. [SEP]\n", "[CLS] However, it is also useful to note certain special cases of our model, obtained by limiting the flexibility of certain parameters in intuitive ways. [SEP]\n", "[CLS] The point is that our results apply a fortiori to these more limited special cases. [SEP]\n", "[CLS] First, we have already observed one natural special case of our model: cases in which, for each feature vector FORMULA , only members of one group (but not the other) can exhibit FORMULA . [SEP]\n", "[CLS] This means that FORMULA  contains perfect information about group membership, and so it corresponds to instances in which risk assignments would have the potential to use knowledge of an individual's group membership. [SEP]\n", "[CLS] Note that we can convert any instance of our problem into a new instance that belongs to this special case as follows. [SEP]\n", "[CLS] For each feature vector FORMULA , we create two new feature vectors FORMULA  and FORMULA ; then, for each member of group 1 who had feature vector FORMULA , we assign them FORMULA , and for each member of group 2 who had feature vector FORMULA , we assign them FORMULA . [SEP]\n", "[CLS] The resulting instance has the property that each feature vector is associated with members of only one group, but it preserves the essential aspects of the original instance in other respects. [SEP]\n", "[CLS] Second, we allow risk assignments in our model to split people with a given feature vector FORMULA  over several bins. [SEP]\n", "[CLS] Our results also therefore apply to the natural special case of the model with integral risk assignments, in which all people with a given feature FORMULA  must go to the same bin. [SEP]\n", "[CLS] Third, our model is a generalization of binary classification, which only allows for 2 bins. [SEP]\n", "[CLS] Note that although binary classification does not explicitly assign scores, we can consider the probability that an individual belongs to the positive class given that they were assigned to a specific bin to be the score for that bin. [SEP]\n", "[CLS] Thus, our results hold in the traditional binary classification setting as well. [SEP]\n", "[CLS]   Data-Generating Processes. [SEP]\n", "[CLS] Finally, there is the question of where the data in an instance of our problem comes from. [SEP]\n", "[CLS] Our results do not assume any particular process for generating the positive/negative class labels, feature vectors, and group memberships; we simply assume that we are given such a collection of values (regardless of where they came from), and then our results address the existence or non-existence of certain risk assignments for these values. [SEP]\n", "[CLS] This increases the generality of our results, since it means that they apply to any process that produces data of the form described by our model. [SEP]\n", "[CLS] To give an example of a natural generative model that would produce instances with the structure that we need, one could assume that each individual starts with a \u201chidden\u201d class label (positive or negative), and a feature vector FORMULA  is then probabilistically generated for this individual from a distribution that can depend on their class label and their group membership. [SEP]\n", "[CLS] (If feature vectors produced for the two groups are disjoint from one another, then the requirement that the value of FORMULA  is independent of group membership given FORMULA  necessarily holds.) Since a process with this structure produces instances from our model, our results apply to data that arises from such a generative process. [SEP]\n", "[CLS] It is also interesting to note that the basic set-up of our model, with the population divided across a set of feature vectors for which race provides no additional information, is in fact a very close match to the information one gets from the output of a well-calibrated risk tool. [SEP]\n", "[CLS] In this sense, one setting for our model would be the problem of applying post-processing to the output of such a risk tool to ensure additional fairness guarantees. [SEP]\n", "[CLS] Indeed, since much of the recent controversy about fair risk scores has involved risk tools that are well-calibrated but lack the other fairness conditions we consider, such an interpretation of the model could be a useful way to think about how one might work with these tools in the context of a broader system. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Further Related Work Mounting concern over discrimination in machine learning has led to a large body of new work seeking to better understand and prevent it. [SEP]\n", "[CLS] Barocas and Selbst survey a range of ways in which data-analysis algorithms can lead to discriminatory outcomes {{cite:f07e66b4-9f13-4650-a823-b125432cc81d}}, and review articles by Romei and Ruggieri {{cite:914c7ac3-2b1c-4a02-bc15-2fa99400b5a2}} and Zliobaite {{cite:3842bf8d-17e9-44db-ab38-e504966e4118}} survey data-analytic and algorithmic methods for measuring discrimination. [SEP]\n", "[CLS] Kamiran and Calders {{cite:4213c57e-61e5-4ee4-aef1-d8a66db3fb56}} and Hajian and Domingo-Ferrer {{cite:80d4ee24-6413-4fbf-87b1-9d5f356fbe6c}} seek to modify datasets to remove any information that might permit discrimination. [SEP]\n", "[CLS] Similarly, Zemel et al. look to learn fair intermediate representations of data while preserving information needed for classification {{cite:cb458dd0-ec4c-4c91-b6a4-9d26289924e6}}. [SEP]\n", "[CLS] Joseph et al. consider how fairness issues can arise during the process of learning, modeling this using a multi-armed bandit framework {{cite:d88e97ad-5f20-4d8e-a873-39d80f993ca8}}. [SEP]\n", "[CLS] One common notion of fairness is \u201cstatistical parity\u201d \u2013 equal fractions of each group should be treated as belonging to the positive class {{cite:cea0db1f-09ea-4f42-9a13-0ca2d122cbf2}}, {{cite:4213c57e-61e5-4ee4-aef1-d8a66db3fb56}}, {{cite:264ea123-597f-4a83-bb5a-c823dd73c733}}. [SEP]\n", "[CLS] Recent papers have also considered approximate relaxations of statistical parity, motivated by the formulation of disparate impact in the U.S. legal code {{cite:cbcc69f5-644d-4a2b-9329-27920454f480}}, {{cite:d566676c-ef25-4f0d-94ff-38f38a895413}}. [SEP]\n", "[CLS] Work in these directions has developed learning algorithms that penalize violations of statistical parity {{cite:cea0db1f-09ea-4f42-9a13-0ca2d122cbf2}}, {{cite:264ea123-597f-4a83-bb5a-c823dd73c733}}. [SEP]\n", "[CLS] As noted above, we consider definitions other than statistical parity that take into account the class membership (positive or negative) of the people being classified. [SEP]\n", "[CLS] Dwork et al.\u00a0propose a framework based on a task-specific externally defined similarity metric between individuals, seeking to achieve fairness through the goal that \u201csimilar people [be] treated similarly\u201d {{cite:a825c960-a185-4cf6-baa0-088b991c703f}}. [SEP]\n", "[CLS] They strive towards individual fairness, which is a stronger notion of fairness than the definitions we use; however, our approach shares some of the underlying motivation (though not the specifics) in that our balance conditions for the positive and negative classes also reflect the notion that similar people should be treated similarly. [SEP]\n", "[CLS] Much of the applied work on risk scores, as noted above, focuses on calibration as a central goal {{cite:496233fc-94cd-4e14-acdf-cdc60b8dd4ca}}, {{cite:82d9de7d-ecef-430c-8f2d-86f4d1b3f39e}}, {{cite:7510899a-fe95-4d7d-a144-61a8f1987310}}. [SEP]\n", "[CLS] In particular, responding to the criticism of their risk scores as displaying asymmetric errors for different groups, Dietrich et al. [SEP]\n", "[CLS] \u00a0note that empirically, both in their domain and in similar settings, it is typically difficult to achieve symmetry in the error rates across groups when base rates differ significantly. [SEP]\n", "[CLS] Our formulation of the balance conditions for the positive and negative classes, and our result showing the incompatibility of these conditions with calibration, provides a theoretical basis for such observations. [SEP]\n", "[CLS] In recent work concurrent with ours, Hardt et al.\u00a0consider the natural analogues of our conditions (B) and (C), balance for the negative and positive classes, in the case of classifiers that output binary \u201cyes/no\u201d predictions rather than real-valued scores as in our case {{cite:89c66cf5-b2f0-4c9b-bcdf-5f9f3f7d959d}}. [SEP]\n", "[CLS] Since they do not require an analogue of calibration, it is possible to satisfy the two balance constraints simultaneously, and they provide methods for optimizing performance measures of the prediction rule subject to satisfying these two constraints. [SEP]\n", "[CLS] Also concurrent with our work and that of Hardt et al., Chouldechova {{cite:a09e92f9-a91c-42d4-baec-7cdab41c6d64}} and Corbett-Davies et al. {{cite:941a0824-8f2b-4b8c-b184-74f9d4d5a6d5}} (and see also {{cite:d2c94466-fd58-418b-b224-ef52aa82d52d}}) consider binary prediction subject to these same analogues of the balance conditions for the negative and positive classes, together with a form of calibration adapted to binary prediction (requiring that for all people given a positive label, the same fraction of people in each group should truly belong to the positive class). [SEP]\n", "[CLS] Among other results, they show that no classification rule satisfying the required constraints is possible. [SEP]\n", "[CLS] Finally, a recent paper of Friedler et al.\u00a0{{cite:fc16fc6e-73cd-423a-adf9-35fe8e68c4c6}} defines two axiomatic properties of feature generation and shows that no mechanism can be fair under these two properties. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The Characterization Theorems Starting with the notation and definitions from the previous section, we now give a proof of Theorem REF . [SEP]\n", "[CLS]  Informal overview. [SEP]\n", "[CLS] Let us begin with a brief overview of the proof, before going into a more detailed version of it. [SEP]\n", "[CLS] For this discussion, let FORMULA  denote the number of people in group FORMULA , and FORMULA  be the number of people in group FORMULA  who belong to the positive class. [SEP]\n", "[CLS] Roughly speaking, the proof proceeds in two steps. [SEP]\n", "[CLS] First, consider a single bin FORMULA . [SEP]\n", "[CLS] By the calibration condition, the expected total score given to the group-FORMULA  people in bin FORMULA  is equal to the expected number of group-FORMULA  people in bin FORMULA  who belong to the positive class. [SEP]\n", "[CLS] Summing over all bins, we find that the total score given to all people in group FORMULA   [SEP]\n", "[CLS] (that is, the sum of the scores received by everyone in group FORMULA ) is equal to the total number of people in the positive class in group FORMULA , which is FORMULA . [SEP]\n", "[CLS] Now, let FORMULA  be the average score given to a member of the negative class, and let FORMULA  be the average score given to a member of the positive class. [SEP]\n", "[CLS] By the balance conditions for the negative and positive classes, these values of FORMULA  and FORMULA  are the same for both groups. [SEP]\n", "[CLS] Given the values of FORMULA  and FORMULA , the total number of people in the positive class FORMULA , and the total score given out to people in group FORMULA  \u2014 which, as argued above, is also FORMULA  \u2014 we can write the total score as FORMULA   [SEP]\n", "[CLS] This defines a line for each group FORMULA  in the two variables FORMULA  and FORMULA , and hence we obtain a system of two linear equations (one for each group) in the unknowns FORMULA  and FORMULA . [SEP]\n", "[CLS] If all three conditions \u2014 calibration, and balance for the two classes \u2014 are to be satisfied, then we must be at a set of parameters that represents a solution to the system of two equations. [SEP]\n", "[CLS] If the base rates are equal, then FORMULA  and hence the two lines are the same; in this case, the system of equations is satisfied by any choice of FORMULA  and FORMULA . [SEP]\n", "[CLS] If the base rates are not equal, then the two lines are distinct, and they intersect only at the point FORMULA , which implies perfect prediction \u2014 an average score of 0 for members of the negative class and 1 for members of the positive class. [SEP]\n", "[CLS] Thus, the three conditions can be simultaneously satisfied if and only if we have equal base rates or perfect prediction. [SEP]\n", "[CLS] This concludes the overview of the proof; in the remainder of the section we describe the argument at a more detailed level.   Definitions and notation. [SEP]\n", "[CLS] Recall from our notation in the previous section that an FORMULA  fraction of the people in group FORMULA  have feature vector FORMULA ; we thus write FORMULA  for the number of people in group FORMULA  with feature vector FORMULA . [SEP]\n", "[CLS] Many of the components of the risk assignment and its evaluation can be written in terms of operations on a set of underlying matrices and vectors, which we begin by specifying. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] First, let FORMULA  denote the number of feature vectors in the instance, and let FORMULA  be a vector indexed by the possible feature vectors, with the coordinate in position FORMULA  equal to FORMULA . [SEP]\n", "[CLS] For group FORMULA , let FORMULA  also be a vector indexed by the possible feature vectors, with the coordinate in position FORMULA  equal to FORMULA . [SEP]\n", "[CLS] Finally, it will be useful to have a representation of FORMULA  as a diagonal matrix; thus, let FORMULA  be a FORMULA  diagonal matrix with FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We now specify a risk assignment as follows. [SEP]\n", "[CLS] The risk assignment involves a set of FORMULA  bins with associated scores; let FORMULA  be a vector indexed by the bins, with the coordinate in position FORMULA  equal to the score FORMULA  of bin FORMULA . [SEP]\n", "[CLS] Let FORMULA  be a diagonal matrix version of FORMULA : it is a FORMULA  matrix with FORMULA . [SEP]\n", "[CLS] Finally, let FORMULA  be the FORMULA  matrix of FORMULA  values, specifying the fraction of people with feature vector FORMULA  who get mapped to bin FORMULA  under the assignment procedure. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] There is an important point to note about the FORMULA  values. [SEP]\n", "[CLS] If all of them are equal to 0 or 1, this corresponds to a procedure in which all people with the same feature vector FORMULA  get assigned to the same bin. [SEP]\n", "[CLS] When some of the FORMULA  values are not equal to 0 or 1, the people with vector FORMULA  are being divided among multiple bins. [SEP]\n", "[CLS] In this case, there is an implicit randomization taking place with respect to the positive and negative classes, and with respect to the two groups, which we can think of as follows. [SEP]\n", "[CLS] Since the procedure cannot distinguish among people with vector FORMULA , in the case that it distributes these people across multiple bins, the subset of people with vector FORMULA  who belong to the positive and negative classes, and to the two groups, are divided up randomly across these bins in proportions corresponding to FORMULA . [SEP]\n", "[CLS] In particular, if there are FORMULA  group-FORMULA  people with vector FORMULA , the expected number of these people who belong to the positive class and are assigned to bin FORMULA  is FORMULA . [SEP]\n", "[CLS] Let us now proceed with the proof of Theorem REF , starting with the assumption [SEP]\n", "[CLS] that our risk assignment satisfies conditions (A), (B), and (C). [SEP]\n", "[CLS]   Calibration within groups. [SEP]\n", "[CLS] We begin by working out some useful expressions in terms of the matrices and vectors defined above. [SEP]\n", "[CLS] We observe that FORMULA  is a vector in FORMULA  whose coordinate corresponding to feature vector FORMULA  equals the number of people in group FORMULA  who have feature vector FORMULA  and belong to the positive class. [SEP]\n", "[CLS] FORMULA  is a vector in FORMULA  whose coordinate corresponding to bin FORMULA  equals the expected number of people in group FORMULA  assigned to bin FORMULA . [SEP]\n", "[CLS] By further multiplying these vectors on the right, we get additional useful quantities. [SEP]\n", "[CLS] Here are two in particular:  FORMULA  is a vector in FORMULA  whose coordinate corresponding to bin FORMULA  equals the expected sum of the scores assigned to all group-FORMULA  people in bin FORMULA . [SEP]\n", "[CLS] That is, using the subscript FORMULA  to denote the coordinate corresponding to bin FORMULA , we can write FORMULA  by the definition of the diagonal matrix FORMULA . [SEP]\n", "[CLS]  FORMULA  is a vector in FORMULA  whose coordinate corresponding to bin FORMULA  equals the expected number of group-FORMULA  people in the positive class who are placed in bin FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Now, condition (A), that the risk assignment is calibrated within groups, implies that the two vectors above are equal coordinate-wise, and so we have the following equation for all FORMULA : FORMULA   [SEP]\n", "[CLS] Calibration condition (A) also has an implication for the total score received by all people in group FORMULA . [SEP]\n", "[CLS] Suppose we multiply the two sides of (REF ) on the right by the vector FORMULA  whose coordinates are all 1, obtaining FORMULA   [SEP]\n", "[CLS] The left-hand-side is the number of group-FORMULA  people in the positive class. [SEP]\n", "[CLS] The right-hand-side, which we can also write as FORMULA , is equal to the sum of the expected scores received by all group-FORMULA  people. [SEP]\n", "[CLS] These two quantities are thus the same, and we write their common value as FORMULA . [SEP]\n", "[CLS]   Fairness to the positive and negative classes. [SEP]\n", "[CLS] We now want to write down vector equations corresponding to the fairness conditions (B) and (C) for the negative and positive classes. [SEP]\n", "[CLS] First, recall that for the FORMULA -dimensional vector FORMULA , the coordinate corresponding to bin FORMULA  equals the expected number of group-FORMULA  people in the positive class who are placed in bin FORMULA . [SEP]\n", "[CLS] Thus, to compute the sum of the expected scores received by all group-FORMULA  people in the positive class, we simply need to take the inner product with the vector FORMULA , yielding FORMULA . [SEP]\n", "[CLS] Since FORMULA  is the total number of group-FORMULA  people in the positive class, the average of the expected scores received by a group-FORMULA  person in the positive class is the ratio FORMULA . [SEP]\n", "[CLS] Thus, condition (C), that members of the positive class should receive the same average score in each group, can be written FORMULA  Applying strictly analogous reasoning but to the fractions [SEP]\n", "[CLS] FORMULA  of people in the negative class, we can write condition (B), that members of the negative class should receive the same average score in each group, as FORMULA   [SEP]\n", "[CLS] Using\u00a0(REF ), we can rewrite\u00a0(REF ) to get FORMULA   [SEP]\n", "[CLS] Similarly, we can rewrite\u00a0(REF ) as FORMULA    The portion of the score received by the positive class. [SEP]\n", "[CLS] We think of the ratios on the two sides of (REF ), and equivalently (REF ), as the average of the expected scores received by a member of the positive class in group FORMULA : the numerator is the sum of the expected scores received by the members of the positive class, and the denominator is the size of the positive class. [SEP]\n", "[CLS] Let us denote this fraction by FORMULA ; we note that this is the quantity FORMULA  used in the informal overview of the proof at the start of the section. [SEP]\n", "[CLS] By (REF ), we can alternately think of the denominator as the sum of the expected scores received by all group-FORMULA  people. [SEP]\n", "[CLS] Hence, the two sides of (REF ) and (REF ) can be viewed as representing the ratio of the sum of the expected scores in the positive class of group FORMULA  to the sum of the expected scores in group FORMULA  as a whole. [SEP]\n", "[CLS] (REF ) requires that FORMULA ; let us denote this common value by FORMULA . [SEP]\n", "[CLS] Now, we observe that FORMULA  corresponds to a case in which the sum of the expected scores in just the positive class of group FORMULA  is equal to the sum of the expected scores in all of group FORMULA . [SEP]\n", "[CLS] In this case, it must be that all members of the negative class are assigned to bins of score 0. [SEP]\n", "[CLS] If any members of the positive class were assigned to a bin of score 0, this would violate the calibration condition (A); hence all members of the positive class are assigned to bins of positive score. [SEP]\n", "[CLS] Moreover, these bins of positive score contain no members of the negative class (since they've all been assigned to bins of score 0), and so again by the calibration condition (A), the members of the positive class are all assigned to bins of score 1. [SEP]\n", "[CLS] Finally, applying the calibration condition once more, it follows that the members of the negative class all have feature vectors FORMULA  with FORMULA  and the members of the positive class all have feature vectors FORMULA  with FORMULA . [SEP]\n", "[CLS] Hence, when FORMULA  we have perfect prediction. [SEP]\n", "[CLS] Finally, we use our definition of FORMULA  as FORMULA , and the fact that FORMULA  to write (REF ) as  1N1-1 (1 - 1) = 1N2-2 (2 - 2) 1N1-1 1 (1 - ) = 1N2-2 2 (1 - ) 1/N11-1/N1 (1 - ) = 2/N21-2/N2 (1 - )   [SEP]\n", "[CLS] Now, this last equality implies that one of two things must be the case. [SEP]\n", "[CLS] Either FORMULA , in which case FORMULA   [SEP]\n", "[CLS] and we have perfect prediction; or FORMULA  in which case FORMULA   [SEP]\n", "[CLS] and we have equal base rates. [SEP]\n", "[CLS] This completes the proof of Theorem REF . [SEP]\n", "[CLS]   Some Comments on the Connection to Statistical Parity. [SEP]\n", "[CLS] Earlier we noted that conditions (B) and (C) \u2014 the balance conditions for the positive and negative classes \u2014 are quite different from the requirement of statistical parity, which asserts that the average of the scores over all members of each group be the same. [SEP]\n", "[CLS] When the two groups have equal base rates, then the risk assignment that gives the same score to everyone in the population achieves statistical parity along with conditions (A), (B), and (C). [SEP]\n", "[CLS] But when the two groups do not have equal base rates, it is immediate to show that statistical parity is inconsistent with both the calibration condition (A) and with the conjunction of the two balance conditions (B) and (C). [SEP]\n", "[CLS] To see the inconsistency of statistical parity with the calibration condition, we take Equation (REF ) from the proof above, sum the coordinates of the vectors on both sides, and divide by FORMULA , the number of people in group FORMULA . [SEP]\n", "[CLS] Statistical parity requires that the right-hand sides of the resulting equation be the same for FORMULA , while the assumption that the two groups have unequal base rates implies that the left-hand sides of the equation must be different for FORMULA . [SEP]\n", "[CLS] To see the inconsistency of statistical parity with the two balance conditions (B) and (C), we simply observe that if the average score assigned to the positive class and to the negative class are the same in the two groups, then the average of the scores over all members of the two groups cannot be the same provided they do not contain the same proportion of positive-class and negative-class members. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The Approximate Theorem In this section we prove Theorem REF . [SEP]\n", "[CLS] First, we must first give a precise specification of the approximate fairness conditions:  (1-) [ntXV]b [ntPX]b (1-) [ntXV]b A' (1-) (1N2-2) nt(I-P) Xv [SEP]\n", "[CLS] (1N1-1) nt(I-P)Xv (1+) (1N2-2) nt(I-P) Xv [SEP]\n", "[CLS] B' (1-) (12) ntP [SEP]\n", "[CLS] Xv (11) ntPXv [SEP]\n", "[CLS] (1+) (12) ntP Xv C'   For () and (), we also require that these hold when FORMULA  and FORMULA  are interchanged. [SEP]\n", "[CLS] We also specify the approximate versions of perfect prediction and equal base rates in terms of FORMULA , which is a function that goes to 0 as FORMULA  goes to 0. [SEP]\n", "[CLS]  Approximate perfect prediction. [SEP]\n", "[CLS] FORMULA  and  FORMULA   [SEP]\n", "[CLS] Approximately equal base rates. [SEP]\n", "[CLS]  FORMULA   [SEP]\n", "[CLS] A brief overview of the proof of Theorem REF  is as follows. [SEP]\n", "[CLS] It proceeds by first establishing an approximate form of Equation (REF ) above, which implies that the total expected score assigned in each group is approximately equal to the total size of the positive class. [SEP]\n", "[CLS] This in turn makes it possible to formulate approximate forms of Equations (REF ) and (REF ). [SEP]\n", "[CLS] When the base rates are close together, the approximation is too loose to derive bounds on the predictive power; but this is okay since in this case we have approximately equal base rates. [SEP]\n", "[CLS] Otherwise, when the base rates differ significantly, we show that most of the expected score must be assigned to the positive class, giving us approximately perfect prediction. [SEP]\n", "[CLS] The remainder of this section provides the full details of the proof. [SEP]\n", "[CLS]  Total scores and the number of people in the positive class. [SEP]\n", "[CLS] First, we will show that the total score for each group is approximately FORMULA , the number of people in the positive class. [SEP]\n", "[CLS] Define FORMULA . [SEP]\n", "[CLS] Using (), we have  t = ntXv = ntXVe = b=1B [ntPX]b (1+) b=1B [SEP]\n", "[CLS] [ntPX]b = (1+) ntPXe = (1+) t   [SEP]\n", "[CLS] Similarly, we can lower bound FORMULA  as  t = b=1B [ntPX]b (1-) b=1B [SEP]\n", "[CLS] [ntPX]b = (1-) t   [SEP]\n", "[CLS] Combining these, we have FORMULA     [SEP]\n", "[CLS] The portion of the score received by the positive class. [SEP]\n", "[CLS] We can use () to show that FORMULA . [SEP]\n", "[CLS] Recall that FORMULA , the average of the expected scores assigned to members of the positive class in group FORMULA , is defined as FORMULA . [SEP]\n", "[CLS] Then, it follows trivially from () that FORMULA     [SEP]\n", "[CLS] The relationship between the base rates. [SEP]\n", "[CLS] We can apply this to () to relate FORMULA  and FORMULA , using the observation that the score not received by people of the positive class must fall instead to people of the negative class. [SEP]\n", "[CLS] Examining the left inequality of (), we have  (1-) (1N2-2) nt(I-P) Xv = (1-) (1N2-2) (ntXv - ntPXv) = (1-) (1N2-2) (2 - 2 2) (1-) (1N2-2) ((1-) 2 - 2 t) = (1-) (2N2-2) (1-- 2) (1-) (2N2-2) (1-- 11-) = (1-2+ 2 - 1)(2N2-2)   [SEP]\n", "[CLS] Thus, the left inequality of () becomes FORMULA   [SEP]\n", "[CLS] By definition, FORMULA  and FORMULA , so this becomes FORMULA    If the base rates differ. [SEP]\n", "[CLS] Let FORMULA  and FORMULA  be the respective base rates, i.e. FORMULA  and FORMULA . [SEP]\n", "[CLS] Assume that FORMULA  (otherwise we can switch FORMULA  and FORMULA  in the above analysis), and assume towards contradiction that the base rates differ by at least FORMULA , meaning FORMULA . [SEP]\n", "[CLS] Using (REF ),  1 + 1-1 =  21-2   [SEP]\n", "[CLS] (1+- 11 - 2+ 2 - 1)(11-1) (1 + )(1-1)(1 - 2+ 2 - 1) 1 (1-1 - )(1+- 1) (1 + )(1-1)(1-2) - 1(1-1 - )(1+) 1 [SEP]\n", "[CLS] [(1 + )(1-1) - 1(1-1 - )] 1[(1-1)(1-2) - (1-1-)(1+)] + (1-1)(1-2) 1 [SEP]\n", "[CLS] [(1-1) +  1] 1(-2+ 21 - + 1 +  + ) +  (1 [SEP]\n", "[CLS] - 2- 1 + 21) 1 1(-3+ 31 +  +  -  + 2) + (1-2) 1 1(-3 + 3 1 + 3 ) + (1-2) 1 31(-1 + 1) + (1-2) 1 1 - 2- 31(1-1) 1 1 - (2 + 34) 1  Recall that FORMULA , so  2 (1-) 1 [SEP]\n", "[CLS] (1-)(1- (2  + 34)) 1 - -  (2  + 34) = 1 -  (3 + 34)   [SEP]\n", "[CLS] Let FORMULA . [SEP]\n", "[CLS] Note that we assumed that FORMULA  and FORMULA  differ by an additive FORMULA . [SEP]\n", "[CLS] Therefore if the FORMULA -fairness conditions are met and the base rates are not within an additive FORMULA , then FORMULA  and FORMULA . [SEP]\n", "[CLS] This completes the proof of Theorem REF . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Reducing Loss with Equal Base Rates In a risk assignment, we would like as much of the score as possible to be assigned to members of the positive class. [SEP]\n", "[CLS] With this in mind, if an individual receives a score of FORMULA , we define their individual loss to be FORMULA  if they belong to the negative class, and FORMULA  if they belong to the positive class. [SEP]\n", "[CLS] The loss of the risk assignment in group FORMULA  is then the sum of the expected individual losses to each member of group FORMULA . [SEP]\n", "[CLS] In terms of the matrix-vector products used in the proof of Theorem REF , one can show that the loss for group FORMULA  may be written as  t(X) = nt(I-P)Xv + (t - ntPXv) = 2(t - ntPXv),  and the total loss is just the weighted sum of the losses for each group. [SEP]\n", "[CLS] Now, let us say that a fair assignment is one that satisfies our three conditions (A), (B), and (C). [SEP]\n", "[CLS] As noted above, when the base rates in the two groups are equal, the set of fair assignments is non-empty, since the calibrated risk assignment that places everyone in a single bin is fair. [SEP]\n", "[CLS] We can therefore ask, in the case of equal base rates, whether there exists a fair assignment whose loss is strictly less than that of the trivial one-bin assignment. [SEP]\n", "[CLS] It is not hard to show that this is possible if and only if there is any assignment using more than one bin; we will call such an assignment a non-trivial assignment. [SEP]\n", "[CLS] Note that the assignment that minimizes loss is simply the one that assigns each FORMULA  to a separate bin with a score of FORMULA , meaning FORMULA  is the identity matrix. [SEP]\n", "[CLS] While this assignment, which we refer to as the identity assignment FORMULA , is well-calibrated, it may violate fairness conditions (B) and (C). [SEP]\n", "[CLS] It is not hard to show that the loss for any other assignment is strictly greater than the loss for FORMULA . [SEP]\n", "[CLS] As a result, unless the identity assignment happens to be fair, every fair assignment must have larger loss than that of FORMULA , forcing a tradeoff between performance and fairness. [SEP]\n", "[CLS] Characterization of Well-Calibrated Solutions To better understand the space of feasible solutions, suppose we drop the fairness conditions (B) and (C) for now and study risk assignments that are simply well-calibrated, satisfying (A). [SEP]\n", "[CLS] As in the proof of Theorem REF , we write FORMULA  for the average of the expected scores assigned to members of the positive class in group FORMULA , and we define the fairness difference to be FORMULA . [SEP]\n", "[CLS] If this is nonnegative, we say the risk assignment weakly favors group 1; if it is nonpositive, it weakly favors group 2. [SEP]\n", "[CLS] Since a risk assignment is fair if and only if FORMULA , it is fair if and only if the fairness difference is 0. [SEP]\n", "[CLS] We wish to characterize when non-trivial fair risk assignments are possible. [SEP]\n", "[CLS] First, we observe that without the fairness requirements, the set of possible fairness differences under well-calibrated assignments is an interval. [SEP]\n", "[CLS] Lemma 4.1 [SEP]\n", "[CLS] If group 1 and group 2 have equal base rates, then for any two non-trivial well-calibrated risk assignments with fairness differences FORMULA  and FORMULA  and for any FORMULA , there exists a non-trivial well-calibrated risk assignment with fairness difference FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Proof:\u00a0\u00a0  [SEP]\n", "[CLS] The basic idea is that we can effectively take convex combinations of well-calibrated assignments to produce any well-calibrated assignment \u201cin between\u201d them. [SEP]\n", "[CLS] We carry this out as follows. [SEP]\n", "[CLS] Let FORMULA  and FORMULA  be the allocation matrices for assignments with fairness differences FORMULA  and FORMULA  respectively, where FORMULA . [SEP]\n", "[CLS] Choose FORMULA  such that FORMULA , meaning FORMULA . [SEP]\n", "[CLS] Then, FORMULA  is a nontrivial well-calibrated assignment with fairness difference FORMULA . [SEP]\n", "[CLS] First, we observe that FORMULA  is a valid assignment because each row sums to 1 (meaning everyone from every FORMULA  gets assigned to a bin), since each row of FORMULA  sums to FORMULA  and each row of FORMULA  sums to FORMULA . [SEP]\n", "[CLS] Moreover, it is nontrivial because every nonempty bin created by FORMULA  and FORMULA  is a nonempty bin under FORMULA . [SEP]\n", "[CLS] Let FORMULA  and FORMULA  be the respective bin labels for assignments FORMULA  and FORMULA . [SEP]\n", "[CLS] Define FORMULA . [SEP]\n", "[CLS] Finally, let FORMULA . [SEP]\n", "[CLS] Define FORMULA  and FORMULA  analogously. [SEP]\n", "[CLS] Note that FORMULA . [SEP]\n", "[CLS] We observe that FORMULA  is calibrated because  ntPX(3) = ntP [SEP]\n", "[CLS] [X(1) \u00a0\u00a0\u00a0  [SEP]\n", "[CLS] (1-) X(2)] = [ntPX(1) \u00a0\u00a0\u00a0  [SEP]\n", "[CLS] (1-) ntPX(2)] = [ntX(1) V(1) \u00a0\u00a0\u00a0  [SEP]\n", "[CLS] (1-) ntX(2)V(2)] = nt[X(1) \u00a0\u00a0\u00a0  [SEP]\n", "[CLS] (1-) X(2)] V(3) = ntX(3)V(3) Finally, we show that the fairness difference is FORMULA . [SEP]\n", "[CLS] Let FORMULA  and FORMULA  be the portions of the total expected score received by the positive class from each group respectively. [SEP]\n", "[CLS] Define FORMULA  similarly. [SEP]\n", "[CLS]  1(3) - 2(3) = 1 n1PX(3)v(3) - 1 n2PX(3)v(3) = 1 (n1- n2) PX(3)v(3) = 1 [SEP]\n", "[CLS] (n1- n2) P[X(1)v(1) \u00a0\u00a0\u00a0  [SEP]\n", "[CLS] (1-) X(2) v(2)] = 1 [SEP]\n", "[CLS] ((n1- n2) PX(1)v(1) + (1-) (n1- n2) X(2) v(2)]) = (1(1) - 2(1)) + (1-) (1(2) - 2(2)) = d1 + (1-) d2 = d3   FORMULA Corollary 4.2 There exists a non-trivial fair assignment if and only if there exist non-trivial well-calibrated assignments FORMULA  and FORMULA  such that FORMULA  weakly favors group 1 and FORMULA  weakly favors group 2.   [SEP]\n", "[CLS] Proof:\u00a0\u00a0  [SEP]\n", "[CLS] If there is a non-trivial fair assignment, then it weakly favors both group 1 and group 2, proving one direction. [SEP]\n", "[CLS] To prove the other direction, observe that the fairness differences FORMULA  and FORMULA  of FORMULA  and FORMULA  are nonnegative and nonpositive respectively. [SEP]\n", "[CLS] Since the set of fairness differences achievable by non-trivial well-calibrated assignments is an interval by Lemma REF , there exists a non-trivial well-calibrated assignment with fairness difference 0, meaning there exists a non-trivial fair assignment. [SEP]\n", "[CLS]  FORMULA It is an open question whether there is a polynomial-time algorithm to find a fair assignment of minimum loss, or even to determine whether a non-trivial fair solution exists. [SEP]\n", "[CLS]  NP-Completeness of Non-Trivial Integral Fair Risk Assignments As discussed in the introduction, risk assignments in our model are allowed to split people with a given feature vector FORMULA  over several bins; however, it is also of interest to consider the special case of integral risk assignments, in which all people with a given feature FORMULA  must go to the same bin. [SEP]\n", "[CLS] For the case of equal base rates, we can show that determining whether there is a non-trivial integral fair assignment is NP-complete. [SEP]\n", "[CLS] The proof uses a reduction from the Subset Sum problem and is given in the Appendix. [SEP]\n", "[CLS] The basic idea of the reduction is as follows. [SEP]\n", "[CLS] We have an instance of Subset Sum with numbers FORMULA  and a target number FORMULA ; the question is whether there is a subset of the FORMULA 's that sums to FORMULA . [SEP]\n", "[CLS] As before, FORMULA  denotes the average of the expected scores received by members of the positive class in group FORMULA . [SEP]\n", "[CLS] We first ensure that there is exactly one non-trivial way to allocate the people of group 1, allowing us to control FORMULA . [SEP]\n", "[CLS] The fairness conditions then require that FORMULA , which we can use to encode the target value in the instance of Subset Sum. [SEP]\n", "[CLS] For every input number FORMULA  in the Subset Sum instance, we create FORMULA  and FORMULA , close to each other in value and far from all other FORMULA  values, such that grouping FORMULA  and FORMULA  together into a bin corresponds to choosing FORMULA  for the subset, while not grouping them corresponds to not taking FORMULA . [SEP]\n", "[CLS] This ensures that group 2 can be assigned with the correct value of FORMULA   [SEP]\n", "[CLS] if and only if there is a solution to the Subset Sum instance. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusion [SEP]\n", "[CLS] In this work we have formalized three fundamental conditions for risk assignments to individuals, each of which has been proposed as a basic measure of what it means for the risk assignment to be fair. [SEP]\n", "[CLS] Our main results show that except in highly constrained special cases, it is not possible to satisfy these three constraints simultaneously; and moreover, a version of this fact holds in an approximate sense as well. [SEP]\n", "[CLS] Since these results hold regardless of the method used to compute the risk assignment, it can be phrased in fairly clean terms in a number of domains where the trade-offs among these conditions do not appear to be well-understood. [SEP]\n", "[CLS] To take one simple example, suppose we want to determine the risk that a person is a carrier for a disease FORMULA , and suppose that a higher fraction of women than men are carriers. [SEP]\n", "[CLS] Then our results imply that in any test designed to estimate the probability that someone is a carrier of FORMULA , at least one of the following undesirable properties must hold: (a) the test's probability estimates are systematically skewed upward or downward for at least one gender; or (b) the test assigns a higher average risk estimate to healthy people (non-carriers) in one gender than the other; or (c) the test assigns a higher average risk estimate to carriers of the disease in one gender than the other. [SEP]\n", "[CLS] The point is that this trade-off among (a), (b), and (c) is not a fact about medicine; it is simply a fact about risk estimates when the base rates differ between two groups. [SEP]\n", "[CLS] Finally, we note that our results suggest a number of interesting directions for further work. [SEP]\n", "[CLS] First, when the base rates between the two underlying groups are equal, our results do not resolve the computational tractability of finding the most accurate risk assignment, subject to our three fairness conditions, when the people with a given feature vector can be split across multiple bins. [SEP]\n", "[CLS] (Our NP-completeness result applies only to the case in which everyone with a given feature vector must be assigned to the same bin.) [SEP]\n", "[CLS] Second, there may be a number of settings in which the cost (social or otherwise) of false positives may differ greatly from the cost of false negatives. [SEP]\n", "[CLS] In such cases, we could imagine searching for risk assignments that satisfy the calibration condition together with only one of the two balance conditions, corresponding to the class for whom errors are more costly. [SEP]\n", "[CLS] Determining when two of our three conditions can be simultaneously satisfied in this way is an interesting open question. [SEP]\n", "[CLS] More broadly, determining how the trade-offs discussed here can be incorporated into broader families of proposed fairness conditions suggests interesting avenues for future research. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Appendix: NP-Completeness of Non-Trivial Integral Fair Risk Assignments We can reduce to the integral assignment problem, parameterized by FORMULA , and FORMULA , from subset sum as follows. [SEP]\n", "[CLS] Suppose we have an instance of the subset sum problem specified by FORMULA  numbers FORMULA  and a target FORMULA ; the goal is to determine whether a subset of the FORMULA  add up to FORMULA . [SEP]\n", "[CLS] We create an instance of the integral assignment problem with FORMULA . [SEP]\n", "[CLS] FORMULA   [SEP]\n", "[CLS] if FORMULA  and 0 otherwise. [SEP]\n", "[CLS] FORMULA   [SEP]\n", "[CLS] if FORMULA  and 0 otherwise. [SEP]\n", "[CLS] We make the following definitions:  wi = wi/(T m4) i = wi / 2 p2i-1 = i/(m+1) - i  FORMULA p2i = i/(m+1) + i  FORMULA = 1/m i=12m pi2 - 1/m5 p2m+1 = (1 - 2-1)/2 p2m+2 = (1 + 2-1)/2 [SEP]\n", "[CLS] With this definition, the subset sum instance has a solution if and only if the integral assignment instance given by FORMULA  has a solution. [SEP]\n", "[CLS] Before we prove this, we need the following lemma. [SEP]\n", "[CLS] Lemma 5.1 For any FORMULA , FORMULA    [SEP]\n", "[CLS] Proof:\u00a0\u00a0  i=1k zi2 - 1k (i=1m zi)2 = i=1k zi2 - 1k (i=1k zi2 + 2 i < jk zi zj) = k-1k i=1k zi2 - 2k i < jk zi zj = 1k [SEP]\n", "[CLS] i < jk (zi2 + zj2) - 2k i < jk zi zj = 1k [SEP]\n", "[CLS] i < jk zi2 - 2 zi zj + zj2 = 1k i < jk (zi - zj)2   FORMULA Now, we can prove that the integral assignment problem is NP-hard. [SEP]\n", "[CLS] Proof:\u00a0\u00a0  [SEP]\n", "[CLS] First, we observe that for any nontrivial solution to the integral assignment instance, there must be two bins FORMULA  such that FORMULA  and FORMULA . [SEP]\n", "[CLS] In other words, the people with FORMULA  and FORMULA  must be split up. [SEP]\n", "[CLS] If not, then all the people of group 1 would be in the same bin, meaning that bin must be labeled with the base rate FORMULA . [SEP]\n", "[CLS] In order to maintain fairness, the same would have to be done for all the people of group 2, resulting in the trivial solution. [SEP]\n", "[CLS] Moreover, FORMULA  and FORMULA  must be labeled FORMULA  respectively because those are the fraction of people of group 1 in those bins who belong to the positive class. [SEP]\n", "[CLS] This means that FORMULA  as defined above. [SEP]\n", "[CLS] We know that a well-calibrated assignment is fair only if FORMULA , so we know FORMULA . [SEP]\n", "[CLS] Next, we observe that FORMULA  because all of the positive FORMULA 's are FORMULA , so FORMULA  is just the average of FORMULA , which is FORMULA  by symmetry. [SEP]\n", "[CLS] Let FORMULA  be the partition of FORMULA  corresponding to the assignment, meaning that for a given FORMULA , there is a bin FORMULA  containing all people with FORMULA  such that FORMULA . [SEP]\n", "[CLS] The label on that bin is  vq = [SEP]\n", "[CLS] i q a2,i pii q a2,i = 1/(2m) i q pi|q|/(2m) = 1|q| [SEP]\n", "[CLS] i q pi   [SEP]\n", "[CLS] Furthermore, bin FORMULA  contains FORMULA  positive fraction. [SEP]\n", "[CLS] Using this, we can come up with an expression for FORMULA . [SEP]\n", "[CLS]  2 = 1 q Q (vb 12m i q pi) = 1m q Q 1|q| [SEP]\n", "[CLS] (i q pi)2   [SEP]\n", "[CLS] Setting this equal to FORMULA , we have  1m q Q 1|q| (i q pi)2 = 1m i=12m pi2 - 1m5 q Q 1|q| (i q pi)2 = i=12m pi2 - 1m4   [SEP]\n", "[CLS] Subtracting both sides from FORMULA  and using Lemma\u00a0REF , we have FORMULA   [SEP]\n", "[CLS] Thus, FORMULA  is a fair nontrivial assignment if and only if (REF ) holds. [SEP]\n", "[CLS] Next, we show that there exists FORMULA  that satisfies (REF ) if and only if there there exists some FORMULA  such that FORMULA . [SEP]\n", "[CLS] Assume FORMULA  satisfies (REF ). [SEP]\n", "[CLS] Then, we first observe that any FORMULA  must either contain a single FORMULA , meaning it does not contribute to the left hand side of (REF ), or FORMULA  for some FORMULA . [SEP]\n", "[CLS] To show this, observe that the closest two elements of FORMULA  not of the form FORMULA  must be some FORMULA . [SEP]\n", "[CLS] However, we find that  (p2i+1 - p2i)2 = (i+1m+1 - i+1 - (im+1 + i))2 = (1m+1 - i+1 - i)2 = (1m+1 - wi+12 - wi2)2 (1m+1 - 2m4 FORMULA )2 = (1m+1 - 2m2)2 (12m - 2m2)2 = (m - 222m2)2 (m4m2)2 = (14m)2 = 116 m2   [SEP]\n", "[CLS] If any FORMULA  contains any FORMULA  not of the form FORMULA , then (REF ) will have a term on the left hand side at least FORMULA  for large enough FORMULA , and since there can be no negative terms on the left hand side, this immediately makes it impossible for FORMULA  to satisfy (REF ). [SEP]\n", "[CLS] Consider every FORMULA . [SEP]\n", "[CLS] Let FORMULA . [SEP]\n", "[CLS] As shown above, either FORMULA  or FORMULA  and FORMULA . [SEP]\n", "[CLS] In the latter case, neither FORMULA  nor FORMULA  contributes to (REF ). [SEP]\n", "[CLS] If FORMULA , then FORMULA  contributes FORMULA  to the overall sum on the left hand side. [SEP]\n", "[CLS] Therefore, we can write the left hand side of (REF ) as FORMULA   [SEP]\n", "[CLS] Then, we can build a solution to the original subset sum instance as FORMULA , giving us FORMULA . [SEP]\n", "[CLS] Multiplying both sides by FORMULA , we get FORMULA , meaning FORMULA  is a solution for the subset sum instance. [SEP]\n", "[CLS] To prove the other direction, assume we have a solution FORMULA  such that FORMULA . [SEP]\n", "[CLS] Dividing both sides by FORMULA , we get FORMULA . [SEP]\n", "[CLS] We build a partition FORMULA  of FORMULA  by starting with the empty set and adding FORMULA  to FORMULA  if FORMULA  and FORMULA  and FORMULA  to FORMULA  otherwise. [SEP]\n", "[CLS] Clearly, each element of FORMULA  appears in FORMULA  at most once, making this a valid partition. [SEP]\n", "[CLS] Moreover, when checking to see if (REF ) is satisfied (which is true if and only if FORMULA  is a fair assignment), we can ignore all FORMULA  such that FORMULA  because they don't contribute to the left hand side. [SEP]\n", "[CLS] Since, we again have FORMULA  meaning FORMULA  is a fair assignment. [SEP]\n", "[CLS] This completes the reduction. [SEP]\n", "[CLS]  FORMULA We have shown that the integral assignment problem is NP-hard, and it is clearly in NP because given an integral assignment, we can verify in polynomial time whether such an assignment satisfies the conditions (A), (B), and (C). [SEP]\n", "[CLS] Thus, the integral assignment problem is NP-complete. [SEP]\n"], "1708.02182": ["[CLS]  Regularizing and Optimizing LSTM Language Models [SEP]\n", "[CLS] [ Regularizing and Optimizing LSTM Language Models Stephen Meritysfr Nitish Shirish Keskarsfr Richard Sochersfr sfrSalesforce Research, Palo Alto, USA Stephen Meritysmerity@salesforce.com machine learning, deep learning, LSTM, regularization, optimization ] Recurrent neural networks (RNNs), such as long short-term memory networks (LSTMs), serve as a fundamental building block for many sequence learning tasks, including machine translation, language modeling, and question answering. [SEP]\n", "[CLS] In this paper, we consider the specific problem of word-level language modeling and investigate strategies for regularizing and optimizing LSTM-based models. [SEP]\n", "[CLS] We propose the weight-dropped LSTM which uses DropConnect on hidden-to-hidden weights as a form of recurrent regularization. [SEP]\n", "[CLS] Further, we introduce NT-ASGD, a variant of the averaged stochastic gradient method, wherein the averaging trigger is determined using a non-monotonic condition as opposed to being tuned by the user. [SEP]\n", "[CLS] Using these and other regularization strategies, we achieve state-of-the-art word level perplexities on two data sets: 57.3 on Penn Treebank and 65.8 on WikiText-2. [SEP]\n", "[CLS] In exploring the effectiveness of a neural cache in conjunction with our proposed model, we achieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and 52.0 on WikiText-2. [SEP]\n", "[CLS] Introduction Effective regularization techniques for deep learning have been the subject of much research in recent years. [SEP]\n", "[CLS] Given the over-parameterization of neural networks, generalization performance crucially relies on the ability to regularize the models sufficiently. [SEP]\n", "[CLS] Strategies such as dropout {{cite:17e16bff-87ee-466b-a3cd-51b68e865c38}} and batch normalization {{cite:a798fff3-08b9-44eb-8455-b6cadc686dbb}} have found great success and are now ubiquitous in feed-forward and convolutional neural networks. [SEP]\n", "[CLS] Na\u00efvely applying these approaches to the case of recurrent neural networks (RNNs) has not been highly successful however. [SEP]\n", "[CLS] Many recent works have hence been focused on the extension of these regularization strategies to RNNs; we briefly discuss some of them below. [SEP]\n", "[CLS] A na\u00efve application of dropout {{cite:17e16bff-87ee-466b-a3cd-51b68e865c38}} to an RNN's hidden state is ineffective as it disrupts the RNN's ability to retain long term dependencies {{cite:b00ecdca-ccd8-443f-88e0-674ceb433337}}. [SEP]\n", "[CLS] {{cite:1f93d427-c2eb-40eb-ba5d-71f52a277d7b}} propose overcoming this problem by retaining the same dropout mask across multiple time steps as opposed to sampling a new binary mask at each timestep. [SEP]\n", "[CLS] Another approach is to regularize the network through limiting updates to the RNN's hidden state. [SEP]\n", "[CLS] One such approach is taken by {{cite:8942cab4-f8e4-4fa8-8ab2-5ad25d859eec}} wherein the authors drop updates to network units, specifically the input gates of the LSTM, in lieu of the units themselves. [SEP]\n", "[CLS] This is reminiscent of zoneout {{cite:564cfaee-c8e5-4e2e-8e27-aa52acb21fd5}} where updates to the hidden state may fail to occur for randomly selected neurons. [SEP]\n", "[CLS] Instead of operating on the RNN's hidden states, one can regularize the network through restrictions on the recurrent matrices as well. [SEP]\n", "[CLS] This can be done either through restricting the capacity of the matrix {{cite:08d39b55-adf3-485b-b235-448b292468f4}}, {{cite:e3825b72-b752-4f82-8529-59c864c9af18}}, {{cite:1eaf2e51-cf4a-4ee6-a901-8cb423db8522}} or through element-wise interactions {{cite:4e7915ca-c0b6-49ab-9708-2521cdbe67a7}}, {{cite:9f3783e4-edcb-4a41-adc0-c1db84e8f4dc}}, {{cite:165ee27f-4806-4cbb-bdc8-5de661afea4e}}. [SEP]\n", "[CLS] Other forms of regularization explicitly act upon activations such as batch normalization\u00a0{{cite:a798fff3-08b9-44eb-8455-b6cadc686dbb}}, recurrent batch normalization\u00a0{{cite:fb651292-8fc8-4446-ab87-20ca857e2ad6}}, and layer normalization\u00a0{{cite:f1996132-199c-4505-b407-a836c547ee28}}. [SEP]\n", "[CLS] These all introduce additional training parameters and can complicate the training process while increasing the sensitivity of the model. [SEP]\n", "[CLS] In this work, we investigate a set of regularization strategies that are not only highly effective but which can also be used with no modification to existing LSTM implementations. [SEP]\n", "[CLS] The weight-dropped LSTM applies recurrent regularization through a DropConnect mask on the hidden-to-hidden recurrent weights. [SEP]\n", "[CLS] Other strategies include the use of randomized-length backpropagation through time (BPTT), embedding dropout, activation regularization (AR), and temporal activation regularization (TAR). [SEP]\n", "[CLS] As no modifications are required of the LSTM implementation these regularization strategies are compatible with black box libraries, such as NVIDIA cuDNN, which can be many times faster than na\u00efve LSTM implementations. [SEP]\n", "[CLS] Effective methods for training deep recurrent networks have also been a topic of renewed interest. [SEP]\n", "[CLS] Once a model has been defined, the training algorithm used is required to not only find a good minimizer of the loss function but also converge to such a minimizer rapidly. [SEP]\n", "[CLS] The choice of the optimizer is even more important in the context of regularized models since such strategies, especially the use of dropout, can impede the training process. [SEP]\n", "[CLS] Stochastic gradient descent (SGD), and its variants such as Adam {{cite:3ce28d0b-8805-4317-bf94-426b8a80c4c0}} and RMSprop {{cite:f6af8535-5ff5-4a61-a7d6-0d1d00a60394}} are amongst the most popular training methods. [SEP]\n", "[CLS] These methods iteratively reduce the training loss through scaled (stochastic) gradient steps. [SEP]\n", "[CLS] In particular, Adam has been found to be widely applicable despite requiring less tuning of its hyperparameters. [SEP]\n", "[CLS] In the context of word-level language modeling, past work has empirically found that SGD outperforms other methods in not only the final loss but also in the rate of convergence. [SEP]\n", "[CLS] This is in agreement with recent evidence pointing to the insufficiency of adaptive gradient methods {{cite:89b7dfe3-e059-49bc-82b8-7a87efc38e08}}. [SEP]\n", "[CLS] Given the success of SGD, especially within the language modeling domain, we investigate the use of averaged SGD (ASGD) {{cite:163cba14-eead-4bb3-9b87-f562becb0ea4}} which is known to have superior theoretical guarantees. [SEP]\n", "[CLS] ASGD carries out iterations similar to SGD, but instead of returning the last iterate as the solution, returns an average of the iterates past a certain, tuned, threshold FORMULA . [SEP]\n", "[CLS] This threshold FORMULA  is typically tuned and has a direct impact on the performance of the method. [SEP]\n", "[CLS] We propose a variant of ASGD where FORMULA  is determined on the fly through a non-monotonic criterion and show that it achieves better training outcomes compared to SGD. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Weight-dropped LSTM [SEP]\n", "[CLS] We refer to the mathematical formulation of the LSTM, FORMULA  where FORMULA  are weight matrices, FORMULA  is the vector input to the timestep FORMULA , FORMULA  is the current exposed hidden state, FORMULA  is the memory cell state, and FORMULA  is element-wise multiplication. [SEP]\n", "[CLS] Preventing overfitting within the recurrent connections of an RNN has been an area of extensive research in language modeling. [SEP]\n", "[CLS] The majority of previous recurrent regularization techniques have acted on the hidden state vector FORMULA , most frequently introducing a dropout operation between timesteps, or performing dropout on the update to the memory state FORMULA . [SEP]\n", "[CLS] These modifications to a standard LSTM prevent the use of black box RNN implementations that may be many times faster due to low-level hardware-specific optimizations. [SEP]\n", "[CLS] We propose the use of DropConnect {{cite:1ca6ce4d-4e38-4d6c-b45f-e0a9e53edc58}} on the recurrent hidden to hidden weight matrices which does not require any modifications to an RNN's formulation. [SEP]\n", "[CLS] As the dropout operation is applied once to the weight matrices, before the forward and backward pass, the impact on training speed is minimal and any standard RNN implementation can be used, including inflexible but highly optimized black box LSTM implementations such as NVIDIA's cuDNN LSTM. [SEP]\n", "[CLS] By performing DropConnect on the hidden-to-hidden weight matrices FORMULA  within the LSTM, we can prevent overfitting from occurring on the recurrent connections of the LSTM. [SEP]\n", "[CLS] This regularization technique would also be applicable to preventing overfitting on the recurrent weight matrices of other RNN cells. [SEP]\n", "[CLS] As the same weights are reused over multiple timesteps, the same individual dropped weights remain dropped for the entirety of the forward and backward pass. [SEP]\n", "[CLS] The result is similar to variational dropout, which applies the same dropout mask to recurrent connections within the LSTM by performing dropout on FORMULA , except that the dropout is applied to the recurrent weights. [SEP]\n", "[CLS] DropConnect could also be used on the non-recurrent weights of the LSTM FORMULA  though our focus was on preventing overfitting on the recurrent connection. [SEP]\n", "[CLS]  Optimization SGD is among the most popular methods for training deep learning models across various modalities including computer vision, natural language processing, and reinforcement learning. [SEP]\n", "[CLS] The training of deep networks can be posed as a non-convex optimization problem FORMULA   where FORMULA  is the loss function for the FORMULA  data point, FORMULA  are the weights of the network, and the expectation is taken over the data. [SEP]\n", "[CLS] Given a sequence of learning rates, FORMULA , SGD iteratively takes steps of the form FORMULA   where the subscript denotes the iteration number and the FORMULA  denotes a stochastic gradient that may be computed on a minibatch of data points. [SEP]\n", "[CLS] SGD demonstrably performs well in practice and also possesses several attractive theoretical properties such as linear convergence {{cite:99d55e81-63a2-4899-b1dc-ae88b675006a}}, saddle point avoidance {{cite:7a9ae2e9-a9a0-4aa5-845e-faca54bb9d14}} and better generalization performance {{cite:2bb5852e-3ea1-4ef1-b89d-0820661aa8f5}}. [SEP]\n", "[CLS] For the specific task of neural language modeling, traditionally SGD without momentum has been found to outperform other algorithms such as momentum SGD {{cite:07d68796-119a-421e-aa6a-f79c5aea4406}}, Adam {{cite:3ce28d0b-8805-4317-bf94-426b8a80c4c0}}, Adagrad {{cite:e22f679d-c9bf-4965-b9f4-552f93d457ff}} and RMSProp {{cite:f6af8535-5ff5-4a61-a7d6-0d1d00a60394}} by a statistically significant margin. [SEP]\n", "[CLS] Motivated by this observation, we investigate averaged SGD (ASGD) to further improve the training process. [SEP]\n", "[CLS] ASGD has been analyzed in depth theoretically and many surprising results have been shown including its asymptotic second-order convergence {{cite:163cba14-eead-4bb3-9b87-f562becb0ea4}}, {{cite:a1a47a5e-a2e6-45c2-b908-25ed0fed8ab1}}. [SEP]\n", "[CLS] ASGD takes steps identical to equation (REF ) but instead of returning the last iterate as the solution, returns FORMULA , where FORMULA  is the total number of iterations and FORMULA  is a user-specified averaging trigger. [SEP]\n", "[CLS] Non-monotonically Triggered ASGD (NT-ASGD)   [SEP]\n", "[CLS] Inputs: Initial point FORMULA , learning rate FORMULA , logging interval FORMULA , non-monotone interval FORMULA . [SEP]\n", "[CLS] [1] Initialize FORMULA , FORMULA , FORMULA , logs FORMULA   [SEP]\n", "[CLS] [] stopping criterion not met Compute stochastic gradient FORMULA  and take SGD step (REF ). [SEP]\n", "[CLS]  modFORMULA  and FORMULA   [SEP]\n", "[CLS] Compute validation perplexity FORMULA . [SEP]\n", "[CLS] FORMULA  and FORMULA  logs[l] Set FORMULA   [SEP]\n", "[CLS] Append FORMULA  to logs FORMULA   return   FORMULA Despite its theoretical appeal, ASGD has found limited practical use in training of deep networks. [SEP]\n", "[CLS] This may be in part due to unclear tuning guidelines for the learning-rate schedule FORMULA  and averaging trigger FORMULA . [SEP]\n", "[CLS] If the averaging is triggered too soon, the efficacy of the method is impacted, and if it is triggered too late, many additional iterations may be needed to converge to the solution. [SEP]\n", "[CLS] In this section, we describe a non-monotonically triggered variant of ASGD (NT-ASGD), which obviates the need for tuning FORMULA . [SEP]\n", "[CLS] Further, the algorithm uses a constant learning rate throughout the experiment and hence no further tuning is necessary for the decay scheduling. [SEP]\n", "[CLS] Ideally, averaging needs to be triggered when the SGD iterates converge to a steady-state distribution {{cite:a1a47a5e-a2e6-45c2-b908-25ed0fed8ab1}}. [SEP]\n", "[CLS] This is roughly equivalent to the convergence of SGD to a neighborhood around a solution. [SEP]\n", "[CLS] In the case of SGD, certain learning-rate reduction strategies such as the step-wise strategy analogously reduce the learning rate by a fixed quantity at such a point. [SEP]\n", "[CLS] A common strategy employed in language modeling is to reduce the learning rates by a fixed proportion when the performance of the model's primary metric (such as perplexity) worsens or stagnates. [SEP]\n", "[CLS] Along the same lines, one could make a triggering decision based on the performance of the model on the validation set. [SEP]\n", "[CLS] However, instead of averaging immediately after the validation metric worsens, we propose a non-monotonic criterion that conservatively triggers the averaging when the validation metric fails to improve for multiple cycles; see Algorithm . [SEP]\n", "[CLS] Given that the choice of triggering is irreversible, this conservatism ensures that the randomness of training does not play a major role in the decision. [SEP]\n", "[CLS] Analogous strategies have also been proposed for learning-rate reduction in SGD {{cite:aeafb6c7-157e-43c0-a8f4-05e8e93c4a16}}. [SEP]\n", "[CLS] While the algorithm introduces two additional hyperparameters, the logging interval FORMULA  and non-monotone interval FORMULA , we found that setting FORMULA  to be the number of iterations in an epoch and FORMULA  worked well across various models and data sets. [SEP]\n", "[CLS] As such, we use this setting in all of our NT-ASGD experiments in the following section and demonstrate that it achieves better training outcomes as compared to SGD. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Extended regularization techniques [SEP]\n", "[CLS] In addition to the regularization and optimization techniques above, we explored additional regularization techniques that aimed to improve data efficiency during training and to prevent overfitting of the RNN model. [SEP]\n", "[CLS] Variable length backpropagation sequences [SEP]\n", "[CLS] Given a fixed sequence length that is used to break a data set into fixed length batches, the data set is not efficiently used. [SEP]\n", "[CLS] To illustrate this, imagine being given 100 elements to perform backpropagation through with a fixed backpropagation through time (BPTT) window of 10. [SEP]\n", "[CLS] Any element divisible by 10 will never have any elements to backprop into, no matter how many times you may traverse the data set. [SEP]\n", "[CLS] Indeed, the backpropagation window that each element receives is equal to FORMULA  where FORMULA  is the element's index. [SEP]\n", "[CLS] This is data inefficient, preventing FORMULA  of the data set from ever being able to improve itself in a recurrent fashion, and resulting in FORMULA  of the remaining elements receiving only a partial backpropagation window compared to the full possible backpropagation window of length 10. [SEP]\n", "[CLS] To prevent such inefficient data usage, we randomly select the sequence length for the forward and backward pass in two steps. [SEP]\n", "[CLS] First, we select the base sequence length to be FORMULA  with probability FORMULA  and FORMULA  with probability FORMULA , where FORMULA  is a high value approaching 1. [SEP]\n", "[CLS] This spreads the starting point for the BPTT window beyond the base sequence length. [SEP]\n", "[CLS] We then select the sequence length according to FORMULA , where FORMULA  is the base sequence length and FORMULA  is the standard deviation. [SEP]\n", "[CLS] This jitters the starting point such that it doesn't always fall on a specific word divisible by FORMULA  or FORMULA . [SEP]\n", "[CLS] From these, the sequence length more efficiently uses the data set, ensuring that when given enough epochs all the elements in the data set experience a full BPTT window, while ensuring the average sequence length remains around the base sequence length for computational efficiency. [SEP]\n", "[CLS] During training, we rescale the learning rate depending on the length of the resulting sequence compared to the original specified sequence length. [SEP]\n", "[CLS] The rescaling step is necessary as sampling arbitrary sequence lengths with a fixed learning rate favors short sequences over longer ones. [SEP]\n", "[CLS] This linear scaling rule has been noted as important for training large scale minibatch SGD without loss of accuracy {{cite:285acf40-49e7-4185-8fb7-f752f7f214af}} and is a component of unbiased truncated backpropagation through time {{cite:8e6d5918-570c-4a62-bd90-9e134ca8a73a}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Variational dropout [SEP]\n", "[CLS] In standard dropout, a new binary dropout mask is sampled each and every time the dropout function is called. [SEP]\n", "[CLS] New dropout masks are sampled even if the given connection is repeated, such as the input FORMULA  to an LSTM at timestep FORMULA  receiving a different dropout mask than the input FORMULA  fed to the same LSTM at FORMULA . [SEP]\n", "[CLS] A variant of this, variational dropout {{cite:1f93d427-c2eb-40eb-ba5d-71f52a277d7b}}, samples a binary dropout mask only once upon the first call and then to repeatedly use that locked dropout mask for all repeated connections within the forward and backward pass. [SEP]\n", "[CLS] While we propose using DropConnect rather than variational dropout to regularize the hidden-to-hidden transition within an RNN, we use variational dropout for all other dropout operations, specifically using the same dropout mask for all inputs and outputs of the LSTM within a given forward and backward pass. [SEP]\n", "[CLS] Each example within the minibatch uses a unique dropout mask, rather than a single dropout mask being used over all examples, ensuring diversity in the elements dropped out. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Embedding dropout Following {{cite:1f93d427-c2eb-40eb-ba5d-71f52a277d7b}}, we employ embedding dropout. [SEP]\n", "[CLS] This is equivalent to performing dropout on the embedding matrix at a word level, where the dropout is broadcast across all the word vector's embedding. [SEP]\n", "[CLS] The remaining non-dropped-out word embeddings are scaled by FORMULA  where FORMULA  is the probability of embedding dropout. [SEP]\n", "[CLS] As the dropout occurs on the embedding matrix that is used for a full forward and backward pass, this means that all occurrences of a specific word will disappear within that pass, equivalent to performing variational dropout on the connection between the one-hot embedding and the embedding lookup.   [SEP]\n", "[CLS] Weight tying Weight tying {{cite:65c6d7e2-d74f-4c62-9307-0156e8920ea6}}, {{cite:14051560-a384-4ffd-8e29-d86efeceaa53}} shares the weights between the embedding and softmax layer, substantially reducing the total parameter count in the model. [SEP]\n", "[CLS] The technique has theoretical motivation {{cite:65c6d7e2-d74f-4c62-9307-0156e8920ea6}} and prevents the model from having to learn a one-to-one correspondence between the input and output, resulting in substantial improvements to the standard LSTM language model. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Independent embedding size and hidden size In most natural language processing tasks, both pre-trained and trained word vectors are of relatively low dimensionality\u2014frequently between 100 and 400 dimensions in size. [SEP]\n", "[CLS] Most previous LSTM language models tie the dimensionality of the word vectors to the dimensionality of the LSTM's hidden state. [SEP]\n", "[CLS] Even if reducing the word embedding size was not beneficial in preventing overfitting, the easiest reduction in total parameters for a language model is reducing the word vector size. [SEP]\n", "[CLS] To achieve this, the first and last LSTM layers are modified such that their input and output dimensionality respectively are equal to the reduced embedding size. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Activation Regularization (AR) and Temporal Activation Regularization (TAR) FORMULA -regularization is often used on the weights of the network to control the norm of the resulting model and reduce overfitting. [SEP]\n", "[CLS] In addition, FORMULA  decay can be used on the individual unit activations and on the difference in outputs of an RNN at different time steps; these strategies labeled as activation regularization (AR) and temporal activation regularization (TAR) respectively {{cite:05252815-c712-443d-904b-4810b3766d48}}. [SEP]\n", "[CLS] AR penalizes activations that are significantly larger than 0 as a means of regularizing the network. [SEP]\n", "[CLS] Concretely, AR is defined as FORMULA  where FORMULA  is the dropout mask, FORMULA , FORMULA  is the output of the RNN at timestep FORMULA , and FORMULA  is a scaling coefficient. [SEP]\n", "[CLS] TAR falls under the broad category of slowness regularizers {{cite:5e493d2f-4baa-4f14-9ce3-1d4a887cb64c}}, {{cite:afdc3e73-183f-41ba-9ddf-b25451297f62}}, {{cite:cf2e830f-2e38-46b6-bcb0-fd492ca872de}}, {{cite:eb358ab3-c994-4fc4-abdf-ff2ff49a6960}} which penalize the model from producing large changes in the hidden state. [SEP]\n", "[CLS] Using the notation from AR, TAR is defined as FORMULA  where FORMULA  is a scaling coefficient. [SEP]\n", "[CLS] As in {{cite:05252815-c712-443d-904b-4810b3766d48}}, the AR and TAR loss are only applied to the output of the final RNN layer as opposed to being applied to all layers. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Experiment Details For evaluating the impact of these approaches, we perform language modeling over a preprocessed version of the Penn Treebank (PTB) {{cite:7b7f2033-18d6-4285-ba7e-132473fcedf8}} and the WikiText-2 (WT2) data set {{cite:9e1c867e-a396-4001-902d-168a749ba1d1}}. [SEP]\n", "[CLS] PTB: The Penn Treebank data set has long been a central data set for experimenting with language modeling. [SEP]\n", "[CLS] The data set is heavily preprocessed and does not contain capital letters, numbers, or punctuation. [SEP]\n", "[CLS] The vocabulary is also capped at 10,000 unique words, quite small in comparison to most modern datasets, which results in a large number of out of vocabulary (OoV) tokens. [SEP]\n", "[CLS] WT2: WikiText-2 is sourced from curated Wikipedia articles and is approximately twice the size of the PTB data set. [SEP]\n", "[CLS] The text is tokenized and processed using the Moses tokenizer {{cite:0a28ffa7-262d-430e-baaa-c800e295662d}}, frequently used for machine translation, and features a vocabulary of over 30,000 words. [SEP]\n", "[CLS] Capitalization, punctuation, and numbers are retained in this data set. [SEP]\n", "[CLS] All experiments use a three-layer LSTM model with 1150 units in the hidden layer and an embedding of size 400. [SEP]\n", "[CLS] The loss was averaged over all examples and timesteps. [SEP]\n", "[CLS] All embedding weights were uniformly initialized in the interval FORMULA  and all other weights were initialized between FORMULA , where FORMULA  is the hidden size. [SEP]\n", "[CLS] For training the models, we use the NT-ASGD algorithm discussed in the previous section for 750 epochs with FORMULA  equivalent to one epoch and FORMULA . [SEP]\n", "[CLS] We use a batch size of 80 for WT2 and 40 for PTB. [SEP]\n", "[CLS] Empirically, we found relatively large batch sizes (e.g., 40-80) performed better than smaller sizes (e.g., 10-20) for NT-ASGD. [SEP]\n", "[CLS] After completion, we run ASGD with FORMULA  and hot-started FORMULA  as a fine-tuning step to further improve the solution. [SEP]\n", "[CLS] For this fine-tuning step, we terminate the run using the same non-monotonic criterion detailed in Algorithm 1. [SEP]\n", "[CLS] We carry out gradient clipping with maximum norm FORMULA  and use an initial learning rate of 30 for all experiments. [SEP]\n", "[CLS] We use a random BPTT length which is FORMULA  with probability FORMULA  and FORMULA  with probability FORMULA . [SEP]\n", "[CLS] The values used for dropout on the word vectors, the output between LSTM layers, the output of the final LSTM layer, and embedding dropout where FORMULA  respectively. [SEP]\n", "[CLS] For the weight-dropped LSTM, a dropout of FORMULA  was applied to the recurrent weight matrices. [SEP]\n", "[CLS] For WT2, we increase the input dropout to FORMULA  to account for the increased vocabulary size. [SEP]\n", "[CLS] For all experiments, we use AR and TAR values of 2 and 1 respectively, and tie the embedding and softmax weights. [SEP]\n", "[CLS] These hyperparameters were chosen through trial and error and we expect further improvements may be possible if a fine-grained hyperparameter search were to be conducted. [SEP]\n", "[CLS] In the results, we abbreviate our approach as AWD-LSTM for ASGD [SEP]\n", "[CLS] Weight-Dropped LSTM. [SEP]\n", "[CLS] TABLE  TABLE   Experimental Analysis [SEP]\n", "[CLS] We present the single-model perplexity results for both our models (AWD-LSTM) and other competitive models in Table REF  and REF  for PTB and WT2 respectively. [SEP]\n", "[CLS] On both data sets we improve the state-of-the-art, with our vanilla LSTM model beating the state of the art by approximately 1 unit on PTB and 0.1 units on WT2. [SEP]\n", "[CLS] In comparison to other recent state-of-the-art models, our model uses a vanilla LSTM. [SEP]\n", "[CLS] {{cite:b3148ca5-55cb-4cb0-8997-83ec1a08ebb9}} propose the recurrent highway network, which extends the LSTM to allow multiple hidden state updates per timestep. [SEP]\n", "[CLS] {{cite:571ddbaa-2263-45b7-9172-8f8b1c43b885}} use a reinforcement learning agent to generate an RNN cell tailored to the specific task of language modeling, with the cell far more complex than the LSTM. [SEP]\n", "[CLS] Independently of our work, {{cite:efd37ff0-d385-4f58-80a6-5e126a88991d}} apply extensive hyperparameter search to an LSTM based language modeling implementation, analyzing the sensitivity of RNN based language models to hyperparameters. [SEP]\n", "[CLS] Unlike our work, they use a modified LSTM, which caps the input gate FORMULA  to be FORMULA , use Adam with FORMULA  rather than SGD or ASGD, use skip connections between LSTM layers, and use a black box hyperparameter tuner for exploring models and settings. [SEP]\n", "[CLS] Of particular interest is that their hyperparameters were tuned individually for each data set compared to our work which shared almost all hyperparameters between PTB and WT2, including the embedding and hidden size for both data sets. [SEP]\n", "[CLS] Due to this, they used less model parameters than our model and found shallow LSTMs of one or two layers worked best for WT2. [SEP]\n", "[CLS] Like our work, {{cite:efd37ff0-d385-4f58-80a6-5e126a88991d}} find that the underlying LSTM architecture can be highly effective compared to complex custom architectures when well tuned hyperparameters are used. [SEP]\n", "[CLS] The approaches used in our work and {{cite:efd37ff0-d385-4f58-80a6-5e126a88991d}} may be complementary and would be worth exploration. [SEP]\n", "[CLS]  Pointer models In past work, pointer based attention models have been shown to be highly effective in improving language modeling {{cite:9e1c867e-a396-4001-902d-168a749ba1d1}}, {{cite:d9666a6c-643b-4479-b0c3-083c40a85f37}}. [SEP]\n", "[CLS] Given such substantial improvements to the underlying neural language model, it remained an open question as to how effective pointer augmentation may be, especially when improvements such as weight tying may act in mutually exclusive ways. [SEP]\n", "[CLS] The neural cache model {{cite:d9666a6c-643b-4479-b0c3-083c40a85f37}} can be added on top of a pre-trained language model at negligible cost. [SEP]\n", "[CLS] The neural cache stores the previous hidden states in memory cells and then uses a simple convex combination of the probability distributions suggested by the cache and the language model for prediction. [SEP]\n", "[CLS] The cache model has three hyperparameters: the memory size (window) for the cache, the coefficient of the combination (which determines how the two distributions are mixed), and the flatness of the cache distribution. [SEP]\n", "[CLS] All of these are tuned on the validation set once a trained language model has been obtained and require no training by themselves, making it quite inexpensive to use. [SEP]\n", "[CLS] The tuned values for these hyperparameters were FORMULA  for PTB and FORMULA  for WT2 respectively. [SEP]\n", "[CLS] In Tables 1 and 2, we show that the model further improves the perplexity of the language model by as much as 6 perplexity points for PTB and 11 points for WT2. [SEP]\n", "[CLS] While this is smaller than the gains reported in {{cite:d9666a6c-643b-4479-b0c3-083c40a85f37}}, which used an LSTM without weight tying, this is still a substantial drop. [SEP]\n", "[CLS] Given the simplicity of the neural cache model, and the lack of any trained components, these results suggest that existing neural language models remain fundamentally lacking, failing to capture long term dependencies or remember recently seen words effectively. [SEP]\n", "[CLS] To understand the impact the pointer had on the model, specifically the validation set perplexity, we detail the contribution that each word has on the cache model's overall perplexity in Table 3. [SEP]\n", "[CLS] We compute the sum of the total difference in the loss function value (i.e., log perplexity) between the LSTM-only and LSTM-with-cache models for the target words in the validation portion of the WikiText-2 data set. [SEP]\n", "[CLS] We present results for the sum of the difference as opposed to the mean since the latter undesirably overemphasizes infrequently occurring words for which the cache helps significantly and ignores frequently occurring words for which the cache provides modest improvements that cumulatively make a strong contribution. [SEP]\n", "[CLS] The largest cumulative gain is in improving the handling of <unk> tokens, though this is over 11540 instances. [SEP]\n", "[CLS] The second best improvement, approximately one fifth the gain given by the <unk> tokens, is for Meridian, yet this word only occurs 161 times. [SEP]\n", "[CLS] This indicates the cache still helps significantly even for relatively rare words, further demonstrated by Churchill, Blythe, or Sonic. [SEP]\n", "[CLS] The cache is not beneficial when handling frequent word categories, such as punctuation or stop words, for which the language model is likely well suited. [SEP]\n", "[CLS] These observations motivate the design of a cache framework that is more aware of the relative strengths of the two models. [SEP]\n", "[CLS] TABLE   Model Ablation Analysis TABLE   [SEP]\n", "[CLS] In Table REF , we present the values of validation and testing perplexity for different variants of our best-performing LSTM model. [SEP]\n", "[CLS] Each variant removes a form of optimization or regularization. [SEP]\n", "[CLS] The first two variants deal with the optimization of the language models while the rest deal with the regularization. [SEP]\n", "[CLS] For the model using SGD with learning rate reduced by 2 using the same nonmonotonic fashion, there is a significant degradation in performance. [SEP]\n", "[CLS] This stands as empirical evidence regarding the benefit of averaging of the iterates. [SEP]\n", "[CLS] Using a monotonic criterion instead also hampered performance. [SEP]\n", "[CLS] Similarly, the removal of the fine-tuning step expectedly also degrades the performance. [SEP]\n", "[CLS] This step helps improve the estimate of the minimizer by resetting the memory of the previous experiment. [SEP]\n", "[CLS] While this process of fine-tuning can be repeated multiple times, we found little benefit in repeating it more than once. [SEP]\n", "[CLS] The removal of regularization strategies paints a similar picture; the inclusion of all of the proposed strategies was pivotal in ensuring state-of-the-art performance. [SEP]\n", "[CLS] The most extreme perplexity jump was in removing the hidden-to-hidden LSTM regularization provided by the weight-dropped LSTM. [SEP]\n", "[CLS] Without such hidden-to-hidden regularization, perplexity rises substantially, up to 11 points. [SEP]\n", "[CLS] This is in line with previous work showing the necessity of recurrent regularization in state-of-the-art models {{cite:1f93d427-c2eb-40eb-ba5d-71f52a277d7b}}, {{cite:65c6d7e2-d74f-4c62-9307-0156e8920ea6}}. [SEP]\n", "[CLS] We also experiment with static sequence lengths which we had hypothesized would lead to inefficient data usage. [SEP]\n", "[CLS] This also worsens the performance by approximately one perplexity unit. [SEP]\n", "[CLS] Next, we experiment with reverting to matching the sizes of the embedding vectors and the hidden states. [SEP]\n", "[CLS] This significantly increases the number of parameters in the network (to 43M in the case of PTB and 70M for WT2) and leads to degradation by almost 8 perplexity points, which we attribute to overfitting in the word embeddings. [SEP]\n", "[CLS] While this could potentially be improved with more aggressive regularization, the computational overhead involved with substantially larger embeddings likely outweighs any advantages. [SEP]\n", "[CLS] Finally, we experiment with the removal of embedding dropout, AR/TAR and weight decay. [SEP]\n", "[CLS] In all of the cases, the model suffers a perplexity increase of 2\u20136 points which we hypothesize is due to insufficient regularization in the network. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusion [SEP]\n", "[CLS] In this work, we discuss regularization and optimization strategies for neural language models. [SEP]\n", "[CLS] We propose the weight-dropped LSTM, a strategy that uses a DropConnect mask on the hidden-to-hidden weight matrices, as a means to prevent overfitting across the recurrent connections. [SEP]\n", "[CLS] Further, we investigate the use of averaged SGD with a non-monontonic trigger for training language models and show that it outperforms SGD by a significant margin. [SEP]\n", "[CLS] We investigate other regularization strategies including the use of variable BPTT length and achieve a new state-of-the-art perplexity on the PTB and WikiText-2 data sets. [SEP]\n", "[CLS] Our models outperform custom-built RNN cells and complex regularization strategies that preclude the possibility of using optimized libraries such as the NVIDIA cuDNN LSTM. [SEP]\n", "[CLS] Finally, we explore the use of a neural cache in conjunction with our proposed model and show that this further improves the performance, thus attaining an even lower state-of-the-art perplexity. [SEP]\n", "[CLS] While the regularization and optimization strategies proposed are demonstrated on the task of language modeling, we anticipate that they would be generally applicable across other sequence learning tasks. [SEP]\n"], "1702.00071": ["[CLS]   [SEP]\n", "[CLS] On orthogonality and learning RNNs with long term dependencies [ On orthogonality and learning recurrent networks with long term dependencies Eugene Vorontsovpoly,mila Chiheb Trabelsipoly,mila Samuel Kadourypoly,chum Chris Palpoly,mila poly\u00c9cole Polytechnique de Montr\u00e9al, Montr\u00e9al, Canada milaMontreal Institute for Learning Algorithms, Montr\u00e9al, Canada chumCHUM Research Center, Montr\u00e9al, Canada Eugene Vorontsoveugene.vorontsov@gmail.com ] It is well known that it is challenging to train deep neural networks and recurrent neural networks for tasks that exhibit long term dependencies. [SEP]\n", "[CLS] The vanishing or exploding gradient problem is a well known issue associated with these challenges. [SEP]\n", "[CLS] One approach to addressing vanishing and exploding gradients is to use either soft or hard constraints on weight matrices so as to encourage or enforce orthogonality. [SEP]\n", "[CLS] Orthogonal matrices preserve gradient norm during backpropagation and may therefore be a desirable property. [SEP]\n", "[CLS] This paper explores issues with optimization convergence, speed and gradient stability when encouraging or enforcing orthogonality. [SEP]\n", "[CLS] To perform this analysis, we propose a weight matrix factorization and parameterization strategy through which we can bound matrix norms and therein control the degree of expansivity induced during backpropagation. [SEP]\n", "[CLS] We find that hard constraints on orthogonality can negatively affect the speed of convergence and model performance. [SEP]\n", "[CLS] Introduction [SEP]\n", "[CLS] The depth of deep neural networks confers representational power, but also makes model optimization more challenging. [SEP]\n", "[CLS] Training deep networks with gradient descent based methods is known to be difficult as a consequence of the vanishing and exploding gradient problem \u00a0{{cite:394b4cc9-fb1c-42cf-8688-23ae644e14c1}}. [SEP]\n", "[CLS] Typically, exploding gradients are avoided by clipping large gradients \u00a0{{cite:02bcee42-46f4-47e6-b57b-170dde9b8325}} or introducing an FORMULA  or FORMULA  weight norm penalty. [SEP]\n", "[CLS] The latter has the effect of bounding the spectral radius of the linear transformations, thus limiting the maximal gain across the transformation. [SEP]\n", "[CLS] \u00a0{{cite:381f1597-423a-4652-92ff-81c2e8fd7597}} attempt to stabilize the norm of propagating signals directly by penalizing differences in successive norm pairs in the forward pass and \u00a0{{cite:02bcee42-46f4-47e6-b57b-170dde9b8325}} propose to penalize successive gradient norm pairs in the backward pass. [SEP]\n", "[CLS] These regularizers affect the network parameterization with respect to the data instead of penalizing weights directly. [SEP]\n", "[CLS] Both expansivity and contractivity of linear transformations can also be limited by more tightly bounding their spectra. [SEP]\n", "[CLS] By limiting the transformations to be orthogonal, their singular spectra are limited to unitary gain causing the transformations to be norm-preserving. [SEP]\n", "[CLS] \u00a0{{cite:e670dc65-c105-4ab5-905e-3ee1e66d96fa}} and \u00a0{{cite:4bda33e7-5f2b-485b-8766-03c2472b3755}} have respectively shown that identity initialization and orthogonal initialization can be beneficial. [SEP]\n", "[CLS] \u00a0{{cite:1168c77a-e95a-4b0d-8c82-85ce8e9e50c4}} have gone beyond initialization, building unitary recurrent neural network (RNN) models with transformations that are unitary by construction which they achieved by composing multiple basic unitary transformations. [SEP]\n", "[CLS] The resulting transformations, for some n-dimensional input, cover only some subset of possible FORMULA  unitary matrices but appear to perform well on simple tasks and have the benefit of having low complexity in memory and computation. [SEP]\n", "[CLS] Similarly, {{cite:0ed73661-4be1-4832-9c8e-80892c90c702}} introduce an efficient algorithm to cover a large subset. [SEP]\n", "[CLS] The entire set of possible unitary or orthogonal parameterizations forms the Stiefel manifold. [SEP]\n", "[CLS] At a much higher computational cost, gradient descent optimization directly along this manifold can be done via geodesic steps {{cite:ce7d0b71-aa07-4abc-9ef8-fa018c801ae8}}, {{cite:a68b4633-356d-49ea-aec1-00d5c1e9835b}}. [SEP]\n", "[CLS] Recent work {{cite:6cfb260f-70e3-4a5f-9b99-c55928aff6db}} has proposed the optimization of unitary matrices along the Stiefel manifold using geodesic gradient descent. [SEP]\n", "[CLS] To produce a full-capacity parameterization for unitary matrices they use some insights from {{cite:a68b4633-356d-49ea-aec1-00d5c1e9835b}}, combining the use of canonical inner products and Cayley transformations. [SEP]\n", "[CLS] Their experimental work indicates that full capacity unitary RNN models can solve the copy memory problem whereas both LSTM networks and restricted capacity unitary RNN models having similar complexity appear unable to solve the task for a longer sequence length (FORMULA  = 2000). [SEP]\n", "[CLS] {{cite:27745977-f2bf-4356-8e22-5dd8b24a88f0}} and {{cite:0a6dbd92-b0da-4239-ace9-e21170a62647}} introduced more computationally efficient full capacity parameterizations. [SEP]\n", "[CLS] {{cite:981ada1c-dbfb-4dad-8bff-e8f266da23d1}} also find that the use of fully connected \u201cStiefel layers\u201d improves the performance of some convolutional neural networks. [SEP]\n", "[CLS] We seek to gain a new perspective on this line of research by exploring the optimization of real valued matrices within a configurable margin about the Stiefel manifold. [SEP]\n", "[CLS] We suspect that a strong constraint of orthogonality limits the model's representational power, hindering its performance, and may make optimization more difficult. [SEP]\n", "[CLS] We explore this hypothesis empirically by employing a factorization technique that allows us to limit the degree of deviation from the Stiefel manifoldSource code for the model and experiments located at https://github.com/veugene/spectre_release. [SEP]\n", "[CLS] While we use geodesic gradient descent, we simultaneously update the singular spectra of our matrices along Euclidean steps, allowing optimization to step away from the manifold while still curving about it. [SEP]\n", "[CLS] Vanishing and Exploding Gradients [SEP]\n", "[CLS] The issue of vanishing and exploding gradients as it pertains to the parameterization of neural networks can be illuminated by looking at the gradient back-propagation chain through a network. [SEP]\n", "[CLS] A neural network with FORMULA  hidden layers has pre-activations FORMULA   [SEP]\n", "[CLS] For notational convenience, we combine parameters FORMULA  and FORMULA  to form an affine matrix FORMULA . [SEP]\n", "[CLS] We can see that for some loss function FORMULA  at layer FORMULA , the derivative with respect to parameters FORMULA  is: FORMULA   [SEP]\n", "[CLS] The partial derivatives for the pre-activations can be decomposed as follows: FORMULA  where FORMULA  is the Jacobian corresponding to the activation function, containing partial derivatives of the hidden units at layer FORMULA  1 with respect to the pre-activation inputs. [SEP]\n", "[CLS] Typically, FORMULA  is diagonal. [SEP]\n", "[CLS] Following the above, the gradient in equation REF  can be fully decomposed into a recursive chain of matrix products: FORMULA   [SEP]\n", "[CLS] In {{cite:02bcee42-46f4-47e6-b57b-170dde9b8325}}, it is shown that the 2-norm of FORMULA  is bounded by the product of the norms of the non-linearity's Jacobian and transition matrix at time FORMULA  (layer FORMULA ), as follows: FORMULA  where FORMULA  and FORMULA  are the largest singular values of the non-linearity's Jacobian FORMULA  and the transition matrix FORMULA . [SEP]\n", "[CLS] In RNNs, FORMULA  is shared across time and can be simply denoted as FORMULA . [SEP]\n", "[CLS] Equation REF  shows that the gradient can grow or shrink at each layer depending on the gain of each layer's linear transformation FORMULA  and the gain of the Jacobian FORMULA . [SEP]\n", "[CLS] The gain caused by each layer is magnified across all time steps or layers. [SEP]\n", "[CLS] It is easy to have extreme amplification in a recurrent neural network where FORMULA  is shared across time steps and a non-unitary gain in FORMULA  is amplified exponentially. [SEP]\n", "[CLS] The phenomena of extreme growth or contraction of the gradient across time steps or layers are known as the exploding and the vanishing gradient problems, respectively. [SEP]\n", "[CLS] It is sufficient for RNNs to have FORMULA  FORMULA  1 at each time FORMULA  to enable the possibility of vanishing gradients, typically for some large number of time steps FORMULA . [SEP]\n", "[CLS] The rate at which a gradient (or forward signal) vanishes depends on both the parameterization of the model and on the input data. [SEP]\n", "[CLS] The parameterization may be conditioned by placing appropriate constraints on FORMULA . [SEP]\n", "[CLS] It is worth keeping in mind that the Jacobian FORMULA  is typically contractive, thus tending to be norm-reducing) and is also data-dependent, whereas FORMULA  can vary from being contractive to norm-preserving, to expansive and applies the same gain on the forward signal as on the back-propagated gradient signal. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Our Approach Vanishing and exploding gradients can be controlled to a large extent by controlling the maximum and minimum gain of FORMULA . [SEP]\n", "[CLS] The maximum gain of a matrix FORMULA  is given by the spectral norm which is given by FORMULA   [SEP]\n", "[CLS] By keeping our weight matrix FORMULA  close to orthogonal, one can ensure that it is close to a norm-preserving transformation (where the spectral norm is equal to one, but the minimum gain is also one). [SEP]\n", "[CLS] One way to achieve this is via a simple soft constraint or regularization term of the form: FORMULA   [SEP]\n", "[CLS] However, it is possible to formulate a more direct parameterization or factorization for FORMULA  which permits hard bounds on the amount of expansion and contraction induced by FORMULA . [SEP]\n", "[CLS] This can be achieved by simply parameterizing FORMULA  according to its singular value decomposition, which consists of the composition of orthogonal basis matrices FORMULA  and FORMULA  with a diagonal spectral matrix FORMULA  containing the singular values which are real and positive by definition. [SEP]\n", "[CLS] We have FORMULA   [SEP]\n", "[CLS] Since the spectral norm or maximum gain of a matrix is equal to its largest singular value, this decomposition allows us to control the maximum gain or expansivity of the weight matrix by controlling the magnitude of the largest singular value. [SEP]\n", "[CLS] Similarly, the minimum gain or contractivity of a matrix can be obtained from the minimum singular value. [SEP]\n", "[CLS] We can keep the bases FORMULA  and FORMULA  orthogonal via geodesic gradient descent along the set of weights that satisfy FORMULA  and FORMULA  respectively. [SEP]\n", "[CLS] The submanifolds that satisfy these constraints are called Stiefel manifolds. [SEP]\n", "[CLS] We discuss how this is achieved in more detail below, then discuss our construction for bounding the singular values. [SEP]\n", "[CLS] During optimization, in order to maintain the orthogonality of an orthogonally-initialized matrix FORMULA , i.e. where FORMULA , FORMULA  or FORMULA  if so desired, we employ a Cayley transformation of the update step onto the Stiefel manifold of (semi-)orthogonal matrices, as in {{cite:ce7d0b71-aa07-4abc-9ef8-fa018c801ae8}} and {{cite:a68b4633-356d-49ea-aec1-00d5c1e9835b}}. [SEP]\n", "[CLS] Given an orthogonally-initialized parameter matrix FORMULA  and its Jacobian, FORMULA  with respect to the objective function, an update is performed as follows: FORMULA  where FORMULA  is a skew-symmetric matrix (that depends on the Jacobian and on the parameter matrix) which is mapped to an orthogonal matrix via a Cayley transform and FORMULA  is the learning rate. [SEP]\n", "[CLS] While the update rule in (REF ) allows us to maintain an orthogonal hidden to hidden transition matrix FORMULA  if desired, we are interested in exploring the effect of stepping away from the Stiefel manifold. [SEP]\n", "[CLS] As such, we parameterize the transition matrix FORMULA  in factorized form, as a singular value decomposition with orthogonal bases FORMULA  and FORMULA  updated by geodesic gradient descent using the Cayley transform approach above. [SEP]\n", "[CLS] If FORMULA  is an orthogonal matrix, the singular values in the diagonal matrix FORMULA  are all equal to one. [SEP]\n", "[CLS] However, in our formulation we allow these singular values to deviate from one and employ a sigmoidal parameterization to apply a hard constraint on the maximum and minimum amount of deviation. [SEP]\n", "[CLS] Specifically, we define a margin FORMULA  around 1 within which the singular values must lie. [SEP]\n", "[CLS] This is achieved with the parameterization FORMULA   [SEP]\n", "[CLS] The singular values are thus restricted to the range FORMULA  and the underlying parameters FORMULA  are updated freely via stochastic gradient descent. [SEP]\n", "[CLS] Note that this parameterization strategy also has implications on the step sizes that gradient descent based optimization will take when updating the singular values \u2013 they tend to be smaller compared to models with no margin constraining their values. [SEP]\n", "[CLS] Specifically, a singular value's progression toward a margin is slowed the closer it is to the margin. [SEP]\n", "[CLS] The sigmoidal parameterization can also impart another effect on the step size along the spectrum which needs to be accounted for. [SEP]\n", "[CLS] Considering REF , the gradient backpropagation of some loss FORMULA  toward parameters FORMULA  is found as FORMULA  From (REF ), it can be seen that the magnitude of the update step for FORMULA  is scaled by the margin hyperparameter FORMULA . [SEP]\n", "[CLS] This means for example that for margins less than one, the effective learning rate for the spectrum is reduced in proportion to the margin. [SEP]\n", "[CLS] Consequently, we adjust the learning rate along the spectrum to be independent of the margin by renormalizing it by FORMULA . [SEP]\n", "[CLS] This margin formulation both guarantees singular values lie within a well defined range and slows deviation from orthogonality. [SEP]\n", "[CLS] Alternatively, one could enforce the orthogonality of FORMULA  and FORMULA  and impose a regularization term corresponding to a mean one Gaussian prior on these singular values. [SEP]\n", "[CLS] This encourages the weight matrix FORMULA  to be norm preserving with a controllable strength equivalent to the variance of the Gaussian. [SEP]\n", "[CLS] We also explore this approach further below.   [SEP]\n", "[CLS] Experiments [SEP]\n", "[CLS] In this section, we explore hard and soft orthogonality constraints on factorized weight matrices for recurrent neural network hidden to hidden transitions. [SEP]\n", "[CLS] With hard orthogonality constraints on FORMULA  and FORMULA , we investigate the effect of widening the spectral margin or bounds on convergence and performance. [SEP]\n", "[CLS] Loosening these bounds allows increasingly larger margins within which the transition matrix FORMULA  can deviate from orthogonality. [SEP]\n", "[CLS] We confirm that orthogonal initialization is useful as noted in {{cite:4bda33e7-5f2b-485b-8766-03c2472b3755}}, and we show that although strict orthogonality guarantees stable gradient norm, loosening orthogonality constraints can increase the rate of gradient descent convergence. [SEP]\n", "[CLS] We begin our analyses on tasks that are designed to stress memory: a sequence copying task and a basic addition task {{cite:394b4cc9-fb1c-42cf-8688-23ae644e14c1}}. [SEP]\n", "[CLS] We then move on to tasks on real data that require models to capture long-range dependencies: digit classification based on sequential and permuted MNIST vectors {{cite:e670dc65-c105-4ab5-905e-3ee1e66d96fa}}, {{cite:8c2ffcfa-968f-43ac-aeda-81923ebb51cb}}. [SEP]\n", "[CLS] Finally, we look at a basic language modeling task using the Penn Treebank dataset {{cite:c14db011-1b9a-4313-8bea-8948fd67c6c6}}. [SEP]\n", "[CLS] The copy and adding tasks, introduced by {{cite:394b4cc9-fb1c-42cf-8688-23ae644e14c1}}, are synthetic benchmarks with pathologically hard long distance dependencies that require long-term memory in models. [SEP]\n", "[CLS] The copy task consists of an input sequence that must be remembered by the network, followed by a series of blank inputs terminated by a delimiter that denotes the point at which the network must begin to output a copy of the initial sequence. [SEP]\n", "[CLS] We use an input sequence of FORMULA  elements that begins with a sub-sequence of 10 elements to copy, each containing a symbol FORMULA  out of FORMULA  possible symbols. [SEP]\n", "[CLS] This sub-sequence is followed by FORMULA  elements of the blank category FORMULA  which is terminated at step FORMULA  by a delimiter symbol FORMULA  and 10 more elements of the blank category. [SEP]\n", "[CLS] The network must learn to remember the initial 10 element sequence for FORMULA  time steps and output it after receiving the delimiter symbol. [SEP]\n", "[CLS] The goal of the adding task is to add two numbers together after a long delay. [SEP]\n", "[CLS] Each number is randomly picked at a unique position in a sequence of length FORMULA . [SEP]\n", "[CLS] The sequence is composed of FORMULA  values sampled from a uniform distribution in the range FORMULA , with each value paired with an indicator value that identifies the value as one of the two numbers to remember (marked 1) or as a value to ignore (marked 0). [SEP]\n", "[CLS] The two numbers are positioned randomly in the sequence, the first in the range FORMULA  and the second in the range FORMULA , where 0 marks the first element. [SEP]\n", "[CLS] The network must learn to identify and remember the two numbers and output their sum. [SEP]\n", "[CLS] In the sequential MNIST task from {{cite:e670dc65-c105-4ab5-905e-3ee1e66d96fa}}, MNIST digits are flattened into vectors that can be traversed sequentially by a recurrent neural network. [SEP]\n", "[CLS] The goal is to classify the digit based on the sequential input of pixels. [SEP]\n", "[CLS] The simple variant of this task is with a simple flattening of the image matrices; the harder variant of this task includes a random permutation of the pixels in the input vector that is determined once for an experiment. [SEP]\n", "[CLS] The latter formulation introduces longer distance dependencies between pixels that must be interpreted by the classification model. [SEP]\n", "[CLS] The English Penn Treebank (PTB) dataset from {{cite:c14db011-1b9a-4313-8bea-8948fd67c6c6}} is an annotated corpus of English sentences, commonly used for benchmarking language models. [SEP]\n", "[CLS] We employ a sequential character prediction task: given a sentence, a recurrent neural network must predict the next character at each step, from left to right. [SEP]\n", "[CLS] We use input sequences of variable length, with each sequence containing one sentence. [SEP]\n", "[CLS] We model 49 characters including lowercase letters (all strings are in lowercase), numbers, common punctuation, and an unknown character placeholder. [SEP]\n", "[CLS] We use two subsets of the data in our experiments: in the first, we first use 23% of the data with strings with up to 75 characters and in the second we include over 99% of the dataset, picking strings with up to 300 characters. [SEP]\n", "[CLS] Loosening Hard Orthogonality Constraints In this section, we experimentally explore the effect of loosening hard orthogonality constraints through loosening the spectral margin defined above for the hidden to hidden transition matrix. [SEP]\n", "[CLS] In all experiments, we employed RMSprop {{cite:d6159f5a-66b9-4c79-9051-a1389ba81964}} when not using geodesic gradient descent. [SEP]\n", "[CLS] We used minibatches of size 50 and for generated data (the copy and adding tasks), we assumed an epoch length of 100 minibatches. [SEP]\n", "[CLS] We cautiously introduced gradient clipping at magnitude 100 (unless stated otherwise) in all of our RNN experiments although it may not be required and we consistently applied a small weight decay of 0.0001. [SEP]\n", "[CLS] Unless otherwise specified, we trained all simple recurrent neural networks with the hidden to hidden matrix factorization as in (REF ) using geodesic gradient descent on the bases (learning rate FORMULA ) and RMSprop on the other parameters (learning rate 0.0001), using a tanh transition nonlinearity, and clipping gradients of 100 magnitude. [SEP]\n", "[CLS] The neural network code was built on the Theano framework {{cite:215b1b89-d347-4c65-8f5d-a63233cd7717}}. [SEP]\n", "[CLS] When parameterizing a matrix in factorized form, we apply the weight decay on the composite matrix rather than on the factors in order to be consistent across experiments. [SEP]\n", "[CLS] For MNIST and PTB, hyperparameter selection and early stopping were performed targeting the best validation set accuracy, with results reported on the test set. [SEP]\n", "[CLS] Convergence on Synthetic Memory Tasks For different sequence lengths FORMULA  of the copy and adding tasks, we trained a factorized RNN with 128 hidden units and various spectral margins FORMULA . [SEP]\n", "[CLS] For the copy task, we used Elman networks without a transition non-linearity as in {{cite:4bda33e7-5f2b-485b-8766-03c2472b3755}}. [SEP]\n", "[CLS] We also investigated the use of nonlinearities, as discussed below. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] As shown in Figure REF  we see an increase in the rate of convergence as we increase the spectral margin. [SEP]\n", "[CLS] This observation generally holds across the tested sequence lengths (FORMULA , FORMULA , FORMULA , FORMULA ); however, large spectral margins hinder convergence on extremely long sequence lengths. [SEP]\n", "[CLS] At sequence length FORMULA , parameterizations with spectral margins larger than 0.001 converge slower than when using a margin of 0.001. [SEP]\n", "[CLS] In addition, the experiment without a margin failed to converge on the longest sequence length. [SEP]\n", "[CLS] This follows the expected pattern where stepping away from the Stiefel manifold may help with gradient descent optimization but loosening orthogonality constraints can reduce the stability of signal propagation through the network. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] For the adding task, we trained a factorized RNN on FORMULA  length sequences, using a ReLU activation function on the hidden to hidden transition matrix. [SEP]\n", "[CLS] The mean squared error (MSE) is shown for different spectral margins in Figure REF . [SEP]\n", "[CLS] Testing spectral margins FORMULA , FORMULA , FORMULA , FORMULA , and no margin, we find that the models with the purely orthogonal (FORMULA ) and the unconstrained (no margin) transition matrices failed to begin converging beyond baseline MSE within 2000 epochs. [SEP]\n", "[CLS] We found that nonlinearities such as a rectified linear unit (ReLU) {{cite:f7ac4622-c693-4e9e-ac5f-5964cc80d7a1}} or hyperbolic tangent (tanh) made the copy task far more difficult to solve. [SEP]\n", "[CLS] Using tanh, a short sequence length (FORMULA ) copy task required both a soft constraint that encourages orthogonality and thousands of epochs for training. [SEP]\n", "[CLS] It is worth noting that in the unitary evolution recurrent neural network of {{cite:1168c77a-e95a-4b0d-8c82-85ce8e9e50c4}}, the non-linearity (referred to as the \"modReLU\") is actually initialized as an identity operation that is free to deviate from identity during training. [SEP]\n", "[CLS] Furthermore, {{cite:4bda33e7-5f2b-485b-8766-03c2472b3755}} derive a solution mechanism for the copy task that drops the non-linearity from an RNN. [SEP]\n", "[CLS] To explore this further, we experimented with a parametric leaky ReLU activation function (PReLU) which introduces a trainable slope FORMULA  for negative valued inputs FORMULA , producing FORMULA  {{cite:e1b7ef03-84f0-43a1-8995-d5857e6e09db}}. [SEP]\n", "[CLS] Setting the slope FORMULA  to one would make the PReLU equivalent to an identity function. [SEP]\n", "[CLS] We experimented with clamping FORMULA  to 0.5, 0.7 or 1 in a factorized RNN with a spectral margin of 0.3 and found that only the model with FORMULA  solved the FORMULA  length copy task. [SEP]\n", "[CLS] We also experimented with a trainable slope FORMULA , initialized to 0.7 and found that it converges to 0.96, further suggesting the optimal solution for the copy task is without a transition nonlinearity. [SEP]\n", "[CLS] Since the copy task is purely a memory task, one may imagine that a transition nonlinearity such as a tanh or ReLU may be detrimental to the task as it can lose information. [SEP]\n", "[CLS] Thus, we also tried a recent activation function that preserves information, called an orthogonal permutation linear unit (OPLU) {{cite:348c1e88-1a22-49ad-9c6a-d29692626627}}. [SEP]\n", "[CLS] The OPLU preserves norm, making a fully norm-preserving RNN possible. [SEP]\n", "[CLS] Interestingly, this activation function allowed us to recover identical results on the copy task to those without a nonlinearity for different spectral margins. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Performance on Real Data TABLE   [SEP]\n", "[CLS] Having confirmed that an orthogonality constraint can negatively impact convergence rate, we seek to investigate the effect on model performance for tasks on real data. [SEP]\n", "[CLS] In Table REF , we show the results of experiments on ordered and permuted sequential MNIST classification tasks and on the PTB character prediction task. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] For the sequential MNIST experiments, loss curves are shown in Figure REF  and reveal an increased convergence rate for larger spectral margins. [SEP]\n", "[CLS] We trained the factorized RNN models with 128 hidden units for 120 epochs. [SEP]\n", "[CLS] We also trained an LSTM with 128 hidden units (tanh activation) on both tasks for 150 epochs, configured with peephole connections, orthogonally initialized (and forget gate bias initialized to one), and trained with RMSprop (learning rate 0.0001, clipping gradients of magnitude 1). [SEP]\n", "[CLS] For PTB character prediction, we evaluate results in terms of bits per character (bpc) and prediction accuracy. [SEP]\n", "[CLS] Prediction results are shown in REF  both for a subset of short sequences (up to 75 characters; 23% of data) and for a subset of long sequences (up to 300 characters; 99% of data). [SEP]\n", "[CLS] We trained factorized RNN models with 512 hidden units for 200 epochs with geodesic gradient descent on the bases (learning rate FORMULA ) and RMSprop on the other parameters (learning rate 0.001), using a tanh transition nonlinearity, and clipping gradients of 30 magnitude. [SEP]\n", "[CLS] As a rough point of reference, we also trained an LSTM with 512 hidden units for each of the data subsets (configured as for MNIST). [SEP]\n", "[CLS] On sequences up to 75 characters, LSTM performance was limited by early stopping of training due to overfitting. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Interestingly, for both the ordered and permuted sequential MNIST tasks, models with a non-zero margin significantly outperform those that are constrained to have purely orthogonal transition matrices (margin of zero). [SEP]\n", "[CLS] The best results on both the ordered and sequential MNIST tasks were yielded by models with a spectral margin of 0.1, at 94.10% accuracy and 91.44% accuracy, respectively. [SEP]\n", "[CLS] An LSTM outperformed the RNNs in both tasks; nevertheless, RNNs with hidden to hidden transitions initialized as orthogonal matrices performed admirably without a memory component and without all of the additional parameters associated with gates. [SEP]\n", "[CLS] Indeed, orthogonally initialized RNNs performed almost on par with the LSTM in the permuted sequential MNIST task which presents longer distance dependencies than the ordered task. [SEP]\n", "[CLS] Although the optimal margin appears to be 0.1, RNNs with large margins perform almost identically to an RNN without a margin, as long as the transition matrix is initialized as orthogonal. [SEP]\n", "[CLS] On these tasks, orthogonal initialization appears to significantly outperform Glorot normal initialization {{cite:b1d13940-f837-4bff-b96e-4a6387da78f4}} or initializing the matrix as identity. [SEP]\n", "[CLS] It is interesting to note that for the MNIST tasks, orthogonal initialization appears useful while orthogonality constraints appear mainly detrimental. [SEP]\n", "[CLS] This suggests that while orthogonality helps early training by stabilizing gradient flow across many time steps, orthogonality constraints may need to be loosened on some tasks so as not to over-constrain the model's representational ability. [SEP]\n", "[CLS] Curiously, larger margins and even models without sigmoidal constraints on the spectrum (no margin) performed well as long as they were initialized to be orthogonal, suggesting that evolution away from orthogonality is not a serious problem on MNIST. [SEP]\n", "[CLS] It is not surprising that orthogonality is useful for the MNIST tasks since they depend on long distance signal propagation with a single output at the end of the input sequence. [SEP]\n", "[CLS] On the other hand, character prediction with PTB produces an output at every time step. [SEP]\n", "[CLS] Constraining deviation from orthogonality proved detrimental for short sentences and beneficial when long sentences were included. [SEP]\n", "[CLS] Furthermore, Glorot normal initialization did not perform worse than orthogonal initialization for PTB. [SEP]\n", "[CLS] Since an output is generated for every character in a sentence, short distance signal propagation is possible. [SEP]\n", "[CLS] Thus it is possible that the RNN is first learning very local dependencies between neighbouring characters and that given enough context, constraining deviation from orthogonality can help force the network to learn longer distance dependencies. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Spectral and Gradient Evolution [SEP]\n", "[CLS] It is interesting to note that even long sequence lengths (T=1000) in the copy task can be solved efficiently with rather large margins on the spectrum. [SEP]\n", "[CLS] In Figure REF  we look at the gradient propagation of the loss from the last time step in the network with respect to the hidden activations. [SEP]\n", "[CLS] We can see that for a purely orthogonal parameterization of the transition matrix (when the margin is zero), the gradient norm is preserved across time steps, as expected. [SEP]\n", "[CLS] We further observe that with increasing margin size, the number of update steps over which this norm preservation survives decreases, though surprisingly not as quickly as expected. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Although the deviation of singular values from one should be slowed by the sigmoidal parameterizations, even parameterizations without a sigmoid (no margin) can be effectively trained for all but the longest sequence lengths. [SEP]\n", "[CLS] This suggests that the spectrum is not deviating far from orthogonality and that inputs to the hidden to hidden transitions are mostly not aligned along the dimensions of greatest expansion or contraction. [SEP]\n", "[CLS] We evaluated the spread of the spectrum in all of our experiments and found that indeed, singular values tend to stay well within their prescribed bounds and only reach the margin when using a very large learning rate that does not permit convergence. [SEP]\n", "[CLS] Furthermore, when transition matrices are initialized as orthogonal, singular values remain near one throughout training even without a sigmoidal margin for tasks that require long term memory (copy, adding, sequential MNIST). [SEP]\n", "[CLS] On the other hand, singular value distributions tend to drift away from one for PTB character prediction which may help explain why enforcing an orthogonality constraint can be helpful for this task, when modeling long sequences. [SEP]\n", "[CLS] Interestingly, singular values spread out less for longer sequence lengths (nevertheless, the T=10000 copy task could not be solved with no sigmoid on the spectrum). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Exploring Soft Orthogonality Constraints FIGURE   [SEP]\n", "[CLS] We visualize the spread of singular values for different model parameterizations on the permuted sequential MNIST task in Figure REF . [SEP]\n", "[CLS] Curiously, we find that the distribution of singular values tends to shift upward to a mean of approximately 1.05 on both the ordered and permuted sequential MNIST tasks. [SEP]\n", "[CLS] We note that in those experiments, a tanh transition nonlinearity was used which is contractive in both the forward signal pass and the gradient backward pass. [SEP]\n", "[CLS] An upward shift in the distribution of singular values of the transition matrix would help compensate for that contraction. [SEP]\n", "[CLS] Indeed, {{cite:6d0c604c-dd8b-4a78-ad29-6910aca3cca7}} describe this as a possibly good regime for learning in deep neural networks. [SEP]\n", "[CLS] That the model appears to evolve toward this regime suggests that deviating from it may incur a cost. [SEP]\n", "[CLS] This is interesting because the cost function cannot take into account numerical issues such as vanishing or exploding gradients (or forward signals); we do not know what could make this deviation costly. [SEP]\n", "[CLS] Unlike orthgonally initialized models, the RNN on the bottom right of Figure REF  with Glorot normal initialized transition matrices begins and ends with a wide singular spectrum. [SEP]\n", "[CLS] While there is no clear positive shift in the distribution of singular values, the mean value appears to very gradually increase for both the ordered and permuted sequential MNIST tasks. [SEP]\n", "[CLS] If the model is to be expected to positively shift singular values to compensate for the contractivity of the tanh nonlinearity, it is not doing so well for the Glorot-initialized case; however, this may be due to the inefficiency of training as a result of vanishing gradients, given that initialization. [SEP]\n", "[CLS] That the transition matrix may be compensating for the contraction of the tanh is supported by further experiments: applying a 1.05 pre-activation gain appears to allow a model with a margin of 0 to nearly match the top performance reached on both of the MNIST tasks. [SEP]\n", "[CLS] Furthermore, when using the OPLU norm-preserving activation function {{cite:348c1e88-1a22-49ad-9c6a-d29692626627}}, we found that orthogonally initialized models performed equally well with all margins, achieving over 90% accuracy on the permuted sequential MNIST task. [SEP]\n", "[CLS] It is reasonable to assume that the sequential MNIST task benefits from a lack of a transition nonlinearity because it is a pure memory task. [SEP]\n", "[CLS] However, using no transition nonlinearity results in reduced accuracy. [SEP]\n", "[CLS] Furthermore, while a nonlinear transition may lose information, thus countering the task of memory preservation, it is critical on more advanced tasks like PTB character prediction. [SEP]\n", "[CLS] Indeed, tasks that require more than just memory preservation in the hidden state can benefit from forgetting. [SEP]\n", "[CLS] {{cite:f22884d9-1e17-4062-a77c-cfad53e63277}} demonstrated that adding a forgetting mechanism to RNNs constrained to have an orthogonal transition matrix improved performance on such tasks. [SEP]\n", "[CLS] Some forgetting could be achieved by allowing deviation from orthogonality. [SEP]\n", "[CLS] Having established that it may indeed be useful to step away from orthogonality, here we explore two forms of soft constraints (rather than hard bounds as above) on hidden to hidden transition matrix orthogonality. [SEP]\n", "[CLS] The first is a simple penalty that directly encourages a transition matrix FORMULA  to be orthogonal, of the form FORMULA . [SEP]\n", "[CLS] This is similar to the orthogonality penalty introduced by {{cite:4bda33e7-5f2b-485b-8766-03c2472b3755}}. [SEP]\n", "[CLS] In subfigures (A) and (B) of Figure REF , we explore the effect of weakening this form of regularization. [SEP]\n", "[CLS] We trained both a regular non-factorized RNN on the FORMULA  copy task (A) and a factorized RNN with orthogonal bases on the FORMULA  copy task (B). [SEP]\n", "[CLS] For the regular RNN, we had to reduce the learning rate to FORMULA . [SEP]\n", "[CLS] Here again we see that weakening the strength of the orthogonality-encouraging penalty can increase convergence speed. [SEP]\n", "[CLS] The second approach we explore replaces the sigmoidal margin parameterization with a mean one Gaussian prior on the singular values. [SEP]\n", "[CLS] In subfigures (C) and (D) of Figure REF , we visualize the accuracy on the length 200 copy task, using geoSGD (learning rate FORMULA  to keep FORMULA  and FORMULA  orthogonal and different strengths FORMULA  of a Gaussian prior with mean one on the singular values FORMULA : FORMULA . [SEP]\n", "[CLS] We trained these experiments with regular SGD on the spectrum and other non-orthogonal parameter matrices, using a FORMULA  learning rate. [SEP]\n", "[CLS] We see that strong priors lead to slow convergence. [SEP]\n", "[CLS] Loosening the strength of the prior makes the optimization more efficient. [SEP]\n", "[CLS] Furthermore, we compare a direct parameterization of the spectrum (no sigmoid) in (C) with a sigmoidal parameterization, using a large margin of 1 in (D). [SEP]\n", "[CLS] Without the sigmoidal parameterization, optimization quickly becomes unstable; on the other hand, the optimization also becomes unstable if the prior is removed completely in the sigmoidal formulation (margin 1). [SEP]\n", "[CLS] These results further motivate the idea that parameterizations that deviate from orthogonality may perform better than purely orthogonal ones, as long as they are sufficiently constrained to avoid instability during training. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusions We have explored a number of methods for controlling the expansivity of gradients during backpropagation based learning in RNNs through manipulating orthogonality constraints and regularization on weight matrices. [SEP]\n", "[CLS] Our experiments indicate that while orthogonal initialization may be beneficial, maintaining hard constraints on orthogonality can be detrimental. [SEP]\n", "[CLS] Indeed, moving away from hard constraints on matrix orthogonality can help improve optimization convergence rate and model performance. [SEP]\n", "[CLS] However, we also observe with synthetic tasks that relaxing regularization which encourages the spectral norms of weight matrices to be close to one too much, or allowing bounds on the spectral norms of weight matrices to be too wide, can reverse these gains and may lead to unstable optimization. [SEP]\n", "[CLS] Acknowledgments We thank the Natural Sciences and Engineeering Research Council (NSERC) of Canada and Samsung for supporting this research. [SEP]\n"], "1706.09847": ["[CLS]  =1 theme=colorsig,mode=multiuser,inlineface=,envface= [SEP]\n", "[CLS] svasvSuresh deadeDani sfasfSorelle cscesCarlos 81 2018 Conference on Fairness, Accountability, and Transparency Runaway Feedback Loops in Predictive PolicingThis research was funded in part by the NSF under grants IIS-1633387, IIS-1513651, and IIS-1633724. [SEP]\n", "[CLS] Code for our urn simulations can be found at https://github.com/algofairness/runaway-feedback-loops-src. [SEP]\n", "[CLS] Danielle Ensign [SEP]\n", "[CLS] daniphye@gmail.com [SEP]\n", "[CLS] University of Utah Sorelle A. Friedler sorelle@cs.haverford.edu Haverford College Scott Neville drop.scott.n@gmail.com University of Utah Carlos Scheidegger [SEP]\n", "[CLS] cscheid@cscheid.net University of Arizona Suresh VenkatasubramanianCorresponding author. [SEP]\n", "[CLS] suresh@cs.utah.edu University of Utah Sorelle A. Friedler and Christo Wilson [SEP]\n", "[CLS] Predictive policing systems are increasingly used to determine how to allocate police across a city in order to best prevent crime. [SEP]\n", "[CLS] Discovered crime data (e.g., arrest counts) are used to help update the model, and the process is repeated. [SEP]\n", "[CLS] Such systems have been empirically shown to be susceptible to runaway feedback loops, where police are repeatedly sent back to the same neighborhoods regardless of the true crime rate. [SEP]\n", "[CLS] In response, we develop a mathematical model of predictive policing that proves why this feedback loop occurs, show empirically that this model exhibits such problems, and demonstrate how to change the inputs to a predictive policing system (in a black-box manner) so the runaway feedback loop does not occur, allowing the true crime rate to be learned. [SEP]\n", "[CLS] Our results are quantitative: we can establish a link (in our model) between the degree to which runaway feedback causes problems and the disparity in crime rates between areas. [SEP]\n", "[CLS] Moreover, we can also demonstrate the way in which reported incidents of crime (those reported by residents) and discovered incidents of crime (i.e. those directly observed by police officers dispatched as a result of the predictive policing algorithm) interact: in brief, while reported incidents can attenuate the degree of runaway feedback, they cannot entirely remove it without the interventions we suggest. [SEP]\n", "[CLS] Feedback loops, predictive policing, online learning. [SEP]\n", "[CLS] Introduction Machine learning models are increasingly being used to make real-world decisions, such as who to hire, who should receive a loan, where to send police, and who should receive parole. [SEP]\n", "[CLS] These deployed models mostly use traditional batch-mode machine learning, where decisions are made and observed results supplement the training data for the next batch. [SEP]\n", "[CLS] However, the problem of feedback makes traditional batch learning frameworks both inappropriate and (as we shall see) incorrect. [SEP]\n", "[CLS] Hiring algorithms only receive feedback on people who were hired, predictive policing algorithms only observe crime in neighborhoods they patrol, and so on. [SEP]\n", "[CLS] Decisions made by the system influence the data that is fed to it in the future. [SEP]\n", "[CLS] For example, once a decision has been made to patrol a certain neighborhood, crime discovered in that neighborhood will be fed into the training apparatus for the next round of decision-making. [SEP]\n", "[CLS] In this paper, we focus on predictive policing \u2013 an important exemplar problem demonstrating these feedback issues. [SEP]\n", "[CLS] Predictive policing is increasingly employed to determine where to send police, who to target for surveillance, and even who may be a future crime victim\u00a0{{cite:b060f24d-897f-40d1-a6e9-b6976c25e5b9}}. [SEP]\n", "[CLS] We focus on the most popular of these forms of predictive policing (with PredPol, HunchLab, IBM, and other companies entering the market) which attempts to determine how to deploy police given historical crime data. [SEP]\n", "[CLS] [Predictive Policing] Given historical crime incident data for a collection of regions, decide how to allocate patrol officers to areas to detect crime. [SEP]\n", "[CLS] Once police are deployed based on these predictions, data from observations in the neighborhood is then used to further update the model. [SEP]\n", "[CLS] We will call these observations discovered incidents, as opposed to reported incidents that are crime incidents reported to the police (e.g., via 911 calls). [SEP]\n", "[CLS] Since such discovered incidents only occur in neighborhoods that police have been sent to by the predictive policing algorithm itself, there is the potential for this sampling bias to be compounded, causing a runaway feedback loop. [SEP]\n", "[CLS] Indeed, {{cite:1baedf52-30e0-497a-a995-e05a33a11123}} have shown that this can happen. [SEP]\n", "[CLS] Lum and Isaac's work focused on PredPol {{cite:84c52858-0827-4215-9998-1be1ad740caa}}, a predictive policing system in use by the LAPD and other cities across the U.S.. {{cite:1baedf52-30e0-497a-a995-e05a33a11123}} model what would happen if PredPol were used in Oakland to distribute police to find drug crime by using historical crime incident data as the historical data and a synthetic population of likely drug users based on public health data {{cite:f9ba2c0d-48dd-4560-bb06-e44a3da67645}}, {{cite:c9a3cc50-5ddb-4b14-9033-0a2b94fa5c86}}; they find that increasing policing efforts based on discovered incidents causes PredPol's prediction to substantially diverge from the true crime rate, repeatedly sending back police to the same neighborhoods. [SEP]\n", "[CLS] In addition to its importance in the criminal justice pipeline, predictive policing serves as an archetypal problem, through which we can better understand issues which arise out of deploying batch-mode machine learning algorithms in an online setting, where they essentially see results that are influenced by their own predictions. [SEP]\n", "[CLS] Other such algorithms include recidivism prediction, hiring algorithms, college admissions, and distribution of loans. [SEP]\n", "[CLS] In all of these contexts, the outcome of the prediction (e.g., who to hire) determines what feedback the algorithm receives (e.g., who performs well on the job). [SEP]\n", "[CLS] Results We use the theory of urns (a common framework in reinforcement learning) to analyze existing methods for predictive policing. [SEP]\n", "[CLS] We show formally as well as empirically why these methods will not work. [SEP]\n", "[CLS] Subsequently, we provide remedies that can be used directly with these methods in a black-box fashion that improve their behavior, and provide theoretical justification for these remedies. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Related Work [SEP]\n", "[CLS] Our work builds most strongly on the work of {{cite:1baedf52-30e0-497a-a995-e05a33a11123}} described above, demonstrating the consequences of feedback loops in simulation in the predictive policing setting. [SEP]\n", "[CLS] There are a number of systems currently in place for predictive policing {{cite:b060f24d-897f-40d1-a6e9-b6976c25e5b9}}. [SEP]\n", "[CLS] The most well known system used for predictive policing is called PredPol {{cite:84c52858-0827-4215-9998-1be1ad740caa}} (described in more depth below). [SEP]\n", "[CLS] Our implementation of PredPol is the one used by {{cite:1baedf52-30e0-497a-a995-e05a33a11123}} in their work. [SEP]\n", "[CLS] Recidivism prediction systems are also related to this work in that we believe they may exhibit some of the same feedback loop issues, given that recidivism outcomes are only known for prisoners who are released. [SEP]\n", "[CLS] While the details of the actual implementations (such as COMPAS {{cite:f432bd5b-3688-47f4-bb47-7f82a57e8bc5}}) remain proprietary, {{cite:333800d9-a75c-4ece-a1b6-eb4f13d59c04}} provide a comprehensive review of the methods used in this area. [SEP]\n", "[CLS] PredPol [SEP]\n", "[CLS] The predictive policing software PredPol will be critical to our experimental investigations, so we describe it in more detail here. [SEP]\n", "[CLS] PredPol {{cite:84c52858-0827-4215-9998-1be1ad740caa}} assumes that crimes follow an earthquake aftershock model, so that regions that previously experienced crime are likely to experience crime again, with some decay. [SEP]\n", "[CLS] {{cite:84c52858-0827-4215-9998-1be1ad740caa}} model the crime rate FORMULA  in region FORMULA  at time FORMULA  as follows: FORMULA  where FORMULA  represents the time of an event in region FORMULA , FORMULA  quantifies the time decay of a shock, and FORMULA  captures the degree to which aftershocks are generated from an initial event. [SEP]\n", "[CLS] They use an expectation-maximization procedure to determine the parameters of the model. [SEP]\n", "[CLS] Note that this model only uses incident data (including both discovered and reported incidents \u2013 see Section\u00a0REF ) per region to determine the true crime ratePredPol\u2014 critically \u2014 conflates amount of crime and incident data. and does not use any context in the form of demographics, arrest profiles and so on. [SEP]\n", "[CLS] PredPol, in essence, is predicting where incidents will be reported or discovered (since that's all it sees), not where crime will happen. [SEP]\n", "[CLS] Each day officers are sent to the areas with highest predicted intensity and the resulting discovered incident data is fed back into the system. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Predictive Policing with Urns We will model the predictive policing process by a series of urn models with increasing complexity. [SEP]\n", "[CLS] Urn models (especially the P\u00f3lya -Eggenberger urns) have a long history in machine learning, but notably also in reinforcement learning {{cite:371acb06-9061-482b-ab74-2e3cf3a1077e}}, where they have been used, starting with the work of {{cite:fbb32040-29d8-4df7-8d98-2ec64d80a140}}, as a way to model how bounded-rationality players in a game might interact with each other. [SEP]\n", "[CLS] Studying the dynamics of urn models allows us to understand the convergent behavior of reinforcement learning in such settings. [SEP]\n", "[CLS] We will use a generalized P\u00f3lya urn model {{cite:371acb06-9061-482b-ab74-2e3cf3a1077e}} containing balls of two colors (red and black). [SEP]\n", "[CLS] At each time step, one ball is drawn from the urn, the color is noted, and the ball is replaced. [SEP]\n", "[CLS] Then the following replacement matrix is used to decide how to update the urn contents: FORMULA   [SEP]\n", "[CLS] This matrix says that if we initially sampled a red ball, then we replace it and add FORMULA  more red balls and FORMULA  more black balls to the urn. [SEP]\n", "[CLS] We refer to the standard P\u00f3lya urn as a generalized urn with FORMULA  and FORMULA . [SEP]\n", "[CLS] Goals and assumptions In the simplest predictive policing setting, a precinct has a single police officer and polices two regions A and B. Every day the police officer is sent to one neighborhood where they may or may not observe an incident; if they do, it is logged and we refer to such a log as a discovered incident. [SEP]\n", "[CLS] In addition, residents might report incidents that are also logged: we call these reported incidents. [SEP]\n", "[CLS] The goal is to build a predictive model for where to send the officer on each day. [SEP]\n", "[CLS] Specifically, the goal is to distribute the police officers in proportion to the crime in each area. [SEP]\n", "[CLS] Why should this be the goal? [SEP]\n", "[CLS] Suppose there are exactly enough police officers to stop all the crime and no more, then a deployment according to the true crime rates will perfectly police all regions. [SEP]\n", "[CLS] Goal 3.1 (Effective Policing)   [SEP]\n", "[CLS] A region with FORMULA  percent of the crime in the precinct should receive FORMULA  percent of the police. [SEP]\n", "[CLS]  Achieving this goal [SEP]\n", "[CLS] requires learning the relative crime rates of the regions. [SEP]\n", "[CLS] To understand the behavior of predictive models, we will make some simplifying assumptions. [SEP]\n", "[CLS] We will firstly assume that the predictive model only uses current statistics (in some form) to make predictions. [SEP]\n", "[CLS] Assumption 3.1 (Predictive Model)   [SEP]\n", "[CLS] The officer tosses a coin based on current statistics to decide where to go next. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] To fully specify a predictive model, we also need to understand context \u2013 what information is collected during policing \u2013 and ground truth \u2013 what assumptions we make about underlying crime rates. [SEP]\n", "[CLS] We assume the simplest form of context. [SEP]\n", "[CLS] Assumption 3.2 (Context)   [SEP]\n", "[CLS] The only information retained about a crime is a count. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Assumptions about ground truth are both critical and complicated. [SEP]\n", "[CLS] For some neighborhood A, let FORMULA  be the underlying ground truth crime rate for the neighborhood. [SEP]\n", "[CLS] We will assume that this is observed via discovered and reported incidents. [SEP]\n", "[CLS] Let FORMULA  be the rate at which police that visit neighborhood A discover incidents. [SEP]\n", "[CLS] Let FORMULA  be the weight of the discovered incidents within all incidents. [SEP]\n", "[CLS] Similarly, let FORMULA  be the rate at which incidents are reported from neighborhood A, and let FORMULA  be the weight of reported incidents among all incidents. [SEP]\n", "[CLS] We will assume that FORMULA . [SEP]\n", "[CLS] The total rate of incident data from neighborhood A is then FORMULA . [SEP]\n", "[CLS] We note here that discovered incidents are directly implicated in the feedback loop since police are deployed in areas based on the results of the predictive model. [SEP]\n", "[CLS] Reported incidents on the other hand are not. [SEP]\n", "[CLS] To start our examinations, we make the following assumptions. [SEP]\n", "[CLS] In the subsections below, we explore what happens as we vary these factors. [SEP]\n", "[CLS] Assumption 3.3 (Truth in Crime Data)   If an officer goes to a location A with an underlying ground truth crime rate of FORMULA , the officer discovers crime at a rate of FORMULA . [SEP]\n", "[CLS] I.e., FORMULA . [SEP]\n", "[CLS] Reported incidents are also reported at a rate that matches the underlying ground truth crime rate, i.e., FORMULA .   [SEP]\n", "[CLS] Note that Assumption REF  allows the predictive policing system to operate in a generous context. [SEP]\n", "[CLS] There are many reasons to believe that this assumption does not hold. [SEP]\n", "[CLS] We will show that even in this optimistic setting problems occur. [SEP]\n", "[CLS] Assumption 3.4 (Discovery Only)    [SEP]\n", "[CLS] Incident data is only collected by an officer's presence in a neighborhood. [SEP]\n", "[CLS] Neighborhoods with no officers will contribute no incidents to the data. [SEP]\n", "[CLS] I.e., FORMULA  and FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We will also start with the assumption that all incident data is made up of discovered incidents. [SEP]\n", "[CLS] We will modify this assumption to also account for reported incidents in Section REF . [SEP]\n", "[CLS]  Uniform crime rates Let us start by assuming that the crime rate is uniform between areas. [SEP]\n", "[CLS] Assumption 3.5 (Uniform Crime Rate) If an officer goes to a location, crime happens with probability FORMULA . [SEP]\n", "[CLS] I.e., for any neighborhoods A and B, FORMULA . [SEP]\n", "[CLS]  Consider an urn that contains red and black balls, where the proportion of red and black balls represent the current observed statistics of crime in areas A and B respectively. [SEP]\n", "[CLS] Visiting area A corresponds to picking a red ball and visiting area B corresponds to picking a black ball. [SEP]\n", "[CLS] Observing crime (which happens with probability FORMULA ) causes a new ball of the same color to be placed in the urn. [SEP]\n", "[CLS] The initial balls are always returned to the urn. [SEP]\n", "[CLS] The long-term distribution of red and black balls in the urn corresponds to the long-term belief about crime prevalence in the two areas. [SEP]\n", "[CLS] In general, we can describe the evolution of this process as the following urn. [SEP]\n", "[CLS] We toss a coin that returns 1 with probability FORMULA . [SEP]\n", "[CLS] If the coin returns 1, we simulate one time step of a standard P\u00f3lya urn, and if 0, we merely replace the sampled ball. [SEP]\n", "[CLS] This corresponds to a standard P\u00f3lya urn \u201cslowed\u201d down by a factor FORMULA . [SEP]\n", "[CLS] As such, its long-term convergence is well-characterized. [SEP]\n", "[CLS] Let the beta distribution FORMULA  be a distribution over the interval FORMULA  where the probability of FORMULA  is given byThe constant of proportionality is FORMULA  where FORMULA  is the standard gamma function. [SEP]\n", "[CLS]  FORMULA [{{cite:4f79a40c-f05e-4af4-a5ed-99d5897bef07}}] Assume the urn starts off with FORMULA  red balls and FORMULA  black balls. [SEP]\n", "[CLS] Then the limiting probability of seeing a red ball is a draw from the beta distribution FORMULA . [SEP]\n", "[CLS] Significance. [SEP]\n", "[CLS] The long-term probability of seeing red is the long-term estimate of crime in area A generated by the model. [SEP]\n", "[CLS] The above result shows that this probability is a random draw governed only by the parameters FORMULA , which represents the prior belief of the system. [SEP]\n", "[CLS] In other words, the prior belief coupled with the lack of feedback about the unobserved region prevents the system from learning that the two areas are in fact identical with respect to crime rates. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] On the contrary, consider how this process would work without feedback. [SEP]\n", "[CLS] The officer could be sent to an area chosen uniformly at random each day, and this process would clearly converge to a uniform crime rate for each area. [SEP]\n", "[CLS] Indeed, such a process resembles the standard update for the bias of a coin where the prior distribution on the bias is governed by a FORMULA  distribution. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Non-uniform crime rates Let us now drop the assumption of uniformity in crime rates, replacing Assumption\u00a0REF  by Assumption 3.6 (Non-uniform Crime Rate)   [SEP]\n", "[CLS] A visit to area A has probability FORMULA  of encountering a crime, and a visit to area B has probability FORMULA  of encountering a crime. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Nonuniform crime rates in neighborhoods A and B can also be modeled by a P\u00f3lya urn, with the caveat that the updates to the urn are now random variables instead of deterministic updates. [SEP]\n", "[CLS] Formally, we can think of the urn as being described by the FORMULA  (addition) matrix FORMULA  where FORMULA  is a Bernoulli variable taking the value 1 with probability FORMULA  and 0 with probability FORMULA , and FORMULA  is defined similarly If the urn satisfied the so-called balance condition that the number of balls added at each time step is a constant {{cite:194a35c0-2206-45fc-8d9f-2efbaf8200e7}}, then we could invoke standard results to determine the limiting behavior. [SEP]\n", "[CLS] This is not the case in this setting. [SEP]\n", "[CLS] However, we now show that it is possible to reduce this to a deterministic update model by exploiting the Bernoulli structure of the update. [SEP]\n", "[CLS] At any time FORMULA , let FORMULA  be the number of balls \u201ccolored\u201d A and B respectively. [SEP]\n", "[CLS] The probability of adding any ball to the urn is given by the expression FORMULA   [SEP]\n", "[CLS] Note that this can be viewed as a convex combination of the two probabilities FORMULA  and FORMULA   [SEP]\n", "[CLS] and so the overall probability of a ball being added to the bin varies between two constants. [SEP]\n", "[CLS] As before, consider the update process limited to time steps when a ball is added to the urn. [SEP]\n", "[CLS] The probability of adding a ball colored A, conditioned on adding some ball, is given by FORMULA  with a similar expression for adding a B -colored ball. [SEP]\n", "[CLS] This is identical to the deterministic P\u00f3lya urn in which we sample an FORMULA -colored ball, replace it and then add in FORMULA  more balls of the same color. [SEP]\n", "[CLS] Essentially by conditioning on the event that we add a ball, we have eliminated the randomness in the update while retaining the randomness in the sampling. [SEP]\n", "[CLS] This latter P\u00f3lya urn can be represented by the stochastic addition matrix FORMULA   [SEP]\n", "[CLS] A very elegant result by {{cite:4f79a40c-f05e-4af4-a5ed-99d5897bef07}} provides a general expression for the long-term probability of seeing a A -colored ball. [SEP]\n", "[CLS] [{{cite:4f79a40c-f05e-4af4-a5ed-99d5897bef07}}]  Suppose we are given a P\u00f3lya urn with replacement matrix of the form FORMULA  with a positive number of balls of each kind to start with. [SEP]\n", "[CLS] Assume that FORMULA  and at least one entry is strictly positive. [SEP]\n", "[CLS] Then the limit of the fraction of balls of each type exists almost surely. [SEP]\n", "[CLS] The fraction FORMULA  of A -colored balls can be characterized as follows:   [SEP]\n", "[CLS] If FORMULA , then FORMULA  tends towards a beta distribution. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] If not, then FORMULA  tends towards a single point distribution FORMULA , where FORMULA  is a root of the quadratic polynomial FORMULA   [SEP]\n", "[CLS] If two such roots exist, then it is the one such that FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] By limiting ourselves to the subsequence of events when some ball is added to the urn, and using the above general lemma characterizing the asymptotics of deterministic urn updates from {{cite:4f79a40c-f05e-4af4-a5ed-99d5897bef07}}, we have the following lemma about the urn under this new assumption. [SEP]\n", "[CLS] In the urn with addition matrix given above, the asymptotic probability of sampling a red ball is 1 if FORMULA   [SEP]\n", "[CLS] and is zero if FORMULA . [SEP]\n", "[CLS]   Invoking Lemma\u00a0REF , we set the parameters FORMULA , FORMULA  and FORMULA . [SEP]\n", "[CLS] The resulting quadratic polynomial is FORMULA . [SEP]\n", "[CLS] This polynomial has two roots: FORMULA . [SEP]\n", "[CLS] The first derivative is FORMULA . [SEP]\n", "[CLS] If FORMULA , then this is negative for FORMULA . [SEP]\n", "[CLS] Conversely, if FORMULA , then this is negative for FORMULA . [SEP]\n", "[CLS] Significance. [SEP]\n", "[CLS] In this scenario, the update process will view one region as having much more crime than the other, even if crime rates are similar. [SEP]\n", "[CLS] In particular, if region A has a crime rate of FORMULA  and region B has a crime rate of FORMULA , the update process will settle on region B with probability 1. [SEP]\n", "[CLS] This is a classic \u201cgo with the winner\u201d problem where feedback causes a runaway effect on the estimated probabilities. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Accounting for reported incidents Now we consider what happens when we remove Assumption REF , i.e., we allow both discovered and reported incidents to be used as input to the urn model as is more usually the case in predictive policing systems. [SEP]\n", "[CLS] As discussed earlier, the weight terms FORMULA  and FORMULA  are used to weight discovered and reported crimes from a neighborhood, and so the total weight of crime incidents from (say) area [SEP]\n", "[CLS] A would be FORMULA  if it was visited, and FORMULA  otherwise. [SEP]\n", "[CLS] This leads to the following urn replacement matrix: FORMULA  where, as in Section\u00a0REF , we should interpret the entries of the matrix as expected values of a Bernoulli process. [SEP]\n", "[CLS] Using the same trick as in Section\u00a0REF , we can reinterpret the above matrix as a deterministic update process, and invoke Lemma\u00a0REF  to understand the limiting behavior. [SEP]\n", "[CLS] The corresponding quadratic equation associated with this replacement urn is given by: FORMULA  Let FORMULA  be the total weight of reported incidents, and let us denote FORMULA  by FORMULA , the weighted differential in discovered crime. [SEP]\n", "[CLS] We can then rewrite the above expression as: FORMULA   [SEP]\n", "[CLS] We can now find the roots of FORMULA . [SEP]\n", "[CLS] These are given by FORMULA  which can be written as FORMULA  where FORMULA . [SEP]\n", "[CLS] Taking the first derivative, FORMULA  and thus FORMULA  when FORMULA . [SEP]\n", "[CLS] Therefore, by Lemma\u00a0REF , the limiting fraction of \u201cFORMULA -colored\u201d balls in the urn is FORMULA   [SEP]\n", "[CLS] Interpretation We can interpret Equation\u00a0(REF ) through a number of cases. [SEP]\n", "[CLS] Firstly, consider the case of no feedback. [SEP]\n", "[CLS] This corresponds to setting FORMULA . [SEP]\n", "[CLS] In that case, the urn replacement matrix is fixed: regardless of which ball we draw, we always add FORMULA  FORMULA -colored and FORMULA  B -colored balls. [SEP]\n", "[CLS] Clearly, the limiting fraction of FORMULA -colored balls is FORMULA  and this is the answer we would expect given the crime reporting rates \u2013 we denote this fraction as FORMULA . [SEP]\n", "[CLS] We can rewrite Equation\u00a0(REF ) in terms of FORMULA  by introducing a change of variable. [SEP]\n", "[CLS] Define FORMULA  which allows us to rewrite FORMULA . [SEP]\n", "[CLS] We can now rewrite Equation\u00a0(REF ) as FORMULA   [SEP]\n", "[CLS] The second term under the square root comes from noting that FORMULA . [SEP]\n", "[CLS] A first observation is that as FORMULA , FORMULA . [SEP]\n", "[CLS] Similarly, as FORMULA , FORMULA . [SEP]\n", "[CLS] In other words, if the crime rates between the neighborhoods are heavily skewed, this urn will converge to a good approximation of the correct answer. [SEP]\n", "[CLS] For intermediate values of FORMULA , we transform the equation as follows: FORMULA   [SEP]\n", "[CLS] Significance The limiting behavior of this urn is represented by FORMULA . [SEP]\n", "[CLS] How does this relate to the ideal limiting behavior FORMULA ? [SEP]\n", "[CLS] For FORMULA , it must be that the ratio FORMULA  is close to 1. [SEP]\n", "[CLS] This can happen in two ways. [SEP]\n", "[CLS] Either FORMULA  must be very large, or FORMULA  must be small. [SEP]\n", "[CLS] FORMULA  which is bounded by 2. [SEP]\n", "[CLS] Thus, the only other option is to have FORMULA  be very small. [SEP]\n", "[CLS] Recall that FORMULA . [SEP]\n", "[CLS] To make it small, we must either make FORMULA  small, which corresponds to discounting the importance of discovered incidents (thus relying heavily on the distribution of reported incidents assumed to be correct by Assumption REF ), or it must be that the discovered crime rates FORMULA  and FORMULA  are very similar. [SEP]\n", "[CLS] In other words, the only scenarios where feedback does not drive the outcome away from the true result are when we effective ignore feedback (by downweighting the importance of discovered crime) or when the crime rates are similar enough for the feedback to not matter. [SEP]\n", "[CLS] However, it is precisely when crime rates are different that predictive policing is of value (because resources are then deployed differently). [SEP]\n", "[CLS] Thus, once again the urn model reveals problems (via simulation) in existing models for predictive policing. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Modifying the urn model to account for feedback In order to learn the crime rate, we want the P\u00f3lya urn to contain balls in proportion to the relative probability of crime occurrence. [SEP]\n", "[CLS] As we have seen, a standard P\u00f3lya urn with stochastic update rates will converge to a distribution that has no relation to the true crime rates. [SEP]\n", "[CLS] Here, we present a simple change to the urn process which does guarantee that the urn proportion will converge to the ratio of replacement (i.e. crime) rates. [SEP]\n", "[CLS] Discovered Incidents Only Again, we first consider what happens if Assumption REF  is in place. [SEP]\n", "[CLS] Consider the standard P\u00f3lya urn update rule: the probabilities FORMULA  and FORMULA  model the probability of an additional ball being added to the urn, conditional on a ball of the respective color having been sampled. [SEP]\n", "[CLS] This means that the probability of a ball being added is not FORMULA , but FORMULA . [SEP]\n", "[CLS] As a result, the expected fraction of FORMULA -balls being added to the urn after one step of the process is FORMULA  instead of FORMULA . [SEP]\n", "[CLS] This immediately suggests a fix: instead of always adding the new balls, we first sample another ball from the urn, and only add the new balls if the colors are different. [SEP]\n", "[CLS] With this fix, the probability of adding a ball with label A is FORMULA , while the probability of adding a ball with label B is FORMULA . [SEP]\n", "[CLS] Crucially, these two expressions are proportional to FORMULA  and FORMULA , except for a constant factor that is a function of the current state of the urn. [SEP]\n", "[CLS] The intuition behind this fix is that if our decision procedure sends police to region A 90% of the time, we should not be surprised that discovered incidents in region A happen at a rate of nine to one, even if the crime rate is the same across both regions. [SEP]\n", "[CLS] In such a scenario, if we see a crime in region A (where police go 90% of the time), we should simply drop the incident record 90% of the time; analogously, in region B (where police only go 10% of the time), we drop the incident record 10% of the time. [SEP]\n", "[CLS] One way to interpret our fix is as a form of rejection sampling: we are dropping sampled values according to some probability scheme to affect the statistic we are collecting. [SEP]\n", "[CLS] The importance-sampling analog to this scheme would be to use weighted balls, where the weight of each ball is inversely proportional to be rate at which police are sent. [SEP]\n", "[CLS] Effectively, we want a scheme where as more police are sent, smaller weights are assigned to discovered incidents. [SEP]\n", "[CLS] But such a scheme is precisely the Thompson-Horvitz estimator, used in survey designs with unequal probability distributions\u00a0{{cite:8a8b689d-ea9d-4d5c-886f-4f0543bd5899}}, and so we see that our proposal is a rejection-sampling variant of Thompson-Horvitz estimation. [SEP]\n", "[CLS]  Reported and Discovered Incidents Now we consider what happens if there are both discovered and reported incidents. [SEP]\n", "[CLS] Intuitively, we want to correct for the runaway feedback caused by the discovered incidents, but not over-correct for the reported incidents, which don't suffer from the issue. [SEP]\n", "[CLS] Recall that the replacement matrix is: FORMULA   [SEP]\n", "[CLS] Suppose that Assumption REF  is in place and recall that FORMULA . [SEP]\n", "[CLS] Then this replacement matrix is: FORMULA  FORMULA   [SEP]\n", "[CLS] Note that the first matrix represents the discovered replacement and the second represents the reported replacement. [SEP]\n", "[CLS] From the previous section, we know how to modify the discovery replacement matrix so that the feedback effect is mitigated. [SEP]\n", "[CLS] We first apply that same technique here, but only to the discovered incidents. [SEP]\n", "[CLS] As before, doing this ensures that the replacement contributes (in expectation) exactly FORMULA  to the urn when visiting FORMULA , and FORMULA  when visiting FORMULA . [SEP]\n", "[CLS] But what about the reported incidents? [SEP]\n", "[CLS] If we add them as is (i.e as given by the second matrix), the total contribution in the case of an FORMULA -visit is FORMULA . [SEP]\n", "[CLS] Again, invoking Assumption\u00a0REF , the total contribution becomes FORMULA  (with a similar expression for a FORMULA -visit). [SEP]\n", "[CLS] Unfortunately, this expression leads to the urn converging to an incorrect rate, ultimately because the contribution to the region not visited has been incorrectly down-weighted. [SEP]\n", "[CLS] The fix is simple: we remove the down-weighting of the reported incidents in the neighborhood where police were not deployed. [SEP]\n", "[CLS] The resulting replacement matrix, in expectation, is: FORMULA  and we apply our earlier fix to any discovered data. [SEP]\n", "[CLS] This ensures that in expectation, the contribution to the urn regardless of whether FORMULA  or FORMULA  is visited is FORMULA  FORMULA -balls and FORMULA  FORMULA -balls, as desired. [SEP]\n", "[CLS]  Evaluating the urn model  TABLE [SEP]\n", "[CLS] The distribution over 1000 days versus percentage of balls from region FORMULA  in the urn over 1000 runs. [SEP]\n", "[CLS] A police force deployed based on the underlying crime rates would send FORMULA  of the force to FORMULA  instead of FORMULA  and FORMULA  of the force to FORMULA  instead of FORMULA  (the green line shown). [SEP]\n", "[CLS] Top row (discovered incidents only): both charts (left) converge to sending FORMULA  of the force to FORMULA , while with the improvement policy (right) the charts appear to converge to the correct crime rates. [SEP]\n", "[CLS] Bottom row (all incidents, equally weighted): both charts (left) converge to the incorrect rate (red line), while with the improvement policy (right) the charts appear to converge correctly to the true crime rates. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] In this section, we will focus on validating the existence of the feedback loop problem experimentally within our urn model. [SEP]\n", "[CLS] Code for our urn simulations can be found at https://github.com/algofairness/runaway-feedback-loops-src. [SEP]\n", "[CLS] Observational decay Thus far, our urn models have captured some key elements of the model used by PredPol\u2013 the idea of differential crime rates as well as the updates based on discovered and reported incidents. [SEP]\n", "[CLS] PredPol also includes a notion of limited memory, both by incorporating time decay into crime aftershocks, and by using a limited time window for training. [SEP]\n", "[CLS] We model limited memory in the urn setting by adding a simple notion of decay. [SEP]\n", "[CLS] After every round, each ball disappears from the urn independently with a fixed probability FORMULA . [SEP]\n", "[CLS] This can be thought of as a relaxation of Assumption\u00a0REF . [SEP]\n", "[CLS] Varying FORMULA  is analogous to varying the size of the PredPol training window. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Illustrating runaway feedback in urns To the best of our knowledge there is no theoretical characterization of the asymptotic distributions in this full model once the notion of decay is included. [SEP]\n", "[CLS] We present empirical evidence illustrating the problems with using this model to learn crime rates. [SEP]\n", "[CLS] In our experiments, FORMULA . [SEP]\n", "[CLS] Using the {{cite:1baedf52-30e0-497a-a995-e05a33a11123}} data, we consider a two neighborhood police deployment scenario using, first, the two regions of Oakland with the most historical incident data (FORMULA  and FORMULA ) and, second, the Oakland neighborhood with the most incidents as compared to a randomly chosen region with many fewer incidents (FORMULA ). [SEP]\n", "[CLS] We simulate the effect of the historical incident data on the prior for the system by determining the number of balls for each region in our urn based on the past number of incidents. [SEP]\n", "[CLS] We use the full number of incidents (609, 379, and 7 for regions FORMULA , FORMULA  and FORMULA  respectively) as the starting number of balls in the urn from each region. [SEP]\n", "[CLS] The urns are then updated based on the estimated number of daily drug use incidents, i.e., FORMULA , FORMULA , and FORMULA . [SEP]\n", "[CLS] Discovered Incidents Only First, we begin with Assumption REF  in place stating that we'll only consider discovered incident data (i.e., FORMULA ). [SEP]\n", "[CLS] This allows us to isolate the part of the data that causes the feedback loop in order to examine its effect. [SEP]\n", "[CLS] The results, shown in the top left of Figure REF , demonstrate that even if police sent to a neighborhood discover crime incidents according to the true crime rate (Assumption REF ), the urn model will converge to only sending police to the neighborhood with the most crime. [SEP]\n", "[CLS] This replicates (within our urn model) the feedback loop problems with PredPol found by {{cite:1baedf52-30e0-497a-a995-e05a33a11123}}. [SEP]\n", "[CLS] Recall, from Lemma REF , that skew occurs even if the difference in crime rates between the two neighborhoods is small. [SEP]\n", "[CLS] Note that while we included a notion of decay in our urn model in order to more closely model PredPol, we found similar results under the urn model without decay. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Discovered and Reported Incidents Now, considering both reported and discovered incident data, we repeat the experiments. [SEP]\n", "[CLS] Again, we'll assume that both discovered and reported incidents are reported at the underlying true rate (Assumption REF ), and we'll assume that these incidents are equally weighted, i.e., that FORMULA . [SEP]\n", "[CLS] The results shown in the bottom left of Figure REF  show that while the error in police deployment is not as great as if only discovered incidents are used, the urn still does not converge to the correct rate. [SEP]\n", "[CLS] Here, it's important to note the strength of the assumption that incidents are reported at the true underlying rate and not influenced by police deployment - we suspect that this assumption helps this convergence to be closer to (though still not the same as) the correct rate. [SEP]\n", "[CLS]  Evaluating the modified urn Using this improvement policy to determine when to replace balls, we can now determine if the urns can learn the true crime rate despite the issue of observational bias. [SEP]\n", "[CLS] Again, using the estimated daily drug usage per region as the underlying true crime rate and the historical incident data as the prior for the urn color distribution, we simulate the urn's ability to find the relative crime rates in two regions, the FORMULA  and FORMULA  incident regions and a FORMULA  region. [SEP]\n", "[CLS] As shown in the right of Figure REF , urns under this improvement policy converge to a distribution of colors that represents the true crime rate, whether using only discovered incidents or both discovered and reported incidents. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] PredPol's relative deployment to region FORMULA  versus FORMULA  or FORMULA . [SEP]\n", "[CLS] Along the top row, we use the model which only accounts for discovered incidents (those based on police having been deployed to an area). [SEP]\n", "[CLS] Along the bottom row, we use the model which accounts for both discovered and reported incidents. [SEP]\n", "[CLS] Left: PredPol operating as usual. [SEP]\n", "[CLS] Right: discovered incident entries modified using our improvement policy. [SEP]\n", "[CLS] Police deployment based on underlying crime rates would send FORMULA  of the force to FORMULA  instead of FORMULA  and FORMULA  of the force to FORMULA  instead of FORMULA . [SEP]\n", "[CLS] These correct crime rates (indicated with a dashed red line) appear to be what PredPol converges to under the improvement policy. [SEP]\n", "[CLS]   Fixing PredPol Modifying PredPol in a black-box manner The urn models we explore provide a justification for the observed feedback loop failures of PredPol. [SEP]\n", "[CLS] But can we remedy PredPol itself using the improvements described in Section\u00a0REF ? [SEP]\n", "[CLS] We first demonstrate how asymmetric feedback affects PredPol by simulating the decisions a precinct might take after running it. [SEP]\n", "[CLS] We run PredPol's prediction model (using the {{cite:1baedf52-30e0-497a-a995-e05a33a11123}} data and implementation), trained on Oakland historical crime data, and generate crime according to the drug usage rates described above. [SEP]\n", "[CLS] At each simulation day, PredPol trains on the previous 180 days of incident data, and produces predicted crime rates FORMULA  and FORMULA . [SEP]\n", "[CLS] The decision of where to send police is made probabilistically, by a Bernoulli trial with FORMULA . [SEP]\n", "[CLS] This models the targeting effect of sending more police where more crime is expected, simulating a typical use of PredPol\u00a0{{cite:84c52858-0827-4215-9998-1be1ad740caa}}. [SEP]\n", "[CLS] To counteract the effects of the feedback, we can employ the same strategy as in Section\u00a0REF . [SEP]\n", "[CLS] The key insight is that we need only filter the inputs presented to PredPol rather than trying to modify its internal workings. [SEP]\n", "[CLS] Specifically, once we obtain crime report data from the system, we conduct another Bernoulli trial with FORMULA , where FORMULA  is the predicted rate of the district we did not police that day, and only add the incidents to the training set if the trial succeeds. [SEP]\n", "[CLS] In other words, the more likely it is that police are sent to a given district, the less likely it is that we should incorporate those discovered incidents. [SEP]\n", "[CLS]  Evaluating the PredPol simulation and its repair Simulating the effects of PredPol on policing as described above, both before and [SEP]\n", "[CLS] after our improvement policy is applied, we compare the policing rates of region FORMULA  to FORMULA  and FORMULA  to FORMULA  as before. [SEP]\n", "[CLS] Each simulation is repeated 300 times and run for one year. [SEP]\n", "[CLS] As can be seen in the top row of Figure\u00a0REF , regular PredPol rates fluctuate wildly over different runs, and do not converge to the appropriate crime rates (marked with the red dashed line). [SEP]\n", "[CLS] However, when the inputs to PredPol are changed according to our improvement policy, PredPol's prediction rates appear to fluctuate around the correct crime ratio. [SEP]\n", "[CLS] Note that the process is still quite noisy, a further indication that PredPol generates crime rate predictions that are still somewhat unreliable. [SEP]\n", "[CLS] In Section\u00a0REF , we provided an analysis and correction for urn models based on more than only discovered incidents. [SEP]\n", "[CLS] We provide a similar analysis for the mixed case in PredPol, shown along the bottom row of Figure\u00a0REF . [SEP]\n", "[CLS] Note that even with a large number of reported incidents, PredPol seems to remain susceptible to runaway feedback. [SEP]\n", "[CLS] When the correction mechanism of Section\u00a0REF  is applied to the (discovered only) incidents, PredPol appears to converge to the appropriate crime rate predictions. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Discussion and Limitations [SEP]\n", "[CLS] In this paper we show that urn models can be used to formally model predictive policing as well as indicate remedies for problems with feedback. [SEP]\n", "[CLS] We demonstrate this both formally and empirically. [SEP]\n", "[CLS] Our solution also suggests a black-box method to counteract runaway feedback in predictive policing by appropriately filtering the inputs fed to the system. [SEP]\n", "[CLS] Our results are not just a qualitative indicator of problems with feedback. [SEP]\n", "[CLS] They also indicate exactly how the problem of runaway feedback can be exacerbated: specifically as crime rates vary between regions and as the model relies more and more on discovered incident reports. [SEP]\n", "[CLS] Our results also indicate that if crime rates are more or less the same between regions, then the problem of feedback is much less, and it might be possible to generate reasonable predictions without explicitly countering feedback loops (though the results will still be inaccurate). [SEP]\n", "[CLS] There are many avenues that our analysis does not yet explore. [SEP]\n", "[CLS] Firstly, while we expect that our solution generalizes to multiple regions (and indeed the problems with feedback remain exactly the same), there might be technical difficulties in working with the much smaller probabilities we will encounter. [SEP]\n", "[CLS] As an abstraction of predictive policing, an urn model suffices to capture feedback issues, but does not account for potentially richer predictive systems that might use other information (for example demographics) to make predictions. [SEP]\n", "[CLS] Another interesting dimension that is unexplored is the fact that different types of crime might have different reporting and discovery profiles, and might interact with each other in a predictive model in complex ways. [SEP]\n", "[CLS] One of the most crucial assumptions we make (and one that in fact is sympathetic to current predictive policing models) is that reported and discovered incident rates track the true crime rates. [SEP]\n", "[CLS] There is considerable evidence that crime reporting is noisy and skewed by area and by type of crime {{cite:3663d8d9-fd04-4a53-9c8b-9d0815b41484}}. [SEP]\n", "[CLS] Once we remove that assumption, the analysis becomes more complicated, and while the problems of runaway feedback remain, the solutions might not continue to work. [SEP]\n", "[CLS] In this case, we would require better models to describe how crime rates manifest themselves in terms of reported and discovered incidents. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Acknowledgements This paper would not have been possible without Kristian Lum and William Isaac's generosity in sharing the code and data developed for {{cite:1baedf52-30e0-497a-a995-e05a33a11123}}. [SEP]\n", "[CLS] Many thanks! [SEP]\n"], "1810.04020": ["[CLS]  0pt - CSUR 0 0 0 2018 acmcopyright 0000001.0000001 [SEP]\n", "[CLS] April 2018 [SEP]\n", "[CLS] [Revised]October 2018 [SEP]\n", "[CLS] [Accepted]October 2018 A Comprehensive Survey of Deep Learning for Image Captioning Md. [SEP]\n", "[CLS] Zakir Hossain 0000-0003-1212-4652   [SEP]\n", "[CLS] Murdoch University Australia MdZakir.Hossain@murdoch.edu.au Ferdous Sohel   [SEP]\n", "[CLS] Murdoch University Australia  F.Sohel@murdoch.edu.au Mohd Fairuz Shiratuddin  Murdoch University Australia f.shiratuddin@murdoch.edu.au [SEP]\n", "[CLS] Hamid Laga  Murdoch University Australia  H.Laga@murdoch.edu.au Generating a description of an image is called image captioning. [SEP]\n", "[CLS] Image captioning requires to recognize the important objects, their attributes and their relationships in an image. [SEP]\n", "[CLS] It also needs to generate syntactically and semantically correct sentences. [SEP]\n", "[CLS] Deep learning-based techniques are capable of handling the complexities and challenges of image captioning. [SEP]\n", "[CLS] In this survey paper, we aim to present a comprehensive review of existing deep learning-based image captioning techniques. [SEP]\n", "[CLS] We discuss the foundation of the techniques to analyze their performances, strengths and limitations. [SEP]\n", "[CLS] We also discuss the datasets and the evaluation metrics popularly used in deep learning based automatic image captioning. [SEP]\n", "[CLS] <ccs2012> <concept> <conceptid>10010147.10010257</conceptid> <conceptdesc>Computing methodologies\u00a0Machine learning</conceptdesc> <conceptsignificance>500</conceptsignificance> </concept> <concept> <conceptid>10010147.10010257.10010258.10010259</conceptid> <conceptdesc>Computing methodologies\u00a0Supervised learning</conceptdesc> <conceptsignificance>500</conceptsignificance> </concept> <concept> <conceptid>10010147.10010257.10010258.10010260</conceptid> <conceptdesc>Computing methodologies\u00a0Unsupervised learning</conceptdesc> <conceptsignificance>500</conceptsignificance> </concept> <concept> <conceptid>10010147.10010257.10010258.10010261</conceptid> <conceptdesc>Computing methodologies\u00a0Reinforcement learning</conceptdesc> <conceptsignificance>500</conceptsignificance> </concept> <concept> <conceptid>10010147.10010257.10010293.10010294</conceptid> <conceptdesc>Computing methodologies\u00a0Neural networks</conceptdesc> <conceptsignificance>500</conceptsignificance> </concept> </ccs2012> [SEP]\n", "[CLS] [500]Computing methodologies\u00a0Machine learning [500]Computing methodologies\u00a0Supervised learning [500]Computing methodologies\u00a0Unsupervised learning [500]Computing methodologies\u00a0Reinforcement learning [500]Computing methodologies\u00a0Neural networks Image Captioning, Deep Learning, Computer Vision, Natural Language Processing, CNN, LSTM. [SEP]\n", "[CLS] Introduction Every day, we encounter a large number of images from various sources such as the internet, news articles, document diagrams and advertisements. [SEP]\n", "[CLS] These sources contain images that viewers would have to interpret themselves. [SEP]\n", "[CLS] Most images do not have a description, but the human can largely understand them without their detailed captions. [SEP]\n", "[CLS] However, machine needs to interpret some form of image captions if humans need automatic image captions from it. [SEP]\n", "[CLS] Image captioning is important for many reasons. [SEP]\n", "[CLS] For example, they can be used for automatic image indexing. [SEP]\n", "[CLS] Image indexing is important for Content-Based Image Retrieval (CBIR) and therefore, it can be applied to many areas, including biomedicine, commerce, the military, education, digital libraries, and web searching. [SEP]\n", "[CLS] Social media platforms such as Facebook and Twitter can directly generate descriptions from images. [SEP]\n", "[CLS] The descriptions can include where we are (e.g., beach, cafe), what we wear and importantly what we are doing there. [SEP]\n", "[CLS] Image captioning is a popular research area of Artificial Intelligence (AI) that deals with image understanding and a language description for that image. [SEP]\n", "[CLS] Image understanding needs to detect and recognize objects. [SEP]\n", "[CLS] It also needs to understand scene type or location, object properties and their interactions. [SEP]\n", "[CLS] Generating well-formed sentences requires both syntactic and semantic understanding of the language {{cite:c2632ab0-f321-4906-aedc-c70a9dcd6673}}. [SEP]\n", "[CLS] Understanding an image largely depends on obtaining image features. [SEP]\n", "[CLS] The techniques used for this purpose can be broadly divided into two categories: (1) Traditional machine learning based techniques and (2) Deep machine learning based techniques. [SEP]\n", "[CLS] In traditional machine learning, hand crafted features such as Local Binary Patterns (LBP) {{cite:cab00e1c-bece-49da-ac3e-0a9cbd890167}}, Scale-Invariant Feature Transform (SIFT) {{cite:d73b6a9f-54dd-4eb0-aaf2-a205b1d07c0e}}, the Histogram of Oriented Gradients (HOG) {{cite:c011eebb-d099-422b-bbb4-7a004d98dd38}}, and a combination of such features are widely used. [SEP]\n", "[CLS] In these techniques, features are extracted from input data. [SEP]\n", "[CLS] They are then passed to a classifier such as Support Vector Machines (SVM) {{cite:54558c16-0aed-4271-8a35-228154e2e2b2}} in order to classify an object. [SEP]\n", "[CLS] Since hand crafted features are task specific, extracting features from a large and diverse set of data is not feasible. [SEP]\n", "[CLS] Moreover, real world data such as images and video are complex and have different semantic interpretations. [SEP]\n", "[CLS] On the other hand, in deep machine learning based techniques, features are learned automatically from training data and they can handle a large and diverse set of images and videos. [SEP]\n", "[CLS] For example, Convolutional Neural Networks (CNN) {{cite:54320d6c-aa27-4fa1-b4a5-452c42f9b6c3}} are widely used for feature learning, and a classifier such as Softmax is used for classification. [SEP]\n", "[CLS] CNN is generally followed by Recurrent Neural Networks (RNN) in order to generate captions. [SEP]\n", "[CLS] In the last 5 years, a large number of articles have been published on image captioning with deep machine learning being popularly used. [SEP]\n", "[CLS] Deep learning algorithms can handle complexities and challenges of image captioning quite well. [SEP]\n", "[CLS] So far, only three survey papers {{cite:fa3ed7a3-074b-408c-b929-04786b3bcab0}}, {{cite:a2f9cc73-614a-4e46-85ce-637376440506}}, {{cite:0d588a08-c369-4fcf-b6df-26c976c3e88b}} have been published on this research topic. [SEP]\n", "[CLS] Although the papers have presented a good literature survey of image captioning, they could only cover a few papers on deep learning because the bulk of them was published after the survey papers. [SEP]\n", "[CLS] These survey papers mainly discussed template based, retrieval based, and a very few deep learning-based novel image caption generating models. [SEP]\n", "[CLS] However, a large number of works have been done on deep learning-based image captioning. [SEP]\n", "[CLS] Moreover, the availability of large and new datasets has made the learning-based image captioning an interesting research area. [SEP]\n", "[CLS] To provide an abridged version of the literature, we present a survey mainly focusing on the deep learning-based papers on image captioning. [SEP]\n", "[CLS] The main aim of this paper is to provide a comprehensive survey of deep learning for image captioning. [SEP]\n", "[CLS] First, we group the existing image captioning articles into three main categories: (1) Template-based Image captioning, (2) Retrieval-based image captioning, and (3) Novel image caption generation. [SEP]\n", "[CLS] The categories are discussed briefly in Section 2. [SEP]\n", "[CLS] Most deep learning based image captioning methods fall into the category of novel caption generation. [SEP]\n", "[CLS] Therefore, we focus only on novel caption generation with deep learning. [SEP]\n", "[CLS] Second, we group the deep learning-based image captioning methods into different categories namely (1) Visual space-based, (2) Multimodal space-based, (3) Supervised learning, (4) Other deep learning, (5) Dense captioning, (6) Whole scene-based, (7) Encoder-Decoder Architecture-based, (8) Compositional Architecture-based, (9) LSTM [SEP]\n", "[CLS] (Long Short-Term Memory) {{cite:f1a3ecf6-2d14-4bc2-9148-80fdc62f6ece}} language model-based, (10) Others language model-based, (11) Attention-Based, (12) Semantic concept-based, (13) Stylized captions, and (12) Novel object-based image captioning. [SEP]\n", "[CLS] We discuss all the categories in Section 3. [SEP]\n", "[CLS] We provide an overview of the datasets and commonly used evaluation metrics for measuring the quality of image captions in Section 4. [SEP]\n", "[CLS] We also discuss and compare the results of different methods in Section 5. [SEP]\n", "[CLS] Finally, we give a brief discussion and future research directions in Section 6 and then a conclusion in Section 7. [SEP]\n", "[CLS] FIGURE    Image Captioning Methods In this section, we review and describe the main categories of existing image captioning methods and they include template-based image captioning, retrieval-based image captioning, and novel caption generation. [SEP]\n", "[CLS] Template-based approaches have fixed templates with a number of blank slots to generate captions. [SEP]\n", "[CLS] In these approaches, different objects, attributes, actions are detected first and then the blank spaces in the templates are filled. [SEP]\n", "[CLS] For example, Farhadi et al. {{cite:8134d161-c715-4280-b515-62fbb699dcfa}} use a triplet of scene elements to fill the template slots for generating image captions. [SEP]\n", "[CLS] Li et al. {{cite:5141d9e0-c94d-4b78-a836-6adcc7286c28}} extract the phrases related to detected objects, attributes and their relationships for this purpose. [SEP]\n", "[CLS] A Conditional Random Field (CRF) is adopted by Kulkarni et al. {{cite:6b8b3376-9e16-43bd-8dab-66911350a807}} to infer the objects, attributes, and prepositions before filling in the gaps. [SEP]\n", "[CLS] Template-based methods can generate grammatically correct captions. [SEP]\n", "[CLS] However, templates are predefined and cannot generate variable-length captions. [SEP]\n", "[CLS] Moreover, later on, parsing based language models have been introduced in image captioning {{cite:ecca979c-a685-4b1b-88e1-40c84f1baa58}}, {{cite:bd9b0c9b-e71f-41ed-82e0-56443d7f5407}}, {{cite:fd91524a-cff9-45b3-be5c-9b63aef99ade}}, {{cite:ae296acf-85f9-4193-aca4-39a998e924b0}}, {{cite:4e923b3a-48cc-40cf-833d-ccdca60f8d0c}} which are more powerful than fixed template-based methods. [SEP]\n", "[CLS] Therefore, in this paper, we do not focus on these template based methods. [SEP]\n", "[CLS] Captions can be retrieved from visual space and multimodal space. [SEP]\n", "[CLS] In retrieval-based approaches, captions are retrieved from a set of existing captions. [SEP]\n", "[CLS] Retrieval based methods first find the visually similar images with their captions from the training data set. [SEP]\n", "[CLS] These captions are called candidate captions. [SEP]\n", "[CLS] The captions for the query image are selected from these captions pool {{cite:cb2a2002-31f7-4da9-abb0-35dfb3c2c312}}, {{cite:9c91863e-545c-4b4a-b390-5abc842fdc34}}, {{cite:b1e4ae4e-c23f-49e5-9a43-260d548e159c}}, {{cite:fc015bfe-b05d-4b45-a498-e9032385966c}}. [SEP]\n", "[CLS] These methods produce general and syntactically correct captions. [SEP]\n", "[CLS] However, they cannot generate image specific and semantically correct captions. [SEP]\n", "[CLS] Novel captions can be generated from both visual space and multimodal space. [SEP]\n", "[CLS] A general approach of this category is to analyze the visual content of the image first and then generate image captions from the visual content using a language model {{cite:33f57a0c-d49f-4545-ba0f-765e84164664}}, {{cite:ef6f4e52-6d73-4602-a270-fe99843c9384}}, {{cite:a0f717f7-d780-471a-9706-9178a74a8b28}}, {{cite:d9591ebf-7942-48c0-9111-56eb4b711716}}. [SEP]\n", "[CLS] These methods can generate new captions for each image that are semantically more accurate than previous approaches. [SEP]\n", "[CLS] Most novel caption generation methods use deep machine learning based techniques. [SEP]\n", "[CLS] Therefore, deep learning based novel image caption generating methods are our main focus in this literature. [SEP]\n", "[CLS] An overall taxonomy of deep learning-based image captioning methods is depicted in Figure 1. [SEP]\n", "[CLS] The figure illustrates the comparisons of different categories of image captioning methods. [SEP]\n", "[CLS] Novel caption generation-based image caption methods mostly use visual space and deep machine learning based techniques. [SEP]\n", "[CLS] Captions can also be generated from multimodal space. [SEP]\n", "[CLS] Deep learning-based image captioning methods can also be categorized on learning techniques: Supervised learning, Reinforcement learning, and Unsupervised learning. [SEP]\n", "[CLS] We group the reinforcement learning and unsupervised learning into Other Deep Learning. [SEP]\n", "[CLS] Usually captions are generated for a whole scene in the image. [SEP]\n", "[CLS] However, captions can also be generated for different regions of an image (Dense captioning). [SEP]\n", "[CLS] Image captioning methods can use either simple Encoder-Decoder architecture or Compositional architecture. [SEP]\n", "[CLS] There are methods that use attention mechanism, semantic concept, and different styles in image descriptions. [SEP]\n", "[CLS] Some methods can also generate description for unseen objects. [SEP]\n", "[CLS] We group them into one category as \u201cOthers\". [SEP]\n", "[CLS] Most of the image captioning methods use LSTM as language model. [SEP]\n", "[CLS] However, there are a number of methods that use other language models such as CNN and RNN. [SEP]\n", "[CLS] Therefore, we include a language model-based category as \u201cLSTM vs. Others\". [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Deep Learning Based Image [SEP]\n", "[CLS] Captioning Methods We draw an overall taxonomy in Figure 1 for deep learning-based image captioning methods. [SEP]\n", "[CLS] We discuss their similarities and dissimilarities by grouping them into visual space vs. multimodal space, dense captioning vs. captions for the whole scene, Supervised learning vs. Other deep learning, Encoder-Decoder architecture vs. Compositional architecture, and one `Others' group that contains Attention-Based, Semantic Concept-Based, Stylized captions, and Novel Object-Based captioning. [SEP]\n", "[CLS] We also create a category named LSTM vs. Others. [SEP]\n", "[CLS] A brief overview of the deep learning-based image captioning methods is shown in Table 1. [SEP]\n", "[CLS] Table 1 contains the name of the image captioning methods, the type of deep neural networks used to encode image information, and the language models used in describing the information. [SEP]\n", "[CLS] In the final column, we give a category label to each captioning technique based on the taxonomy in Figure 1. [SEP]\n", "[CLS] Visual Space vs. Multimodal Space   [SEP]\n", "[CLS] Deep learning-based image captioning methods can generate captions from both visual space and multimodal space. [SEP]\n", "[CLS] Understandably image captioning datasets have the corresponding captions as text. [SEP]\n", "[CLS] In the visual space-based methods, the image features and the corresponding captions are independently passed to the language decoder. [SEP]\n", "[CLS] In contrast, in a multimodal space case, a shared multimodal space is learned from the images and the corresponding caption-text. [SEP]\n", "[CLS] This multimodal representation is then passed to the language decoder. [SEP]\n", "[CLS] Visual Space Bulk of the image captioning methods use visual space for generating captions. [SEP]\n", "[CLS] These methods are discussed in Section 3.2 to Section 3.5. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Multimodal Space [SEP]\n", "[CLS] The architecture of a typical multimodal space-based method contains a language Encoder part, a vision part, a multimodal space part, and a language decoder part. [SEP]\n", "[CLS] A general diagram of multimodal space-based image captioning methods is shown in Figure 2. [SEP]\n", "[CLS] The vision part uses a deep convolutional neural network as a feature extractor to extract the image features. [SEP]\n", "[CLS] The language encoder part extracts the word features and learns a dense feature embedding for each word. [SEP]\n", "[CLS] It then forwards the semantic temporal context to the recurrent layers. [SEP]\n", "[CLS] The multimodal space part maps the image features into a common space with the word features. [SEP]\n", "[CLS] The resulting map is then passed to the language decoder which generates captions by decoding the map. [SEP]\n", "[CLS] The methods in this category follow the following steps:   [SEP]\n", "[CLS] Deep neural networks and multimodal neural language model are used to learn both image and text jointly in a multimodal space. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The language generation part generates captions using the information from Step 1 . [SEP]\n", "[CLS]  TABLE   [SEP]\n", "[CLS] An initial work in this area proposed by Kiros et al. {{cite:1dd13c18-398c-4c6a-aaee-da03d0effe98}}. [SEP]\n", "[CLS] The method applies a CNN for extracting image features in generating image captions. [SEP]\n", "[CLS] It uses a multimodal space that represents both image and text jointly for multimodal representation learning and image caption generation. [SEP]\n", "[CLS] It also introduces the multimodal neural language models such as Modality-Biased Log-Bilinear Model (MLBL-B) and the Factored 3-way Log-Bilinear Model (MLBL-F) of {{cite:87af254c-96e6-4988-9685-74ec437ccb43}} followed by AlexNet {{cite:5d426b7d-b12b-4d7a-843d-ccf1c1d3ac74}}. [SEP]\n", "[CLS] Unlike most previous approaches, this method does not rely on any additional templates, structures, or constraints. [SEP]\n", "[CLS] Instead it depends on the high level image features and word representations learned from deep neural networks and multimodal neural language models respectively. [SEP]\n", "[CLS] The neural language models have limitations to handle a large amount of data and are inefficient to work with long term memory {{cite:965c19d8-86c5-4026-bcde-3cfb05a6b3e1}}. [SEP]\n", "[CLS] Kiros et al. {{cite:1dd13c18-398c-4c6a-aaee-da03d0effe98}} extended their work in {{cite:33f57a0c-d49f-4545-ba0f-765e84164664}} to learn a joint image sentence embedding where LSTM is used for sentence encoding and a new neural language model called the structure-content neural language model (SC-NLM) is used for image captions generations. [SEP]\n", "[CLS] The SC-NLM has an advantage over existing methods in that it can extricate the structure of the sentence to its content produced by the encoder. [SEP]\n", "[CLS] It also helps them to achieve significant improvements in generating realistic image captions over the approach proposed by {{cite:1dd13c18-398c-4c6a-aaee-da03d0effe98}} Karpathy et al. {{cite:e22775f4-f5be-49ac-b299-80e3110ac8cb}} proposed a deep, multimodal model, embedding of image and natural language data for the task of bidirectional images and sentences retrieval. [SEP]\n", "[CLS] The previous multimodal-based methods use a common, embedding space that directly maps images and sentences. [SEP]\n", "[CLS] However, this method works at a finer level and embeds fragments of images and fragments of sentences. [SEP]\n", "[CLS] This method breaks down the images into a number of objects and sentences into a dependency tree relations (DTR) {{cite:e9d0142a-6479-422b-99ce-4b8899faad6b}} and reasons about their latent, inter-modal alignment. [SEP]\n", "[CLS] It shows that the method achieves significant improvements in the retrieval task compared to other previous methods. [SEP]\n", "[CLS] This method has a few limitations as well. [SEP]\n", "[CLS] In terms of modelling, the dependency tree can model relations easily but they are not always appropriate. [SEP]\n", "[CLS] For example, a single visual entity might be described by a single complex phrase that can be split into multiple sentence fragments. [SEP]\n", "[CLS] The phrase \u201cblack and white dog\u201d can be formed into two relations (CONJ, black, white) and (AMOD, white, dog). [SEP]\n", "[CLS] Again, for many dependency relations we do not find any clear mapping in the image (For example: \u201ceach other\u201d cannot be mapped to any object). [SEP]\n", "[CLS] Mao et al. {{cite:d7c0574a-e631-42dc-99d8-e292f0ffb684}} proposed a multimodal Recurrent Neural Network (m-RNN) method for generating novel image captions. [SEP]\n", "[CLS] This method has two sub-networks: a deep recurrent neural network for sentences and a deep convolutional network for images. [SEP]\n", "[CLS] These two sub-networks interact with each other in a multimodal layer to form the whole m-RNN model. [SEP]\n", "[CLS] Both image and fragments of sentences are given as input in this method. [SEP]\n", "[CLS] It calculates the probabilty distribution to generate the next word of captions. [SEP]\n", "[CLS] There are five more layers in this model: Two-word embedding layers, a recurrent layer, a multimodal layer and a SoftMax layer. [SEP]\n", "[CLS] Kiros et al. {{cite:1dd13c18-398c-4c6a-aaee-da03d0effe98}} proposed a method that is built on a Log-Bilinear model and used AlexNet to extract visual features. [SEP]\n", "[CLS] This multimodal recurrent neural network method is closely related to the method of Kiros et al. {{cite:1dd13c18-398c-4c6a-aaee-da03d0effe98}}. [SEP]\n", "[CLS] Kiros et al. use a fixed length context (i.e. five words), whereas in this method, the temporal context is stored in a recurrent architecture, which allows an arbitrary context length. [SEP]\n", "[CLS] The two word embedding layers use one hot vector to generate a dense word representation. [SEP]\n", "[CLS] It encodes both the syntactic and semantic meaning of the words. [SEP]\n", "[CLS] The semantically relevant words can be found by calculating the Euclidean distance between two dense word vectors in embedding layers. [SEP]\n", "[CLS] Most sentence-image multimodal methods {{cite:e22775f4-f5be-49ac-b299-80e3110ac8cb}}, {{cite:d1389378-580b-487c-a291-2899699a83e4}}, {{cite:9fc0d142-91e6-410a-a703-52b0b8f08a5e}}, {{cite:33f57a0c-d49f-4545-ba0f-765e84164664}} use pre-computed word embedding vectors to initialize their model. [SEP]\n", "[CLS] In contrast, this method randomly initializes word embedding layers and learn them from the training data. [SEP]\n", "[CLS] This helps them to generate better image captions than the previous methods. [SEP]\n", "[CLS] Many image captioning methods {{cite:c3c2e784-56d5-43ae-8378-87bca7bf5d6e}}, {{cite:1dd13c18-398c-4c6a-aaee-da03d0effe98}}, {{cite:e22775f4-f5be-49ac-b299-80e3110ac8cb}} are built on recurrent neural networks at the contemporary times. [SEP]\n", "[CLS] They use a recurrent layer for storing visual information. [SEP]\n", "[CLS] However, (m-RNN) use both image representations and sentence fragments to generate captions. [SEP]\n", "[CLS] It utilizes the capacity of the recurrent layer more efficiently that helps to achieve a better performance using a relatively small dimensional recurrent layer. [SEP]\n", "[CLS] Chen et al. {{cite:cb64ad44-61d9-4866-afb0-08291fcbf610}} proposed another multimodal space-based image captioning method. [SEP]\n", "[CLS] The method can generate novel captions from image and restore visual features from the given description. [SEP]\n", "[CLS] It also can describe a bidirectional mapping between images and their captions. [SEP]\n", "[CLS] Many of the existing methods {{cite:9c91863e-545c-4b4a-b390-5abc842fdc34}}, {{cite:9fc0d142-91e6-410a-a703-52b0b8f08a5e}}, {{cite:e22775f4-f5be-49ac-b299-80e3110ac8cb}} use joint embedding to generate image captions. [SEP]\n", "[CLS] However, they do not use reverse projection that can generate visual features from captions. [SEP]\n", "[CLS] On the other hand, this method dynamically updates the visual representations of the image from the generated words. [SEP]\n", "[CLS] It has an additional recurrent visual hidden layer with RNN that makes reverse projection. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Supervised Learning vs. Other Deep Learning   [SEP]\n", "[CLS] In supervised learning, training data come with desired output called label. [SEP]\n", "[CLS] Unsupervised learning, on the other hand, deals with unlabeled data. [SEP]\n", "[CLS] Generative Adversarial Networks (GANs) {{cite:bfb9e34d-fa06-429a-bd6a-ba6c0eeb11f6}} are a type of unsupervised learning techniques. [SEP]\n", "[CLS] Reinforcement learning is another type of machine learning approach where the aims of an agent are to discover data and/or labels through exploration and a reward signal. [SEP]\n", "[CLS] A number of image captioning methods use reinforcement learning and GAN based approaches. [SEP]\n", "[CLS] These methods sit in the category of \u201cOther Deep Learning\". [SEP]\n", "[CLS] Supervised Learning-Based Image Captioning Supervised learning-based networks have successfully been used for many years in image classification {{cite:5d426b7d-b12b-4d7a-843d-ccf1c1d3ac74}}, {{cite:00cfc39f-034c-4d7c-960d-3640c0df9958}}, {{cite:5f9587a0-28b2-45d7-8879-8257e388478c}}, {{cite:5aaaa777-736e-4487-8e7a-a66128be0c46}}, object detection {{cite:78ac9f28-0bfa-4bb8-a0a1-dd2da21bdc42}}, {{cite:e1373f97-34d8-4991-af11-96a75faaed88}}, {{cite:00fd7948-e454-4ebb-91b0-a33b021694f7}}, and attribute learning {{cite:3cb41525-e7ab-4333-9919-913d50c299f0}}. [SEP]\n", "[CLS] This progress makes researchers interested in using them in automatic image captioning {{cite:9bdb43fb-a77e-4807-99a9-f22beea9c216}}, {{cite:d7c0574a-e631-42dc-99d8-e292f0ffb684}}, {{cite:76d406a2-4609-43a1-8231-cd3a91c85b85}}, {{cite:cb64ad44-61d9-4866-afb0-08291fcbf610}}. [SEP]\n", "[CLS] In this paper, we have identified a large number of supervised learning-based image captioning methods. [SEP]\n", "[CLS] We classify them into different categories: (i) Encoder-Decoder Architecture, (ii) Compositional Architecture, (iii) Attention-based, (iv) Semantic concept-based, (v) Stylized captions, (vi) Novel object-based, and (vii) Dense image captioning. [SEP]\n", "[CLS] FIGURE   Other Deep Learning-Based Image [SEP]\n", "[CLS] Captioning In our day to day life, data are increasing with unlabled data because it is often impractical to accurately annotate data. [SEP]\n", "[CLS] Therefore, recently, researchers are focusing more on reinforcement learning and unsupervised learning-based techniques for image captioning. [SEP]\n", "[CLS] A reinforcement learning agent chooses an action, receives reward values, and moves to a new state. [SEP]\n", "[CLS] The agent attempts to select the action with the expectation of having a maximum long-term reward. [SEP]\n", "[CLS] It needs continuous state and action information, to provide the guarantees of a value function. [SEP]\n", "[CLS] Traditional reinforcement learning approaches face a number of limitations such as the lack of guarantees of a value function and uncertain state-action information. [SEP]\n", "[CLS] Policy gradient methods {{cite:4c69f050-483f-40de-b193-516a1610c491}} are a type of reinforcement learning that can choose a specific policy for a specific action using gradient descent and optimization techniques. [SEP]\n", "[CLS] The policy can incorporate domain knowledge for the action that guarantees convergence. [SEP]\n", "[CLS] Thus, policy gradient methods require fewer parameters than value-function based approaches. [SEP]\n", "[CLS] Existing deep learning-based image captioning methods use variants of image encoders to extract image features. [SEP]\n", "[CLS] The features are then fed into the neural network-based language decoders to generate captions. [SEP]\n", "[CLS] The methods have two main issues: (i) They are trained using maximum likelihood estimation and back-propagation\u00a0{{cite:990ff5b1-8238-463a-bfae-fb89fb96dd82}} approaches. [SEP]\n", "[CLS] In this case, the next word is predicted given the image and all the previously generated ground-truth words. [SEP]\n", "[CLS] Therefore, the generated captions look-like ground-truth captions. [SEP]\n", "[CLS] This phenomenon is called exposure bias\u00a0{{cite:cbf644e2-fc2d-4171-a349-a94720ac46b1}} problem. [SEP]\n", "[CLS] (ii) Evaluation metrics at test time are non-differentiable. [SEP]\n", "[CLS] Ideally sequence models for image captioning should be trained to avoid exposure bias and directly optimise metrics for the test time. [SEP]\n", "[CLS] In actor-critic-based reinforcement learning algorithm, critic can be used in estimating the expected future reward to train the actor (captioning policy network). [SEP]\n", "[CLS] Reinforcement learning-based image captioning methods sample the next token from the model based on the rewards they receive in each state. [SEP]\n", "[CLS] Policy gradient methods in reinforcement learning can optimize the gradient in order to predict the cumulative long-term rewards. [SEP]\n", "[CLS] Therefore, it can solve the non-differentiable problem of evaluation metrics. [SEP]\n", "[CLS] The methods in this category follow the following steps:   [SEP]\n", "[CLS] A CNN and RNN based combined network generates captions. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Another CNN-RNN based network evaluates the captions and send feedback to the first network to generate high quality captions. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A block diagram of a typical method of this category is shown in Figure 3. [SEP]\n", "[CLS] Ren et al. 2017 {{cite:55b9c3a0-0640-4284-b1f3-307f52fcb4a4}} introduced a novel reinforcement learning based image captioning method. [SEP]\n", "[CLS] The architecture of this method has two networks that jointly compute the next best word at each time step. [SEP]\n", "[CLS] The \u201cpolicy network\u201d works as local guidance and helps to predict next word based on the current state. [SEP]\n", "[CLS] The \u201cvalue network\u201d' works as global guidance and evaluates the reward value considering all the possible extensions of the current state. [SEP]\n", "[CLS] This mechanism is able to adjust the networks in predicting the correct words. [SEP]\n", "[CLS] Therefore, it can generate good captions similar to ground truth captions at the end. [SEP]\n", "[CLS] It uses an actor-critic reinforcement learning model {{cite:87a335d1-cca3-4845-84c0-34b7dd41f3a5}} to train the whole network. [SEP]\n", "[CLS] Visual semantic embedding {{cite:b915cf8f-81c0-4f08-9522-af96221b7c0f}}, {{cite:d8669d92-82ff-407e-aa83-f061ebd56f38}} is used to compute the actual reward value in predicting the correct word. [SEP]\n", "[CLS] It also helps to measure the similarity between images and sentences that can evaluate the correctness of generated captions. [SEP]\n", "[CLS] Rennie et al. {{cite:f2ddf4e4-4897-4c57-9542-53168b0c6b32}} proposed another reinforcement learning based image captioning method. [SEP]\n", "[CLS] The method utilizes the test-time inference algorithm to normalize the reward rather than estimating the reward signal and normalization in training time. [SEP]\n", "[CLS] It shows that this test-time decoding is highly effective for generating quality image captions. [SEP]\n", "[CLS] Zhang et al. {{cite:86005928-a4db-4315-9e8a-6edd14d93c24}} proposed an actor-critic reinforcement learning-based image captioning method. [SEP]\n", "[CLS] The method can directly optimize non-differentiable problems of the existing evaluation metrics. [SEP]\n", "[CLS] The architecture of the actor-critic method consists of a policy network (actor) and a value network (critic). [SEP]\n", "[CLS] The actor treats the job as sequential decision problem and can predict the next token of the sequence. [SEP]\n", "[CLS] In each state of the sequence, the network will receive a task-specific reward (in this case, it is evaluation metrics score). [SEP]\n", "[CLS] The job of the critic is to predict the reward. [SEP]\n", "[CLS] If it can predict the expected reward, the actor will continue to sample outputs according to its probability distribution. [SEP]\n", "[CLS] GAN based methods can learn deep features from unlabeled data. [SEP]\n", "[CLS] They achieve this representations applying a competitive process between a pair of networks: the Generator and the Discriminator. [SEP]\n", "[CLS] GANs have already been used successfully in a variety of applications, including image captioning{{cite:fe2079a5-8e93-4b98-80d9-7854481855ee}}, {{cite:f0580113-cad5-4922-b6ee-3391a9885a13}}, image to image translation {{cite:734df811-545c-4141-8a85-4901cef0722e}}, text to image synthesis {{cite:dc6f4f30-f43b-46e3-a5e8-dd203989fd6a}}, {{cite:b0fd3a46-2a38-4b35-91bc-d809ef6c373c}}, and text generation {{cite:4c59b187-d142-45ae-a2ff-a64555f852c8}}, {{cite:59634230-2523-47e9-a471-71b3868b2c11}}. [SEP]\n", "[CLS] There are two issues with GAN. [SEP]\n", "[CLS] First, GAN can work well in generating natural images from real images because GANs are proposed for real-valued data. [SEP]\n", "[CLS] However, text processing is based on discrete numbers. [SEP]\n", "[CLS] Therefore, such operations are non-differentiable, making it difficult to apply back-propagation directly. [SEP]\n", "[CLS] Policy gradients apply a parametric function to allow gradients to be back-propagated. [SEP]\n", "[CLS] Second, the evaluator faces problems in vanishing gradients and error propagation for sequence generation. [SEP]\n", "[CLS] It needs a probable future reward value for every partial description. [SEP]\n", "[CLS] Monte Carlo rollouts\u00a0{{cite:4d45e12d-a048-4b54-92f3-4fdfc8da85d4}} is used to compute this future reward value. [SEP]\n", "[CLS] GAN based image captioning methods can generate a diverse set of image captions in contrast to conventional deep convolutional network and deep recurrent network based model. [SEP]\n", "[CLS] Dai et al. {{cite:fe2079a5-8e93-4b98-80d9-7854481855ee}} also proposed a GAN based image captioning method. [SEP]\n", "[CLS] However, they do not consider multiple captions for a single image. [SEP]\n", "[CLS] Shetty et al. {{cite:f0580113-cad5-4922-b6ee-3391a9885a13}} introduced a new GAN based image captioning method. [SEP]\n", "[CLS] This method can generate multiple captions for a single image and showed impressive improvements in generating diverse captions. [SEP]\n", "[CLS] GANs have limitations in backpropagating the discrete data. [SEP]\n", "[CLS] Gumbel sampler {{cite:7345fc10-cc66-4076-9e7a-58f770b6af40}}, {{cite:1016ed7f-246e-4f1b-a2c1-dfc6de2aa777}} is used to overcome the discrete data problem. [SEP]\n", "[CLS] The two main parts of this adversarial network are the generator and the discriminator. [SEP]\n", "[CLS] During training, generator learns the loss value provided by the discriminator instead of learning it from explicit sources. [SEP]\n", "[CLS] Discriminator has true data distribution and can discriminate between generator-generated samples and true data samples. [SEP]\n", "[CLS] This allows the network to learn diverse data distribution. [SEP]\n", "[CLS] Moreover, the network classifies the generated caption sets either real or fake. [SEP]\n", "[CLS] Thus, it can generate captions similar to human generated one. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Dense Captioning vs. Captions for the whole scene   [SEP]\n", "[CLS] In dense captioning, captions are generated for each region of the scene. [SEP]\n", "[CLS] Other methods generate captions for the whole scene. [SEP]\n", "[CLS] Dense Captioning The previous image captioning methods can generate only one caption for the whole image. [SEP]\n", "[CLS] They use different regions of the image to obtain information of various objects. [SEP]\n", "[CLS] However, these methods do not generate region wise captions. [SEP]\n", "[CLS] Johnson et al. {{cite:49d53571-8899-48f2-a362-1522416dd19c}} proposed an image captioning method called DenseCap. [SEP]\n", "[CLS] This method localizes all the salient regions of an image and then it generates descriptions for those regions. [SEP]\n", "[CLS] A typical method of this category has the following steps:  Region proposals are generated for the different regions of the given image. [SEP]\n", "[CLS]  CNN is used to obtain the region-based image features. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The outputs of Step 2 are used by a language model to generate captions for every region. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A block diagram of a typical dense captioning method is given in Figure 4. [SEP]\n", "[CLS] Dense captioning\u00a0{{cite:49d53571-8899-48f2-a362-1522416dd19c}} proposes a fully convolutional localization network architecture, which is composed of a convolutional network, a dense localization layer, and an LSTM {{cite:f1a3ecf6-2d14-4bc2-9148-80fdc62f6ece}} language model. [SEP]\n", "[CLS] The dense localization layer processes an image with a single, efficient forward pass, which implicitly predicts a set of region of interest in the image. [SEP]\n", "[CLS] Thereby, it requires no external region proposals unlike to Fast R-CNN or a full network (i.e., RPN (Region Proposal Network {{cite:78ac9f28-0bfa-4bb8-a0a1-dd2da21bdc42}})) of Faster R-CNN. [SEP]\n", "[CLS] The working principle of the localization layer is related to the work of Faster R-CNN {{cite:00fd7948-e454-4ebb-91b0-a33b021694f7}}. [SEP]\n", "[CLS] However, Johnson et al. {{cite:49d53571-8899-48f2-a362-1522416dd19c}} use a differential, spatial soft attention mechanism {{cite:99200f8d-efdf-45b1-a085-a1c151393336}}, {{cite:00672cdb-86a6-45ef-bc8f-addea6603e2e}} and bilinear interpolation {{cite:00672cdb-86a6-45ef-bc8f-addea6603e2e}} instead of ROI pooling mechanism {{cite:78ac9f28-0bfa-4bb8-a0a1-dd2da21bdc42}}. [SEP]\n", "[CLS] This modification helps the method to backpropagate through the network and smoothly select the active regions. [SEP]\n", "[CLS] It uses Visual Genome\u00a0{{cite:8e1f6af8-153a-44b4-900b-8ff4e51a1d7e}} dataset for the experiments in generating region level image captions. [SEP]\n", "[CLS] One description of the entire visual scene is quite subjective and is not enough to bring out the complete understanding. [SEP]\n", "[CLS] Region-based descriptions are more objective and detailed than global image description. [SEP]\n", "[CLS] The region-based description is known as dense captioning. [SEP]\n", "[CLS] There are some challenges in dense captioning. [SEP]\n", "[CLS] As regions are dense, one object may have multiple overlapping regions of interest. [SEP]\n", "[CLS] Moreover, it is very difficult to recognize each target region for all the visual concepts. [SEP]\n", "[CLS] Yang et al. {{cite:30a97375-f491-4cdd-819e-562bfec4c320}} proposed another dense captioning method. [SEP]\n", "[CLS] This method can tackle these challenges. [SEP]\n", "[CLS] First, it addresses an inference mechanism that jointly depends on the visual features of the region and the predicted captions for that region. [SEP]\n", "[CLS] This allows the model to find an appropriate position of the bounding box. [SEP]\n", "[CLS] Second, they apply a context fusion that can combine context features with the visual features of respective regions to provide a rich semantic description. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Captions for the whole scene Encoder-Decoder architecture, Compositional architecture, attention-based, semantic concept-based, stylized captions, Novel object-based image captioning, and other deep learning networks-based image captioning methods generate single or multiple captions for the whole scene. [SEP]\n", "[CLS]  Encoder-Decoder Architecture vs. Compositional Architecture [SEP]\n", "[CLS] Some methods use just simple vanilla encoder and decoder to generate captions. [SEP]\n", "[CLS] However, other methods use multiple networks for it. [SEP]\n", "[CLS] Encoder-Decoder Architecture-Based Image captioning The neural network-based image captioning methods work as just simple end to end manner. [SEP]\n", "[CLS] These methods are very similar to the encoder-decoder framework-based neural machine translation {{cite:ddb02149-bfe4-4221-8140-4cd847a7b711}}. [SEP]\n", "[CLS] In this network, global image features are extracted from the hidden activations of CNN and then fed them into an LSTM to generate a sequence of words. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] A typical method of this category has the following general steps:   [SEP]\n", "[CLS] A vanilla CNN is used to obtain the scene type, to detect the objects and their relationships. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The output of Step 1 is used by a language model to convert them into words, combined phrases that produce an image captions. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A simple block diagram of this category is given in Figure 5. [SEP]\n", "[CLS] Vinyals et al. {{cite:9bdb43fb-a77e-4807-99a9-f22beea9c216}} proposed a method called Neural Image Caption Generator (NIC). [SEP]\n", "[CLS] The method uses a CNN for image representations and an LSTM for generating image captions. [SEP]\n", "[CLS] This special CNN uses a novel method for batch normalization and the output of the last hidden layer of CNN is used as an input to the LSTM decoder. [SEP]\n", "[CLS] This LSTM is capable of keeping track of the objects that already have been described using text. [SEP]\n", "[CLS] NIC is trained based on maximum likelihood estimation. [SEP]\n", "[CLS] In generating image captions, image information is included to the initial state of an LSTM. [SEP]\n", "[CLS] The next words are generated based on the current time step and the previous hidden state. [SEP]\n", "[CLS] This process continues until it gets the end token of the sentence. [SEP]\n", "[CLS] Since image information is fed only at the beginning of the process, it may face vanishing gradient problems. [SEP]\n", "[CLS] The role of the words generated at the beginning is also becoming weaker and weaker. [SEP]\n", "[CLS] Therefore, LSTM is still facing challenges in generating long length sentences {{cite:5e2d47c0-f822-4a20-a3e5-26903bb01f51}}, {{cite:59a71cf7-09d4-4784-b416-9101bacbccde}}. [SEP]\n", "[CLS] Therefore, Jia et al. {{cite:808a6450-9a4f-404d-ad7c-80bff8cd66a4}} proposed an extension of LSTM called guided LSTM (gLSTM). [SEP]\n", "[CLS] This gLSTM can generate long sentences. [SEP]\n", "[CLS] In this architecture, it adds global semantic information to each gate and cell state of LSTM. [SEP]\n", "[CLS] It also considers different length normalization strategies to control the length of captions. [SEP]\n", "[CLS] Semantic information is extracted in different ways. [SEP]\n", "[CLS] First, it uses a cross-modal retrieval task for retrieving image captions and then semantic information is extracted from these captions. [SEP]\n", "[CLS] The semantic based information can also be extracted using a multimodal embedding space. [SEP]\n", "[CLS] Mao et al. {{cite:ee1d1bad-da75-42de-a3cb-9d26f8af058a}} proposed a special type of text generation method for images. [SEP]\n", "[CLS] This method can generate a description for an specific object or region that is called referring expression {{cite:a75577f4-fa0a-45b3-9b0d-8b62caa7e9f7}}, {{cite:145ee75c-71b4-469f-a92a-01122d821707}}, {{cite:d64251c1-467d-4f8a-bc67-ee34463ba302}}, {{cite:583b1102-349d-4dfa-9c2e-0ffb734b03df}}, {{cite:0088d8d3-6c45-45e5-83ec-8fd1f12443f2}}, {{cite:b8de0861-743a-4e15-bc16-bdb63fadfaa3}}, {{cite:27993624-1f98-45dd-a6f6-3af634e8329c}}. [SEP]\n", "[CLS] Using this expression it can then infer the object or region which is being described. [SEP]\n", "[CLS] Therefore, generated description or expression is quite unambiguous. [SEP]\n", "[CLS] In order to address the referring expression, this method uses a new dataset called ReferIt dataset {{cite:27993624-1f98-45dd-a6f6-3af634e8329c}} based on popular MS COCO dataset. [SEP]\n", "[CLS] Previous CNN-RNN based image captioning methods use LSTM that are unidirectional and relatively shallow in depth. [SEP]\n", "[CLS] In unidirectional language generation techniques, the next word is predicted based on visual context and all the previous textual contexts. [SEP]\n", "[CLS] Unidirectional LSTM cannot generate contextually well formed captions. [SEP]\n", "[CLS] Moreover, recent object detection and classification methods {{cite:5d426b7d-b12b-4d7a-843d-ccf1c1d3ac74}}, {{cite:5f9587a0-28b2-45d7-8879-8257e388478c}} show that deep, hierarchical methods are better at learning than shallower ones. [SEP]\n", "[CLS] Wang et al. {{cite:8616c84b-41ff-481f-b3e5-98c96347e177}} proposed a deep bidirectional LSTM-based method for image captioning. [SEP]\n", "[CLS] This method is capable of generating contextually and semantically rich image captions. [SEP]\n", "[CLS] The proposed architecture consists of a CNN and two separate LSTM networks. [SEP]\n", "[CLS] It can utilize both past and future context information to learn long term visual language interactions. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Compositional Architecture-Based Image captioning Compositional architecture-based methods composed of several independent functional building blocks: First, a CNN is used to extract the semantic concepts from the image. [SEP]\n", "[CLS] Then a language model is used to generate a set of candidate captions. [SEP]\n", "[CLS] In generating the final caption, these candidate captions are re-ranked using a deep multimodal similarity model. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] A typical method of this category maintains the following steps:  Image features are obtained using a CNN. [SEP]\n", "[CLS]  Visual concepts (e.g. attributes) are obtained from visual features. [SEP]\n", "[CLS]  Multiple captions are generated by a language model using the information of Step 1 and Step 2.   [SEP]\n", "[CLS] The generated captions are re-ranked using a deep multimodal similarity model to select high quality image captions.   [SEP]\n", "[CLS] A common block diagram of compositional network-based image captioning methods is given in Figure 6. [SEP]\n", "[CLS] Fang et al.{{cite:84a442cb-e2ff-47aa-895e-1e74cc818e9a}} introduced generation-based image captioning. [SEP]\n", "[CLS] It uses visual detectors, a language model, and a multimodal similarity model to train the model on an image captioning dataset. [SEP]\n", "[CLS] Image captions can contain nouns, verbs, and adjectives. [SEP]\n", "[CLS] A vocabulary is formed using 1000 most common words from the training captions. [SEP]\n", "[CLS] The system works with the image sub-regions rather that the full image. [SEP]\n", "[CLS] Convolutional neural networks (both AlexNet {{cite:5d426b7d-b12b-4d7a-843d-ccf1c1d3ac74}} and VGG16Net) are used for extracting features for the sub-regions of an image. [SEP]\n", "[CLS] The features of sub-regions are mapped with the words of the vocabulary that likely to be contained in the image captions. [SEP]\n", "[CLS] Multiple instance learning (MIL) {{cite:37ccb444-9548-40d9-bb9f-4b359ea68503}} is used to train the model for learning discriminative visual signatures of each word. [SEP]\n", "[CLS] A maximum entropy (ME) {{cite:8ecdcb47-c92a-418c-9fd6-db4226f05d0d}} language model is used for generating image captions from these words. [SEP]\n", "[CLS] Generated captions are ranked by a linear weighting of sentence features. [SEP]\n", "[CLS] Minimum Error rate training (MERT) {{cite:c23cb8d1-466c-4ae5-8818-f00021cde7e6}} is used to learn these weights. [SEP]\n", "[CLS] Similarity between image and sentence can be easily measured using a common vector representation. [SEP]\n", "[CLS] Image and sentence fragments are mapped with the common vector representation by a deep multimodal similarity model (DMSM). [SEP]\n", "[CLS] It achieves a significant improvement in choosing high quality image captions. [SEP]\n", "[CLS] Until now a significant number of methods have achieved satisfactory progress in generating image captions. [SEP]\n", "[CLS] The methods use training and testing samples from the same domain. [SEP]\n", "[CLS] Therefore, there is no certainty that these methods can perform well in open-domain images. [SEP]\n", "[CLS] Moreover, they are only good at recognizing generic visual content. [SEP]\n", "[CLS] There are certain key entities such as celebrities and landmarks that are out of their scope. [SEP]\n", "[CLS] The generated captions of these methods are evaluated on automatic metrics such as BLEU {{cite:7c90d7d7-25d6-41dc-9ade-894160f3ae53}}, METEOR {{cite:3576b07b-fb58-480e-8d95-4c10d33266a6}}, and CIDEr {{cite:4557f434-8bb6-4585-8165-6c4479048477}}. [SEP]\n", "[CLS] These evaluation metrics have already shown good results on these methods. [SEP]\n", "[CLS] However, in terms of performance there exists a large gap between the evaluation of the metrics and human judgement of evaluation {{cite:075c9e02-c880-4f08-8462-11b2985b9be0}}, {{cite:e3ea1e10-82ff-4123-9041-5c7e1d247844}}, {{cite:6b8b3376-9e16-43bd-8dab-66911350a807}}. [SEP]\n", "[CLS] If it is considered real life entity information, the performance could be weaker. [SEP]\n", "[CLS] However, Tran et al. {{cite:85f48de7-de3c-408e-9195-f6c57e396de9}} introduced a different image captioning method. [SEP]\n", "[CLS] This method is capable of generating image captions even for open domain images. [SEP]\n", "[CLS] It can detect a diverse set of visual concepts and generate captions for celebrities and landmarks. [SEP]\n", "[CLS] It uses an external knowledge base Freebase {{cite:309ebf57-cfd8-4a8e-b6fc-8c4bd46e892f}} in recognizing a broad range of entities such as celebrities and landmarks. [SEP]\n", "[CLS] A series of human judgments are applied for evaluating the performances of generated captions. [SEP]\n", "[CLS] In experiments, it uses three datasets: MS COCO, Adobe-MIT FiveK {{cite:ce6d9b98-2234-4f32-828f-b939b62fcb15}}, and images from Instagram. [SEP]\n", "[CLS] The images of MS COCO dataset were collected from the same domain but the images of other datasets were chosen from an open domain. [SEP]\n", "[CLS] The method achieves notable performances especially on the challenging Instagram dataset. [SEP]\n", "[CLS] Ma et al. {{cite:1f2e3feb-79ed-4854-95ee-f337d20ee4ab}} proposed another compositional network-based image captioning method. [SEP]\n", "[CLS] This method uses structural words FORMULA object, attribute, activity, sceneFORMULA  to generate semantically meaningful descriptions. [SEP]\n", "[CLS] It also uses a multi-task method similar to multiple instance learning method {{cite:84a442cb-e2ff-47aa-895e-1e74cc818e9a}}, and multi-layer optimization method {{cite:f22eb5eb-8ce6-439d-bc1b-022b25d3ebdb}} to generate structural words. [SEP]\n", "[CLS] An LSTM encoder-decoder-based machine translation method {{cite:ddb02149-bfe4-4221-8140-4cd847a7b711}} is then used to translate the structural words into image captions. [SEP]\n", "[CLS] Wang et al. {{cite:d1eb508f-9957-4a77-91c0-3c3b2930b828}} proposed a parallel-fusion RNN-LSTM architecture for image caption generation. [SEP]\n", "[CLS] The architecture of the method divides the hidden units of RNN and LSTM into a number of same-size parts. [SEP]\n", "[CLS] The parts work in parallel with corresponding ratios to generate image captions. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Others Attention-based, Semantic concept-based, Novel object-based methods, and Stylized captions are put together into \u201cOthers\" group because these categories are independent to other methods. [SEP]\n", "[CLS] Attention based Image Captioning Neural encoder-decoder based approaches were mainly used in machine translation {{cite:ddb02149-bfe4-4221-8140-4cd847a7b711}}. [SEP]\n", "[CLS] Following these trends, they have also been used for the task of image captioning and found very effective. [SEP]\n", "[CLS] In image captioning, a CNN is used as an encoder to extract the visual features from the input image and an RNN is used as a decoder to convert this representation word-by-word into natural language description of the image. [SEP]\n", "[CLS] However, these methods are unable to analyze the image over time while they generate the descriptions for the image. [SEP]\n", "[CLS] In addition to this, the methods do not consider the spatial aspects of the image that is relevant to the parts of the image captions. [SEP]\n", "[CLS] Instead, they generate captions considering the scene as a whole. [SEP]\n", "[CLS] Attention based mechanisms are becoming increasingly popular in deep learning because they can address these limitations. [SEP]\n", "[CLS] They can dynamically focus on the various parts of the input image while the output sequences are being produced. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] A typical method of this category adopts the following steps:  Image information is obtained based on the whole scene by a CNN. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The language generation phase generates words or phrases based on the output of Step 1. [SEP]\n", "[CLS]  Salient regions of the given image are focused in each time step of the language generation model based on generated words or phrases.   [SEP]\n", "[CLS] Captions are updated dynamically until the end state of language generation model. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A block diagram of the attention-based image captioning method is shown in Figure 7. [SEP]\n", "[CLS] Xu et al. {{cite:ef6f4e52-6d73-4602-a270-fe99843c9384}} were the first to introduce an attention-based image captioning method. [SEP]\n", "[CLS] The method describes the salient contents of an image automatically. [SEP]\n", "[CLS] The main difference between the attention-based methods with other methods is that they can concentrate on the salient parts of the image and generate the corresponding words at the same time. [SEP]\n", "[CLS] This method applies two different techniques: stochastic hard attention and deterministic soft attention to generate attentions. [SEP]\n", "[CLS] Most CNN-based approaches use the top layer of ConvNet for extracting information of the salient objects from the image. [SEP]\n", "[CLS] A drawback of these techniques is that they may lose certain information which is useful to generate detailed captions. [SEP]\n", "[CLS] In order to preserve the information, the attention method uses features from the lower convolutional layer instead of fully connected layer. [SEP]\n", "[CLS] Jin et al. {{cite:892a4f6c-59c4-4212-949d-b3a6b092ec8e}} proposed another attention-based image captioning method. [SEP]\n", "[CLS] This method is capable to extract the flow of abstract meaning based on the semantic relationship between visual information and textual information. [SEP]\n", "[CLS] It can also obtain higher level semantic information by proposing a scene specific context. [SEP]\n", "[CLS] The main difference between this method with other attention-based methods is that it introduces multiple visual regions of an image at multiple scales. [SEP]\n", "[CLS] This technique can extract proper visual information of a particular object. [SEP]\n", "[CLS] For extracting scene specific context, it first uses the Latent Dirichlet Allocation (LDA) {{cite:957396eb-6c3c-4719-b118-ac5085b47f5b}} for generating a dictionary from all the captions of the dataset. [SEP]\n", "[CLS] Then a multilayer perceptron is used to predict a topic vector for every image. [SEP]\n", "[CLS] A scene factored LSTM that has two stacked layers are used to generate a description for the overall context of the image. [SEP]\n", "[CLS] Wu et al. {{cite:f0f3e915-2ec5-4605-980e-28d2fe57feba}} proposed a review-based attention method for image captioning. [SEP]\n", "[CLS] It introduces a review model that can perform multiple review steps with attention on CNN hidden states. [SEP]\n", "[CLS] The output of the CNN is a number of fact vectors that can obtain the global facts of the image. [SEP]\n", "[CLS] The vectors are given as input to the attention mechanism of the LSTM. [SEP]\n", "[CLS] For example, a reviewer module can first review: What are the objects in the image? [SEP]\n", "[CLS] Then it can review the relative positions of the objects and another review can extract the information of the overall context of the image. [SEP]\n", "[CLS] These information is passed to the decoder to generate image captions. [SEP]\n", "[CLS] Pedersoli et al. {{cite:d93ff1b7-2da3-431c-be4e-f414d3a1bc7a}} proposed an area based attention mechanism for image captioning. [SEP]\n", "[CLS] Previous attention based methods map image regions only to the state of RNN language model. [SEP]\n", "[CLS] However, this approach associates image regions with caption words given the RNN state. [SEP]\n", "[CLS] It can predict the next caption word and corresponding image region in each time-step of RNN. [SEP]\n", "[CLS] It is capable of predicting the next word as well as corresponding image regions in each time-step of RNN for generating image captions. [SEP]\n", "[CLS] In order to find the areas of attention, previous attention-based image caption methods use either the position of CNN activation grid or object proposals. [SEP]\n", "[CLS] In contrast, this method uses an end to end trainable convolutional spatial transformer along with CNN activation gird and object proposal methods. [SEP]\n", "[CLS] A combination of these techniques help this method to compute image adaptive areas of attention. [SEP]\n", "[CLS] In experiments, the method shows that this new attention mechanism together with the spatial transformer network can produce high quality image captions. [SEP]\n", "[CLS] Lu et al. {{cite:d982cfff-b9fd-41a4-a5f3-4495059b0974}} proposed another attention-based image captioning method. [SEP]\n", "[CLS] The method is based on adaptive attention model with a visual sentinel. [SEP]\n", "[CLS] Current attention-based image captioning methods focus on the image in every time step of RNN. [SEP]\n", "[CLS] However, there are some words or phrase (for example: a, of) that do not need to attend visual signals. [SEP]\n", "[CLS] Moreover, these unnecessary visual signals could affect the caption generation process and degrade the overall performance. [SEP]\n", "[CLS] Therefore, their proposed method can determine when it will focus on image region and when it will just focus on language generation model. [SEP]\n", "[CLS] Once it determines to look on the image then it must have to choose the spatial location of the image. [SEP]\n", "[CLS] The first contribution of this method is to introduce a novel spatial attention method that can compute spatial features from the image. [SEP]\n", "[CLS] Then in their adaptive attention method, they introduced a new LSTM extension. [SEP]\n", "[CLS] Generally, an LSTM works as a decoder that can produce a hidden state at every time step. [SEP]\n", "[CLS] However, this extension is capable of producing an additional visual sentinel that provides a fallback option to the decoder. [SEP]\n", "[CLS] It also has a sentinel gate that can control how much information the decoder will get from the image. [SEP]\n", "[CLS] While attention-based methods look to find the different areas of the image at the time of generating words or phrases for image captions, the attention maps generated by these methods cannot always correspond to the proper region of the image. [SEP]\n", "[CLS] It can affect the performance of image caption generation. [SEP]\n", "[CLS] Liu et al. {{cite:13a0085a-58b6-4383-86be-b546ec6cfc1f}} proposed a method for neural image captioning. [SEP]\n", "[CLS] This method can evaluate and correct the attention map at time step. [SEP]\n", "[CLS] Correctness means to make consistent map between image regions and generated words. [SEP]\n", "[CLS] In order to achieve these goals, this method introduced a quantitative evaluation metric to compute the attention maps. [SEP]\n", "[CLS] It uses Flickr30k entity dataset {{cite:8555ae08-2a44-428d-8fb6-4b7bd5342c62}} and MS COCO {{cite:e9dacdc4-318c-46a3-9ce8-caa22654a074}} dataset for measuring both ground truth attention map and semantic labelings of image regions. [SEP]\n", "[CLS] In order to learn a better attention function, it proposed supervised attention model. [SEP]\n", "[CLS] Two types of supervised attention models are used here: strong supervision with alignment annotation and weak supervision with semantic labelling. [SEP]\n", "[CLS] In strong supervision with alignment annotation model, it can directly map ground truth word to a region. [SEP]\n", "[CLS] However, ground truth alignment is not always possible because collecting and annotating data is often very expensive. [SEP]\n", "[CLS] Weak supervision is performed to use bounding box or segmentation masks on MS COCO dataset. [SEP]\n", "[CLS] In experiments, the method shows that supervised attention model performs better in mapping attention as well as image captioning. [SEP]\n", "[CLS] Chen et al. {{cite:6c384051-f616-4fa7-b2c2-3c875df4c7cf}} proposed another attention-based image captioning method. [SEP]\n", "[CLS] This method considers both spatial and channel wise attentions to compute an attention map. [SEP]\n", "[CLS] The existing attention-based image captioning methods only consider spatial information for generating an attention map. [SEP]\n", "[CLS] A common drawback of these spatial attention methods are that they compute weighted pooling only on attentive feature map. [SEP]\n", "[CLS] As a result, these methods lose the spatial information gradually. [SEP]\n", "[CLS] Moreover, they use the spatial information only from the last conv-layer of the CNN. [SEP]\n", "[CLS] The receptive field regions of this layer are quite large that make the limited gap between the regions. [SEP]\n", "[CLS] Therefore, they do not get significant spatial attentions for an image. [SEP]\n", "[CLS] However, in this method, CNN features are extracted not only from spatial locations but also from different channels and multiple layers. [SEP]\n", "[CLS] Therefore, it gets significant spatial attention. [SEP]\n", "[CLS] In addition to this, in this method, each filter of a convolutional layer acts as semantic detectors {{cite:8d11cdfc-8a56-4e7c-8da5-0663db10ea2c}} while other methods use external sources for obtaining semantic information. [SEP]\n", "[CLS] In order to reduce the gap between human generated description and machine generated description Tavakoli et al. {{cite:72f61cbc-d7fc-48fe-926b-ff5a6e3ec89d}} introduced an attention-based image captioning method. [SEP]\n", "[CLS] This is a bottom up saliency based attention model that can take advantages for comparisons with other attention-based image captioning methods. [SEP]\n", "[CLS] It found that humans first describe the more important objects than less important ones. [SEP]\n", "[CLS] It also shows that the method performs better on unseen data. [SEP]\n", "[CLS] Most previous image captioning methods applied top-down approach for constructing a visual attention map. [SEP]\n", "[CLS] These mechanisms typically focused on some selective regions obtained from the output of one or two layers of a CNN. [SEP]\n", "[CLS] The input regions are of the same size and have the same shape of receptive field. [SEP]\n", "[CLS] This approach has a little consideration to the content of the image. [SEP]\n", "[CLS] However, the method of Anderson et al. {{cite:3cd2e8fd-c712-48eb-b76d-9495da3633e8}} applied both top down and bottom up approaches. [SEP]\n", "[CLS] The bottom up attention mechanism uses Faster R-CNN {{cite:00fd7948-e454-4ebb-91b0-a33b021694f7}} for region proposals that can select salient regions of an image . [SEP]\n", "[CLS] Therefore, this method can attend both object level regions as well as other salient image regions. [SEP]\n", "[CLS] Park et al. {{cite:437fc78e-5021-4217-a019-a3bd44746a60}} introduced a different type of attention-based image captioning method. [SEP]\n", "[CLS] This method can generate image captions addressing personal issues of an image. [SEP]\n", "[CLS] It mainly considers two tasks : hashtag prediction and post generation. [SEP]\n", "[CLS] This method uses a Context Sequence Memory Network (CSMN) to obtain the context information from the image. [SEP]\n", "[CLS] Description of an image from personalized view has a lot of applications in social media networks. [SEP]\n", "[CLS] For example, everyday people share a lot of images as posts in Facebook, Instagram or other social media. [SEP]\n", "[CLS] Photo-taking or uploading is a very easy task. [SEP]\n", "[CLS] However, describing them is not easy because it requires theme, sentiment, and context of the image. [SEP]\n", "[CLS] Therefore, the method considers the past knowledge about the user's vocabularies or writing styles from the prior documents for generating image descriptions. [SEP]\n", "[CLS] In order to work with this new type of image captioning, the CSMN method has three contributions: first, the memory of this network can work as a repository and retain multiple types of context information. [SEP]\n", "[CLS] Second, the memory is designed in such a way that it can store all the previously generated words sequentially. [SEP]\n", "[CLS] As a result, it does not suffer from vanishing gradient problem. [SEP]\n", "[CLS] Third, the proposed CNN can correlate with multiple memory slots that is helpful for understanding contextual concepts. [SEP]\n", "[CLS] Attention-based methods have already shown good performance and efficiency in image captioning as well as other computer vision tasks. [SEP]\n", "[CLS] However, attention maps generated by these attention based methods are only machine dependent. [SEP]\n", "[CLS] They do not consider any supervision from human attention. [SEP]\n", "[CLS] This creates the necessity to think about the gaze information whether it can improve the performance of these attention methods in image captioning. [SEP]\n", "[CLS] Gaze indicates the cognition and perception of humans about a scene. [SEP]\n", "[CLS] Human gaze can identify the important locations of objects in an image. [SEP]\n", "[CLS] Thus, gaze mechanisms have already shown their potential performances in eye-based user modeling {{cite:f2f00cad-cdab-4947-a832-ba0e9c143100}}, {{cite:a0d98865-f42b-4e4a-8afc-b40e821696d1}}, {{cite:bfb9768d-d64a-4530-96e1-3d9ec84143a6}}, {{cite:48b5cff0-9a67-464d-94c3-a0b7817027c4}}, {{cite:a86c26b2-acc6-4d64-96f8-58cca616b68a}}, object localization {{cite:3545e876-c856-4ebb-bfc1-afc5fe2f7b7b}} or recognition {{cite:e018a1ba-42c9-4290-9cb9-32981f9ba8a2}} and holistic scene understanding {{cite:5c9d5e0c-7e56-4e69-803d-043461ab1f74}}, {{cite:297e6484-512b-4a6e-a797-dbd01c0ff4cf}}. [SEP]\n", "[CLS] However, Sugano et al. {{cite:59cead2c-39ad-4bf0-8cbc-41010689d221}} claimed that gaze information has not yet been integrated in image captioning methods. [SEP]\n", "[CLS] This method introduced human gaze with the attention mechanism of deep neural networks in generating image captions. [SEP]\n", "[CLS] The method incorporates human gaze information into an attention-based LSTM model {{cite:ef6f4e52-6d73-4602-a270-fe99843c9384}}. [SEP]\n", "[CLS] For experiments, it uses SALICON dataset {{cite:435bed8b-dcee-48b1-bcc5-e941416a95e9}} and achieves good results. [SEP]\n", "[CLS] FIGURE   Semantic Concept-Based Image [SEP]\n", "[CLS] Captioning Semantic concept-based methods selectively attend to a set of semantic concept proposals extracted from the image. [SEP]\n", "[CLS] These concepts are then combined into hidden states and the outputs of recurrent neural networks. [SEP]\n", "[CLS] The methods in this category follow the following steps:  CNN based encoder is used to encode the image features and semantic concepts. [SEP]\n", "[CLS]  Image features are fed into the input of language generation model. [SEP]\n", "[CLS]  Semantic concepts are added to the different hidden states of the language model. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The language generation part produces captions with semantic concepts. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A typical block diagram of this category is shown in Figure 8. [SEP]\n", "[CLS] Karpathy et al. extended their method {{cite:e22775f4-f5be-49ac-b299-80e3110ac8cb}} in {{cite:76d406a2-4609-43a1-8231-cd3a91c85b85}}. [SEP]\n", "[CLS] The later method can generate natural language descriptions for both images as well as for their regions. [SEP]\n", "[CLS] This method employs a novel combination of CNN over the image regions, bidirectional Recurrent Neural Networks over sentences, and a common multimodal embedding that associates the two modalities. [SEP]\n", "[CLS] It also demonstrates a multimodal recurrent neural network architecture that utilizes the resultant alignments to train the model for generating novel descriptions of image regions. [SEP]\n", "[CLS] In this method, dependency tree relations (DTR) are used to train to map the sentence segments with the image regions that have a fixed window context. [SEP]\n", "[CLS] In contrast to their previous method, this method uses a bidirectional neural network to obtain word representations in the sentence. [SEP]\n", "[CLS] It considers contiguous fragments of sentences to align in embedding space which is more meaningful, interpretable, and not fixed in length. [SEP]\n", "[CLS] Generally an RNN considers the current word and the contexts from all the previously generated words for estimating a probability distribution of the next word in a sequence. [SEP]\n", "[CLS] However, this method extends it for considering the generative process on the content of an input image. [SEP]\n", "[CLS] This addition is simple but it makes it very effective for generating novel image captions. [SEP]\n", "[CLS] Attributes of an image are considered as rich semantic cues. [SEP]\n", "[CLS] The method of Yao et al. {{cite:a0f717f7-d780-471a-9706-9178a74a8b28}} has different architectures to incorporate attributes with image representations. [SEP]\n", "[CLS] Mainly, two types of architectural representations are introduced here. [SEP]\n", "[CLS] In the first group, it inserts only attributes to the LSTM or image representations to the LSTM first and then attributes and vice versa. [SEP]\n", "[CLS] In the second group, it can control the time step of LSTM. [SEP]\n", "[CLS] It decides whether image representation and attributes will be inputted once or every time step. [SEP]\n", "[CLS] These variants of architectures are tested on MS COCO dataset and common evaluation metrics. [SEP]\n", "[CLS] You et al. {{cite:d9591ebf-7942-48c0-9111-56eb4b711716}} proposed a semantic attention-based image captioning method. [SEP]\n", "[CLS] The method provides a detailed, coherent description of semantically important objects. [SEP]\n", "[CLS] The top-down paradigms {{cite:cb64ad44-61d9-4866-afb0-08291fcbf610}}, {{cite:9bdb43fb-a77e-4807-99a9-f22beea9c216}}, {{cite:d7c0574a-e631-42dc-99d8-e292f0ffb684}}, {{cite:76d406a2-4609-43a1-8231-cd3a91c85b85}}, {{cite:200bd516-a884-4c7d-90e4-06ac80a066b2}}, {{cite:ef6f4e52-6d73-4602-a270-fe99843c9384}}, {{cite:8ad03912-56ae-4c81-9288-95dca69d09d8}} are used for extracting visual features first and then convert them into words. [SEP]\n", "[CLS] In bottom up approaches, {{cite:8134d161-c715-4280-b515-62fbb699dcfa}}, {{cite:6b8b3376-9e16-43bd-8dab-66911350a807}}, {{cite:5141d9e0-c94d-4b78-a836-6adcc7286c28}}, {{cite:bd9b0c9b-e71f-41ed-82e0-56443d7f5407}}, {{cite:fd91524a-cff9-45b3-be5c-9b63aef99ade}}, {{cite:8c701beb-8780-4410-9e71-7e615dc41fde}} visual concepts (e.g., regions, objects, and attributes) are extracted first from various aspects of an image and then combine them. [SEP]\n", "[CLS] Fine details of an image are often very important for generating a description of an image. [SEP]\n", "[CLS] Top- down approaches have limitations in obtaining fine details of the image. [SEP]\n", "[CLS] Bottom up approaches are capable of operating on any image resolution and therefore they can do work on fine details of the image. [SEP]\n", "[CLS] However, they have problems in formulating an end to end process. [SEP]\n", "[CLS] Therefore, semantic based attention model applied both top-down and bottom up approaches for generating image captions. [SEP]\n", "[CLS] In top-down approaches, the image features are obtained using the last 1024-dimensional convolutional layer of the GoogleNet {{cite:5aaaa777-736e-4487-8e7a-a66128be0c46}} CNN model. [SEP]\n", "[CLS] The visual concepts are collected using different non-parametric and parametric method. [SEP]\n", "[CLS] Nearest neighbour image retrieval technique is used for computing non-parametric visual concepts. [SEP]\n", "[CLS] Fully convolutional network (FCN) {{cite:3ce577f1-166a-42ef-98fa-574355d71b77}} is used to learn attribute from local patches for parametric attribute prediction. [SEP]\n", "[CLS] Although Xu et al. {{cite:ef6f4e52-6d73-4602-a270-fe99843c9384}} considered attention-based captioning, it works on fixed and pre-defined spatial location. [SEP]\n", "[CLS] However, this semantic attention-based method can work on any resolution and any location of the image. [SEP]\n", "[CLS] Moreover, this method also considers a feedback process that accelerates to generate better image captions. [SEP]\n", "[CLS] Previous image captioning methods do not include high level semantic concepts explicitly. [SEP]\n", "[CLS] However, Wu et al.  proposed a high-level semantic concept-based image captioning. [SEP]\n", "[CLS] It uses an intermediate attribute prediction layer in a neural network-based CNN-LSTM framework. [SEP]\n", "[CLS] First, attributes are extracted by a CNN-based classifier from training image captions. [SEP]\n", "[CLS] Then these attributes are used as high level semantic concepts in generating semantically rich image captions. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Recent semantic concept based image captioning methods {{cite:b8fd91a8-d7fe-499e-be8e-4e459034d785}}, {{cite:d9591ebf-7942-48c0-9111-56eb4b711716}} applied semantic-concept-detection process {{cite:3cb41525-e7ab-4333-9919-913d50c299f0}}to obtain explicit semantic concepts. [SEP]\n", "[CLS] They use these high level semantic concepts in CNN-LSTM based encoder-decoder and achieves significant improvements in image captioning. [SEP]\n", "[CLS] However, they have problems in generating semantically sound captions. [SEP]\n", "[CLS] They cannot distribute semantic concepts evenly in the whole sentence. [SEP]\n", "[CLS] For example, Wu et al. {{cite:b8fd91a8-d7fe-499e-be8e-4e459034d785}} consider the initial state of the LSTM to add semantic concepts. [SEP]\n", "[CLS] Moreover, it encodes visual features vector or an inferred scene vector from the CNN and then feeds them to LSTM for generating captions. [SEP]\n", "[CLS] However, Gan et al. {{cite:29c8b464-0066-44ad-8c73-04c7fcf396eb}} introduced a Semantic Compositional Network (SCN) for image captioning. [SEP]\n", "[CLS] In this method, a semantic concept vector is constructed from all the probable concepts (called tags here) found in the image. [SEP]\n", "[CLS] This semantic vector has more potential than visual feature vector and scene vector and can generate captions covering the overall meaning of the image. [SEP]\n", "[CLS] This is called compositional network because it can compose most semantic concepts. [SEP]\n", "[CLS] Existing LSTM based image captioning methods have limitations in generating a diverse set of captions because they have to predict the next word on a predefined word by word format. [SEP]\n", "[CLS] However, a combination of attributes, subjects and their relationship in a sentence irrespective of their location can generate a broad range of image captions. [SEP]\n", "[CLS] Wang et al. {{cite:fa6b1721-7965-44fa-8a3f-1abb024622d1}} proposed a method that locates the objects and their interactions first and then identifies and extracts the relevant attributes to generate image captions. [SEP]\n", "[CLS] The main aim of this method is to decompose the ground truth image captions into two parts: Skeleton sentence and attribute phrases. [SEP]\n", "[CLS] The method is also called Skeleton Key. [SEP]\n", "[CLS] The architecture of this method has ResNet {{cite:00cfc39f-034c-4d7c-960d-3640c0df9958}} and two LSTMs called Skel-LSTM and Attr-LSTM. [SEP]\n", "[CLS] During training, skeleton sentences are trained by Skel-LSTM network and attribute phrases are trained by the Attr-LSTM network. [SEP]\n", "[CLS] In the testing phase, skeleton sentences are generated first that contain the words for main objects of the image and their relationships. [SEP]\n", "[CLS] Then these objects look back through the image again to obtain the relevant attributes. [SEP]\n", "[CLS] It is tested on MS COCO dataset and a new Stock3M dataset and can generate more accurate and novel captions. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Novel Object-based Image Captioning Despite recent deep learning-based image captioning methods have achieved promising results, they largely depend on the paired image and sentence caption datasets. [SEP]\n", "[CLS] These type of methods can only generate description of the objects within the context. [SEP]\n", "[CLS] Therefore, the methods require a large set of training image-sentence pairs. [SEP]\n", "[CLS] Novel object-based image captioning methods can generate descriptions of novel objects which are not present in paired image-captions datasets. [SEP]\n", "[CLS] The methods of this category follow the following general steps:   [SEP]\n", "[CLS] A separate lexical classifier and a language model are trained on unpaired image data and unpaired text data. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A deep caption model is trained on paired image caption data. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Finally, both models are combined together to train jointly in that can generate captions for novel object. [SEP]\n", "[CLS]  FIGURE   [SEP]\n", "[CLS] A simple block diagram of a novel object-based image captioning method is given in Figure 9. [SEP]\n", "[CLS] Current image captioning methods are trained on image-captions paired datasets. [SEP]\n", "[CLS] As a result, if they get unseen objects in the test images, they cannot present them in their generated captions. [SEP]\n", "[CLS] Anne et al. {{cite:d5734452-030c-47fa-93b6-65a1399c1950}} proposed a Deep Compositional Captioner (DCC) that can represent the unseen objects in generated captions. [SEP]\n", "[CLS] Yao et al. {{cite:5d4f5a0e-3391-4807-8d0d-e323f9848a8e}} proposed a copying mechanism to generate description for novel objects. [SEP]\n", "[CLS] This method uses a separate object recognition dataset to develop classifiers for novel objects. [SEP]\n", "[CLS] It integrates the appropriate words in the output captions by a decoder RNN with copying mechanism. [SEP]\n", "[CLS] The architecture of the method adds a new network to recognize the unseen objects from unpaired images and incorporate them with LSTM to generate captions. [SEP]\n", "[CLS] Generating captions for the unseen images is a challenging research problem. [SEP]\n", "[CLS] Venugopalan et al. {{cite:3d930a73-437d-4ae1-b658-78c2c7d031b1}} introduced a Novel Object Captioner (NOC) for generating captions for unseen objects in the image. [SEP]\n", "[CLS] They used external sources for recognizing unseen objects and learning semantic knowledge. [SEP]\n", "[CLS]  Stylized Caption Existing image captioning systems generate captions just based on only the image content that can also be called factual description. [SEP]\n", "[CLS] They do not consider the stylized part of the text separately from other linguistic patterns. [SEP]\n", "[CLS] However, the stylized captions can be more expressive and attractive than just only the flat description of an image. [SEP]\n", "[CLS] The methods of this category follow the following general steps:  CNN based image encoder is used to obtain the image information. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A separate text corpus is prepared to extract various stylized concepts (For example: romantic, humorous) from training data. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The language generation part can generate stylized and attractive captions using the information of Step 1 and Step 2.   [SEP]\n", "[CLS] A simple block diagram of stylized image captioning is given in Figure 10. [SEP]\n", "[CLS] Such captions have become popular because they are particularly valuable for many real-world applications. [SEP]\n", "[CLS] For example, everyday people are uploading a lot of photos in different social media. [SEP]\n", "[CLS] The photos need stylized and attractive descriptions. [SEP]\n", "[CLS] Gan et al. {{cite:c1e5ea25-65d4-4b7b-b5c5-d2ff50f69ead}} proposed a novel image captioning system called StyleNet. [SEP]\n", "[CLS] This method can generate attractive captions adding various styles. [SEP]\n", "[CLS] The architecture of this method consists of a CNN and a factored LSTM that can separate factual and style factors from the captions. [SEP]\n", "[CLS] It uses multitask sequence to sequence training {{cite:b4514ca7-b4b1-4244-af99-8070e7a3b643}} for identifying the style factors and then add these factors at run time for generating attractive captions. [SEP]\n", "[CLS] More interestingly, it uses an external monolingual stylized language corpus for training instead of paired images. [SEP]\n", "[CLS] However, it uses a new stylized image caption dataset called FlickrStyle10k and can generate captions with different styles. [SEP]\n", "[CLS] Existing image captioning methods consider the factual description about the objects, scene, and their interactions of an image in generating image captions. [SEP]\n", "[CLS] In our day to day conversations, communications, interpersonal relationships, and decision making we use various stylized and non-factual expressions such as emotions, pride, and shame. [SEP]\n", "[CLS] However, Mathews et al. {{cite:743e73c4-3050-4dad-ace8-a0889763d1a0}} claimed that automatic image descriptions are missing this non-factual aspects. [SEP]\n", "[CLS] Therefore, they proposed a method called SentiCap. [SEP]\n", "[CLS] This method can generate image descriptions with positive or negative sentiments. [SEP]\n", "[CLS] It introduces a novel switching RNN model that combines two CNN+RNNs running in parallel. [SEP]\n", "[CLS] In each time step, this switching model generates the probability of switching between two RNNs. [SEP]\n", "[CLS] One generates captions considering the factual words and other considers the words with sentiments. [SEP]\n", "[CLS] It then takes inputs from the hidden states of both two RNNs for generating captions. [SEP]\n", "[CLS] This method can generate captions successfully given the appropriate sentiments. [SEP]\n", "[CLS]  LSTM vs. Others Image captioning intersects computer vision and natural language processing (NLP) research. [SEP]\n", "[CLS] NLP tasks, in general, can be formulated as a sequence to sequence learning. [SEP]\n", "[CLS] Several neural language models such as neural probabilistic language model {{cite:6395c446-528c-4688-8b93-a1898e5b6647}}, log-bilinear models {{cite:f7c292d5-4f50-40e4-996e-8ed6e0cc1f20}}, skip-gram models {{cite:388e91bd-97f2-4c97-ac78-18d2c5953660}}, and recurrent neural networks (RNNs) {{cite:35f0d12a-dfbf-4f4b-a9da-4b2381955d51}} have been proposed for learning sequence to sequence tasks. [SEP]\n", "[CLS] RNNs have widely been used in various sequence learning tasks. [SEP]\n", "[CLS] However, traditional RNNs suffer from vanishing and exploding gradient problems and cannot adequately handle long-term temporal dependencies. [SEP]\n", "[CLS] LSTM {{cite:f1a3ecf6-2d14-4bc2-9148-80fdc62f6ece}} networks are a type of RNN that has special units in addition to standard units. [SEP]\n", "[CLS] LSTM units use a memory cell that can maintain information in memory for long periods of time. [SEP]\n", "[CLS] In recent years, LSTM based models have dominantly been used in sequence to sequence learning tasks. [SEP]\n", "[CLS] Another network, Gated Recurrent Unit (GRU) {{cite:10deabf3-695f-4a74-b703-01e7ef53c4aa}} has a similar structure to LSTM [SEP]\n", "[CLS] but it does not use separate memory cells and uses fewer gates to control the flow of information. [SEP]\n", "[CLS] However, LSTMs ignore the underlying hierarchical structure of a sentence. [SEP]\n", "[CLS] They also require significant storage due to long-term dependencies through a memory cell. [SEP]\n", "[CLS] In contrast, CNNs can learn the internal hierarchical structure of the sentences and they are faster in processing than LSTMs. [SEP]\n", "[CLS] Therefore, recently, convolutional architectures are used in other sequence to sequence tasks, e.g., conditional image generation {{cite:1392e55c-fb74-4887-9480-ad8d9201a6f7}} and machine translation {{cite:adac0493-bb65-49e0-9cdd-4875c2227d1f}}, {{cite:23e92772-b5b4-4ba1-a331-ecf1cf4db2da}}, {{cite:85cd1b46-85c4-4e91-8e6d-d63b1169c2f1}}. [SEP]\n", "[CLS] Inspired by the above success of CNNs in sequence learning tasks, Gu et al. {{cite:433cd850-95bb-46bd-888d-aa7fded5805e}} proposed a CNN language model-based image captioning method. [SEP]\n", "[CLS] This method uses a language-CNN for statistical language modelling. [SEP]\n", "[CLS] However, the method cannot model the dynamic temporal behaviour of the language model only using a language-CNN. [SEP]\n", "[CLS] It combines a recurrent network with the language-CNN to model the temporal dependencies properly. [SEP]\n", "[CLS] Aneja et al. {{cite:523261f8-57b3-4a39-9fe7-29a0ddca1d82}} proposed a convolutional architecture for the task of image captioning. [SEP]\n", "[CLS] They use a feed-forward network without any recurrent function. [SEP]\n", "[CLS] The architecture of the method has four components: (i) input embedding layer (ii) image embedding layer (iii) convolutional module, and (iv) output embedding layer. [SEP]\n", "[CLS] It also uses an attention mechanism to leverage spatial image features. [SEP]\n", "[CLS] They evaluate their architecture on the challenging MSCOCO dataset and shows comparable performance to an LSTM based method on standard metrics. [SEP]\n", "[CLS] Wang et al. {{cite:c5cb1546-ccbe-49b3-aaf9-da55ec96ace5}} proposed another CNN+CNN based image captioning method. [SEP]\n", "[CLS] It is similar to the method of Aneja et al. except that it uses a hierarchical attention module to connect the vision-CNN with the language-CNN. [SEP]\n", "[CLS] The authors of this method also investigate the use of various hyperparameters, including the number of layers and the kernel width of the language-CNN. [SEP]\n", "[CLS] They show that the influence of the hyperparameters can improve the performance of the method in image captioning. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Datasets and Evaluation Metrics [SEP]\n", "[CLS] A number of datasets are used for training, testing, and evaluation of the image captioning methods. [SEP]\n", "[CLS] The datasets differ in various perspective such as the number of images, the number of captions per image, format of the captions, and image size. [SEP]\n", "[CLS] Three datasets: Flickr8k {{cite:9c91863e-545c-4b4a-b390-5abc842fdc34}}, Flickr30k {{cite:8555ae08-2a44-428d-8fb6-4b7bd5342c62}}, and MS COCO Dataset {{cite:e9dacdc4-318c-46a3-9ce8-caa22654a074}} are popularly used. [SEP]\n", "[CLS] These datasets together with others are described in Section 4.1. [SEP]\n", "[CLS] In this section, we show sample images with their captions generated by image captioning methods on MS COCO, Flickr30k, and Flickr8k datasets. [SEP]\n", "[CLS] A number of evaluation metrics are used to measure the quality of the generated captions compared to the ground-truth. [SEP]\n", "[CLS] Each metric applies its own technique for computation and has distinct advantages. [SEP]\n", "[CLS] The commonly used evaluation metrics are discussed in Section 4.2. [SEP]\n", "[CLS] A summary of deep learning-based image captioning methods with their datasets and evaluation metrics are listed in Table 2. [SEP]\n", "[CLS] FIGURE   Datasets MS COCO Dataset Microsoft COCO Dataset {{cite:e9dacdc4-318c-46a3-9ce8-caa22654a074}} is a very large dataset for image recognition, segmentation, and captioning. [SEP]\n", "[CLS] There are various features of MS COCO dataset such as object segmentation, recognition in context, multiple objects per class, more than 300,000 images, more than 2 million instances, 80 object categories, and 5 captions per image. [SEP]\n", "[CLS] Many image captioning methods {{cite:892a4f6c-59c4-4212-949d-b3a6b092ec8e}}, {{cite:f0f3e915-2ec5-4605-980e-28d2fe57feba}}, {{cite:85f48de7-de3c-408e-9195-f6c57e396de9}}, {{cite:8616c84b-41ff-481f-b3e5-98c96347e177}}, {{cite:d9591ebf-7942-48c0-9111-56eb4b711716}}, {{cite:c1e5ea25-65d4-4b7b-b5c5-d2ff50f69ead}}, {{cite:d93ff1b7-2da3-431c-be4e-f414d3a1bc7a}}, {{cite:55b9c3a0-0640-4284-b1f3-307f52fcb4a4}}, {{cite:fe2079a5-8e93-4b98-80d9-7854481855ee}}, {{cite:f0580113-cad5-4922-b6ee-3391a9885a13}}, {{cite:f3bf71f4-459d-48f9-9805-d9bbd38c3b61}} use the dataset in their experiments. [SEP]\n", "[CLS] For example, Wu et al. {{cite:f3bf71f4-459d-48f9-9805-d9bbd38c3b61}} use MS COCO dataset in their method and the generated captions of two sample images are shown in Figure 11.   [SEP]\n", "[CLS] Flickr30K Dataset Flickr30K {{cite:8555ae08-2a44-428d-8fb6-4b7bd5342c62}} is a dataset for automatic image description and grounded language understanding. [SEP]\n", "[CLS] It contains 30k images collected from Flickr with 158k captions provided by human annotators. [SEP]\n", "[CLS] It does not provide any fixed split of images for training, testing, and validation. [SEP]\n", "[CLS] Researchers can choose their own choice of numbers for training, testing, and validation. [SEP]\n", "[CLS] The dataset also contains detectors for common objects, a color classifier, and a bias towards selecting larger objects. [SEP]\n", "[CLS] Image captioning methods such as {{cite:76d406a2-4609-43a1-8231-cd3a91c85b85}}, {{cite:9bdb43fb-a77e-4807-99a9-f22beea9c216}}, {{cite:8616c84b-41ff-481f-b3e5-98c96347e177}}, {{cite:b8fd91a8-d7fe-499e-be8e-4e459034d785}}, {{cite:c6bb2087-9b52-4bb9-8805-7e3c057e343f}} use this dataset for their experiments. [SEP]\n", "[CLS] For example, performed their experiment on Flickr30k dataset. [SEP]\n", "[CLS] The generated captions by Chen et al. {{cite:c6bb2087-9b52-4bb9-8805-7e3c057e343f}} of two sample images of the dataset are shown in Figure 12. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] FIGURE   Flickr8 [SEP]\n", "[CLS] K Dataset Flickr8k {{cite:9c91863e-545c-4b4a-b390-5abc842fdc34}} is a popular dataset and has 8000 images collected from Flickr. [SEP]\n", "[CLS] The training data consists of 6000 images, the test and development data, each consists of 1,000 images. [SEP]\n", "[CLS] Each image in the dataset has 5 reference captions annotated by humans. [SEP]\n", "[CLS] A number of image captioning methods {{cite:808a6450-9a4f-404d-ad7c-80bff8cd66a4}}, {{cite:892a4f6c-59c4-4212-949d-b3a6b092ec8e}}, {{cite:ef6f4e52-6d73-4602-a270-fe99843c9384}}, {{cite:8616c84b-41ff-481f-b3e5-98c96347e177}}, {{cite:b8fd91a8-d7fe-499e-be8e-4e459034d785}}, {{cite:6c384051-f616-4fa7-b2c2-3c875df4c7cf}} have performed experiments using the dataset. [SEP]\n", "[CLS] Two sample results by Jia et al. {{cite:808a6450-9a4f-404d-ad7c-80bff8cd66a4}} on this dataset are shown in Figure 13. [SEP]\n", "[CLS]  Visual Genome Dataset Visual Genome dataset {{cite:8e1f6af8-153a-44b4-900b-8ff4e51a1d7e}} is another dataset for image captioning. [SEP]\n", "[CLS] Image captioning requires not only to recognise the objects of an image but it also needs reasoning their interactions and attributes. [SEP]\n", "[CLS] Unlike the first three datasets where a caption is given to the whole scene, Visual Genome dataset has separate captions for multiple regions in an image. [SEP]\n", "[CLS] The dataset has seven main parts: region descriptions, objects, attributes, relationships, region graphs, scene graphs, and question answer pairs. [SEP]\n", "[CLS] The dataset has more than 108k images. [SEP]\n", "[CLS] Each image contains an average of 35 objects, 26 attributes, and 21 pairwise relationships between objects. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Instagram Dataset Tran et al. {{cite:85f48de7-de3c-408e-9195-f6c57e396de9}} and Park et al. {{cite:437fc78e-5021-4217-a019-a3bd44746a60}} created two datasets using images from Instagram which is a photo-sharing social networking services. [SEP]\n", "[CLS] The dataset of Tran et al. has about 10k images which are mostly from celebrities. [SEP]\n", "[CLS] However, Park et al. used their dataset for hashtag prediction and post-generation tasks in social media networks. [SEP]\n", "[CLS] This dataset contains 1.1m posts on a wide range of topics and a long hashtag lists from 6.3k users. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] IAPR TC-12 Dataset IAPR TC-12 dataset {{cite:b4e95b03-a977-4608-b2f7-e2aa790be7bf}} has 20k images. [SEP]\n", "[CLS] The images are collected from various sources such as sports, photographs of people, animals, landscapes and many other locations around the world. [SEP]\n", "[CLS] The images of this dataset have captions in multiple languages. [SEP]\n", "[CLS] Images have multiple objects as well.   [SEP]\n", "[CLS] Stock3M Dataset Stock3 [SEP]\n", "[CLS] M dataset has 3,217,654 images uploaded by users and it is 26 times larger than MSCOCO dataset. [SEP]\n", "[CLS] The images of this dataset have a diversity of content. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] MIT-Adobe FiveK dataset MIT-Adobe FiveK {{cite:ce6d9b98-2234-4f32-828f-b939b62fcb15}} dataset consists of 5,000 images. [SEP]\n", "[CLS] These images contain a diverse set of scenes, subjects, and lighting conditions and they are mainly about people, nature, and man-made objects. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] FlickrStyle10k [SEP]\n", "[CLS] Dataset FlickrStyle10k dataset has 10,000 Flickr images with stylized captions. [SEP]\n", "[CLS] The training data consists of 7000 images. [SEP]\n", "[CLS] The validation and test data consists of 2,000 and 1,000 images respectively. [SEP]\n", "[CLS] Each image contains romantic, humorous, and factual captions. [SEP]\n", "[CLS]  Evaluation Metrics BLEU BLEU (Bilingual evaluation understudy) {{cite:7c90d7d7-25d6-41dc-9ade-894160f3ae53}} is a metric that is used to measure the quality of machine generated text. [SEP]\n", "[CLS] Individual text segments are compared with a set of reference texts and scores are computed for each of them. [SEP]\n", "[CLS] In estimating the overall quality of the generated text, the computed scores are averaged. [SEP]\n", "[CLS] However, syntactical correctness is not considered here. [SEP]\n", "[CLS] The performance of the BLEU metric is varied depending on the number of reference translations and the size of the generated text. [SEP]\n", "[CLS] Subsequently, Papineni et al. introduced a modified precision metric. [SEP]\n", "[CLS] This metrics uses n-grams. [SEP]\n", "[CLS] BLEU is popular because it is a pioneer in automatic evaluation of machine translated text and has a reasonable correlation with human judgements of quality {{cite:f6923e8d-fdfe-4606-897f-fa251bbdd089}}, {{cite:e3ea1e10-82ff-4123-9041-5c7e1d247844}}. [SEP]\n", "[CLS] However, it has a few limitations such as BLEU scores are good only if the generated text is short {{cite:e3ea1e10-82ff-4123-9041-5c7e1d247844}}. [SEP]\n", "[CLS] There are some cases where an increase in BLEU score does not mean that the quality of the generated text is good {{cite:acd7b74f-bd15-4a2c-b0a2-c0cc2250cd24}}.   [SEP]\n", "[CLS] ROUGE ROUGE [SEP]\n", "[CLS] (Recall-Oriented Understudy for Gisting Evaluation) {{cite:65b8a913-5a39-4031-ae07-a43fb4144217}} is a set of metrics that are used for measuring the quality of text summary. [SEP]\n", "[CLS] It compares word sequences, word pairs, and n-grams with a set of reference summaries created by humans. [SEP]\n", "[CLS] Different types of ROUGE such as ROUGE-1, 2, ROUGE-W, ROUGE-SU4 are used for different tasks. [SEP]\n", "[CLS] For example, ROUGE-1 and ROUGE-W are appropriate for single document evaluation whereas ROUGE-2 and ROUGE-SU4 have good performance in short summaries. [SEP]\n", "[CLS] However, ROUGE has problems in evaluating multi-document text summary. [SEP]\n", "[CLS]  METEOR METEOR [SEP]\n", "[CLS] (Metric for Evaluation of Translation with Explicit ORdering) {{cite:ea588999-8cf2-464d-9b6f-3c230acb3f04}} is another metric used to evaluate the machine translated language. [SEP]\n", "[CLS] Standard word segments are compared with the reference texts. [SEP]\n", "[CLS] In addition to this, stems of a sentence and synonyms of words are also considered for matching. [SEP]\n", "[CLS] METEOR can make better correlation at the sentence or the segment level. [SEP]\n", "[CLS]  CIDEr CIDEr (Consensus-based Image Descripton Evaluation) {{cite:4557f434-8bb6-4585-8165-6c4479048477}} is an automatic consensus metric for evaluating image descriptions. [SEP]\n", "[CLS] Most existing datasets have only five captions per image. [SEP]\n", "[CLS] Previous evaluation metrics work with these small number of sentences and are not enough to measure the consensus between generated captions and human judgement. [SEP]\n", "[CLS] However, CIDEr achieves human consensus using term frequency-inverse document frequency (TF-IDF) {{cite:095b2b40-a944-4d85-843c-208dcb44b441}}. [SEP]\n", "[CLS]  SPICE SPICE (Semantic Propositional Image Caption Evaluation) {{cite:175017c2-36f5-428f-a25b-d0f25dbb2d35}} is a new caption evaluation metric based on semantic concept. [SEP]\n", "[CLS] It is based on a graph-based semantic representation called scene-graph {{cite:967e0155-8728-4aff-9b6e-26ec6627e28d}}, {{cite:8bdeed0b-89fd-4cbb-b8a0-3500724b3fa5}}. [SEP]\n", "[CLS] This graph can extract the information of different objects, attributes and their relationships from the image descriptions. [SEP]\n", "[CLS] Existing image captioning methods compute log-likelihood scores to evaluate their generated captions. [SEP]\n", "[CLS] They use BLEU, METEOR, ROUGE, SPICE, and CIDEr as evaluation metrics. [SEP]\n", "[CLS] However, BLEU, METEOR, ROUGE are not well correlated with human assessments of quality. [SEP]\n", "[CLS] SPICE and CIDEr have better correlation but they are hard to optimize. [SEP]\n", "[CLS] Liu et al. {{cite:6a300837-3133-4883-bbb7-efe906b63044}} introduced a new captions evaluation metric that is a good choice by human raters. [SEP]\n", "[CLS] It is developed by a combination of SPICE and CIDEr, and termed as SPIDEr. [SEP]\n", "[CLS] It uses a policy gradient method to optimize the metrics. [SEP]\n", "[CLS] The quality of image captioning depends on the assessment of two main aspects: adequacy and fluency. [SEP]\n", "[CLS] An evaluation metric needs to focus on a diverse set of linguistic features to achieve these aspects. [SEP]\n", "[CLS] However, commonly used evaluation metrics consider only some specific features (e.g., lexical or semantic) of languages. [SEP]\n", "[CLS] Sharif et al. {{cite:02c26ca8-728a-4c10-b056-163b80296a87}} proposed learning-based composite metrics for evaluation of image captions. [SEP]\n", "[CLS] The composite metric incorporates a set of linguistic features to achieve the two main aspects of assessment and shows improved performances. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Comparison on benchmark datasets and common evaluation metrics While formal experimental evaluation was left out of the scope of this paper, we present a brief analysis of the experimental results and the performance of various techniques as reported. [SEP]\n", "[CLS] We cover three sets of results:   [SEP]\n", "[CLS] We find a number of methods use the first three datasets listed in Section 4.1. [SEP]\n", "[CLS] and a number of commonly used evaluation metrics to present the results. [SEP]\n", "[CLS] These results are shown in Table 3. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A few methods fall into the following groups: Attention-based and Other deep learning-based (Reinforcement learning and GAN-based methods) image captioning. [SEP]\n", "[CLS] The results of such methods are shown in Tables 4 and 5, respectively. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We also list the methods that proivide top two results scored on each evaluation metric on the MSCOCO dataset. [SEP]\n", "[CLS] These results are shown in Table 6.   [SEP]\n", "[CLS] As shown in Table 3, on Flickr8k, Mao et al. achieved 0.565, 0.386, 0.256, and 0.170 on BLEU-1, BLEU-2, BLEU-3, and BLEU-4 , respectively. [SEP]\n", "[CLS] For Flickr30k dataset, the scores are 0.600, 0.410, 0.280, and 0.190, respectively which are higher than the Flickr8k scores. [SEP]\n", "[CLS] The highest scores were achieved on the MSCOCO dataset. [SEP]\n", "[CLS] The higher results on a larger dataset follows the fact that a large dataset has more data, comprehensive representation of various scenes, complexities, and their own natural context. [SEP]\n", "[CLS] The results of Jia et al. are similar for Flickr8k and Flickr30k datasets but higher on MSCOCO dataset. [SEP]\n", "[CLS] The method uses visual space for mapping image-features and text features. [SEP]\n", "[CLS] Mao et al. use multimodal space for the mapping of image-features and text features. [SEP]\n", "[CLS] On the other hand, Jia et al. use visual space for the mapping. [SEP]\n", "[CLS] Moreover, the method uses an Encoder-Decoder architecture where it can guide the decoder part dynamically. [SEP]\n", "[CLS] Consequently, this method performs better than Mao et al. [SEP]\n", "[CLS] Xu et al. also perform better on MSCOCO dataset. [SEP]\n", "[CLS] This method outperformed both Mao et al. and Jia et al. [SEP]\n", "[CLS] The main reason behind this is that it uses an attention mechanism which focuses only on relevant objects of the image. [SEP]\n", "[CLS] The semantic concept-based methods can generate semantically rich captions. [SEP]\n", "[CLS] Wu et al. proposed a semantic concept-based image captioning method. [SEP]\n", "[CLS] This method first predicts the attributes of different objects from the image and then adds these attributes with the captions which are semantically meaningful. [SEP]\n", "[CLS] In terms of performance, the method is superior to all the methods mentioned in Table 3. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] Table 4 shows the results of attention-based based methods on MSCOCO dataset. [SEP]\n", "[CLS] Xu et al.'s stochastic hard attention produced better results than deterministic soft attention. [SEP]\n", "[CLS] However, these results were outperformed by Jin et al. which can update its attention based on the scene-specific context. [SEP]\n", "[CLS] Wu et al. 2016 and Pedersoli et al. 2017 [SEP]\n", "[CLS] only show BLEU-4 and METEOR scores which are higher than the aforementioned methods. [SEP]\n", "[CLS] The method of Wu et al. uses an attention mechanism with a review process. [SEP]\n", "[CLS] The review process checks the focused attention in every time step and updates it if necessary. [SEP]\n", "[CLS] This mechanism helps to achieve better results than the prior attention-based methods. [SEP]\n", "[CLS] Pedersoli et al. propose a different attention mechanism that maps the focused image regions directly with the caption words instead of LSTM state. [SEP]\n", "[CLS] This behavior of the method drives it to achieve top performances among the mentioned attention-based methods in Table 4. [SEP]\n", "[CLS] Reinforcement learning-based (RL) and GAN-based methods are becoming increasingly popular. [SEP]\n", "[CLS] We name them as \u201cOther Deep Learning-based Image Captioning\". [SEP]\n", "[CLS] The results of the methods of this group are shown in Table 5. [SEP]\n", "[CLS] The methods do not have results on commonly used evaluation metrics. [SEP]\n", "[CLS] However, they have their own potentials to generate the descriptions for the image. [SEP]\n", "[CLS] Shetty et al. employed adversarial training in their image captioning method. [SEP]\n", "[CLS] This method is capable to generate diverse captions. [SEP]\n", "[CLS] The captions are less-biased with the ground-truth captions compared to the methods use maximum likelihood estimation. [SEP]\n", "[CLS] To take the advantages of RL, Ren et al. proposed a method that can predict all possible next words for the current word in current time step. [SEP]\n", "[CLS] This mechanism helps them to generate contextually more accurate captions. [SEP]\n", "[CLS] Actor-critic of RL are similar to the Generator and the Discriminator of GAN. [SEP]\n", "[CLS] However, at the beginning of the training, both actor and critic do not have any knowledge about data. [SEP]\n", "[CLS] Zhang et al. proposed an actor-critic-based image captioning method. [SEP]\n", "[CLS] This method is capable of predicting the ultimate captions at its early stage and can generate more accurate captions than other reinforcement learning-based methods. [SEP]\n", "[CLS] TABLE  alim[L]*A dash (-) in the tables of this paper indicates results are unavailable [SEP]\n", "[CLS]  TABLE  TABLE   [SEP]\n", "[CLS] We found that the performance of a technique can vary across different metrics. [SEP]\n", "[CLS] Table 6 shows the methods based on the top two scores on every individual evaluation metric. [SEP]\n", "[CLS] For example, Lu et al., Gan et al., and Zhang et al. are within the top two methods based on the scores achieved on BLEU-n and METEOR metrics. [SEP]\n", "[CLS] BLEU-n metrics use variable length phrases of generated captions to match against ground-truth captions. [SEP]\n", "[CLS] METEOR {{cite:ea588999-8cf2-464d-9b6f-3c230acb3f04}} considers the precision, recall, and the alignments of the matched tokens. [SEP]\n", "[CLS] Therefore, the generated captions by these methods have good precision and recall accuracy as well as the good similarity in word level. [SEP]\n", "[CLS] ROUGE-L evaluates the adequacy and fluency of generated captions, whereas CIDEr focuses on grammaticality and saliency. [SEP]\n", "[CLS] SPICE can analyse the semantics of the generated captions. [SEP]\n", "[CLS] Zhang et al., Rennie et al., and Lu et al. can generate captions, which have adequacy, fluency, saliency, and are grammaticality correct than other methods in Table 6. [SEP]\n", "[CLS] Gu et al. and Yao et al. perform well in generating semantically correct captions. [SEP]\n", "[CLS]  Discussions and Future Research Directions [SEP]\n", "[CLS] Many deep learning-based methods have been proposed for generating automatic image captions in the recent years. [SEP]\n", "[CLS] Supervised learning, reinforcement learning, and GAN based methods are commonly used in generating image captions. [SEP]\n", "[CLS] Both visual space and multimodal space can be used in supervised learning-based methods. [SEP]\n", "[CLS] The main difference between visual space and multimodal space occurs in mapping. [SEP]\n", "[CLS] Visual space-based methods perform explicit mapping from images to descriptions. [SEP]\n", "[CLS] In contrast, multimodal space-based methods incorporate implicit vision and language models. [SEP]\n", "[CLS] Supervised learning-based methods are further categorized into Encoder-Decoder architecture-based, Compositional architecture-based, Attention-based, Semantic concept-based, Stylized captions, Dense image captioning, and Novel object-based image captioning. [SEP]\n", "[CLS] Encoder-Decoder architecture-based methods use a simple CNN and a text generator for generating image captions. [SEP]\n", "[CLS] Attention-based image captioning methods focus on different salient parts of the image and achieve better performance than encoder-decoder architecture-based methods. [SEP]\n", "[CLS] Semantic concept-based image captioning methods selectively focus on different parts of the image and can generate semantically rich captions. [SEP]\n", "[CLS] Dense image captioning methods can generate region based image captions. [SEP]\n", "[CLS] Stylized image captions express various emotions such as romance, pride, and shame. [SEP]\n", "[CLS] GAN and RL based image captioning methods can generate diverse and multiple captions. [SEP]\n", "[CLS] MSCOCO, Flickr30k and Flickr8k dataset are common and popular datasets used for image captioning. [SEP]\n", "[CLS] MSCOCO dataset is very large dataset and all the images in these datasets have multiple captions. [SEP]\n", "[CLS] Visual Genome dataset is mainly used for region based image captioning. [SEP]\n", "[CLS] Different evaluation metrics are used for measuring the performances of image captions. [SEP]\n", "[CLS] BLEU metric is good for small sentence evaluation. [SEP]\n", "[CLS] ROUGE has different types and they can be used for evaluating different types of texts. [SEP]\n", "[CLS] METEOR can perform an evaluation on various segments of a caption. [SEP]\n", "[CLS] SPICE is better in understanding semantic details of captions compared to other evaluation metrics. [SEP]\n", "[CLS] Although success has been achieved in recent years, there is still a large scope for improvement. [SEP]\n", "[CLS] Generation based methods can generate novel captions for every image. [SEP]\n", "[CLS] However, these methods fail to detect prominent objects and attributes and their relationships to some extent in generating accurate and multiple captions. [SEP]\n", "[CLS] In addition to this, the accuracy of the generated captions largely depends on syntactically correct and diverse captions which in turn rely on powerful and sophisticated language generation model. [SEP]\n", "[CLS] Existing methods show their performances on the datasets where images are collected from the same domain. [SEP]\n", "[CLS] Therefore, working on open domain dataset will be an interesting avenue for research in this area. [SEP]\n", "[CLS] Image-based factual descriptions are not enough to generate high-quality captions. [SEP]\n", "[CLS] External knowledge can be added in order to generate attractive image captions. [SEP]\n", "[CLS] Supervised learning needs a large amount of labelled data for training. [SEP]\n", "[CLS] Therefore, unsupervised learning and reinforcement learning will be more popular in future in image captioning. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusions [SEP]\n", "[CLS] In this paper, we have reviewed deep learning-based image captioning methods. [SEP]\n", "[CLS] We have given a taxonomy of image captioning techniques, shown generic block diagram of the major groups and highlighted their pros and cons. [SEP]\n", "[CLS] We discussed different evaluation metrics and datasets with their strengths and weaknesses. [SEP]\n", "[CLS] A brief summary of experimental results is also given. [SEP]\n", "[CLS] We briefly outlined potential research directions in this area. [SEP]\n", "[CLS] Although deep learning-based image captioning methods have achieved a remarkable progress in recent years, a robust image captioning method that is able to generate high quality captions for nearly all images is yet to be achieved. [SEP]\n", "[CLS] With the advent of novel deep learning network architectures, automatic image captioning will remain an active research area for some time. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Acknowledgements This work was partially supported by an Australian Research Council grant DE120102960. [SEP]\n"], "0907.3942": ["[CLS]    A Fast Algorithm for Computing Geodesic Distances in Tree Space Megan\u00a0Owen, J.\u00a0Scott\u00a0Provan M. Owen is with the Department of Mathematics at North Carolina State University, Raleigh, NC, 27695. [SEP]\n", "[CLS] E [SEP]\n", "[CLS] -mail: maowen@ncsu.edu. [SEP]\n", "[CLS] J.S.\u00a0Provan is with the Department of Statistics and Operations Research at the University of North Carolina, Chapel Hill, NC, 27599. [SEP]\n", "[CLS] E-mail: provan@email.unc.edu.2020/09/07 02:36:14 [SEP]\n", "[CLS] Comparing and computing distances between phylogenetic trees are important biological problems, especially for models where edge lengths play an important role. [SEP]\n", "[CLS] The geodesic distance measure between two phylogenetic trees with edge lengths is the length of the shortest path between them in the continuous tree space introduced by Billera, Holmes, and Vogtmann. [SEP]\n", "[CLS] This tree space provides a powerful tool for studying and comparing phylogenetic trees, both in exhibiting a natural distance measure and in providing a Euclidean-like structure for solving optimization problems on trees. [SEP]\n", "[CLS] An important open problem is to find a polynomial time algorithm for finding geodesics in tree space. [SEP]\n", "[CLS] This paper gives such an algorithm, which starts with a simple initial path and moves through a series of successively shorter paths until the geodesic is attained. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Introduction A phylogenetic tree describes the evolutionary history of a set of organisms, with the leaf vertices representing the organisms and the interior vertices representing points at which the evolutionary history branches. [SEP]\n", "[CLS] Researchers use different criteria and methods for constructing phylogenetic trees from available data about the set of organisms, which can result in several possible trees or a distribution of trees describing the phylogenetic history. [SEP]\n", "[CLS] For example, reconstructing the most likely tree for different genes may yield different trees {{cite:83a35d83-52fd-4dbd-9af9-087fa45e9d33}}; different reconstruction methods can also produce different trees on the same set of organisms {{cite:c271ff49-884c-4589-bd84-200b4ffd4135}}. [SEP]\n", "[CLS] Thus a way is needed to quantitatively compare different phylogenetic trees, by computing some metric describing the differences between them. [SEP]\n", "[CLS] Many such distance measures have been proposed, including the Robinson-Foulds or partition distance {{cite:8d7ccd88-0287-4480-9a9d-cd85715516a0}}, the Nearest Neighbor Interchange (NNI) distance {{cite:bbd16991-9866-45eb-b1ea-6c14b33267b4}}, the Subtree-Prune-and-Regraft (SPR) distance {{cite:e362931a-ab5b-4aed-813a-1e6900b5a84a}}, and the Tree Bisection and Reconnection (TBR) distance {{cite:55759cb8-c101-4ec1-997d-28233e86e6fd}}. [SEP]\n", "[CLS] These measures tend to emphasize the differences in topologies between the trees, and often do not account for edge lengths. [SEP]\n", "[CLS] If the edge lengths represent such information as number of mutations between speciation events, we lose important information by ignoring them. [SEP]\n", "[CLS] Worst yet, most of these measures cannot be computed efficiently and so are of little use when applied to large trees. [SEP]\n", "[CLS] To address this issue, Billera et al. {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}} propose the concept of a continuous tree space, and its associated geodesic distance metric, as a natural way to embed and compare phylogenetic trees. [SEP]\n", "[CLS] This tree space consists of a set of Euclidean regions, called orthants, one for each tree topology. [SEP]\n", "[CLS] Orthants are joined together whenever one tree topology can be made into another by exchanging edges between the trees. [SEP]\n", "[CLS] Within an orthant, the coordinates of each point represent the edge lengths for a particular tree with the topology associated with that orthant. [SEP]\n", "[CLS] The geodesic between two trees is the unique shortest path connecting the two associated points in this space. [SEP]\n", "[CLS] Thus traversing the geodesic corresponds to continuously transforming one tree into the other. [SEP]\n", "[CLS] In contrast to previous measures, geodesic distance incorporates in a natural way edge lengths as well as the tree topology. [SEP]\n", "[CLS] Furthermore, the uniqueness of the geodesic between any pair of trees and the continuity of the tree space suggest this framework has useful properties with respect to optimization over trees and to formulating statistical measures associated with trees ({{cite:2b27a920-9251-4e0c-931c-f823e5330c1b}} and {{cite:47018409-1ba9-4142-a4b6-22d278d00ac8}}). [SEP]\n", "[CLS] Other versions of tree space with different metrics or no metric have been investigated in phylogenetics contexts ({{cite:174fb333-9d8c-4cc8-b74c-258b99262b8f}}, {{cite:ccddacc2-3d28-4615-ad47-9f7b7d0f8cd5}}, and {{cite:0455a3f8-5198-48f7-9509-1ed84f81e280}} for example) and in combinatorial ones ({{cite:0583228e-ed76-4e39-8c80-37bfd43b0b47}} and {{cite:aed25f71-f055-477b-acfa-fcdbe9170daa}}). [SEP]\n", "[CLS] Two algorithms have been previously proposed for computing the geodesic distance: GeoMeTree {{cite:09f824cb-b833-464c-830d-5a0ddf7f9b47}} and GeodeMaps {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}}. [SEP]\n", "[CLS] Both these algorithms search through an exponential number of candidate paths to find the geodesic, so their run time is exponential in the size of the trees. [SEP]\n", "[CLS] Currently there are no known polynomial-time algorithms to find tree space geodesics, although a polynomial time FORMULA -approximation of the geodesic distance was given by Amenta et al. {{cite:73c6b6b9-cf67-4a84-a9ac-b014557db05a}}. [SEP]\n", "[CLS] Some combinatorial and geometric properties of the space of phylogenetic trees were also presented in {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}}. [SEP]\n", "[CLS] This paper presents the first polynomial-time method for computing geodesic distances \u2014 and the associated geodesics \u2014 between trees in tree space. [SEP]\n", "[CLS] The algorithm uses a different approach from the previous papers, by starting with a simple path between the trees and transforming it into successively shorter paths until the geodesic is obtained. [SEP]\n", "[CLS] At each step, the algorithm identifies one new orthant that intersects the geodesic, and transforms the current path so that it passes through this new orthant in an optimal manner. [SEP]\n", "[CLS] By restricting consideration to the orthants intersecting the geodesic, the algorithm makes only a polynomial number of path transformations. [SEP]\n", "[CLS] Each new orthant is identified by finding a weighted vertex cover in a specially constructed bipartite graph, which also is a polynomial time problem. [SEP]\n", "[CLS] Section\u00a0 describes the tree space in which we define the geodesic distance, along with some important geometric and combinatorial properties relevant to finding the geodesic. [SEP]\n", "[CLS] Section\u00a0 gives the geodesic path algorithm between trees with disjoint edge sets, and establishes its correctness and complexity. [SEP]\n", "[CLS] Section\u00a0 explains how to efficiently use the geodesic path algorithm when the trees have common edges. [SEP]\n", "[CLS] The final section outlines some interesting problems that extend the scope of this algorithm and the associated structures. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Tree Space and Geodesic Distance [SEP]\n", "[CLS] This section describes the continuous space of phylogenetic trees and the concept of geodesic distance. [SEP]\n", "[CLS] For further details, see {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}}. [SEP]\n", "[CLS] A phylogenetic FORMULA -tree, or just FORMULA -tree, is a tree FORMULA , where FORMULA  is a labeled set of vertices, called leaves, of degree 1, and FORMULA  is the set of interior (nonleaf) edges, such that each interior vertex of FORMULA  has degree at least 3. [SEP]\n", "[CLS] The leaf 0 is sometimes identified as the root of FORMULA , although we do not distinguish it here. [SEP]\n", "[CLS] Each interior edge FORMULA  is given an associated non-negative length FORMULA , or FORMULA  if we want to emphasize the tree FORMULA  to which FORMULA  belongs. [SEP]\n", "[CLS] For now we do not attach lengths to the leaf edges of FORMULA , although the relevant properties of tree space apply as well when leaf edge lengths are present. [SEP]\n", "[CLS] At the end of Section  we extend our results to trees with leaf edge lengths. [SEP]\n", "[CLS] For our purposes it is most convenient to represent the topology of a tree FORMULA  by its set FORMULA  of splits of the interior edges, where the split FORMULA  associated with edge FORMULA  represents the partition of FORMULA  induced by removing the edge FORMULA  from FORMULA . [SEP]\n", "[CLS] In order that these splits actually correspond to a tree, they must be compatible, that is, for every two edges FORMULA  and FORMULA , one of the sets FORMULA , FORMULA , FORMULA , or FORMULA  is empty. [SEP]\n", "[CLS] A set of FORMULA  compatible splits uniquely determines the topology of an FORMULA -tree {{cite:0f53335c-9a75-4c57-bf21-224d8a585c21}}. [SEP]\n", "[CLS] Because of this correspondence, we henceforth identify edges in two trees if they correspond to the same split. [SEP]\n", "[CLS] Two example 5-trees are given in Figure\u00a0REF . [SEP]\n", "[CLS] One can verify that the six given edges are distinct, but that, for example, the edge FORMULA  in FORMULA  and the edge FORMULA  in tree FORMULA  have compatible splits. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Tree Space [SEP]\n", "[CLS] The geometric study of the continuous space of phylogenetic trees FORMULA , or just tree space, was pioneered by Billera et al. in {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}}. [SEP]\n", "[CLS] Fix leaf set FORMULA  of cardinality FORMULA , where the element labeled 0 is either another leaf or the root. [SEP]\n", "[CLS] In FORMULA  each FORMULA -tree topology is associated with a unique FORMULA -dimensional [SEP]\n", "[CLS] Euclidean orthant (the non-negative part of FORMULA ), where FORMULA  is the cardinality of the set of edges in that tree topology. [SEP]\n", "[CLS] We denote the smallest orthant containing tree FORMULA  by FORMULA , where FORMULA  is identified in FORMULA  by the vector of lengths of its set FORMULA  of positive-length edges. [SEP]\n", "[CLS] The interiors of the orthants are disjoint, and represent trees with the same topology but varying (positive) edge lengths. [SEP]\n", "[CLS] Thus the maximum-dimension orthants have dimension FORMULA , which is the maximum number of interior edges of an FORMULA -tree. [SEP]\n", "[CLS] Orthants of lower dimension correspond to trees with fewer than FORMULA  edges, and effectively identify the points on the boundary of the higher-dimensional orthants. [SEP]\n", "[CLS] In particular, we can consider a tree FORMULA  with FORMULA  positive-length edges to be on the boundary of any orthant of higher dimension for which some subset of edges in its corresponding tree topology can be contracted \u2014 equivalently, the length of the edges can be set to zero \u2014 to produce the tree FORMULA . [SEP]\n", "[CLS] Note that as a consequence of this property, each edge in FORMULA  also appears in the tree topology of every orthant containing FORMULA . [SEP]\n", "[CLS] For example, in Figure\u00a0REF (a), trees FORMULA  and FORMULA  are represented by distinct points in the same orthant, because they have the same topology but different edge lengths. [SEP]\n", "[CLS] Tree FORMULA  is represented in a different orthant; FORMULA  and FORMULA  have the same edge FORMULA , and so their orthants will be incident. [SEP]\n", "[CLS] In particular, the tree FORMULA , with single interior edge FORMULA , can be obtained from FORMULA  (FORMULA  resp.) by setting edges FORMULA  (FORMULA  resp.) to 0 \u2014 and thus is a point on the FORMULA  axis common to FORMULA  and FORMULA . [SEP]\n", "[CLS] In general, FORMULA  can be embedded in FORMULA , where FORMULA  is the number of possible splits on FORMULA  leaves. [SEP]\n", "[CLS] However, as no point in FORMULA  has a negative coordinate in FORMULA , we often let the positive and negative parts of an axis correspond to different splits. [SEP]\n", "[CLS] This can give a more compact representation of the orthants of interest in tree space. [SEP]\n", "[CLS] For example, Figure\u00a0REF (b) illustrates one way the 2-dimensional orthants of five tree topologies in 4 can be embedded into FORMULA , by letting FORMULA -FORMULA  and FORMULA -FORMULA  be represented by the the same coordinates. [SEP]\n", "[CLS] FIGURE   Geodesic Distance [SEP]\n", "[CLS] The tree space FORMULA  has two important properties:  FORMULA  is path-connected, so we can find a parameterized set FORMULA  of trees FORMULA  connecting any two FORMULA -trees. [SEP]\n", "[CLS] The simplest such path is the cone path {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}}, which consists of the straight line from the first tree to the origin and the straight line from the origin to the second tree. [SEP]\n", "[CLS] We can equivalently think of it as the path formed by contracting all of the edges of each tree at the appropriate constant rates. [SEP]\n", "[CLS] For any path FORMULA , denote its length to be FORMULA . [SEP]\n", "[CLS] For our purposes FORMULA  will always be made up of a sequence of connected line segments, each within its own orthant, and so we can write FORMULA  as the sum of the Euclidean lengths of these segments. [SEP]\n", "[CLS] This provides a natural metric on FORMULA  by defining the distance FORMULA  between trees FORMULA  and FORMULA  in FORMULA  to be the length of a shortest path in FORMULA  between FORMULA  and FORMULA . [SEP]\n", "[CLS]  {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}} FORMULA  is CAT(0), or non-positively curved. [SEP]\n", "[CLS] This means, roughly speaking, that triangles in FORMULA  are \u201cskinnier\u201d than the corresponding triangles in Euclidean space. [SEP]\n", "[CLS] In particular, let FORMULA , FORMULA , FORMULA  be any three points in FORMULA  and let FORMULA  be any point on a shortest path from FORMULA  to FORMULA . [SEP]\n", "[CLS] Then if we construct a triangle FORMULA  in Euclidean space with edge lengths FORMULA , FORMULA  and FORMULA , and let FORMULA  be the point on FORMULA  with FORMULA , then FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] As FORMULA  is CAT(0), there is a unique shortest path FORMULA  between any two trees FORMULA  and FORMULA  in FORMULA . [SEP]\n", "[CLS] The path FORMULA  is called the geodesic, and the geodesic distance between FORMULA  and FORMULA  is defined as FORMULA . [SEP]\n", "[CLS] Figure\u00a0REF (a) gives the geodesic (represented by dotted lines) between two trees in adjacent orthants. [SEP]\n", "[CLS] This is clearly the straight line between them. [SEP]\n", "[CLS] Figure\u00a0REF (b) gives three geodesics between trees with no edges in common. [SEP]\n", "[CLS] In this case the geodesic is either a cone path (as in the (FORMULA ,FORMULA )- and (FORMULA ,FORMULA )-geodesic), or it goes through an intermediate orthant (as in the (FORMULA ,FORMULA )-geodesic). [SEP]\n", "[CLS] Thus the edge lengths, as well as the tree topology, determine the intermediate orthants traversed by the geodesic. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] When the trees have more leaves, the situation becomes more complicated. [SEP]\n", "[CLS] For example, the geodesic between the two trees given in Figure\u00a0REF  is illustrated in Figure\u00a0REF  by a progression of intermediate trees sampled at equidistant points along that geodesic. [SEP]\n", "[CLS] This geodesic crosses an orthant boundary at FORMULA  and FORMULA , with the intermediate leg corresponding to a tree topology containing only two interior edges. [SEP]\n", "[CLS] Two different representations of the sequence of orthants containing the geodesic are given in Figure\u00a0REF : Figure\u00a0REF (a) represents the three relevant orthants embedded in FORMULA , while Figure\u00a0REF (b) rotates the three orthants so that the geodesic is represented by a straight line. [SEP]\n", "[CLS] Figure\u00a0REF (c) gives the tree associated with each leg of the geodesic. [SEP]\n", "[CLS] (Points in the figure are labeled with respect to the coordinate system of the orthant containing them.) FIGURE   [SEP]\n", "[CLS] The definition of geodesic given here differs slightly from the classical definition in a way that is useful to elucidate. [SEP]\n", "[CLS] Call a path FORMULA  a local geodesic if there exists some FORMULA  so that every subpath of FORMULA  of length FORMULA  is the shortest path between its endpoints. [SEP]\n", "[CLS] The following result shows that in CAT(0) space this local condition is sufficient to determine the geodesic. [SEP]\n", "[CLS] This is also proved in more generality in {{cite:fd878ac7-22f4-4f7f-9300-534489a3e362}}. [SEP]\n", "[CLS] Lemma 2.1   [SEP]\n", "[CLS] In a CAT(0) space, every local geodesic is a geodesic. [SEP]\n", "[CLS]  Let FORMULA  be a local geodesic from point FORMULA  to point FORMULA  with associated gauge FORMULA . [SEP]\n", "[CLS] Denote by FORMULA   [SEP]\n", "[CLS] the portion of FORMULA  between points FORMULA  and FORMULA  on FORMULA . [SEP]\n", "[CLS] Choose disjoint points FORMULA  on FORMULA  such that FORMULA , FORMULA . [SEP]\n", "[CLS] Then by definition FORMULA  is a geodesic for FORMULA . [SEP]\n", "[CLS] Now assume by induction that the portion FORMULA  is a geodesic for FORMULA . [SEP]\n", "[CLS] Then FORMULA  by induction, and FORMULA  by the choice of the FORMULA 's. [SEP]\n", "[CLS] Construct the triangle FORMULA  in Euclidean space as specified by the definition of a CAT(0) space, and let FORMULA  be the point on FORMULA  with FORMULA . [SEP]\n", "[CLS] Then FORMULA . [SEP]\n", "[CLS] But by induction we also have that FORMULA  is a geodesic, and so FORMULA    [SEP]\n", "[CLS] This plus the triangle inequality gives FORMULA . [SEP]\n", "[CLS] But the only way this could happen is if FORMULA  is on FORMULA , which in turn implies that FORMULA  must also be on FORMULA . [SEP]\n", "[CLS] Thus FORMULA , and so FORMULA  is also a geodesic. [SEP]\n", "[CLS] This establishes the inductive step, and the lemma follows. [SEP]\n", "[CLS] It is this result which motivated the idea of this paper. [SEP]\n", "[CLS] Namely, we can find a geodesic between trees FORMULA  and FORMULA  by starting with any FORMULA -path in FORMULA , determining whether it is a local geodesic, and if not, transforming it into a shorter FORMULA -path. [SEP]\n", "[CLS] We define the Geodesic Treepath Problem (GTP), to be the problem of finding the geodesic between two trees in FORMULA . [SEP]\n", "[CLS] The remainder of the paper constructs a polynomial-time algorithm for solving GTP. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The Path Space of a Geodesic Billera et al. {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}} showed that the geodesic between FORMULA  and FORMULA  is contained in a sequence of orthants, called a path space, satisfying certain properties. [SEP]\n", "[CLS] These properties were further clarified in {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}}. [SEP]\n", "[CLS] We summarize, from {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}}, the relevant properties of the shortest path, or geodesic, through a particular path space. [SEP]\n", "[CLS] For all path spaces between FORMULA  and FORMULA , the shortest of these path space geodesics will be the geodesic between FORMULA  and FORMULA . [SEP]\n", "[CLS] We start with some preliminary assumptions and definitions. [SEP]\n", "[CLS] For now we assume that FORMULA  and FORMULA  are disjoint, that is, have no common edges. [SEP]\n", "[CLS] (We will show at the end of Section  how to handle common edges between FORMULA  and FORMULA .) We say that edge sets FORMULA  and FORMULA  are compatible if every pair of the splits associated with FORMULA  in FORMULA  and FORMULA  in FORMULA  are compatible, or equivalently, if FORMULA  determines a unique FORMULA -tree. [SEP]\n", "[CLS] Let FORMULA  and FORMULA  be disjoint FORMULA -trees, and let FORMULA  and FORMULA  be partitions of FORMULA  and FORMULA , respectively, such that the pair FORMULA  satisfies the following property: (P1) For each FORMULA , FORMULA  and FORMULA  are compatible. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Then for all FORMULA , FORMULA  is a compatible set, and hence FORMULA  is an orthant in tree space. [SEP]\n", "[CLS] Furthermore, the union FORMULA  of these orthants forms a connected space. [SEP]\n", "[CLS] We call FORMULA  a path space, the pair FORMULA  its support, and the shortest FORMULA -path through FORMULA  the path space geodesic for FORMULA . [SEP]\n", "[CLS] Billera et al. proved the following result {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}} (using the notation FORMULA  and FORMULA  for all FORMULA ). [SEP]\n", "[CLS] Theorem 2.2   [SEP]\n", "[CLS] For disjoint FORMULA -trees FORMULA  and FORMULA , the geodesic between FORMULA  and FORMULA  is a path space geodesic for some path space between FORMULA  and FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] In {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}}, the requirements for path spaces to contain a geodesic are made more explicit, and the construction of the actual path space geodesic is given. [SEP]\n", "[CLS] We summarize the results of this research (Proposition 4.1, Proposition 4.2, Corollary 4.3, Theorem 4.4, and Theorem 4.10 of {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}}) below. [SEP]\n", "[CLS] For set FORMULA  of edges, we use the notation FORMULA  to denote the norm of the vector whose components are the lengths of the edges in FORMULA . [SEP]\n", "[CLS] Theorem 2.3  Let FORMULA  and FORMULA  be two FORMULA -trees, and let FORMULA  be the geodesic in FORMULA  between FORMULA  and FORMULA . [SEP]\n", "[CLS] Then FORMULA  can be represented as a path space geodesic with support FORMULA  of FORMULA  and FORMULA  of FORMULA  which satisfy FORMULA  plus the following additional property: (P2) FORMULA . [SEP]\n", "[CLS]    [SEP]\n", "[CLS] We call a path space satisfying conditions (P1) and (P2) a proper path space, and the associated path space geodesic a proper path. [SEP]\n", "[CLS] The following theorem summarizes results from {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}}. [SEP]\n", "[CLS] Theorem 2.4   [SEP]\n", "[CLS] Let FORMULA  be a proper path between FORMULA  and FORMULA  with support FORMULA . [SEP]\n", "[CLS] Then FORMULA  can be represented in FORMULA  with legs FORMULA  where the points on each leg FORMULA  are associated with tree FORMULA  having edge set FORMULA  edge lengths FORMULA  and splits FORMULA   [SEP]\n", "[CLS] Furthermore, the length of FORMULA  is FORMULA   Remark: It is easy to see that if any two adjacent support pairs in a proper path space have their ratios in (P2) equal, then combining them again results in a proper path space. [SEP]\n", "[CLS] That is, if FORMULA  is as in Theorem\u00a0REF , and if FORMULA  for some FORMULA , then FORMULA , where FORMULA  and FORMULA , is also the support of a proper path space. [SEP]\n", "[CLS] Further, from the description given in Theorem\u00a0REF , the associated proper path FORMULA  does not pass through the interior of the deleted orthant, and hence will also be a proper path for the new path space. [SEP]\n", "[CLS] It follows that we can produce a path space for FORMULA  for which all of the inequalities in (P2) are strict. [SEP]\n", "[CLS] It is shown in {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}} that this in fact is a unique representation for FORMULA . [SEP]\n", "[CLS] In this paper, however, we find it more convenient to allow relaxed inequalities in defining proper paths. [SEP]\n", "[CLS] Example 1: The cone path between trees FORMULA  and FORMULA  is the path space geodesic for the path space consisting of the two orthants containing the original trees, that is, FORMULA  and FORMULA . [SEP]\n", "[CLS] This trivially satisfies (P1) and (P2), and the associated proper path is simply the union of the two straight lines connecting FORMULA  and FORMULA  to the origin. [SEP]\n", "[CLS] Example 2: For the geodesic given in Figure\u00a0REF , the associated path space shown in Figure\u00a0REF  consists of the starting orthant, the target orthant, and a single intermediate orthant of dimension two on edges FORMULA . [SEP]\n", "[CLS] Thus the support for this path space will be FORMULA  and FORMULA , which is proper since FORMULA   [SEP]\n", "[CLS] The coordinates (edge lengths) of the path space geodesic as it passes through the intermediate orthant can be ascertained from the representation in Figure\u00a0REF (b). [SEP]\n", "[CLS] Here the orthants have been positioned so that the geodesic through them is a straight line. [SEP]\n", "[CLS] This can be done using the isometric map presented in {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}} from the shaded regions shown in Figure\u00a0REF (a) to FORMULA , and maps the geodesic to the straight line FORMULA  to FORMULA . [SEP]\n", "[CLS] The length of this line, which is also the length of the path, is FORMULA   [SEP]\n", "[CLS] Theorem\u00a0REF  does not completely characterize the geodesic, in that a path can be proper without being the geodesic. [SEP]\n", "[CLS] Consider the two trees FORMULA  and FORMULA  given in Figure\u00a0REF (b). [SEP]\n", "[CLS] The cone path between FORMULA  and FORMULA  is proper, but this path space does not contain the geodesic. [SEP]\n", "[CLS] It is necessary to add the orthant FORMULA  to this cone path space to get the proper path space containing the geodesic. [SEP]\n", "[CLS] To check whether we can add such an intermediate orthant to the current candidate path space and shorten the proper path length, we need to check whether we can partition some support pair FORMULA  into two support pairs, such that the addition of the new orthant again results in a proper path space. [SEP]\n", "[CLS] That is, we drop some subset of the edges in FORMULA  and add a subset of the edges in FORMULA  to enter the new orthant, and then drop and add the remaining edges to reach the original succeeding orthant. [SEP]\n", "[CLS] However, even if such an intermediate orthant exists, adding it to the path space may not result in a shorter proper path. [SEP]\n", "[CLS] For example, for the trees FORMULA  and FORMULA  in Figure\u00a0REF (b), we could add orthant FORMULA  to the cone path space and obtain a proper path space, but the proper path for this space will be the same length (actually the same path) as it is for the original path space. [SEP]\n", "[CLS] What we need are additional conditions for determining whether adding a specified intermediate orthant will result in a shorter proper path. [SEP]\n", "[CLS] As the next result shows, these conditions in fact characterize a proper path as a geodesic. [SEP]\n", "[CLS] Theorem 2.5    [SEP]\n", "[CLS] A proper FORMULA -path FORMULA  with support FORMULA  satisfying (P1) and (P2) is a geodesic if and only if FORMULA  satisfies the following additional property:    For each support pair FORMULA , there is no nontrivial partition FORMULA  of FORMULA  and partition FORMULA  of FORMULA , such that FORMULA  is compatible  with FORMULA  and FORMULA . [SEP]\n", "[CLS]     [SEP]\n", "[CLS] First assume that (P3) does not hold. [SEP]\n", "[CLS] Then there exists some support pair FORMULA , together with partition FORMULA  of FORMULA  and partition FORMULA  of FORMULA , such that FORMULA  is compatible with FORMULA  and FORMULA . [SEP]\n", "[CLS] Let FORMULA  be the point where FORMULA  passes through the intersection between FORMULA  and FORMULA . [SEP]\n", "[CLS] Suppose the sequence ratios look like FORMULA  with the FORMULA  and FORMULA  indices absent if FORMULA  or FORMULA . [SEP]\n", "[CLS] Then the legs of FORMULA  going through FORMULA  and FORMULA  have point FORMULA  in common and have positive length. [SEP]\n", "[CLS] Let FORMULA  be points before and after FORMULA  on FORMULA  in FORMULA  and FORMULA , respectively, and let FORMULA  be the portion of FORMULA  between FORMULA  and FORMULA , which by choice of FORMULA  and FORMULA  consists of two straight lines connected at FORMULA . [SEP]\n", "[CLS] We will construct a path FORMULA  from FORMULA  to FORMULA  that is shorter than FORMULA , and so FORMULA  cannot be a geodesic. [SEP]\n", "[CLS] The trees corresponding to FORMULA  and FORMULA  have edges FORMULA  in common, so by the remarks at the beginning of the subsection, these edges change their length uniformly between FORMULA  and FORMULA . [SEP]\n", "[CLS] Thus we can restrict attention to the trees FORMULA  comprised of FORMULA  with their common edges contracted. [SEP]\n", "[CLS] The FORMULA  and FORMULA  have the edges FORMULA  and FORMULA , respectively, and by Theorem\u00a0REF  the edges in FORMULA  contract uniformly in FORMULA  from FORMULA  to FORMULA , and the edges in FORMULA  expand uniformly in FORMULA  from FORMULA  to FORMULA . [SEP]\n", "[CLS] Thus there is a positive real number FORMULA  such that the length of any edge FORMULA  at FORMULA  is FORMULA , and a positive real number FORMULA  such that the length of any edge FORMULA  at FORMULA  is FORMULA . [SEP]\n", "[CLS] Let FORMULA , FORMULA , FORMULA , and FORMULA . [SEP]\n", "[CLS] Then by the properties of the sets involved, FORMULA . [SEP]\n", "[CLS] Let FORMULA  be the edge sets FORMULA  scaled by FORMULA  or FORMULA  to represent the edges at the points FORMULA  or FORMULA . [SEP]\n", "[CLS] Since FORMULA  is compatible with FORMULA , and FORMULA  implies that FORMULA , then FORMULA  is a proper path space between FORMULA  and FORMULA . [SEP]\n", "[CLS] Thus Theorem\u00a0REF  holds here as well. [SEP]\n", "[CLS] Let FORMULA  be the proper path between FORMULA  and FORMULA  in FORMULA . [SEP]\n", "[CLS] Then by Theorem REF , FORMULA  passes through the relative interior of the orthants in FORMULA , but not through FORMULA . [SEP]\n", "[CLS] Using Equation (REF ), we get that FORMULA   [SEP]\n", "[CLS] Now FORMULA  together with the triangle inequality implies that FORMULA , and so FORMULA  is not the geodesic between FORMULA  and FORMULA . [SEP]\n", "[CLS] Conversely, assume that FORMULA  is not a geodesic. [SEP]\n", "[CLS] By Lemma\u00a0REF , this is the case if and only if it is not locally shortest in tree space. [SEP]\n", "[CLS] If so, then this must also happen at some bend in FORMULA  \u2014 i.e. intersection of orthants \u2014 such that we could cut through some additional orthants to shorten its length. [SEP]\n", "[CLS] So suppose FORMULA  is such a point, with FORMULA  bending at the intersection between FORMULA  and FORMULA . [SEP]\n", "[CLS] We first consider the simple case where FORMULA , with the right or left inequality absent if FORMULA  or FORMULA . [SEP]\n", "[CLS] Let FORMULA  be points before and after FORMULA  on FORMULA  in FORMULA  and FORMULA , respectively. [SEP]\n", "[CLS] Then the section of FORMULA  between FORMULA  and FORMULA  is not the geodesic from FORMULA  to FORMULA . [SEP]\n", "[CLS] Let FORMULA  be the proper path space containing the geodesic from FORMULA  to FORMULA , with support FORMULA , where FORMULA  and FORMULA . [SEP]\n", "[CLS] By our remark, we can assume that FORMULA  satisfies (P2) with strict inequalities, and note that FORMULA  must be greater than 1. [SEP]\n", "[CLS] Let FORMULA , FORMULA , FORMULA , and FORMULA , and set the length of each edge in FORMULA , FORMULA , FORMULA  and FORMULA  to the length that that edge has in FORMULA  or FORMULA . [SEP]\n", "[CLS] Then FORMULA  partitions FORMULA  and FORMULA  partitions FORMULA , and further, FORMULA  and FORMULA  are compatible since FORMULA  satisfies (P1). [SEP]\n", "[CLS] It remains to show that FORMULA . [SEP]\n", "[CLS] By the same argument as above, we have positive constants FORMULA  and FORMULA  such that for any edge FORMULA , its length at FORMULA  is FORMULA , and for any edge FORMULA , its length at FORMULA  is FORMULA . [SEP]\n", "[CLS] Since FORMULA  was chosen to satisfy (P2) with strict inequalities, we have FORMULA , and thus FORMULA  as desired. [SEP]\n", "[CLS] Next we consider the case where FORMULA , again with the right or left inequality absent if FORMULA  or FORMULA . [SEP]\n", "[CLS] By combining the FORMULA  and FORMULA  as per the remark above, we can apply the simple case, so that there exist partitions FORMULA  of FORMULA  and FORMULA  of FORMULA , such that FORMULA  is compatible with FORMULA  and FORMULA . [SEP]\n", "[CLS] Let FORMULA  be the common value of FORMULA , FORMULA , and let FORMULA  and FORMULA  for FORMULA , FORMULA . [SEP]\n", "[CLS] Note that FORMULA  is compatible with FORMULA , and thus if (P3) holds, it must be that for all FORMULA , FORMULA , and hence FORMULA   [SEP]\n", "[CLS] But FORMULA   [SEP]\n", "[CLS] Thus we have FORMULA  for all FORMULA , so that FORMULA   [SEP]\n", "[CLS] But this contradicts the property of FORMULA , FORMULA , FORMULA  and FORMULA , and thus we have found a partition of an individual pair FORMULA  also violating (P3), as desired. [SEP]\n", "[CLS] Example 2 (continued): For the example path given in Figures\u00a0REF  and REF , if we consider the cone path, then (P3) is violated by sets FORMULA  and FORMULA , since the inequality in Equation (REF ) is strict. [SEP]\n", "[CLS] With the added orthant the resulting proper path becomes the geodesic, since there are no nontrivial partitions of either support pair, and hence (P3) holds. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] A Polynomial Algorithm to Solve the Geodesic Treepath Problem Theorem\u00a0REF  characterizes when a given proper path FORMULA  with support FORMULA  is a geodesic by specifying when a local improvement can be made for the path. [SEP]\n", "[CLS] This suggests the following iterative improvement scheme for finding a geodesic between trees FORMULA  and FORMULA :   [SEP]\n", "[CLS] Begin with some proper FORMULA -path FORMULA  with support FORMULA .   [SEP]\n", "[CLS] At each stage we have proper path FORMULA  having support FORMULA  satisfying condition (P1) and (P2). [SEP]\n", "[CLS] Check to see if FORMULA  also satisfies the condition (P3), and if not, create a new proper path FORMULA  with support FORMULA  and having smaller length than FORMULA . [SEP]\n", "[CLS]  Continue until the geodesic is found. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We now proceed to implement this procedure. [SEP]\n", "[CLS] For our starting proper path, choose FORMULA  to be the cone path {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}}, having support FORMULA  and FORMULA . [SEP]\n", "[CLS] This support vacuously satisfies condition (P1) and (P2), and the path simply corresponds to contracting FORMULA  and FORMULA  uniformly to the origin. [SEP]\n", "[CLS] To perform the iterative step, we recast it as a problem on bipartite graphs. [SEP]\n", "[CLS] To do this, define the incompatibility graph FORMULA  between sets FORMULA  and FORMULA  to be the bipartite graph whose vertex set corresponds to FORMULA , and whose edges correspond to those pairs FORMULA  and FORMULA  such that the corresponding splits FORMULA  and FORMULA  are incompatible. [SEP]\n", "[CLS] An independent set in FORMULA  is any set of vertices having no edges of FORMULA  between them. [SEP]\n", "[CLS] The following lemma follows directly from the definition of compatibility between sets: Lemma 3.1   [SEP]\n", "[CLS] Two edge sets FORMULA  and FORMULA  are compatible if and only if they form an independent set in FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We can use Lemma\u00a0REF  to restate the problem of determining whether a support FORMULA  satisfies (P3) as follows: Extension Problem   [SEP]\n", "[CLS] Given: Sets FORMULA  and  FORMULA Question: Does there exist a partition FORMULA  of FORMULA  and a partition FORMULA  of FORMULA , such that  FORMULA FORMULA  corresponds to an independent set in FORMULA ,  FORMULA FORMULA  ? [SEP]\n", "[CLS]   Lemma 3.2 [SEP]\n", "[CLS] A proper path FORMULA  with support FORMULA  is a geodesic if and only if the Extension Problem has no solution for any support pair FORMULA  of FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The proof follows immediately from Theorem\u00a0REF  and the previous discussion. [SEP]\n", "[CLS] We next proceed to solve the Extension Problem. [SEP]\n", "[CLS] Since scaling will not affect FORMULA , we first scale the edge lengths in FORMULA  and FORMULA   [SEP]\n", "[CLS] so that FORMULA . [SEP]\n", "[CLS] By squaring FORMULA , we get the equivalent condition FORMULA  or FORMULA   [SEP]\n", "[CLS] Thus the Extension Problem reduces to that of finding an independent set in FORMULA  having sufficiently large total weight, where the vertices are weighted by the normalized squares of the edge lengths of FORMULA  and FORMULA . [SEP]\n", "[CLS] Now note that the pair FORMULA  and FORMULA  form an independent set in FORMULA  if and only if their complements FORMULA  and FORMULA  form a vertex cover for FORMULA , that is, every edge of FORMULA  is incident to a vertex of either FORMULA  or FORMULA . [SEP]\n", "[CLS] Thus the Extension problem has a solution if and only if the min weight vertex cover for FORMULA  has weight FORMULA . [SEP]\n", "[CLS] (Note that a solution to the extension problem will necessarily result in a nontrivial cover, and hence nontrivial partitions FORMULA  and FORMULA .) Lemma 3.3   [SEP]\n", "[CLS] The Extension Problem can be solved in FORMULA  time. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The Min Weight Vertex Cover Problem can be solved on bipartite graphs by a simple extension of the max flow formulation of the Min Cardinality Vertex Cover Problem (see e.g. {{cite:10938afe-1e02-4978-abd1-eb6c6a431366}}, Section 12.3), using the vertex weights as capacities on the source and sink arcs. [SEP]\n", "[CLS] Maximum flows can be found in FORMULA  time (see e.g. {{cite:10938afe-1e02-4978-abd1-eb6c6a431366}}, Section 7.7). [SEP]\n", "[CLS] The solution to the Extension Problem also suggests what the new proper path FORMULA  should look like. [SEP]\n", "[CLS] Namely, if the Extension Problem for support sets FORMULA  and FORMULA  results in a min weight cover by vertex sets FORMULA  and FORMULA  with complements FORMULA  and FORMULA , respectively, then we replace FORMULA  and FORMULA  in FORMULA  and FORMULA  by the ordered pairs FORMULA  and FORMULA . [SEP]\n", "[CLS] We summarize this in a formal algorithm. [SEP]\n", "[CLS] The GTP Algorithm Input: FORMULA -trees FORMULA  and  FORMULA Output: The path space geodesic between FORMULA  and  FORMULA Algorithm:  Initialize: Form the incompatibility graph FORMULA  between FORMULA  and FORMULA , and set FORMULA  to be the cone path between FORMULA  and FORMULA  with support FORMULA  and FORMULA . [SEP]\n", "[CLS] Iterative step: At stage FORMULA , we have proper path FORMULA  with support FORMULA  satisfying conditions (P1) and (P2). [SEP]\n", "[CLS] for each support pair FORMULA  in FORMULA , solve the Extension Problem on FORMULA . [SEP]\n", "[CLS] Specifically, find a min weight vertex cover for the graph FORMULA  using vertex weights FORMULA  if every min weight cover found above has weight FORMULA , then FORMULA  satisfies (P3), and hence is the geodesic between FORMULA  and FORMULA . else choose any min weight vertex cover FORMULA , FORMULA  and FORMULA  with complements FORMULA  and FORMULA , respectively, having weight FORMULA . [SEP]\n", "[CLS] Replace FORMULA  and FORMULA  in FORMULA  and FORMULA  by the ordered pairs FORMULA  and FORMULA , respectively, to form new support FORMULA  with associated proper path FORMULA . [SEP]\n", "[CLS]     [SEP]\n", "[CLS] To establish the correctness of the GTP Algorithm, we need to verify that the resulting path FORMULA  is indeed proper, i.e. that (P2) holds. [SEP]\n", "[CLS] Lemma 3.4   [SEP]\n", "[CLS] At each stage of the GTP Algorithm, the associated path space satisfies property (P2). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The cone path is trivially proper, so now assume by induction that (P2) holds after stage FORMULA  of the algorithm. [SEP]\n", "[CLS] Let FORMULA  be the support for FORMULA , comprised of the FORMULA  support pairs FORMULA . [SEP]\n", "[CLS] Since the FORMULA 's are dropped and the FORMULA 's are added in the order given by their index, we can represent this with visually with a left-to-right ordering of the FORMULA 's and FORMULA 's, as in Figure\u00a0REF . [SEP]\n", "[CLS] Furthermore, since each support pair FORMULA  must be entirely contained in some support pair FORMULA  at every stage FORMULA  of the algorithm, the added support pairs maintain the existing left-to-right order. [SEP]\n", "[CLS] Thus we can depict several partitions with different degrees of refinement in the same diagram for instructional purposes (see Figure\u00a0REF ). [SEP]\n", "[CLS] Since (P1) holds at each stage, then there can be no edges of the incompatibility graph between an element of FORMULA  and an element of any group FORMULA  to the \u201cleft\u201d of FORMULA . [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Now suppose that at stage FORMULA  some support pair FORMULA  returns a nontrivial solution to the Extension Problem, comprised of partitions FORMULA  of FORMULA  and FORMULA  of FORMULA , with FORMULA  compatible with FORMULA  and FORMULA . [SEP]\n", "[CLS] Dropping the superscript FORMULA , we first show that if FORMULA  then FORMULA . [SEP]\n", "[CLS] Let FORMULA  be the stage at which sets FORMULA  and FORMULA  (and hence also sets FORMULA  and FORMULA ) are separated in the partition. [SEP]\n", "[CLS] That is, in stage FORMULA  sets FORMULA  and FORMULA  are in the same partition FORMULA , and sets FORMULA  and FORMULA  are in the same partition FORMULA . [SEP]\n", "[CLS] Then in stage FORMULA  the minimum weight vertex cover FORMULA  is found associated with the Extension Problem on FORMULA , creating partitions FORMULA  of FORMULA  and FORMULA  of FORMULA , with FORMULA , FORMULA , FORMULA , and FORMULA . [SEP]\n", "[CLS] Consider the vertical lines FORMULA  and FORMULA  in Figure\u00a0REF . [SEP]\n", "[CLS] From the discussion above, there can be no incompatibility-graph edges from the right of FORMULA  in FORMULA  to the left of FORMULA  in FORMULA , and hence FORMULA  is a vertex cover for FORMULA . [SEP]\n", "[CLS] Likewise there can be no incompatibility-graph edges from the right of FORMULA  in FORMULA  to the left of FORMULA  in FORMULA , and hence FORMULA  is also a vertex cover for FORMULA . [SEP]\n", "[CLS] But because FORMULA  is a minimum weight vertex cover, then it must have weight no greater than either of these covers. [SEP]\n", "[CLS] Hence FORMULA  and FORMULA   [SEP]\n", "[CLS] By cancelling terms and cross-multiplying we get FORMULA  and the inequality follows. [SEP]\n", "[CLS] The argument that if FORMULA  then FORMULA  is symmetric. [SEP]\n", "[CLS] As the other ratios remained unchanged, we have (P2) satisfied after stage FORMULA  as well, and the lemma follows. [SEP]\n", "[CLS] Example 3: Lemma\u00a0REF  does not necessarily hold outside the context of the GTP algorithm. [SEP]\n", "[CLS] In particular, the algorithm may not work correctly if an arbitrary proper path is chosen as the starting path. [SEP]\n", "[CLS] Consider tree FORMULA  in Figure\u00a0REF  and the tree FORMULA  given by the three splits FORMULA , FORMULA , and FORMULA  which have lengths 4, 10, and 2, respectively. [SEP]\n", "[CLS] Then FORMULA  and FORMULA  is the support of a proper path between FORMULA  and FORMULA , since FORMULA    [SEP]\n", "[CLS] Now (P3) fails for support pair FORMULA , since FORMULA  is compatible with FORMULA  and FORMULA . [SEP]\n", "[CLS] The refinement FORMULA  and FORMULA  indicated by the GTP Algorithm, however, is not the support of a proper path, because FORMULA . [SEP]\n", "[CLS] Instead, the support of our new, shorter proper path is FORMULA  and FORMULA , which is not even a refinement of FORMULA . [SEP]\n", "[CLS] Note that when we start with the cone path for FORMULA , however, we obtain the optimal path after a single iteration of the algorithm. [SEP]\n", "[CLS] Theorem 3.5 [SEP]\n", "[CLS] The GTP Algorithm correctly solves GTP in FORMULA  time. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Lemma\u00a0REF  implies that each successful solution to the Extension Problem results in a proper path whose support has one more support pair, so that after at most FORMULA  iterations the algorithm will be unable to find any further nontrivial solutions to the Extension Problem. [SEP]\n", "[CLS] It follows that (P3) is satisfied, and so by Theorem\u00a0REF  the resulting path is the geodesic. [SEP]\n", "[CLS] Further, we need only solve the Extension Problem on newly created support pairs, since an extension for one support pair will not change the status of any other support pairs. [SEP]\n", "[CLS] Thus at most FORMULA  vertex cover problems are be solved throughout the entire algorithm. [SEP]\n", "[CLS] The complexity of the algorithm then follows from Lemma\u00a0REF . [SEP]\n", "[CLS] Note that in each iteration the new path FORMULA  satisfies FORMULA . [SEP]\n", "[CLS] This is straightforward to show, although it does not have a direct bearing on the correctness of the algorithm, since the termination of the algorithm is determined only by FORMULA  satisfying property (P3). [SEP]\n", "[CLS] It does show, however, that the algorithm is a bona fide iterative improvement algorithm. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The GTP algorithm with common edges and leaf edge-lengths present [SEP]\n", "[CLS] We finish the analysis by showing how to handle common edges, including the leaf edges, between the terminal trees. [SEP]\n", "[CLS] This expanded algorithm allows us to include lengths on leaf edges. [SEP]\n", "[CLS] It also allows leaves \u2014 including the root \u2014 to have degree greater than one, since setting the length of the associated leaf edge to 0 contracts the leaf into a vertex with higher degree. [SEP]\n", "[CLS] To handle common edges, we first note from {{cite:c3409047-5342-4c7e-bf08-aaa83900ed8b}} that if FORMULA  and FORMULA  share common edges, then these common edges will be present in every tree on the geodesic, with their lengths changing uniformly between those of their starting and ending trees. [SEP]\n", "[CLS] This suggest the following procedure for dealing with common edges:  Identify the set FORMULA  of all common nonleaf edges in both trees. [SEP]\n", "[CLS] Also let FORMULA  be the set of leaf edges. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Bisect each edge FORMULA  by adding midpoint FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Separate FORMULA  and FORMULA  at each of the vertices FORMULA  for FORMULA . [SEP]\n", "[CLS] By definition this will leave a collection of pairs of disjoint subtrees FORMULA  of FORMULA  and FORMULA , indexed by FORMULA  and with each pair having identical sets of leaves. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] For each pair of trees in this collection, apply the GTP Algorithm. [SEP]\n", "[CLS] Let FORMULA  and FORMULA , FORMULA , be the support for the associated paths. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The composite path can be described as in Theorem\u00a0REF , with the following modifications:  For each FORMULA , the lengths of the edges in the tree FORMULA  associated with the pair FORMULA  will be as given in Theorem\u00a0REF . [SEP]\n", "[CLS] The FORMULA  is common across all pairs. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Each edge FORMULA  reconnects the FORMULA 's by reattaching them at FORMULA , with the splits defined accordingly. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The length of each common edge FORMULA  on the path is FORMULA    [SEP]\n", "[CLS] The length of FORMULA  is    FORMULA   where FORMULA  and FORMULA  are the vectors of the lengths of the common edges in the appropriate tree. [SEP]\n", "[CLS]    [SEP]\n", "[CLS] Since the partitioning of the tree can be done in linear time, this will not increase the complexity of the algorithm. [SEP]\n", "[CLS] An implementation of this algorithm is available at http://www.stat-or.unc.edu/webspace/miscellaneous/provan/treespace. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusion This paper presents the first polynomial time algorithm for finding geodesics between phylogenetic trees in tree space, as well as further characterizing properties of geodesics. [SEP]\n", "[CLS] This significantly increases the usefulness of the geodesic distance as a modeling tool, since the previous exponential algorithms essentially restricted the geodesic distance measure to trees with fewer than 50 leaves. [SEP]\n", "[CLS] We first note that the technique presented here also solves GTP in the case where there is a specific right-left ordering on the non-root leaves of the tree, or equivalently, where the tree must be planar with respect to a given clockwise ordering of the leaves. [SEP]\n", "[CLS] An example of such trees are binary search trees. [SEP]\n", "[CLS] This condition simply adds to the definition of a tree that the splits of the tree must be noncrossing, that is, for any split FORMULA   [SEP]\n", "[CLS] there are no pairs FORMULA  and FORMULA  which appear in clockwise order FORMULA . [SEP]\n", "[CLS] Since if FORMULA  and FORMULA  both satisfy the noncrossing property property, and all of the splits in the intermediate trees on the geodesic between FORMULA  and FORMULA  are made up of the splits of FORMULA  and FORMULA , then these trees must also satisfy the noncrossing property, and so the geodesic for this case is the same as that for the unrestricted case. [SEP]\n", "[CLS] The properties and techniques given here potentially apply to the much wider range of problems and measures on trees that make use of the intrinsic Euclidean nature of tree space. [SEP]\n", "[CLS] For example, Nye {{cite:36260815-853b-4cb7-abfa-bac19907eb07}} compares and groups trees through the idea of \u201cmedial trees\u201d which serve as representatives for topological types within data sets of trees. [SEP]\n", "[CLS] Hillis et al. {{cite:174fb333-9d8c-4cc8-b74c-258b99262b8f}} also investigate tree sets using distance as the distinguishing feature to find statistical groupings and common features. [SEP]\n", "[CLS] Using a more Euclidean-related measure for dissimilarity could allow more powerful statistical techniques to be employed in these situations. [SEP]\n", "[CLS] Billera et al. {{cite:6283bb09-3430-42d3-89a9-dab1d861f268}} look at the concept of medial trees in their paper by defining the centroid of a set of points in tree space. [SEP]\n", "[CLS] Their definition involves an iterative process that is based on finding a converging sequence of midpoints of geodesics between trees. [SEP]\n", "[CLS] The implementation of this would require a fast method of computing geodesics. [SEP]\n", "[CLS] Another way of thinking about a centroid in standard Euclidean space, though, is as the point of minimum sum squared distance to the trees. [SEP]\n", "[CLS] The framework for finding geodesics here naturally lends itself to finding centroids in this alternate sense as well, and could yield a more direct and efficient way of computing centroids. [SEP]\n", "[CLS] A further extension of the idea of centroid comes up in the development of object oriented data analysis (OODA) as it has been applied to trees {{cite:60be900c-2699-4947-ac80-54480ebd3016}}. [SEP]\n", "[CLS] This involves fitting a \u201cline\u201d to a set of trees in such a way as to minimize least-squares distances. [SEP]\n", "[CLS] The set of nearest points on this line can then be analyzed to yield statistical discriminators that can in turn isolate significant properties of the underlying objects. [SEP]\n", "[CLS] This can be done a second time, as a result gaining \u201csecond-order\u201d information about the set of trees, and so on. [SEP]\n", "[CLS] Two problems with OODA have been (a) the difficulty in determining the right concept of \u201cline\u201d and \u201cleast-square distances\u201d when the objects are not Euclidean in nature, and (b) the computational challenge in actually finding these \u201cleast-fit\u201d objects. [SEP]\n", "[CLS] The path space concept presents a compelling model for facilitating both these kinds of analyses, with the CAT(0) property providing the framework for efficient iterative improvement methods to extract useful statistical information in this context. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Acknowledgment This material was based upon work partially supported by the National Science Foundation under Grant DMS-0635449 to the Statistical and Applied Mathematical Sciences Institute. [SEP]\n", "[CLS] Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. [SEP]\n"], "1307.2965": ["[CLS]  Semantic Context Forests for Learning-Based Knee Cartilage Segmentation in 3D MR Images Learning-Based Knee Cartilage Segmentation Quan WangFORMULA   [SEP]\n", "[CLS] Dijia WuFORMULA   [SEP]\n", "[CLS] Le LuFORMULA   [SEP]\n", "[CLS] Meizhu Liu FORMULA Kim L. BoyerFORMULA   [SEP]\n", "[CLS] Shaohua Kevin ZhouFORMULA  Q. Wang D. Wu [SEP]\n", "[CLS] L. Lu M. Liu K. L. Boyer S. K. Zhou FORMULA Siemens Corporate Research, Princeton, NJ 08540, USA FORMULA Rensselaer Polytechnic Institute, Troy, NY 12180, USA Learning-Based Knee Cartilage Segmentation Quan Wang, et al. The automatic segmentation of human knee cartilage from 3D MR images is a useful yet challenging task due to the thin sheet structure of the cartilage with diffuse boundaries and inhomogeneous intensities. [SEP]\n", "[CLS] In this paper, we present an iterative multi-class learning method to segment the femoral, tibial and patellar cartilage simultaneously, which effectively exploits the spatial contextual constraints between bone and cartilage, and also between different cartilages. [SEP]\n", "[CLS] First, based on the fact that the cartilage grows in only certain area of the corresponding bone surface, we extract the distance features of not only to the surface of the bone, but more informatively, to the densely registered anatomical landmarks on the bone surface. [SEP]\n", "[CLS] Second, we introduce a set of iterative discriminative classifiers that at each iteration, probability comparison features are constructed from the class confidence maps derived by previously learned classifiers. [SEP]\n", "[CLS] These features automatically embed the semantic context information between different cartilages of interest. [SEP]\n", "[CLS] Validated on a total of 176 volumes from the Osteoarthritis Initiative (OAI) dataset, the proposed approach demonstrates high robustness and accuracy of segmentation in comparison with existing state-of-the-art MR cartilage segmentation methods.   [SEP]\n", "[CLS] Introduction   [SEP]\n", "[CLS] The quantitative analysis of knee cartilage is advantageous for the study of cartilage morphology and physiology. [SEP]\n", "[CLS] In particular, it is an important prerequisite for the clinical assessment and surgical planning of the cartilage diseases, such as knee osteoarthritis which is characterized as the cartilage deterioration and a prevalent cause of disability among elderly population. [SEP]\n", "[CLS] As the leading imaging modality used for articular cartilage quantification {{cite:e88f7616-a421-4044-8330-6ef8249623a3}}, magnetic resonance (MR) imaging provides direct and noninvasive visualization of the whole knee joint including the soft cartilage tissues (Fig. REF ). [SEP]\n", "[CLS] However, automatic segmentation of the cartilage tissues from MR images, which is required for accurate and reproducible quantitative cartilage measures, still remains an open problem because of the inhomogeneity, small size, low tissue contrast, and shape irregularity of the cartilage. [SEP]\n", "[CLS] An earlier endeavor on this problem is Folkesson et al.'s voxel classification approach {{cite:f462207d-348a-4f5b-acb2-75d6e785bdb7}}, which runs an approximate FORMULA NN classifier on voxel intensity and absolute position based features. [SEP]\n", "[CLS] However, due to the overlap of intensity distribution between cartilage and other tissues such as menisci and muscles, as well as the variability of the cartilage locations from scan to scan, the performance of this method is limited. [SEP]\n", "[CLS] More recently, Vincent et al. have developed a knee joint segmentation approach based on active appearance model (AAM), which captures the statistics of both object shape and image cues. [SEP]\n", "[CLS] Though promising results are reported in {{cite:1f693ff6-9fc8-434d-8af1-61d32eacd085}}, the search for the initial model pose parameter can be very time consuming even if a coarse to fine searching strategy is used. [SEP]\n", "[CLS] Given the strong spatial relation between the cartilages and bones in the knee joint, most proposed cartilage segmentation methods are based on a framework that each bone is segmented first in the knee joint {{cite:e4961cb0-17cd-4f12-80cd-cfd22d934925}}, {{cite:b907ee07-bf9f-44e2-901c-e393de0fc7ab}}, {{cite:44b9f5d5-6ad4-4010-ac74-d17804f8a0fa}}, which is usually easier than direct cartilage segmentation because the bones are much larger in size with more regular shapes. [SEP]\n", "[CLS] Fripp et al. segment the bones based on 3D active shape model (ASM) incorporating the cartilage thickness statistics, and the outer cartilage boundary is then determined by examining the intensity profile along the normal to the bone surface, while being constrained by the cartilage thickness model {{cite:e4961cb0-17cd-4f12-80cd-cfd22d934925}}. [SEP]\n", "[CLS] In Yin's work {{cite:b907ee07-bf9f-44e2-901c-e393de0fc7ab}}, the volume of interest containing the bones and cartilages is first detected using a learning-based approach, then the bones and cartilages are jointly segmented by solving an optimal multi-surface detection problem via multi-column graph cuts {{cite:83344ecf-07bf-4152-a7e9-a5b2ed4dffd6}}. [SEP]\n", "[CLS] Lee et al. employ a constrained branch-and-mincut method with shape priors to obtain the bone surface, and then segment the cartilage with MRF optimization based on local shape and appearance information {{cite:44b9f5d5-6ad4-4010-ac74-d17804f8a0fa}}. [SEP]\n", "[CLS] In spite of the differences, these approaches all require classification of bone surface voxels into bone cartilage interface (BCI) and non-BCI, which is an important intermediate step to determine the search space or impose prior constraint for cartilage segmentation. [SEP]\n", "[CLS] Therefore, any classification error of BCI will probably propagate to the final cartilage segmentation result. [SEP]\n", "[CLS] In this paper, we present a fully automatic learning-based voxel classification method for cartilage segmentation. [SEP]\n", "[CLS] It also requires pre-segmentation of corresponding bones in the knee joint. [SEP]\n", "[CLS] However, the new approach does not rely on explicit classification of BCI. [SEP]\n", "[CLS] Instead, we construct distance features from each voxel to a large number of anatomical landmarks on the surface of the bones to capture the spatial relation between the cartilages and bones. [SEP]\n", "[CLS] By removing the intermediate step of BCI extraction, the whole framework is simplified and classification error propagation can be avoided. [SEP]\n", "[CLS] Besides the connection between the cartilages and bones, strong spatial relation also exists among different cartilages which is more often overlooked in earlier approaches. [SEP]\n", "[CLS] For example, the femoral cartilage is always above the tibial cartilage and two cartilages touch each other in the region where two bones slide over each other during joint movements. [SEP]\n", "[CLS] To utilize this constraint, we introduce the iterative discriminative classification that at each iteration, the multi-class probability maps obtained by previous classifiers are used to extract semantic context features. [SEP]\n", "[CLS] In particular, we compare the probabilities at positions with random shift and compute the difference. [SEP]\n", "[CLS] These features, which we name as the random shift probability difference (RSPD) features, are more computationally efficient and more flexible for different range of context compared to the calculation of probability statistics at fixed relative positions {{cite:d7e4dcf4-2147-4e52-8230-0453d7dfad25}}, {{cite:907c2fe4-9c5a-4dd0-8b2f-0228d01399bd}}. [SEP]\n", "[CLS]   Review of Bone Segmentation    [SEP]\n", "[CLS] In this work, we employ a learning-based bone segmentation approach which has shown the efficiency and effectiveness in different medical image segmentation problems {{cite:004302cf-455c-4e22-bcd4-b83e8285ad7a}}, {{cite:0d642c4b-abb7-4636-a24b-7abc62733388}}. [SEP]\n", "[CLS] We represent the shape of a bone by a closed triangle mesh FORMULA . [SEP]\n", "[CLS] Given a number of training volumes with manual bone annotations, we use the coherent point drift algorithm (CPD) {{cite:9803d261-51bd-4395-a2b0-cf3e68a5a465}} to find anatomical correspondences of the mesh points and thereof construct the statistical shape models with mean shape FORMULA  {{cite:8f4aaad3-c040-4c3d-997d-b14d54bbb5bd}}. [SEP]\n", "[CLS] As shown in Fig. REF , the whole bone segmentation framework comprises three steps. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Pose Estimation: For a volume FORMULA , the bone is first localized by searching for the (sub-)optimal pose parameters FORMULA , i.e., the translation, rotation and anisotropic scaling, using the marginal space learning (MSL) {{cite:0d642c4b-abb7-4636-a24b-7abc62733388}}:  FORMULA  and the shape is initialized by linearly transforming the mean shape FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Model Deformation: At this stage, the shape is repeatedly deformed to fit the boundary and projected to the variation subspace until convergence.   [SEP]\n", "[CLS] Boundary Refinement: To further improve the segmentation accuracy, we use the random walks algorithm {{cite:55f69e2b-9b39-44ed-97b3-8326c671deaf}} to refine the bone boundary (see Table REF  and Fig. REF  for results) and employ the CPD algorithm to obtain anatomically equivalent landmarks on the refined bone surface. [SEP]\n", "[CLS]    Cartilage Classification    [SEP]\n", "[CLS] Given all three knee bones being segmented, we first extract a band of interest within a maximum distance threshold from each of the bone surface, and only classify voxels in the band of interest to simplify the training and testing by removing irrelevant negative voxels. [SEP]\n", "[CLS] Feature Extraction For each voxel with spatial coordinate FORMULA , we construct a number of base features which can be categorized into three subsets. [SEP]\n", "[CLS] Intensity Features include the voxel intensity and its gradient magnitude, respectively: FORMULA , FORMULA . [SEP]\n", "[CLS] Distance Features measure the signed Euclidean distances from each voxel to different knee bone boundaries: FORMULA , FORMULA , FORMULA , where FORMULA  is the signed distance to the femur, FORMULA  to tibia, and FORMULA  to patella. [SEP]\n", "[CLS] Then we have their linear combinations:  FORMULA   [SEP]\n", "[CLS] These features are useful because the sum features FORMULA  and FORMULA  measure whether voxel FORMULA  locates within the narrow space between two bones, and the difference features FORMULA  and FORMULA  measure which bone it is closer to. [SEP]\n", "[CLS] Fig. [SEP]\n", "[CLS] REF  shows how FORMULA  and FORMULA  in addition to intensity feature FORMULA  separate tibial cartilage from femoral and patellar cartilages. [SEP]\n", "[CLS] Given the prior knowledge that the cartilage can only grow in certain area on the bone surface, it is useful for the cartilage segmentation to not only know how close the voxel is to the bone surface, but also where it is anatomically. [SEP]\n", "[CLS] Therefore we define the distance features to the densely registered landmarks on the bone surface as described in Section : FORMULA , where FORMULA  is the spatial coordinate of the FORMULA th landmark of all bone mesh points. [SEP]\n", "[CLS] FORMULA  is randomly generated in training due to the great number of mesh points available (Fig. REF ). [SEP]\n", "[CLS]  TABLE  FIGURE   FIGURE   FIGURE   [SEP]\n", "[CLS] Context Features compare the intensity of the current voxel FORMULA  and another voxel FORMULA  with random offset FORMULA : FORMULA , where FORMULA  is a random offset vector. [SEP]\n", "[CLS] This subset of features, named as random shift intensity difference (RSID) features in this paper, capture the context information in different ranges by randomly generating a large number of different values of FORMULA  from a uniform distribution in training. [SEP]\n", "[CLS] They were earlier used to solve pose classification {{cite:3da14ff6-2f17-4e79-ac37-01279df0e3ad}} and keypoint recognition {{cite:a52b98f5-f270-408d-ad8f-ea1b585a04a0}} problems. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Iterative Semantic Context Forests In this paper, we present a multi-pass iterative classification method to automatically exploit the semantic context for multiple object segmentation problems. [SEP]\n", "[CLS] In each pass, the generated probability maps will be used to extract the context embedded features to enhance the classification performance of the next pass. [SEP]\n", "[CLS] Fig. REF  shows a 2-pass iterative classification framework with the random forests {{cite:3da14ff6-2f17-4e79-ac37-01279df0e3ad}}, {{cite:a52b98f5-f270-408d-ad8f-ea1b585a04a0}}, {{cite:70fcaa52-1e0e-4e5c-99af-3ea7fc94e697}}, {{cite:edf3b8ca-cbf2-4c8b-ba78-38f9456b214a}}, {{cite:edb7c1aa-f3fc-4057-a826-4914eff90c23}}, {{cite:ecdb107c-4df6-4a21-bed9-811a9a6a911a}} selected as the base classifier for each pass. [SEP]\n", "[CLS] However, the method can be extended to more iterations with the use of other discriminative classifiers. [SEP]\n", "[CLS] Semantic Context Features After each pass of the classification, the probability maps are generated and used to extract semantic context features as defined below: FORMULA , FORMULA , FORMULA , where FORMULA , FORMULA  and FORMULA  stand for the femoral, tibia and patellar cartilage probability map, respectively. [SEP]\n", "[CLS] In the same fashion as the RSID features, we compare the probability response of two voxels with random shift:  FORMULA  which is called random shift probability difference features (RSPD). [SEP]\n", "[CLS] RSPD provides semantic context information because the probability map values are directly associated with anatomical labels, rather than original intensity volume. [SEP]\n", "[CLS] In Fig. REF , it can be observed that the probability map of the second pass classification is significantly enhanced with much less noisy responses, compared with the first pass.   [SEP]\n", "[CLS] Post-processing by Graph Cuts Optimization After the classification, we finally use the probabilities of being the background and the three cartilages to construct the energy functions and perform multi-label graph cuts {{cite:ee6554ca-9a54-4f9d-bb30-47ca8e0e4f02}} to refine the segmentation with smoothness constraints. [SEP]\n", "[CLS] The graph cuts algorithm assigns a label FORMULA  to each voxel FORMULA , such that the energy below is minimized: FORMULA  where FORMULA  is the global label configuration, FORMULA  is the neighborhood system, FORMULA  is the smoothness energy, and FORMULA  is the data energy. [SEP]\n", "[CLS] We define FORMULA  FORMULA  takes value 1 when FORMULA  and FORMULA  are different labels, and takes value 0 when FORMULA . [SEP]\n", "[CLS] FORMULA  takes the value FORMULA , FORMULA , FORMULA  or FORMULA , depending on the label FORMULA . [SEP]\n", "[CLS] FORMULA  and FORMULA  are two parameters. [SEP]\n", "[CLS] FORMULA  specifies the weight of data energy versus smoothness energy, while FORMULA  is associated with the image noise {{cite:12f59899-4726-4770-9e7d-ab1b2fc6bc65}}. [SEP]\n", "[CLS]   Experimental Results  Dataset and Experiment Settings [SEP]\n", "[CLS] The dataset we use in our work is the publicly available Osteoarthritis Initiative (OAI) dataset, which contains both 3D MR images and ground truth cartilage annotations, referred to as \u201ckMRI segmentations (iMorphics)\u201d. [SEP]\n", "[CLS] The sagittal 3D 3T (Tesla) DESS (dual echo steady state) WE (water-excitation) MR images in OAI have high-resolution, good delineation of articular cartilage, fast acquisition time and high SNR. [SEP]\n", "[CLS] Our dataset consists of 176 volumes from 88 subjects, and belongs to the Progression subcohort, where all subjects show symptoms of OA. [SEP]\n", "[CLS] Each subject has two volumes scanned in different years. [SEP]\n", "[CLS] The size of each image volume is FORMULA  voxels, and the voxel size is FORMULA . [SEP]\n", "[CLS] For the validation, we divide the OAI dataset to three equally-sized subsets: FORMULA , FORMULA  and FORMULA , and perform a three-fold validation. [SEP]\n", "[CLS] The two volumes from the same subject are always placed in the same subset. [SEP]\n", "[CLS] For each randomized decision tree, we set the depth of the tree to 18, and train 60 trees in each pass. [SEP]\n", "[CLS] During training, the number of candidates at each non-leaf node is set to 1000. [SEP]\n", "[CLS] The dice similarity coefficient (DSC) is used to measure the performance of our method since it is commonly reported in previous literature {{cite:f462207d-348a-4f5b-acb2-75d6e785bdb7}}, {{cite:e4961cb0-17cd-4f12-80cd-cfd22d934925}}, {{cite:b907ee07-bf9f-44e2-901c-e393de0fc7ab}}, {{cite:44b9f5d5-6ad4-4010-ac74-d17804f8a0fa}}, {{cite:a1a95dd7-c126-4d05-8b87-817cc48e12c4}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Results First, we compare the frequency of different features that is selected by the classifiers. [SEP]\n", "[CLS] As shown in Fig. REF , RSID, RSPD and the distance to dense landmarks are very informative features to embed spatial constraints. [SEP]\n", "[CLS] Then we compare the segmentation performance with and without the use of the distance features to the anatomical dense landmarks, and also the results with different number of classification iterations. [SEP]\n", "[CLS] The results in Fig. REF  demonstrate the effectiveness of the distance features to dense landmarks and iterative classification with semantic context forests. [SEP]\n", "[CLS] In particular, 2-pass random forests achieve significant performance improvement, whereas the gain seems quite negligible by adding more passes. [SEP]\n", "[CLS] Finally, the quantitative results (2-pass classification) are listed in Table REF  together with the numbers reported in the earlier literature. [SEP]\n", "[CLS] Because the datasets used are different by all these approaches, the numbers in the table are only for reference. [SEP]\n", "[CLS] Note that only our experiments are based on a relatively large dataset. [SEP]\n", "[CLS] As shown in the table, we achieved high performance with regard to the femoral and tibial cartilage, whereas the DSC of patellar cartilage is notably lower than the other two cartilages. [SEP]\n", "[CLS] This is partly because the size of patellar cartilage is much smaller than femoral and tibial cartilage, so that the same amount of segmentation error will result in lower DSC. [SEP]\n", "[CLS] Besides, some patellar cartilage annotations in the dataset do not appear very consistent with others. [SEP]\n", "[CLS] Example segmentation results are shown in Fig. REF . [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] FIGURE    Conclusion   We have presented a new approach to segment the three knee cartilages in 3-D MR images, which effectively exploits the semantic context information in the knee joint. [SEP]\n", "[CLS] By using the distance features to the bone surface as well as to the dense anatomical landmarks on the bone surface, the spatial constraints between cartilages and bones are incorporated without the need of explicit extraction of the bone cartilage interface. [SEP]\n", "[CLS] Furthermore, the use of multi-pass iterative classification with semantic context forests provides more spatial constraints between different cartilages to further improve the segmentation. [SEP]\n", "[CLS] The experiment validation shows the effectiveness of this method. [SEP]\n", "[CLS] Ongoing work include the joint bone-and-cartilage voxel classification in the iterative classification framework. [SEP]\n", "[CLS] TABLE    [SEP]\n"], "1611.00468": ["[CLS]  =1 CRF-CNN: Modeling Structured Information in Human Pose Estimation [SEP]\n", "[CLS] Xiao Chu The Chinese University of Hong Kongxchu@ee.cuhk.edu.hk Wanli Ouyang [SEP]\n", "[CLS] The Chinese University of Hong Kong wlouyang@ee.cuhk.edu.hk [SEP]\n", "[CLS] Hongsheng Li [SEP]\n", "[CLS] The Chinese University of Hong Kong hsli@ee.cuhk.edu.hk [SEP]\n", "[CLS] Xiaogang Wang [SEP]\n", "[CLS] The Chinese University of Hong Kong xgwang@ee.cuhk.edu.hk 2020/09/16 01:13:24Deep convolutional neural networks (CNN) have achieved great success. [SEP]\n", "[CLS] On the other hand, modeling structural information has been proved critical in many vision problems. [SEP]\n", "[CLS] It is of great interest to integrate them effectively. [SEP]\n", "[CLS] In a classical neural network, there is no message passing between neurons in the same layer. [SEP]\n", "[CLS] In this paper, we propose a CRF-CNN framework which can simultaneously model structural information in both output and hidden feature layers in a probabilistic way, and it is applied to human pose estimation. [SEP]\n", "[CLS] A message passing scheme is proposed, so that in various layers each body joint receives messages from all the others in an efficient way. [SEP]\n", "[CLS] Such message passing can be implemented with convolution between features maps in the same layer, and it is also integrated with feedforward propagation in neural networks. [SEP]\n", "[CLS] Finally, a neural network implementation of end-to-end learning CRF-CNN is provided. [SEP]\n", "[CLS] Its effectiveness is demonstrated through experiments on two benchmark datasets. [SEP]\n", "[CLS] Introduction A lot of efforts have been devoted to structure design of convolutional neural network (CNN). [SEP]\n", "[CLS] They can be divided into two groups. [SEP]\n", "[CLS] One is to achieve higher expressive power by making CNN deeper {{cite:bb4c69de-7fd3-4ef7-b8d5-4fe13d1a4e6f}}, {{cite:b64936b7-6fc4-49cb-b781-13f9494e2db8}}, {{cite:ac465a99-b478-40f1-8a8c-5f2015528102}}. [SEP]\n", "[CLS] The other is to model structures among features and outputs, either as post processing {{cite:757dcea9-6f8c-4895-ba1c-450c3f2d1631}}, {{cite:f1bb394e-c3be-4749-b5e0-168282992fbc}} or as extra information to guide the learning of CNN {{cite:bb183a11-97ce-4c77-82d9-5552ef7987d5}}, {{cite:7e3a6f20-0314-47f3-afcc-14a00eeda70b}}, {{cite:1b150b98-ce4c-44bf-97a3-8034904d873e}}. [SEP]\n", "[CLS] They are complementary. [SEP]\n", "[CLS] Human pose estimation is to estimate body joint locations from 2D images, which could be applied to assist other tasks such as {{cite:71b7254e-7448-46d2-96a9-124ee9d4efa1}}, {{cite:15566a9d-5693-429c-b58e-864e2ba77bea}}, {{cite:7402a231-5b79-43e5-93ab-a0b9978ac104}} The very first attempt adopting CNN for human pose estimation is DeepPose {{cite:62c83b7c-f2e5-42a5-b3c1-b9788087e79c}}. [SEP]\n", "[CLS] It used CNN to regress joint locations repeatedly without directly modeling the output structure. [SEP]\n", "[CLS] However, the prediction of body joint locations relies both on their own appearance scores and the prediction of other joints. [SEP]\n", "[CLS] Hence, the output space for human pose estimation is structured. [SEP]\n", "[CLS] Later, Chen and Yuille {{cite:f1bb394e-c3be-4749-b5e0-168282992fbc}} used a graphical model for the spatial relationship between body joints and used it as post processing after CNN. [SEP]\n", "[CLS] Learning CNN features and structured output together was proposed in {{cite:7e3a6f20-0314-47f3-afcc-14a00eeda70b}}, {{cite:e78354e0-07f4-4534-8ee4-b0f944e08ed1}}, {{cite:1b150b98-ce4c-44bf-97a3-8034904d873e}}. [SEP]\n", "[CLS] Researchers were also aware of the importance of introducing structures at the feature level {{cite:a3e755d7-aea8-4f57-bddb-5bc025939908}}. [SEP]\n", "[CLS] However, the design of CNN for structured output and structured features was heuristic, without principled guidance on how information should be passed. [SEP]\n", "[CLS] As deep models are shown effective for many practical applications, researchers on statistical learning and deep learning try to use probabilistic models to illustrate the ideas behind deep models {{cite:d41b8867-8ab5-4b36-8e1f-f944484e16ae}}, {{cite:bb5dfd66-e1db-46ca-aca4-d9dbe7346856}}, {{cite:bb183a11-97ce-4c77-82d9-5552ef7987d5}}. [SEP]\n", "[CLS] Motivated by these works, we provide a CRF framework that models structures in both output and hidden feature layers in CNN, called CRF-CNN. [SEP]\n", "[CLS] It provides us with a principled illustration on how to model structured information at various levels in a probabilistic way and what are the assumptions made when incorporating different CRF into CNN. [SEP]\n", "[CLS] Existing works can be illustrated as special implementations of CRF-CNN. [SEP]\n", "[CLS] DeepPose {{cite:62c83b7c-f2e5-42a5-b3c1-b9788087e79c}} only considered the feature-output relationship, and the approaches in {{cite:f1bb394e-c3be-4749-b5e0-168282992fbc}}, {{cite:7e3a6f20-0314-47f3-afcc-14a00eeda70b}} considered feature-output and output-output relationships. [SEP]\n", "[CLS] In contrast, our proposed full CRF-CNN model takes feature-output, output-output, and feature-feature relationships into consideration, which is novel in pose estimation. [SEP]\n", "[CLS] It also facilitates us in borrowing the idea behind the sum-product algorithm and developing a message passing scheme so that each body joint receives messages from all the others in an efficient way by saving intermediate messages. [SEP]\n", "[CLS] Given a set of body joints as vertices on a graph, there is no conclusion on whether a tree structured model {{cite:258e7303-126e-459e-851e-7fb3f32ad61d}}, {{cite:3ff9a685-eafd-44d8-abb6-b51a0525d51e}} or a loopy structured model {{cite:8c155c53-9c49-4e3e-9b1c-0a407283f20b}}, {{cite:6fccf82e-20f9-4693-a00b-74272396205b}} is the best choice. [SEP]\n", "[CLS] A tree structure has exact inference while a loopy structure can model more complex relationship among vertices. [SEP]\n", "[CLS] Our proposed message passing scheme is applicable to both. [SEP]\n", "[CLS] Our contributions can be summarized as follows. [SEP]\n", "[CLS] (1) A CRF is proposed to simultaneously model structured features and structured body part spatial relationship. [SEP]\n", "[CLS] We show step by step how approximations are made to use an end-to-end learning CNN for implementing such CRF model. [SEP]\n", "[CLS] (2) Motivated by the efficient algorithm for marginalization on tree structures, we provide a message passing scheme for our CRF-CNN so that every vertex receives messages from all the others in an efficient way. [SEP]\n", "[CLS] Message passing can be implemented with convolution between feature maps in the same layer. [SEP]\n", "[CLS] Because of the approximation used, this message passing can be used for both tree and loopy structures. [SEP]\n", "[CLS] (3) CRF-CNN is applied to two human pose estimation benchmark datasets and achieve better performance on both dataset compared with previous methods. [SEP]\n", "[CLS]  CRF-CNN The power of combing powerful statistical models with CNN has been proved {{cite:757dcea9-6f8c-4895-ba1c-450c3f2d1631}}, {{cite:a3e755d7-aea8-4f57-bddb-5bc025939908}}. [SEP]\n", "[CLS] In this section we start with a brief review of CRF and study how the pose estimation problem can be formulated under the proposed CRF-CNN framework. [SEP]\n", "[CLS] It includes estimating body joints independently from CNN features, modeling the spatial relationship of body joints in the output layer of CNN, and modeling the spatial relationship of features in the hidden layers of CNN. [SEP]\n", "[CLS] Let FORMULA  denote an image, and FORMULA  denote locations of FORMULA  body joints. [SEP]\n", "[CLS] We are interested in modeling the conditional probability FORMULA  parameterized by FORMULA , expressed in a Gibbs distribution: FORMULA  where FORMULA  is the energy function. [SEP]\n", "[CLS] The conditional distribution by introducing latent variables FORMULA  can be modeled as follows: FORMULA  FORMULA  is the energy function to be defined later. [SEP]\n", "[CLS] The latent variables correspond to features obtained from a neural network in our implementation. [SEP]\n", "[CLS] We define an undirected graph FORMULA , where FORMULA , FORMULA . [SEP]\n", "[CLS] FORMULA , FORMULA , and FORMULA  denote sets of edges connecting body joints, connecting latent variables, and connecting latent variables with body joints, respectively. [SEP]\n", "[CLS] Model 1 Denote FORMULA  as an empty set. [SEP]\n", "[CLS] If we suppose there is no edge connecting joints and no edge connecting latent variables in the graphical model, i.e. FORMULA , FORMULA , then FORMULA  FORMULA  where FORMULA  denotes the unary/data term for image FORMULA , FORMULA  denotes the terms for the correlations between latent variables FORMULA  and body joint configurations FORMULA . [SEP]\n", "[CLS] It corresponds to the model in Fig. REF (a) and it is a typical feedforward neural network. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Example. [SEP]\n", "[CLS] In DeepPose {{cite:62c83b7c-f2e5-42a5-b3c1-b9788087e79c}}, CNN features FORMULA  in the top hidden layer were obtained from images, and could be treated as latent variables and illustrated by term FORMULA  in (REF ). [SEP]\n", "[CLS] There is no connection between neurons in hidden layers. [SEP]\n", "[CLS] Body joint locations were estimated from CNN features in {{cite:62c83b7c-f2e5-42a5-b3c1-b9788087e79c}}, which could be illustrated by the term FORMULA . [SEP]\n", "[CLS] The body joints are independently estimated without considering their correlations, which means FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Model 2 [SEP]\n", "[CLS] If we suppose FORMULA  in the graphical model, FORMULA  becomes FORMULA   [SEP]\n", "[CLS] Compared with (REF ), joint locations are no longer independent. [SEP]\n", "[CLS] The energy function for this model is FORMULA   [SEP]\n", "[CLS] It corresponds to the model in Fig. REF (b). [SEP]\n", "[CLS] Compared with (REF ), FORMULA  in (REF ) is added to model the pairwise relationship between joints. [SEP]\n", "[CLS] Example. [SEP]\n", "[CLS] To model the spatial relationship among body joints, the approaches in Yang et al. {{cite:7e3a6f20-0314-47f3-afcc-14a00eeda70b}} built up pairwise terms and spatial models. [SEP]\n", "[CLS] They are different implementations of FORMULA  in (REF ). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Our model In our model, FORMULA  is considered as a set of discrete latent variables and each FORMULA  is represented as a 1-of-FORMULA  FORMULA  dimensional vector. [SEP]\n", "[CLS] FORMULA  and FORMULA  for this model are: FORMULA  FORMULA   [SEP]\n", "[CLS] It is the model in Fig. REF (c) and exhibits the largest expressive power compared with the models in (REF ) and (REF ). [SEP]\n", "[CLS] FORMULA  is added to model the pairwise relationship among features/latent variables in (REF ). [SEP]\n", "[CLS] Details on the set of edges FORMULA . [SEP]\n", "[CLS] Body joints have structures and it may not be suitable to use a fully connected graph. [SEP]\n", "[CLS] The tree structure in Fig. REF (b) is widely used since it fits human knowledge on the skeleton of body joints and how body parts articulate. [SEP]\n", "[CLS] A further benefit for a tree structure with FORMULA  vertices is that all vertices can receive messages from others with FORMULA  message passing operations. [SEP]\n", "[CLS] To better define the structure of latent variables FORMULA , we group the latent variables so that a joint FORMULA  corresponds to a particular group of latent variables denoted by FORMULA , and FORMULA . [SEP]\n", "[CLS] FORMULA  in (REF ) is simplified into FORMULA , i.e. FORMULA  is only connected to latent variables in FORMULA . [SEP]\n", "[CLS] We further constrain connections among feature groups: FORMULA . [SEP]\n", "[CLS] It means that feature groups are connected if and only if their corresponding body joints are connected. [SEP]\n", "[CLS] Fig. REF (d) shows an example of this model. [SEP]\n", "[CLS] Our implementation is as follows: FORMULA   Implementation with neural networks [SEP]\n", "[CLS] In order to marginalize latent variables FORMULA  and obtain FORMULA , the computational complexity of marginalization in (REF ) is high, exponentially proportional to the cardinality of FORMULA . [SEP]\n", "[CLS] In order to infer FORMULA  in a more efficient way, we use the following approximations: FORMULA   [SEP]\n", "[CLS] In (REF ) and (), we replace FORMULA  by its average configuration FORMULA  and this approximation was also used in greedy layer-wise learning for deep belief net in {{cite:38a00b1a-bff7-4c71-8252-a30177ca4886}}. [SEP]\n", "[CLS] FORMULA    [SEP]\n", "[CLS] The target is to marginalize the distribution of FORMULA , as shown in REF . [SEP]\n", "[CLS] We adopt the classical mean-field approximation approach for message passing{{cite:b7cde50e-6a34-40ee-8ac6-bea5bbed9720}}. [SEP]\n", "[CLS] FORMULA  in () is approximated by a product of independent FORMULA  in (REF ) and (). [SEP]\n", "[CLS] We first ignore the pairwise term FORMULA  which will be addressed later in Section REF . [SEP]\n", "[CLS] Suppose FORMULA , where FORMULA  is the feature representation of image FORMULA . [SEP]\n", "[CLS] For a binary latent variable FORMULA , FORMULA  where sigmFORMULA  is the sigmoid function. [SEP]\n", "[CLS] Therefore, the mapping from FORMULA  to FORMULA  can be implemented with one-layer transformation in a neural network and sigmoid is the activation function. [SEP]\n", "[CLS] FORMULA  is a new feature vector derived from FORMULA  and FORMULA  can be obtained from lower layers in a network. [SEP]\n", "[CLS] Message passing on tree structured latent variables In order to infer FORMULA , the key challenge in our framework is to obtain the marginalized distribution of hidden units, i.e. , FORMULA  in (REF ). [SEP]\n", "[CLS] One can obtain FORMULA  through message passing and further estimate FORMULA   [SEP]\n", "[CLS] Then FORMULA  in (REF ) can be estimated with existing works such as {{cite:f1bb394e-c3be-4749-b5e0-168282992fbc}}, {{cite:258e7303-126e-459e-851e-7fb3f32ad61d}}. [SEP]\n", "[CLS] According to the sum-product algorithm for a tree structure, every node can receive the messages from other nodes through two message passing routes, first from leaves to a root and then from the root to the leaves {{cite:123835bf-172f-487e-adf8-0e6449c5b17a}}. [SEP]\n", "[CLS] The key is to have a planned route and to store the intermediate messages. [SEP]\n", "[CLS] Our proposed messaging passing algorithm is summarized in Algorithm REF . [SEP]\n", "[CLS] An example of message passing for a tree structure with 4 nodes as shown in Fig. REF (c). [SEP]\n", "[CLS] For detailed illustrations of REF , please refer to the supplementary material. [SEP]\n", "[CLS] Message passing among features on factor graph. [SEP]\n", "[CLS] [1] Belief propagationFORMULA  FORMULA , for FORMULA  to FORMULA   [SEP]\n", "[CLS] Initialization FORMULA  to FORMULA  Passing messages FORMULA  times Select a predefined message passing route FORMULA  FORMULA  to FORMULA  Choose an edge FORMULA  from FORMULA  according to the route FORMULA   [SEP]\n", "[CLS] Denote FORMULA  as the set of neighboring nodes for node FORMULA  on the graphical model FORMULA  is a factor node denoted by FORMULA  FORMULA    [SEP]\n", "[CLS] Pass message from factors to variable FORMULA   [SEP]\n", "[CLS] Normalize Denote the factor node [SEP]\n", "[CLS] FORMULA  by FORMULA  FORMULA    [SEP]\n", "[CLS] Pass message to the factor FORMULA  to FORMULA   FORMULA FIGURE   [SEP]\n", "[CLS] We drop FORMULA  and FORMULA  to be concise. [SEP]\n", "[CLS] According to the mean-field approximation algorithm, the above message passing process should be conducted for multiple times with share parameter to converge. [SEP]\n", "[CLS] To implement FORMULA , we use matrix multiplication for easier illustration but convolution (which is a special form of matrix multiplication) for implementation in Algorithm REF . [SEP]\n", "[CLS] Then message passing is implemented with convolution between feature maps. [SEP]\n", "[CLS] The proposed method is extensible to loopy structured graphs, as shown in Fig. REF (e). [SEP]\n", "[CLS] The underlying concept of building up probabilistic model at feature level is the same. [SEP]\n", "[CLS] However, for loopy structures, the key challenge is to define the rule in message passing. [SEP]\n", "[CLS] Either a sequence of asymmetric message passing order is predefined, which seems not reasonable for symmetric structure of human poses, or use the flooding scheme to repeated collect information for neighborhood joints. [SEP]\n", "[CLS] We compared tree structure with loop structure with flooding scheme in the experimental section. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Overall picture of CRF-CNN for human pose estimation An overview of the approach is shown in Fig. REF . [SEP]\n", "[CLS] In this pipeline, the prediction on FORMULA th body part configuration FORMULA  is represented by a score map FORMULA , where FORMULA  denotes the predicted confidence on the existence of the FORMULA th body joint at the location FORMULA . [SEP]\n", "[CLS] Similarly, the group of features FORMULA  used for estimating FORMULA  is represented by FORMULA , FORMULA . [SEP]\n", "[CLS] FORMULA  is a length-FORMULA  vector. [SEP]\n", "[CLS] Therefore, the feature group FORMULA  is represented by a feature map of FORMULA  channels, where FORMULA  contains FORMULA  channels of features at location FORMULA . [SEP]\n", "[CLS] 1) It comprises a fully convolutional network stage, which takes an image as input and outputs features FORMULA . [SEP]\n", "[CLS] We use the fully convolutional implementation of VGG and the output of fc6 in VGG is used as the feature map FORMULA . [SEP]\n", "[CLS] 2) Messages are passed among features FORMULA  with Algorithm REF . [SEP]\n", "[CLS] Initially, data term FORMULA  for the FORMULA th feature group is obtained from feature map FORMULA  by convolution, which is our implementation of term FORMULA  in () and corresponds to Algorithm REF  line 2. [SEP]\n", "[CLS] Then CNN is used for passing messages among FORMULA  using lines 3-19 in Algorithm REF , which implements term FORMULA  in () by convolution. [SEP]\n", "[CLS] After message passing, the FORMULA  for FORMULA  is obtained and treated as feature maps to be used. [SEP]\n", "[CLS] 3) Then the feature maps FORMULA  for FORMULA  are used to obtain the score map for inferring FORMULA  with (REF ). [SEP]\n", "[CLS] As a simple example for illustration, we can use FORMULA  to obtain the predicted score FORMULA  for the FORMULA th part at location FORMULA . [SEP]\n", "[CLS] In this case, FORMULA  is the feature with FORMULA  channels at location FORMULA  and FORMULA  can be treated as the classifier. [SEP]\n", "[CLS] Our implementation uses the approach in {{cite:f1bb394e-c3be-4749-b5e0-168282992fbc}} to infer FORMULA , which also models the spatial relationship among FORMULA . [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] During training, a whole image (or many of them) can be used as the mini-batch and the error at each output location of the network can be computed using an appropriate loss function with respect to the ground truth of the body joints. [SEP]\n", "[CLS] We use softmax loss with respect to the estimated part configuration FORMULA  as the approximate loss function. [SEP]\n", "[CLS] Since we have used CNN from input to features FORMULA , FORMULA  and FORMULA  , a single CNN is used for obtaining the score map of body joints from the image. [SEP]\n", "[CLS] End-to-end learning with softmax loss and standard BP is used. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Experiment We conduct experiments on two benchmark datasets: the LSP dataset {{cite:83376c95-884b-468f-8bd4-2956ab072392}} and the FLIC dataset {{cite:c7f2229e-ccf4-4115-bd61-43e5674a603e}}. [SEP]\n", "[CLS] LSP contains FORMULA  images. [SEP]\n", "[CLS] FORMULA  images for training and FORMULA  for test. [SEP]\n", "[CLS] Each person is annotated with 14 joints. [SEP]\n", "[CLS] FLIC contains FORMULA  training images and FORMULA  testing images from Hollywood movies with upper body annotated. [SEP]\n", "[CLS] On both datasets, we use observer centric annotation for training and evaluation. [SEP]\n", "[CLS] We also use negative samples, i.e. images not containing any person, from the INRIA dataset {{cite:259d887b-06d1-4751-aa2d-e2caec67d611}}. [SEP]\n", "[CLS] In summary, we are consistent with Chen et al. {{cite:f1bb394e-c3be-4749-b5e0-168282992fbc}} in training data preparation. [SEP]\n", "[CLS] Results on the LSP dataset The experimental results for our and previous approaches on LSP are shown in Table REF . [SEP]\n", "[CLS] For evaluation metric, we choose the prevailing evaluation method: strict Percentage of Correct Parts (PCP). [SEP]\n", "[CLS] Under this metric, a limb is considered to be detected only if both ends of an limb lie in 50% of the length w.r.t. [SEP]\n", "[CLS] the ground-truth location. [SEP]\n", "[CLS] For pose estimation, it is well known that the accuracy of CNN features is higher than handcrafted features. [SEP]\n", "[CLS] Therefore, we only compare with methods that use CNN features to be concise. [SEP]\n", "[CLS] Pishchulin et al. {{cite:4f946759-5b4b-4618-baf3-4597cb4c3bcd}} use extra training data, so we do not compare with it. [SEP]\n", "[CLS] Yang et al. {{cite:a703fb74-82ef-477d-bb77-2143aecfa4d5}} learned features and structured body part configurations simultaneously. [SEP]\n", "[CLS] Our performance is better than them because we model structure among features. [SEP]\n", "[CLS] Chu et al. {{cite:a3e755d7-aea8-4f57-bddb-5bc025939908}} learned structured features and heuristically defined a message passing scheme. [SEP]\n", "[CLS] Using only the LSP training data, these two approaches have the highest PCP (Observer-Centric) reported in {{cite:93df3fc9-bee2-4a93-b65f-bde74c738adb}}. [SEP]\n", "[CLS] The model in {{cite:a3e755d7-aea8-4f57-bddb-5bc025939908}} has no probabilistic interpretation and cannot be modeled as CRF. [SEP]\n", "[CLS] Most vertices in their CNN can only receive information from half of the vertices, while in our message passing scheme each node could receive information from all vertices, since it is developed from CRF and the sum-product algorithm. [SEP]\n", "[CLS] The approaches in {{cite:a703fb74-82ef-477d-bb77-2143aecfa4d5}}, {{cite:a3e755d7-aea8-4f57-bddb-5bc025939908}} are all based on the VGG structure as ours. [SEP]\n", "[CLS] By using a more effective message passing scheme, our method reduces the mean error rate by FORMULA . [SEP]\n", "[CLS] TABLE   Results on the FLIC dataset We use Percentage of Correct Keypoints (PCK) as the evaluation metric. [SEP]\n", "[CLS] Because it is widely adopted by previous works on FLIC, it provides convenience for comparison. [SEP]\n", "[CLS] These published works only reported results on elbow and wrist and we follow the same practice. [SEP]\n", "[CLS] PCK reports the percentage of predictions that lay in the normalized distance of annotation. [SEP]\n", "[CLS] Toshev et al. {{cite:62c83b7c-f2e5-42a5-b3c1-b9788087e79c}}, Chen and Yuille {{cite:f1bb394e-c3be-4749-b5e0-168282992fbc}} and Tompson et al. {{cite:e78354e0-07f4-4534-8ee4-b0f944e08ed1}} also used CNN features. [SEP]\n", "[CLS] When compared with previous state of the art, our method improves the performance of elbow and wrist by 2.7% and 1.7% respectively. [SEP]\n", "[CLS] TABLE   Diagnostic Experiments [SEP]\n", "[CLS] In this subsection, we conduct experiments to compare different message passing schemes, structures, and noniliear functions. [SEP]\n", "[CLS] The experimental results in Table REF  use the same VGG for feature extraction. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] Flooding is a message passing schedule, in which all vertices pass the messages to their neighboring vertices simultaneously and locally as follows: FORMULA  where FORMULA  denotes the neighboring vertices of the FORMULA th vertex in the graphical model. [SEP]\n", "[CLS] We adopt the iterative updating scheme in the work of Zheng et al. {{cite:bb183a11-97ce-4c77-82d9-5552ef7987d5}}. [SEP]\n", "[CLS] In Table REF , Flooding-1itr-tree denotes the result of using flooding to perform message passing once using CNN as in {{cite:bb183a11-97ce-4c77-82d9-5552ef7987d5}}. [SEP]\n", "[CLS] The tree structure in Fig. REF  (b) is adopted. [SEP]\n", "[CLS] Flooding-2iter-tree indicates the result of using flooding to pass messages twice. [SEP]\n", "[CLS] The weights across the two message passing iterations are shared. [SEP]\n", "[CLS] Experimental results show slight improvement of passing twice than once. [SEP]\n", "[CLS] The result for the loopy structured graph in Fig. REF  (e) is denoted by Flooding-2iter-loopy. [SEP]\n", "[CLS] The connection of a pair of joints is decided by the following protocol: if 90% of the training sample's distance is within 48 pixels, which is the receptive field size of our filters, we connect these two joints. [SEP]\n", "[CLS] Improvement of 1.3% is introduced by these extra connections. [SEP]\n", "[CLS] These approaches share the same drawbacks: lack of information for making predictions. [SEP]\n", "[CLS] With one iteration of message passing, each body part could only receive information from neighborhood parts, while with two iterations a part can only receive information from parts of depth 2. [SEP]\n", "[CLS] However, the largest depth in our graph is 10. [SEP]\n", "[CLS] Flooding is inefficient for a node to receive the messages from the other nodes. [SEP]\n", "[CLS] This problem is solved with the serial scheme. [SEP]\n", "[CLS] Serial scheme passes messages following a predefined order and update information sequentially. [SEP]\n", "[CLS] For a tree structured graph with FORMULA  vertices, each vertex can be marginalized by passing the messages within FORMULA  operations using the efficient sum-product algorithm {{cite:123835bf-172f-487e-adf8-0e6449c5b17a}}. [SEP]\n", "[CLS] The result of using serial message passing is denoted by Serial-tree(Softmax) in Table REF . [SEP]\n", "[CLS] In can be shown that the serial scheme performs better than the flooding scheme. [SEP]\n", "[CLS] It is well known that softmax leads to vanishing of gradients which make the network training inefficient. [SEP]\n", "[CLS] In experiment, we replace FORMULA  with FORMULA  to accelerate the training process. [SEP]\n", "[CLS] We set FORMULA  and FORMULA , where FORMULA  is the number of feature channels. [SEP]\n", "[CLS] With this slight change, the network can converge much faster than softmax without using FORMULA  and FORMULA . [SEP]\n", "[CLS] The performance of using this softmax, which is derived from our CRF in (), is FORMULA  higher than Serial-tree(ReLU), which uses ReLU as the non-linear function for passing messages among features, a scheme used in {{cite:a3e755d7-aea8-4f57-bddb-5bc025939908}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusion We propose to use CRF for modeling structured features and structured human body part configurations. [SEP]\n", "[CLS] This CRF is implemented by an end-to-end learning CNN. [SEP]\n", "[CLS] The efficient sum-product algorithm in the probabilistic model guides us in using an efficient message passing approach so that each vertex receives messages from other nodes in a more efficient way. [SEP]\n", "[CLS] And the use of CRF also helps us to choose non-linear functions and to know what are the assumptions and approximations made in order to use CNN to implement such CRF. [SEP]\n", "[CLS] The gain in performance on two benchmark human pose estimation datasets proves the effectiveness of this attempt, which shows a new direction for the structure design of deep neural networks. [SEP]\n", "[CLS] Acknowledgment: This work is supported by SenseTime Group Limited, Research Grants Council of Hong Kong (Project Number CUHK14206114, CUHK14205615, CUHK14207814, CUHK14203015, and CUHK417011) and National Natural Science Foundation of China (Number 61371192 and 61301269). [SEP]\n", "[CLS] W. Ouyang and X. Wang are the corresponding authors. [SEP]\n"], "1409.0473": ["[CLS]   [SEP]\n", "[CLS] Neural Machine Translation by Jointly Learning to Align and Translate Dzmitry Bahdanau Jacobs University Bremen, [SEP]\n", "[CLS] Germany KyungHyun Cho\u00a0 \u00a0 \u00a0 \u00a0Yoshua BengioCIFAR Senior Fellow Universit\u00e9 de Montr\u00e9al 2020/09/08 23:48:57Neural machine translation is a recently proposed approach to machine translation. [SEP]\n", "[CLS] Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. [SEP]\n", "[CLS] The models proposed recently for neural machine translation often belong to a family of encoder\u2013decoders and encode a source sentence into a fixed-length vector from which a decoder generates a translation. [SEP]\n", "[CLS] In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder\u2013decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. [SEP]\n", "[CLS] With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. [SEP]\n", "[CLS] Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition. [SEP]\n", "[CLS] Introduction Neural machine translation is a newly emerging approach to machine translation, recently proposed by {{cite:19bdcb58-5818-4ba3-ad07-1a5f2a943ad1}}, {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}} and {{cite:5b4f7736-0251-47fc-b34e-b0199bcf4313}}. [SEP]\n", "[CLS] Unlike the traditional phrase-based translation system\u00a0{{cite:ca37179e-89d1-4514-8035-642600699d23}} which consists of many small sub-components that are tuned separately, neural machine translation attempts to build and train a single, large neural network that reads a sentence and outputs a correct translation. [SEP]\n", "[CLS] Most of the proposed neural machine translation models belong to a family of encoder\u2013decoders\u00a0{{cite:5041425c-ca9f-4613-b854-cc45bf859b06}}, {{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}}, with an encoder and a decoder for each language, or involve a language-specific encoder applied to each sentence whose outputs are then compared\u00a0{{cite:cd199508-edb5-408d-bbbe-9dc1cd30f1e5}}. [SEP]\n", "[CLS] An encoder neural network reads and encodes a source sentence into a fixed-length vector. [SEP]\n", "[CLS] A decoder then outputs a translation from the encoded vector. [SEP]\n", "[CLS] The whole encoder\u2013decoder system, which consists of the encoder and the decoder for a language pair, is jointly trained to maximize the probability of a correct translation given a source sentence. [SEP]\n", "[CLS] A potential issue with this encoder\u2013decoder approach is that a neural network needs to be able to compress all the necessary information of a source sentence into a fixed-length vector. [SEP]\n", "[CLS] This may make it difficult for the neural network to cope with long sentences, especially those that are longer than the sentences in the training corpus. [SEP]\n", "[CLS] {{cite:5b4f7736-0251-47fc-b34e-b0199bcf4313}} showed that indeed the performance of a basic encoder\u2013decoder deteriorates rapidly as the length of an input sentence increases. [SEP]\n", "[CLS] In order to address this issue, we introduce an extension to the encoder\u2013decoder model which learns to align and translate jointly. [SEP]\n", "[CLS] Each time the proposed model generates a word in a translation, it (soft-)searches for a set of positions in a source sentence where the most relevant information is concentrated. [SEP]\n", "[CLS] The model then predicts a target word based on the context vectors associated with these source positions and all the previous generated target words. [SEP]\n", "[CLS] The most important distinguishing feature of this approach from the basic encoder\u2013decoder is that it does not attempt to encode a whole input sentence into a single fixed-length vector. [SEP]\n", "[CLS] Instead, it encodes the input sentence into a sequence of vectors and chooses a subset of these vectors adaptively while decoding the translation. [SEP]\n", "[CLS] This frees a neural translation model from having to squash all the information of a source sentence, regardless of its length, into a fixed-length vector. [SEP]\n", "[CLS] We show this allows a model to cope better with long sentences. [SEP]\n", "[CLS] In this paper, we show that the proposed approach of jointly learning to align and translate achieves significantly improved translation performance over the basic encoder\u2013decoder approach. [SEP]\n", "[CLS] The improvement is more apparent with longer sentences, but can be observed with sentences of any length. [SEP]\n", "[CLS] On the task of English-to-French translation, the proposed approach achieves, with a single model, a translation performance comparable, or close, to the conventional phrase-based system. [SEP]\n", "[CLS] Furthermore, qualitative analysis reveals that the proposed model finds a linguistically plausible (soft-)alignment between a source sentence and the corresponding target sentence. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Background: Neural Machine Translation From a probabilistic perspective, translation is equivalent to finding a target sentence FORMULA  that maximizes the conditional probability of FORMULA  given a source sentence FORMULA , i.e., FORMULA . [SEP]\n", "[CLS] In neural machine translation, we fit a parameterized model to maximize the conditional probability of sentence pairs using a parallel training corpus. [SEP]\n", "[CLS] Once the conditional distribution is learned by a translation model, given a source sentence a corresponding translation can be generated by searching for the sentence that maximizes the conditional probability. [SEP]\n", "[CLS] Recently, a number of papers have proposed the use of neural networks to directly learn this conditional distribution\u00a0{{cite:19bdcb58-5818-4ba3-ad07-1a5f2a943ad1}}, {{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}}, {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}}, {{cite:5b4f7736-0251-47fc-b34e-b0199bcf4313}}, {{cite:43abb97c-1aea-40d3-864d-f893308c7a04}}. [SEP]\n", "[CLS] This neural machine translation approach typically consists of two components, the first of which encodes a source sentence FORMULA  and the second decodes to a target sentence FORMULA . [SEP]\n", "[CLS] For instance, two recurrent neural networks (RNN) were used by {{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}} and {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}} to encode a variable-length source sentence into a fixed-length vector and to decode the vector into a variable-length target sentence. [SEP]\n", "[CLS] Despite being a quite new approach, neural machine translation has already shown promising results. [SEP]\n", "[CLS] {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}} reported that the neural machine translation based on RNNs with long short-term memory (LSTM) units achieves close to the state-of-the-art performance of the conventional phrase-based machine translation system on an English-to-French translation task. [SEP]\n", "[CLS] We mean by the state-of-the-art performance, the performance of the conventional phrase-based system without using any neural network-based component. [SEP]\n", "[CLS] Adding neural components to existing translation systems, for instance, to score the phrase pairs in the phrase table\u00a0{{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}} or to re-rank candidate translations\u00a0{{cite:5041425c-ca9f-4613-b854-cc45bf859b06}}, has allowed to surpass the previous state-of-the-art performance level. [SEP]\n", "[CLS] RNN Encoder\u2013Decoder Here, we describe briefly the underlying framework, called RNN Encoder\u2013Decoder, proposed by {{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}} and {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}} upon which we build a novel architecture that learns to align and translate simultaneously. [SEP]\n", "[CLS] In the Encoder\u2013Decoder framework, an encoder reads the input sentence, a sequence of vectors FORMULA , into a vector FORMULA .Although [SEP]\n", "[CLS] most of the previous works\u00a0{{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}}, {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}}, {{cite:19bdcb58-5818-4ba3-ad07-1a5f2a943ad1}} used to encode a variable-length input sentence into a fixed-length vector, it is not necessary, and even it may be beneficial to have a variable-length vector, as we will show later. [SEP]\n", "[CLS] The most common approach is to use an RNN such that FORMULA   and FORMULA   where FORMULA  is a hidden state at time FORMULA , and FORMULA  is a vector generated from the sequence of the hidden states. [SEP]\n", "[CLS] FORMULA  and FORMULA  are some nonlinear functions. [SEP]\n", "[CLS] {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}} used an LSTM as FORMULA  and FORMULA , for instance. [SEP]\n", "[CLS] The decoder is often trained to predict the next word FORMULA  given the context vector FORMULA  and all the previously predicted words FORMULA . [SEP]\n", "[CLS] In other words, the decoder defines a probability over the translation FORMULA  by decomposing the joint probability into the ordered conditionals: FORMULA   where FORMULA . [SEP]\n", "[CLS] With an RNN, each conditional probability is modeled as FORMULA   where FORMULA  is a nonlinear, potentially multi-layered, function that outputs the probability of FORMULA , and FORMULA  is the hidden state of the RNN. [SEP]\n", "[CLS] It should be noted that other architectures such as a hybrid of an RNN and a de-convolutional neural network can be used\u00a0{{cite:19bdcb58-5818-4ba3-ad07-1a5f2a943ad1}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Learning to Align and Translate [SEP]\n", "[CLS] In this section, we propose a novel architecture for neural machine translation. [SEP]\n", "[CLS] The new architecture consists of a bidirectional RNN as an encoder (Sec.\u00a0REF ) and a decoder that emulates searching through a source sentence during decoding a translation (Sec.\u00a0REF ). [SEP]\n", "[CLS] Decoder: General Description FIGURE   [SEP]\n", "[CLS] In a new model architecture, we define each conditional probability in Eq.\u00a0(REF ) as: FORMULA   where FORMULA  is an RNN hidden state for time FORMULA , computed by FORMULA   [SEP]\n", "[CLS] It should be noted that unlike the existing encoder\u2013decoder approach (see Eq.\u00a0(REF )), here the probability is conditioned on a distinct context vector FORMULA  for each target word FORMULA . [SEP]\n", "[CLS] The context vector FORMULA  depends on a sequence of annotations FORMULA  to which an encoder maps the input sentence. [SEP]\n", "[CLS] Each annotation FORMULA  contains information about the whole input sequence with a strong focus on the parts surrounding the FORMULA -th word of the input sequence. [SEP]\n", "[CLS] We explain in detail how the annotations are computed in the next section. [SEP]\n", "[CLS] The context vector FORMULA  is, then, computed as a weighted sum of these annotations FORMULA : FORMULA    [SEP]\n", "[CLS] The weight FORMULA  of each annotation FORMULA  is computed by FORMULA   where FORMULA  is an alignment model which scores how well the inputs around position FORMULA  and the output at position FORMULA  match. [SEP]\n", "[CLS] The score is based on the RNN hidden state FORMULA  (just before emitting FORMULA , Eq.\u00a0(REF )) and the FORMULA -th annotation FORMULA  of the input sentence. [SEP]\n", "[CLS] We parametrize the alignment model FORMULA  as a feedforward neural network which is jointly trained with all the other components of the proposed system. [SEP]\n", "[CLS] Note that unlike in traditional machine translation, the alignment is not considered to be a latent variable. [SEP]\n", "[CLS] Instead, the alignment model directly computes a soft alignment, which allows the gradient of the cost function to be backpropagated through. [SEP]\n", "[CLS] This gradient can be used to train the alignment model as well as the whole translation model jointly. [SEP]\n", "[CLS] We can understand the approach of taking a weighted sum of all the annotations as computing an expected annotation, where the expectation is over possible alignments. [SEP]\n", "[CLS] Let FORMULA  be a probability that the target word FORMULA  is aligned to, or translated from, a source word FORMULA . [SEP]\n", "[CLS] Then, the FORMULA -th context vector FORMULA  is the expected annotation over all the annotations with probabilities FORMULA . [SEP]\n", "[CLS] The probability FORMULA , or its associated energy FORMULA , reflects the importance of the annotation FORMULA  with respect to the previous hidden state FORMULA  in deciding the next state FORMULA  and generating FORMULA . [SEP]\n", "[CLS] Intuitively, this implements a mechanism of attention in the decoder. [SEP]\n", "[CLS] The decoder decides parts of the source sentence to pay attention to. [SEP]\n", "[CLS] By letting the decoder have an attention mechanism, we relieve the encoder from the burden of having to encode all information in the source sentence into a fixed-length vector. [SEP]\n", "[CLS] With this new approach the information can be spread throughout the sequence of annotations, which can be selectively retrieved by the decoder accordingly. [SEP]\n", "[CLS]  Encoder: Bidirectional RNN for Annotating Sequences [SEP]\n", "[CLS] The usual RNN, described in Eq.\u00a0(REF ), reads an input sequence FORMULA  in order starting from the first symbol FORMULA  to the last one FORMULA . [SEP]\n", "[CLS] However, in the proposed scheme, we would like the annotation of each word to summarize not only the preceding words, but also the following words. [SEP]\n", "[CLS] Hence, we propose to use a bidirectional RNN\u00a0{{cite:d5ae8b35-8317-4965-9dd9-9a5f062d06b9}}, which has been successfully used recently in speech recognition\u00a0{{cite:deaf5225-de8c-479a-9c51-da152de6e892}}. [SEP]\n", "[CLS] A BiRNN consists of forward and backward RNN's. [SEP]\n", "[CLS] The forward RNN FORMULA  reads the input sequence as it is ordered (from FORMULA  to FORMULA ) and calculates a sequence of forward hidden states FORMULA . [SEP]\n", "[CLS] The backward RNN FORMULA  reads the sequence in the reverse order (from FORMULA  to FORMULA ), resulting in a sequence of backward hidden states FORMULA . [SEP]\n", "[CLS] We obtain an annotation for each word FORMULA  by concatenating the forward hidden state FORMULA  and the backward one FORMULA , i.e., FORMULA . [SEP]\n", "[CLS] In this way, the annotation FORMULA  contains the summaries of both the preceding words and the following words. [SEP]\n", "[CLS] Due to the tendency of RNNs to better represent recent inputs, the annotation FORMULA  will be focused on the words around FORMULA . [SEP]\n", "[CLS] This sequence of annotations is used by the decoder and the alignment model later to compute the context vector (Eqs.\u00a0(REF )\u2013(REF )). [SEP]\n", "[CLS] See Fig.\u00a0REF  for the graphical illustration of the proposed model. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Experiment Settings We evaluate the proposed approach on the task of English-to-French translation. [SEP]\n", "[CLS] We use the bilingual, parallel corpora provided by ACL WMT '14.http://www.statmt.org/wmt14/translation-task.html [SEP]\n", "[CLS] As a comparison, we also report the performance of an RNN Encoder\u2013Decoder which was proposed recently by {{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}}. [SEP]\n", "[CLS] We use the same training procedures and the same dataset for both models. [SEP]\n", "[CLS] Implementations are available at https://github.com/lisa-groundhog/GroundHog. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Dataset WMT '14 contains the following English-French parallel corpora: Europarl (61M words), news commentary (5.5M), UN (421M) and two crawled corpora of 90M and 272.5M words respectively, totaling 850M words. [SEP]\n", "[CLS] Following the procedure described in {{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}}, we reduce the size of the combined corpus to have 348M words using the data selection method by {{cite:ad2cb49d-74ff-475b-9c65-58edb2228c4b}}.Available online at http://www-lium.univ-lemans.fr/~schwenk/cslm_joint_paper/. [SEP]\n", "[CLS] We do not use any monolingual data other than the mentioned parallel corpora, although it may be possible to use a much larger monolingual corpus to pretrain an encoder. [SEP]\n", "[CLS] We concatenate news-test-2012 and news-test-2013 to make a development (validation) set, and evaluate the models on the test set (news-test-2014) from WMT '14, which consists of 3003 sentences not present in the training data. [SEP]\n", "[CLS] After a usual tokenizationWe used the tokenization script from the open-source machine translation package, Moses. [SEP]\n", "[CLS] , we use a shortlist of 30,000 most frequent words in each language to train our models. [SEP]\n", "[CLS] Any word not included in the shortlist is mapped to a special token (FORMULA ). [SEP]\n", "[CLS] We do not apply any other special preprocessing, such as lowercasing or stemming, to the data. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Models We train two types of models. [SEP]\n", "[CLS] The first one is an RNN Encoder\u2013Decoder\u00a0{{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}}, and the other is the proposed model, to which we refer as RNNsearch. [SEP]\n", "[CLS] We train each model twice: first with the sentences of length up to 30 words (RNNencdec-30, RNNsearch-30) and then with the sentences of length up to 50 word (RNNencdec-50, RNNsearch-50). [SEP]\n", "[CLS] The encoder and decoder of the RNNencdec have 1000 hidden units each. [SEP]\n", "[CLS] In this paper, by a 'hidden unit', we always mean the gated hidden unit (see Appendix\u00a0REF ). [SEP]\n", "[CLS] The encoder of the RNNsearch consists of forward and backward recurrent neural networks (RNN) each having 1000 hidden units. [SEP]\n", "[CLS] Its decoder has 1000 hidden units. [SEP]\n", "[CLS] In both cases, we use a multilayer network with a single maxout\u00a0{{cite:fc44e35a-dcfd-4537-889e-efcbfcc49a16}} hidden layer to compute the conditional probability of each target word\u00a0{{cite:309bfcfe-3ab2-4483-a401-c11c71f31ab3}}. [SEP]\n", "[CLS] We use a minibatch stochastic gradient descent (SGD) algorithm together with Adadelta\u00a0{{cite:b592f8ea-5131-4e65-bb73-ad60953d12d4}} to train each model. [SEP]\n", "[CLS] Each SGD update direction is computed using a minibatch of 80 sentences. [SEP]\n", "[CLS] We trained each model for approximately 5 days. [SEP]\n", "[CLS] Once a model is trained, we use a beam search to find a translation that approximately maximizes the conditional probability\u00a0{{cite:3d357c95-949f-46a6-8d83-efbe67d40a0d}}, {{cite:cc0ca0ae-115b-4461-a337-8c8ceadd5366}}. [SEP]\n", "[CLS] {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}} used this approach to generate translations from their neural machine translation model. [SEP]\n", "[CLS] For more details on the architectures of the models and training procedure used in the experiments, see Appendices\u00a0 and .   [SEP]\n", "[CLS] Results Quantitative Results TABLE   [SEP]\n", "[CLS] In Table\u00a0REF , we list the translation performances measured in BLEU score. [SEP]\n", "[CLS] It is clear from the table that in all the cases, the proposed RNNsearch outperforms the conventional RNNencdec. [SEP]\n", "[CLS] More importantly, the performance of the RNNsearch is as high as that of the conventional phrase-based translation system (Moses), when only the sentences consisting of known words are considered. [SEP]\n", "[CLS] This is a significant achievement, considering that Moses uses a separate monolingual corpus (418M words) in addition to the parallel corpora we used to train the RNNsearch and RNNencdec. [SEP]\n", "[CLS] One of the motivations behind the proposed approach was the use of a fixed-length context vector in the basic encoder\u2013decoder approach. [SEP]\n", "[CLS] We conjectured that this limitation may make the basic encoder\u2013decoder approach to underperform with long sentences. [SEP]\n", "[CLS] In Fig.\u00a0REF , we see that the performance of RNNencdec dramatically drops as the length of the sentences increases. [SEP]\n", "[CLS] On the other hand, both RNNsearch-30 and RNNsearch-50 are more robust to the length of the sentences. [SEP]\n", "[CLS] RNNsearch-50, especially, shows no performance deterioration even with sentences of length 50 or more. [SEP]\n", "[CLS] This superiority of the proposed model over the basic encoder\u2013decoder is further confirmed by the fact that the RNNsearch-30 even outperforms RNNencdec-50 (see Table\u00a0REF ). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Qualitative Analysis Alignment The proposed approach provides an intuitive way to inspect the (soft-)alignment between the words in a generated translation and those in a source sentence. [SEP]\n", "[CLS] This is done by visualizing the annotation weights FORMULA  from Eq.\u00a0(REF ), as in Fig.\u00a0REF . [SEP]\n", "[CLS] Each row of a matrix in each plot indicates the weights associated with the annotations. [SEP]\n", "[CLS] From this we see which positions in the source sentence were considered more important when generating the target word. [SEP]\n", "[CLS] We can see from the alignments in Fig.\u00a0REF  that the alignment of words between English and French is largely monotonic. [SEP]\n", "[CLS] We see strong weights along the diagonal of each matrix. [SEP]\n", "[CLS] However, we also observe a number of non-trivial, non-monotonic alignments. [SEP]\n", "[CLS] Adjectives and nouns are typically ordered differently between French and English, and we see an example in Fig.\u00a0REF \u00a0(a). [SEP]\n", "[CLS] From this figure, we see that the model correctly translates a phrase [European Economic Area] into [zone \u00e9conomique europ\u00e9en]. [SEP]\n", "[CLS] The RNNsearch was able to correctly align [zone] with [Area], jumping over the two words ([European] and [Economic]), and then looked one word back at a time to complete the whole phrase [zone \u00e9conomique europ\u00e9enne]. [SEP]\n", "[CLS] The strength of the soft-alignment, opposed to a hard-alignment, is evident, for instance, from Fig.\u00a0REF \u00a0(d). [SEP]\n", "[CLS] Consider the source phrase [the man] which was translated into [l' homme]. [SEP]\n", "[CLS] Any hard alignment will map [the] to [l'] and [man] to [homme]. [SEP]\n", "[CLS] This is not helpful for translation, as one must consider the word following [the] to determine whether it should be translated into [le], [la], [les] or [l']. [SEP]\n", "[CLS] Our soft-alignment solves this issue naturally by letting the model look at both [SEP]\n", "[CLS] [the] and [man], and in this example, we see that the model was able to correctly translate [the] into [l']. [SEP]\n", "[CLS] We observe similar behaviors in all the presented cases in Fig.\u00a0REF . [SEP]\n", "[CLS] An additional benefit of the soft alignment is that it naturally deals with source and target phrases of different lengths, without requiring a counter-intuitive way of mapping some words to or from nowhere ([NULL])\u00a0{{cite:883e44d9-aa9e-45ff-8dff-d745d043c4eb}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Long Sentences As clearly visible from Fig. [SEP]\n", "[CLS] \u00a0REF  the proposed model (RNNsearch) is much better than the conventional model (RNNencdec) at translating long sentences. [SEP]\n", "[CLS] This is likely due to the fact that the RNNsearch does not require encoding a long sentence into a fixed-length vector perfectly, but only accurately encoding the parts of the input sentence that surround a particular word. [SEP]\n", "[CLS] As an example, consider this source sentence from the test set: An admitting privilege is the right of a doctor to admit a patient to a hospital or a medical centre to carry out a diagnosis or a procedure, based on his status as a health care worker at a hospital. [SEP]\n", "[CLS] The RNNencdec-50 translated this sentence into: Un privil\u00e8ge d'admission est le droit d'un m\u00e9decin de reconna\u00eetre un patient \u00e0 l'h\u00f4pital ou un centre m\u00e9dical d'un diagnostic ou de prendre un diagnostic en fonction de son \u00e9tat de sant\u00e9. [SEP]\n", "[CLS] The RNNencdec-50 correctly translated the source sentence until [a medical center]. [SEP]\n", "[CLS] However, from there on (underlined), it deviated from the original meaning of the source sentence. [SEP]\n", "[CLS] For instance, it replaced [based on his status as a health care worker at a hospital] in the source sentence with [en fonction de son \u00e9tat de sant\u00e9] (\u201cbased on his state of health\u201d). [SEP]\n", "[CLS] On the other hand, the RNNsearch-50 generated the following correct translation, preserving the whole meaning of the input sentence without omitting any details: Un privil\u00e8ge d'admission est le droit d'un [SEP]\n", "[CLS] m\u00e9decin d'admettre un patient \u00e0 un h\u00f4pital ou un centre m\u00e9dical pour effectuer un diagnostic ou une proc\u00e9dure, selon son statut de travailleur des soins de sant\u00e9 \u00e0 l'h\u00f4pital. [SEP]\n", "[CLS] Let us consider another sentence from the test set: This kind of experience is part of Disney's efforts to \"extend the lifetime of its series and build new relationships with audiences via digital platforms that are becoming ever more important,\" he added. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The translation by the RNNencdec-50 is Ce type d'exp\u00e9rience fait partie des initiatives du Disney pour \"prolonger la dur\u00e9e de vie de ses nouvelles et de d\u00e9velopper des liens avec les lecteurs num\u00e9riques qui deviennent plus complexes. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] As with the previous example, the RNNencdec began deviating from the actual meaning of the source sentence after generating approximately 30 words (see the underlined phrase). [SEP]\n", "[CLS] After that point, the quality of the translation deteriorates, with basic mistakes such as the lack of a closing quotation mark. [SEP]\n", "[CLS] Again, the RNNsearch-50 was able to translate this long sentence correctly: Ce genre d'exp\u00e9rience fait partie des efforts de Disney pour \"prolonger la dur\u00e9e de vie de ses s\u00e9ries et cr\u00e9er de nouvelles relations avec des publics via des plateformes num\u00e9riques de plus en plus importantes\", a-t-il ajout\u00e9. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] In conjunction with the quantitative results presented already, these qualitative observations confirm our hypotheses that the RNNsearch architecture enables far more reliable translation of long sentences than the standard RNNencdec model. [SEP]\n", "[CLS] In Appendix\u00a0, we provide a few more sample translations of long source sentences generated by the RNNencdec-50, RNNsearch-50 and Google Translate along with the reference translations. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Related Work Learning to Align A similar approach of aligning an output symbol with an input symbol was proposed recently by {{cite:18b900c2-93b0-4e22-9fda-4e0e408ede35}} in the context of handwriting synthesis. [SEP]\n", "[CLS] Handwriting synthesis is a task where the model is asked to generate handwriting of a given sequence of characters. [SEP]\n", "[CLS] In his work, he used a mixture of Gaussian kernels to compute the weights of the annotations, where the location, width and mixture coefficient of each kernel was predicted from an alignment model. [SEP]\n", "[CLS] More specifically, his alignment was restricted to predict the location such that the location increases monotonically. [SEP]\n", "[CLS] The main difference from our approach is that, in {{cite:18b900c2-93b0-4e22-9fda-4e0e408ede35}}, the modes of the weights of the annotations only move in one direction. [SEP]\n", "[CLS] In the context of machine translation, this is a severe limitation, as (long-distance) reordering is often needed to generate a grammatically correct translation (for instance, English-to-German). [SEP]\n", "[CLS] Our approach, on the other hand, requires computing the annotation weight of every word in the source sentence for each word in the translation. [SEP]\n", "[CLS] This drawback is not severe with the task of translation in which most of input and output sentences are only 15\u201340 words. [SEP]\n", "[CLS] However, this may limit the applicability of the proposed scheme to other tasks. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Neural Networks for Machine Translation Since {{cite:480e1827-cd75-4b41-b0f0-3175c17e0526}} introduced a neural probabilistic language model which uses a neural network to model the conditional probability of a word given a fixed number of the preceding words, neural networks have widely been used in machine translation. [SEP]\n", "[CLS] However, the role of neural networks has been largely limited to simply providing a single feature to an existing statistical machine translation system or to re-rank a list of candidate translations provided by an existing system. [SEP]\n", "[CLS] For instance, {{cite:9782d0ee-13f5-4f75-b813-5fb04c48f824}} proposed using a feedforward neural network to compute the score of a pair of source and target phrases and to use the score as an additional feature in the phrase-based statistical machine translation system. [SEP]\n", "[CLS] More recently, {{cite:19bdcb58-5818-4ba3-ad07-1a5f2a943ad1}} and {{cite:4efbd25b-3bad-4004-807f-2467f8c6eacd}} reported the successful use of the neural networks as a sub-component of the existing translation system. [SEP]\n", "[CLS] Traditionally, a neural network trained as a target-side language model has been used to rescore or rerank a list of candidate translations\u00a0{{cite:816f674c-4e5b-4289-abc2-3a02e5baa351}}. [SEP]\n", "[CLS] Although the above approaches were shown to improve the translation performance over the state-of-the-art machine translation systems, we are more interested in a more ambitious objective of designing a completely new translation system based on neural networks. [SEP]\n", "[CLS] The neural machine translation approach we consider in this paper is therefore a radical departure from these earlier works. [SEP]\n", "[CLS] Rather than using a neural network as a part of the existing system, our model works on its own and generates a translation from a source sentence directly. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusion The conventional approach to neural machine translation, called an encoder\u2013decoder approach, encodes a whole input sentence into a fixed-length vector from which a translation will be decoded. [SEP]\n", "[CLS] We conjectured that the use of a fixed-length context vector is problematic for translating long sentences, based on a recent empirical study reported by {{cite:5b4f7736-0251-47fc-b34e-b0199bcf4313}} and {{cite:9610702b-da62-4299-8de3-0d92391733cc}}. [SEP]\n", "[CLS] In this paper, we proposed a novel architecture that addresses this issue. [SEP]\n", "[CLS] We extended the basic encoder\u2013decoder by letting a model (soft-)search for a set of input words, or their annotations computed by an encoder, when generating each target word. [SEP]\n", "[CLS] This frees the model from having to encode a whole source sentence into a fixed-length vector, and also lets the model focus only on information relevant to the generation of the next target word. [SEP]\n", "[CLS] This has a major positive impact on the ability of the neural machine translation system to yield good results on longer sentences. [SEP]\n", "[CLS] Unlike with the traditional machine translation systems, all of the pieces of the translation system, including the alignment mechanism, are jointly trained towards a better log-probability of producing correct translations. [SEP]\n", "[CLS] We tested the proposed model, called RNNsearch, on the task of English-to-French translation. [SEP]\n", "[CLS] The experiment revealed that the proposed RNNsearch outperforms the conventional encoder\u2013decoder model (RNNencdec) significantly, regardless of the sentence length and that it is much more robust to the length of a source sentence. [SEP]\n", "[CLS] From the qualitative analysis where we investigated the (soft-)alignment generated by the RNNsearch, we were able to conclude that the model can correctly align each target word with the relevant words, or their annotations, in the source sentence as it generated a correct translation. [SEP]\n", "[CLS] Perhaps more importantly, the proposed approach achieved a translation performance comparable to the existing phrase-based statistical machine translation. [SEP]\n", "[CLS] It is a striking result, considering that the proposed architecture, or the whole family of neural machine translation, has only been proposed as recently as this year. [SEP]\n", "[CLS] We believe the architecture proposed here is a promising step toward better machine translation and a better understanding of natural languages in general. [SEP]\n", "[CLS] One of challenges left for the future is to better handle unknown, or rare words. [SEP]\n", "[CLS] This will be required for the model to be more widely used and to match the performance of current state-of-the-art machine translation systems in all contexts. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Acknowledgments The authors would like to thank the developers of Theano\u00a0{{cite:e8fc21ae-cc62-4194-a2f6-09c28418a8c5}}, {{cite:6d9e385b-d969-4555-bfff-67b868bbc70d}}. [SEP]\n", "[CLS] We acknowledge the support of the following agencies for research funding and computing support: NSERC, Calcul Qu\u00e9bec, Compute Canada, the Canada Research Chairs and CIFAR. [SEP]\n", "[CLS] Bahdanau thanks the support from Planet Intelligent Systems GmbH. We also thank Felix Hill, Bart van Merri\u00e9nboer, Jean Pouget-Abadie, Coline Devin and Tae-Ho Kim. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Model Architecture Architectural Choices [SEP]\n", "[CLS] The proposed scheme in Section\u00a0 is a general framework where one can freely define, for instance, the activation functions FORMULA  of recurrent neural networks (RNN) and the alignment model FORMULA . [SEP]\n", "[CLS] Here, we describe the choices we made for the experiments in this paper. [SEP]\n", "[CLS] Recurrent Neural Network [SEP]\n", "[CLS] For the activation function FORMULA  of an RNN, we use the gated hidden unit recently proposed by {{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}}. [SEP]\n", "[CLS] The gated hidden unit is an alternative to the conventional simple units such as an element-wise FORMULA . [SEP]\n", "[CLS] This gated unit is similar to a long short-term memory (LSTM) unit proposed earlier by {{cite:4f0585d0-26c7-4c86-bedc-f92691fd8f5a}}, sharing with it the ability to better model and learn long-term dependencies. [SEP]\n", "[CLS] This is made possible by having computation paths in the unfolded RNN for which the product of derivatives is close to 1. [SEP]\n", "[CLS] These paths allow gradients to flow backward easily without suffering too much from the vanishing effect\u00a0{{cite:2c4d5de6-cae2-4fe0-9911-e1ee3d9750a3}}, {{cite:90993d11-c5ae-4546-b83c-19960ee04b2b}}, {{cite:e3ae5c35-53f8-41f5-9d29-3fe351435872}}. [SEP]\n", "[CLS] It is therefore possible to use LSTM units instead of the gated hidden unit described here, as was done in a similar context by {{cite:5041425c-ca9f-4613-b854-cc45bf859b06}}. [SEP]\n", "[CLS] The new state FORMULA  of the RNN employing FORMULA  gated hidden unitsHere, we show the formula of the decoder. [SEP]\n", "[CLS] The same formula can be used in the encoder by simply ignoring the context vector FORMULA  and the related terms. is computed by FORMULA   where FORMULA  is an element-wise multiplication, and FORMULA  is the output of the update gates (see below). [SEP]\n", "[CLS] The proposed updated state FORMULA  is computed by FORMULA   where FORMULA  is an FORMULA -dimensional embedding of a word FORMULA , and FORMULA  is the output of the reset gates (see below). [SEP]\n", "[CLS] When FORMULA  is represented as a 1-of-FORMULA  vector, FORMULA  is simply a column of an embedding matrix FORMULA . [SEP]\n", "[CLS] Whenever possible, we omit bias terms to make the equations less cluttered. [SEP]\n", "[CLS] The update gates FORMULA  allow each hidden unit to maintain its previous activation, and the reset gates FORMULA  control how much and what information from the previous state should be reset. [SEP]\n", "[CLS] We compute them by FORMULA   where FORMULA  is a logistic sigmoid function. [SEP]\n", "[CLS] At each step of the decoder, we compute the output probability (Eq.\u00a0(REF )) as a multi-layered function\u00a0{{cite:309bfcfe-3ab2-4483-a401-c11c71f31ab3}}. [SEP]\n", "[CLS] We use a single hidden layer of maxout units\u00a0{{cite:fc44e35a-dcfd-4537-889e-efcbfcc49a16}} and normalize the output probabilities (one for each word) with a softmax function (see Eq.\u00a0(REF )). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Alignment Model [SEP]\n", "[CLS] The alignment model should be designed considering that the model needs to be evaluated FORMULA  times for each sentence pair of lengths FORMULA  and FORMULA . [SEP]\n", "[CLS] In order to reduce computation, we use a single-layer multilayer perceptron such that FORMULA   where FORMULA  and FORMULA  are the weight matrices. [SEP]\n", "[CLS] Since FORMULA  does not depend on FORMULA , we can pre-compute it in advance to minimize the computational cost. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Detailed Description of the Model Encoder In this section, we describe in detail the architecture of the proposed model (RNNsearch) used in the experiments (see Sec.\u00a0\u2013). [SEP]\n", "[CLS] From here on, we omit all bias terms in order to increase readability. [SEP]\n", "[CLS] The model takes a source sentence of 1-of-K coded word vectors as input FORMULA  and outputs a translated sentence of 1-of-K coded word vectors FORMULA  where FORMULA  and FORMULA  are the vocabulary sizes of source and target languages, respectively. [SEP]\n", "[CLS] FORMULA  and FORMULA  respectively denote the lengths of source and target sentences. [SEP]\n", "[CLS] First, the forward states of the bidirectional recurrent neural network (BiRNN) are computed: FORMULA   where FORMULA   FORMULA  is the word embedding matrix. [SEP]\n", "[CLS] FORMULA , FORMULA  are weight matrices. [SEP]\n", "[CLS] FORMULA  and FORMULA  are the word embedding dimensionality and the number of hidden units, respectively. [SEP]\n", "[CLS] FORMULA  is as usual a logistic sigmoid function. [SEP]\n", "[CLS] The backward states FORMULA  are computed similarly. [SEP]\n", "[CLS] We share the word embedding matrix FORMULA  between the forward and backward RNNs, unlike the weight matrices. [SEP]\n", "[CLS] We concatenate the forward and backward states to to obtain the annotations FORMULA , where FORMULA   Decoder The hidden state FORMULA  of the decoder given the annotations from the encoder is computed by FORMULA   where FORMULA   FORMULA  is the word embedding matrix for the target language. [SEP]\n", "[CLS] FORMULA , FORMULA , and FORMULA  are weights. [SEP]\n", "[CLS] Again, FORMULA  and FORMULA  are the word embedding dimensionality and the number of hidden units, respectively. [SEP]\n", "[CLS] The initial hidden state FORMULA  is computed by FORMULA  where FORMULA . [SEP]\n", "[CLS] The context vector FORMULA  are recomputed at each step by the alignment model: FORMULA   where FORMULA   and FORMULA  is the FORMULA -th annotation in the source sentence (see Eq.\u00a0(REF )). [SEP]\n", "[CLS] FORMULA  and FORMULA  are weight matrices. [SEP]\n", "[CLS] Note that the model becomes RNN Encoder\u2013Decoder\u00a0{{cite:9f8ac79d-f5cd-4338-ad01-cc35eddb54c4}}, if we fix FORMULA  to FORMULA . [SEP]\n", "[CLS] With the decoder state FORMULA , the context FORMULA  and the last generated word FORMULA , we define the probability of a target word FORMULA  as FORMULA   where FORMULA   and FORMULA  is the FORMULA -th element of a vector FORMULA  which is computed by FORMULA   FORMULA , FORMULA , FORMULA  and FORMULA  are weight matrices. [SEP]\n", "[CLS] This can be understood as having a deep output\u00a0{{cite:309bfcfe-3ab2-4483-a401-c11c71f31ab3}} with a single maxout hidden layer\u00a0{{cite:fc44e35a-dcfd-4537-889e-efcbfcc49a16}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Model Size [SEP]\n", "[CLS] For all the models used in this paper, the size of a hidden layer FORMULA  is 1000, the word embedding dimensionality FORMULA  is 620 and the size of the maxout hidden layer in the deep output FORMULA  is 500. [SEP]\n", "[CLS] The number of hidden units in the alignment model FORMULA  is 1000. [SEP]\n", "[CLS] TABLE    [SEP]\n", "[CLS] Training Procedure Parameter Initialization We initialized the recurrent weight matrices FORMULA  and FORMULA  as random orthogonal matrices. [SEP]\n", "[CLS] For FORMULA  and FORMULA , we initialized them by sampling each element from the Gaussian distribution of mean 0 and variance FORMULA . [SEP]\n", "[CLS] All the elements of FORMULA  and all the bias vectors were initialized to zero. [SEP]\n", "[CLS] Any other weight matrix was initialized by sampling from the Gaussian distribution of mean 0 and variance FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Training We used the stochastic gradient descent (SGD) algorithm. [SEP]\n", "[CLS] Adadelta\u00a0{{cite:b592f8ea-5131-4e65-bb73-ad60953d12d4}} was used to automatically adapt the learning rate of each parameter (FORMULA  and FORMULA ). [SEP]\n", "[CLS] We explicitly normalized the FORMULA -norm of the gradient of the cost function each time to be at most a predefined threshold of 1, when the norm was larger than the threshold\u00a0{{cite:4339e633-8c8a-40b0-8921-f0576c248cfd}}. [SEP]\n", "[CLS] Each SGD update direction was computed with a minibatch of 80 sentences. [SEP]\n", "[CLS] At each update our implementation requires time proportional to the length of the longest sentence in a minibatch. [SEP]\n", "[CLS] Hence, to minimize the waste of computation, before every 20-th update, we retrieved 1600 sentence pairs, sorted them according to the lengths and split them into 20 minibatches. [SEP]\n", "[CLS] The training data was shuffled once before training and was traversed sequentially in this manner. [SEP]\n", "[CLS] In Tables\u00a0REF  we present the statistics related to training all the models used in the experiments. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Translations of Long Sentences [SEP]\n", "[CLS] TABLE   [SEP]\n"], "1703.10593": ["[CLS]   [  Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks Jun-Yan Zhuempty Taesung Park[1] Phillip Isola Alexei A. Efros Berkeley AI Research (BAIR) laboratory, UC Berkeley 2020/09/12 02:14:04   FIGURE  figure Given any two unordered image collections FORMULA  and FORMULA , our algorithm learns to automatically \u201ctranslate\u201d an image from one into the other and vice versa: (left) Monet paintings and landscape photos from Flickr; (center) zebras and horses from ImageNet; (right) summer and winter Yosemite photos from Flickr. [SEP]\n", "[CLS] Example application (bottom): using a collection of paintings of famous artists, our method learns to render natural photographs into the respective styles. ]  Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. [SEP]\n", "[CLS] However, for many tasks, paired training data will not be available. [SEP]\n", "[CLS] We present an approach for learning to translate an image from a source domain FORMULA  to a target domain FORMULA  in the absence of paired examples. [SEP]\n", "[CLS] Our goal is to learn a mapping FORMULA  such that the distribution of images from FORMULA  is indistinguishable from the distribution FORMULA  using an adversarial loss. [SEP]\n", "[CLS] Because this mapping is highly under-constrained, we couple it with an inverse mapping FORMULA  and introduce a cycle consistency loss to enforce FORMULA  (and vice versa). [SEP]\n", "[CLS] Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. [SEP]\n", "[CLS] Quantitative comparisons against several prior methods demonstrate the superiority of our approach. [SEP]\n", "[CLS] Introduction What did Claude Monet see as he placed his easel by the bank of the Seine near Argenteuil on a lovely spring day in 1873 (Figure\u00a0REF , top-left)? [SEP]\n", "[CLS] A color photograph, had it been invented, may have documented a crisp blue sky and a glassy river reflecting it. [SEP]\n", "[CLS] Monet conveyed his impression of this same scene through wispy brush strokes and a bright palette. [SEP]\n", "[CLS] * indicates equal contribution [SEP]\n", "[CLS] What if Monet had happened upon the little harbor in Cassis on a cool summer evening (Figure\u00a0REF , bottom-left)? [SEP]\n", "[CLS] A brief stroll through a gallery of Monet paintings makes it possible to imagine how he would have rendered the scene: perhaps in pastel shades, with abrupt dabs of paint, and a somewhat flattened dynamic range. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] We can imagine all this despite never having seen a side by side example of a Monet painting next to a photo of the scene he painted. [SEP]\n", "[CLS] Instead, we have knowledge of the set of Monet paintings and of the set of landscape photographs. [SEP]\n", "[CLS] We can reason about the stylistic differences between these two sets, and thereby imagine what a scene might look like if we were to \u201ctranslate\u201d it from one set into the other. [SEP]\n", "[CLS] In this paper, we present a method that can learn to do the same: capturing special characteristics of one image collection and figuring out how these characteristics could be translated into the other image collection, all in the absence of any paired training examples. [SEP]\n", "[CLS] This problem can be more broadly described as image-to-image translation\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, converting an image from one representation of a given scene, FORMULA , to another, FORMULA , e.g., grayscale to color, image to semantic labels, edge-map to photograph. [SEP]\n", "[CLS] Years of research in computer vision, image processing, computational photography, and graphics have produced powerful translation systems in the supervised setting, where example image pairs FORMULA  are available (Figure\u00a0REF , left), e.g., {{cite:ec18221f-ec2a-47bb-be30-b672c05a937e}}, {{cite:b531e03b-9a04-4d44-ad63-f81fb133d42d}}, {{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, {{cite:774e6220-7987-445d-b2d3-661db45e701e}}, {{cite:22413f26-f3e1-431c-a1ba-b53456359661}}, {{cite:b6c09b7d-28d2-4601-847a-a20943e41aee}}, {{cite:561e4a65-d54d-46f0-9f3e-e4736b315972}}, {{cite:2fbed1f3-2e8a-4957-bb7e-dbf4a00ed0e3}}, {{cite:89bffe75-370e-4db9-919c-1177c0df95ba}}, {{cite:fa6e26c3-a07a-4904-bae4-698bdbaa852c}}. [SEP]\n", "[CLS] However, obtaining paired training data can be difficult and expensive. [SEP]\n", "[CLS] For example, only a couple of datasets exist for tasks like semantic segmentation (e.g.,\u00a0{{cite:b383ad7e-d8fb-4e55-bfbc-b88353c6b138}}), and they are relatively small. [SEP]\n", "[CLS] Obtaining input-output pairs for graphics tasks like artistic stylization can be even more difficult since the desired output is highly complex, typically requiring artistic authoring. [SEP]\n", "[CLS] For many tasks, like object transfiguration (e.g., zebraFORMULA horse, \u00a0Figure\u00a0REF  top-middle), the desired output is not even well-defined. [SEP]\n", "[CLS] We therefore seek an algorithm that can learn to translate between domains without paired input-output examples (Figure\u00a0REF , right). [SEP]\n", "[CLS] We assume there is some underlying relationship between the domains \u2013 for example, that they are two different renderings of the same underlying scene \u2013 and seek to learn that relationship. [SEP]\n", "[CLS] Although we lack supervision in the form of paired examples, we can exploit supervision at the level of sets: we are given one set of images in domain FORMULA  and a different set in domain FORMULA . [SEP]\n", "[CLS] We may train a mapping FORMULA  such that the output FORMULA , FORMULA , is indistinguishable from images FORMULA  by an adversary trained to classify FORMULA  apart from FORMULA . [SEP]\n", "[CLS] In theory, this objective can induce an output distribution over FORMULA  that matches the empirical distribution FORMULA  (in general, this requires FORMULA  to be stochastic)\u00a0{{cite:161d5480-762b-4573-aef7-cce9f9398296}}. [SEP]\n", "[CLS] The optimal FORMULA  thereby translates the domain FORMULA  to a domain FORMULA  distributed identically to FORMULA . [SEP]\n", "[CLS] However, such a translation does not guarantee that an individual input FORMULA  and output FORMULA  are paired up in a meaningful way \u2013 there are infinitely many mappings FORMULA  that will induce the same distribution over FORMULA . [SEP]\n", "[CLS] Moreover, in practice, we have found it difficult to optimize the adversarial objective in isolation: standard procedures often lead to the well-known problem of mode collapse, where all input images map to the same output image and the optimization fails to make progress\u00a0{{cite:6292e77e-f107-4051-8d3d-2d47f4e56a3e}}. [SEP]\n", "[CLS] These issues call for adding more structure to our objective. [SEP]\n", "[CLS] Therefore, we exploit the property that translation should be \u201ccycle consistent\", in the sense that if we translate, e.g., a sentence from English to French, and then translate it back from French to English, we should arrive back at the original sentence\u00a0{{cite:d366e593-db02-49c8-b8cc-b080b31c28f3}}. [SEP]\n", "[CLS] Mathematically, if we have a translator FORMULA  and another translator FORMULA , then FORMULA  and FORMULA  should be inverses of each other, and both mappings should be bijections. [SEP]\n", "[CLS] We apply this structural assumption by training both the mapping FORMULA  and FORMULA  simultaneously, and adding a cycle consistency loss\u00a0{{cite:c22912de-b2dd-47ff-b067-99e4cc7a2bc0}} that encourages FORMULA  and FORMULA . [SEP]\n", "[CLS] Combining this loss with adversarial losses on domains FORMULA  and FORMULA  yields our full objective for unpaired image-to-image translation. [SEP]\n", "[CLS] We apply our method to a wide range of applications, including collection style transfer, object transfiguration, season transfer and photo enhancement. [SEP]\n", "[CLS] We also compare against previous approaches that rely either on hand-defined factorizations of style and content, or on shared embedding functions, and show that our method outperforms these baselines. [SEP]\n", "[CLS] We provide both PyTorch and Torch implementations. [SEP]\n", "[CLS] Check out more results at our website. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Related work Generative Adversarial Networks (GANs)\u00a0{{cite:161d5480-762b-4573-aef7-cce9f9398296}}, {{cite:9e22807f-5226-42c6-ade6-cbbe77499066}} have achieved impressive results in image generation\u00a0{{cite:2fa61db6-9cc9-442d-9e62-72a982f4b2b4}}, {{cite:1e5fb9a0-391e-4561-9d9f-db09dfeab955}}, image editing\u00a0{{cite:c6c7fb40-bafc-4a1b-8a8a-a8e54f8c7820}}, and representation learning\u00a0{{cite:1e5fb9a0-391e-4561-9d9f-db09dfeab955}}, {{cite:a0f228bf-935d-4f27-bad9-5005c6acf775}}, {{cite:6a3d239c-220a-4a70-bcd2-8401dc8f495f}}. [SEP]\n", "[CLS] \u3000 Recent methods adopt the same idea for conditional image generation applications, such as text2image\u00a0{{cite:a16cbf2a-7d20-468f-b8a8-2850bc048cfe}}, image inpainting\u00a0{{cite:cf37395e-4fb7-424e-8eb8-5b307428faa7}}, and future prediction\u00a0{{cite:ab23070b-6dc0-4d81-8042-5f6fa5818489}}, as well as to other domains like videos\u00a0{{cite:c9d24afa-0919-4800-a6e7-4e25a99c7666}} and 3D data\u00a0{{cite:ecb05246-0587-4388-bea8-0bed2bac462d}}. [SEP]\n", "[CLS] The key to GANs' success is the idea of an adversarial loss that forces the generated images to be, in principle, indistinguishable from real photos. [SEP]\n", "[CLS] This loss is particularly powerful for image generation tasks, as this is exactly the objective that much of computer graphics aims to optimize. [SEP]\n", "[CLS] We adopt an adversarial loss to learn the mapping such that the translated images cannot be distinguished from images in the target domain. [SEP]\n", "[CLS] Image-to-Image Translation [SEP]\n", "[CLS] The idea of image-to-image translation goes back at least to Hertzmann et al.'s [SEP]\n", "[CLS] Image Analogies\u00a0{{cite:b531e03b-9a04-4d44-ad63-f81fb133d42d}}, who employ a non-parametric texture model\u00a0{{cite:63c296ed-fa0b-4856-ab3d-470e71d1d8c3}} on a single input-output training image pair. [SEP]\n", "[CLS] More recent approaches use a dataset of input-output examples to learn a parametric translation function using CNNs (e.g.,\u00a0{{cite:b6c09b7d-28d2-4601-847a-a20943e41aee}}). [SEP]\n", "[CLS] Our approach builds on the \u201cpix2pix\" framework of Isola et al.\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, which uses a conditional generative adversarial network\u00a0{{cite:161d5480-762b-4573-aef7-cce9f9398296}} to learn a mapping from input to output images. [SEP]\n", "[CLS] Similar ideas have been applied to various tasks such as generating photographs from sketches\u00a0{{cite:399dcf7c-b493-4dbf-9129-59576a4125cf}} or from attribute and semantic layouts\u00a0{{cite:af46bab8-8a93-4f14-83d5-6538636e7295}}. [SEP]\n", "[CLS] However, unlike the above prior work, we learn the mapping without paired training examples. [SEP]\n", "[CLS] Unpaired Image-to-Image Translation Several other methods also tackle the unpaired setting, where the goal is to relate two data domains: FORMULA  and FORMULA . [SEP]\n", "[CLS] Rosales et al.\u00a0{{cite:7c97233a-286f-45dd-9942-fbf72a772568}} propose a Bayesian framework that includes a prior based on a patch-based Markov random field computed from a source image and a likelihood term obtained from multiple style images. [SEP]\n", "[CLS] More recently, CoGAN\u00a0{{cite:4e6d1845-2770-4991-8fdd-1d60d42365b8}} and cross-modal scene networks\u00a0{{cite:9c2c05ed-91cd-47f1-b941-078bd77979e2}} use a weight-sharing strategy to learn a common representation across domains. [SEP]\n", "[CLS] Concurrent to our method, Liu et al.\u00a0{{cite:8cb30510-2d3d-4fc8-a858-c56a459d3e5a}} extends the above framework with a combination of variational autoencoders\u00a0{{cite:b78ebe5a-0a07-4524-8be5-637649a7f832}} and generative adversarial networks\u00a0{{cite:161d5480-762b-4573-aef7-cce9f9398296}}. [SEP]\n", "[CLS] Another line of concurrent work\u00a0{{cite:79dbe4ce-e956-45fb-816b-b0e3126a4a19}}, {{cite:7a1c34c9-d49f-48f4-b7d9-a5376ec44d1b}}, {{cite:0a3b27f4-53d6-4050-a401-7730e9cc03b2}} encourages the input and output to share specific \u201ccontent\" features even though they may differ in \u201cstyle\u201c. [SEP]\n", "[CLS] These methods also use adversarial networks, with additional terms to enforce the output to be close to the input in a predefined metric space, such as class label space\u00a0{{cite:0a3b27f4-53d6-4050-a401-7730e9cc03b2}}, image pixel space\u00a0{{cite:79dbe4ce-e956-45fb-816b-b0e3126a4a19}}, and image feature space\u00a0{{cite:7a1c34c9-d49f-48f4-b7d9-a5376ec44d1b}}. [SEP]\n", "[CLS] Unlike the above approaches, our formulation does not rely on any task-specific, predefined similarity function between the input and output, nor do we assume that the input and output have to lie in the same low-dimensional embedding space. [SEP]\n", "[CLS] This makes our method a general-purpose solution for many vision and graphics tasks. [SEP]\n", "[CLS] We directly compare against several prior and contemporary approaches in Section\u00a0REF . [SEP]\n", "[CLS] Cycle Consistency [SEP]\n", "[CLS] The idea of using transitivity as a way to regularize structured data has a long history. [SEP]\n", "[CLS] In visual tracking, enforcing simple forward-backward consistency has been a standard trick for decades\u00a0{{cite:2f2f0ba3-e072-4efb-adea-826b88823a10}}, {{cite:82d31145-3956-462c-9ae7-6263f305feef}}. [SEP]\n", "[CLS] In the language domain, verifying and improving translations via \u201cback translation and reconciliation\u201d is a technique used by human translators\u00a0{{cite:d366e593-db02-49c8-b8cc-b080b31c28f3}} (including, humorously, by Mark Twain\u00a0{{cite:230f2b5b-c50b-4dbe-ada5-22bd034b15b7}}), as well as by machines\u00a0{{cite:679ec956-5af6-4622-a118-da97b5527857}}. [SEP]\n", "[CLS] More recently, higher-order cycle consistency has been used in structure from motion\u00a0{{cite:aa6268a8-6e76-4c7c-9f08-c9360fac447f}}, 3D shape matching\u00a0{{cite:ef9c5aec-e924-4d91-9903-049a18cf20e7}}, co-segmentation\u00a0{{cite:32dc82e2-9252-42f6-903f-8cf704df4428}}, dense semantic alignment\u00a0{{cite:8e9baa21-f7b7-4fff-bf26-65173eb11efd}}, {{cite:c22912de-b2dd-47ff-b067-99e4cc7a2bc0}}, and depth estimation\u00a0{{cite:9c944c29-1dde-4068-9b8c-bf35f680177c}}. [SEP]\n", "[CLS] Of these, Zhou et al.\u00a0{{cite:c22912de-b2dd-47ff-b067-99e4cc7a2bc0}} and Godard et al.\u00a0{{cite:9c944c29-1dde-4068-9b8c-bf35f680177c}} are most similar to our work, as they use a cycle consistency loss as a way of using transitivity to supervise CNN training. [SEP]\n", "[CLS] In this work, we are introducing a similar loss to push FORMULA  and FORMULA  to be consistent with each other. [SEP]\n", "[CLS] Concurrent with our work, in these same proceedings, Yi et al.\u00a0{{cite:736e9104-987d-43c9-8c49-3548d3aa31bb}} independently use a similar objective for unpaired image-to-image translation, inspired by dual learning in machine translation\u00a0{{cite:679ec956-5af6-4622-a118-da97b5527857}}. [SEP]\n", "[CLS] Neural Style Transfer\u00a0{{cite:887d3bde-4015-4a81-9f7f-ca5d6049d45d}}, {{cite:774e6220-7987-445d-b2d3-661db45e701e}}, {{cite:ecaceec6-18cb-40e8-aa57-f7ab102a98cc}}, {{cite:6a764894-c8e1-491f-8af6-cb627f684641}} is another way to perform image-to-image translation, which synthesizes a novel image by combining the content of one image with the style of another image (typically a painting) based on matching the Gram matrix statistics of pre-trained deep features. [SEP]\n", "[CLS] Our primary focus, on the other hand, is learning the mapping between two image collections, rather than between two specific images, by trying to capture correspondences between higher-level appearance structures. [SEP]\n", "[CLS] Therefore, our method can be applied to other tasks, such as paintingFORMULA  photo, object transfiguration, etc. [SEP]\n", "[CLS] where single sample transfer methods do not perform well. [SEP]\n", "[CLS] We compare these two methods in \u00a0Section\u00a0REF . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Formulation Our goal is to learn mapping functions between two domains FORMULA  and FORMULA  given training samples FORMULA  where FORMULA  and FORMULA  where  FORMULAWe often omit the subscript FORMULA  and FORMULA  for simplicity.. [SEP]\n", "[CLS] We denote the data distribution as FORMULA  and FORMULA . [SEP]\n", "[CLS] As illustrated in Figure\u00a0REF  (a), our model includes two mappings FORMULA  and FORMULA . [SEP]\n", "[CLS] In addition, we introduce two adversarial discriminators FORMULA  and FORMULA , where FORMULA  aims to distinguish between images FORMULA  and translated images FORMULA ; in the same way, FORMULA  aims to discriminate between FORMULA  and FORMULA . [SEP]\n", "[CLS] Our objective contains two types of terms: adversarial losses\u00a0{{cite:161d5480-762b-4573-aef7-cce9f9398296}} for matching the distribution of generated images to the data distribution in the target domain; and cycle consistency losses to prevent the learned mappings FORMULA  and FORMULA  from contradicting each other. [SEP]\n", "[CLS] Adversarial Loss [SEP]\n", "[CLS] We apply adversarial losses\u00a0{{cite:161d5480-762b-4573-aef7-cce9f9398296}} to both mapping functions. [SEP]\n", "[CLS] For the mapping function FORMULA  and its discriminator FORMULA , we express the objective as: FORMULA   where FORMULA  tries to generate images FORMULA  that look similar to images from domain FORMULA , while FORMULA  aims to distinguish between translated samples FORMULA  and real samples FORMULA . [SEP]\n", "[CLS] FORMULA  aims to minimize this objective against an adversary FORMULA  that tries to maximize it, i.e., FORMULA . [SEP]\n", "[CLS] We introduce a similar adversarial loss for the mapping function FORMULA  and its discriminator FORMULA  as well: i.e., FORMULA . [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Cycle Consistency Loss Adversarial training can, in theory, learn mappings FORMULA  and FORMULA  that produce outputs identically distributed as target domains FORMULA  and FORMULA  respectively (strictly speaking, this requires FORMULA  and FORMULA  to be stochastic functions)\u00a0{{cite:6292e77e-f107-4051-8d3d-2d47f4e56a3e}}. [SEP]\n", "[CLS] However, with large enough capacity, a network can map the same set of input images to any random permutation of images in the target domain, where any of the learned mappings can induce an output distribution that matches the target distribution. [SEP]\n", "[CLS] Thus, adversarial losses alone cannot guarantee that the learned function can map an individual input FORMULA  to a desired output FORMULA . [SEP]\n", "[CLS] To further reduce the space of possible mapping functions, we argue that the learned mapping functions should be cycle-consistent: as shown in Figure\u00a0REF  (b), for each image FORMULA  from domain FORMULA , the image translation cycle should be able to bring FORMULA  back to the original image, i.e., FORMULA . [SEP]\n", "[CLS] We call this forward cycle consistency. [SEP]\n", "[CLS] Similarly, as illustrated in Figure\u00a0REF  (c), for each image FORMULA  from domain FORMULA , FORMULA  and FORMULA  should also satisfy backward cycle consistency: FORMULA . [SEP]\n", "[CLS] We incentivize this behavior using a cycle consistency loss: FORMULA    [SEP]\n", "[CLS] In preliminary experiments, we also tried replacing the L1 norm in this loss with an adversarial loss between FORMULA  and FORMULA , and between FORMULA  and FORMULA , but did not observe improved performance. [SEP]\n", "[CLS] The behavior induced by the cycle consistency loss can be observed in Figure\u00a0REF : the reconstructed images FORMULA  end up matching closely to the input images FORMULA . [SEP]\n", "[CLS]   Full Objective [SEP]\n", "[CLS] Our full objective is: FORMULA   where FORMULA  controls the relative importance of the two objectives. [SEP]\n", "[CLS] We aim to solve: FORMULA   [SEP]\n", "[CLS] Notice that our model can be viewed as training two \u201cautoencoders\"\u00a0{{cite:f0fa5d71-db57-41b6-bf20-2ea8dc561663}}: we learn one autoencoder FORMULA  jointly with another FORMULA . [SEP]\n", "[CLS] However, these autoencoders each have special internal structures: they map an image to itself via an intermediate representation that is a translation of the image into another domain. [SEP]\n", "[CLS] Such a setup can also be seen as a special case of \u201cadversarial autoencoders\"\u00a0{{cite:d3aabd7b-a715-4770-89d8-5dadcc00d65d}}, which use an adversarial loss to train the bottleneck layer of an autoencoder to match an arbitrary target distribution. [SEP]\n", "[CLS] In our case, the target distribution for the FORMULA  autoencoder is that of the domain FORMULA . [SEP]\n", "[CLS] In Section\u00a0REF , we compare our method against ablations of the full objective, including the adversarial loss FORMULA  alone and the cycle consistency loss FORMULA  alone, and empirically show that both objectives play critical roles in arriving at high-quality results. [SEP]\n", "[CLS] We also evaluate our method with only cycle loss in one direction and show that a single cycle is not sufficient to regularize the training for this under-constrained problem. [SEP]\n", "[CLS]  Implementation Network Architecture [SEP]\n", "[CLS] We adopt the architecture for our generative networks from Johnson et al.\u00a0{{cite:774e6220-7987-445d-b2d3-661db45e701e}} who have shown impressive results for neural style transfer and super-resolution. [SEP]\n", "[CLS] This network contains two stride-2 convolutions, several residual blocks\u00a0{{cite:ce8116d0-4d78-4da8-8c39-9eae420ecacf}}, and two fractionally-strided convolutions with stride FORMULA . [SEP]\n", "[CLS] We use 6 blocks for FORMULA  images and 9 blocks for FORMULA  and higher-resolution training images. [SEP]\n", "[CLS] Similar to Johnson et al.\u00a0{{cite:774e6220-7987-445d-b2d3-661db45e701e}}, we use instance normalization\u00a0{{cite:04cfaba4-6a03-4ff5-b46d-f59071ff362a}}. [SEP]\n", "[CLS] For the discriminator networks we use FORMULA  PatchGANs\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, {{cite:62c29d6c-7fc3-40dd-8d30-8f2a3caf1f36}}, {{cite:b523f47b-b1be-43f6-8c00-e7108a4165ea}}, which aim to classify whether FORMULA  overlapping image patches are real or fake. [SEP]\n", "[CLS] Such a patch-level discriminator architecture has fewer parameters than a full-image discriminator and can work on arbitrarily-sized images in a fully convolutional fashion\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Training details We apply two techniques from recent works to stabilize our model training procedure. [SEP]\n", "[CLS] First, for FORMULA  (Equation\u00a0REF ), we replace the negative log likelihood objective by a least-squares loss\u00a0{{cite:37cc84ab-02fe-46b3-a70f-5236196efe8b}}. [SEP]\n", "[CLS] This loss is more stable during training and generates higher quality results. [SEP]\n", "[CLS] In particular, for a GAN loss FORMULA , we train the FORMULA  to minimize FORMULA  and train the FORMULA  to minimize FORMULA . [SEP]\n", "[CLS] Second, to reduce model oscillation\u00a0{{cite:6292e77e-f107-4051-8d3d-2d47f4e56a3e}}, we follow Shrivastava et al.'s strategy\u00a0{{cite:79dbe4ce-e956-45fb-816b-b0e3126a4a19}} and update the discriminators using a history of generated images rather than the ones produced by the latest generators. [SEP]\n", "[CLS] We keep an image buffer that stores the 50 previously created images. [SEP]\n", "[CLS] For all the experiments, we set FORMULA  in Equation\u00a0REF . [SEP]\n", "[CLS] We use the Adam solver\u00a0{{cite:ad2fc942-aa4d-43d5-b5cc-e99ff3d9f2a5}} with a batch size of 1. [SEP]\n", "[CLS] All networks were trained from scratch with a learning rate of FORMULA . [SEP]\n", "[CLS] We keep the same learning rate for the first 100 epochs and linearly decay the rate to zero over the next 100 epochs. [SEP]\n", "[CLS] Please see the appendix (Section\u00a0) for more details about the datasets, architectures, and training procedures. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Results We first compare our approach against recent methods for unpaired image-to-image translation on paired datasets where ground truth input-output pairs are available for evaluation. [SEP]\n", "[CLS] We then study the importance of both the adversarial loss and the cycle consistency loss and compare our full method against several variants. [SEP]\n", "[CLS] Finally, we demonstrate the generality of our algorithm on a wide range of applications where paired data does not exist. [SEP]\n", "[CLS] For brevity, we refer to our method as CycleGAN. [SEP]\n", "[CLS] The PyTorch and Torch code, models, and full results can be found at our website. [SEP]\n", "[CLS] Evaluation FIGURE  FIGURE  Using the same evaluation datasets and metrics as \u201cpix2pix\u201d\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, we compare our method against several baselines both qualitatively and quantitatively. [SEP]\n", "[CLS] The tasks include semantic labelsFORMULA photo on the Cityscapes dataset\u00a0{{cite:b383ad7e-d8fb-4e55-bfbc-b88353c6b138}}, and mapFORMULA aerial photo on data scraped from Google Maps. [SEP]\n", "[CLS] We also perform ablation study on the full loss function. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Evaluation Metrics  \u00a0\u00a0\u00a0 AMT perceptual studies On the mapFORMULA aerial photo task, we run \u201creal vs fake\" perceptual studies on Amazon Mechanical Turk (AMT) to assess the realism of our outputs. [SEP]\n", "[CLS] We follow the same perceptual study protocol from Isola et al.\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, except we only gather data from 25 participants per algorithm we tested. [SEP]\n", "[CLS] Participants were shown a sequence of pairs of images, one a real photo or map and one fake (generated by our algorithm or a baseline), and asked to click on the image they thought was real. [SEP]\n", "[CLS] The first 10 trials of each session were practice and feedback was given as to whether the participant's response was correct or incorrect. [SEP]\n", "[CLS] The remaining 40 trials were used to assess the rate at which each algorithm fooled participants. [SEP]\n", "[CLS] Each session only tested a single algorithm, and participants were only allowed to complete a single session. [SEP]\n", "[CLS] The numbers we report here are not directly comparable to those in\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}} as our ground truth images were processed slightly differently We train all the models on FORMULA  images while in pix2pix\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, the model was trained on FORMULA  patches of FORMULA  images, and run convolutionally on the FORMULA  images at test time. [SEP]\n", "[CLS] We choose FORMULA  in our experiments as many baselines cannot scale up to high-resolution images, and CoGAN cannot be tested fully convolutionally. [SEP]\n", "[CLS] and the participant pool we tested may be differently distributed from those tested in\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}} (due to running the experiment at a different date and time). [SEP]\n", "[CLS] Therefore, our numbers should only be used to compare our current method against the baselines (which were run under identical conditions), rather than against\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}. [SEP]\n", "[CLS] FCN score Although perceptual studies may be the gold standard for assessing graphical realism, we also seek an automatic quantitative measure that does not require human experiments. [SEP]\n", "[CLS] For this, we adopt the \u201cFCN score\" from\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, and use it to evaluate the Cityscapes labelsFORMULA photo task. [SEP]\n", "[CLS] The FCN metric evaluates how interpretable the generated photos are according to an off-the-shelf semantic segmentation algorithm (the fully-convolutional network, FCN, from\u00a0{{cite:b6c09b7d-28d2-4601-847a-a20943e41aee}}). [SEP]\n", "[CLS] The FCN predicts a label map for a generated photo. [SEP]\n", "[CLS] This label map can then be compared against the input ground truth labels using standard semantic segmentation metrics described below. [SEP]\n", "[CLS] The intuition is that if we generate a photo from a label map of \u201ccar on the road\", then we have succeeded if the FCN applied to the generated photo detects \u201ccar on the road\". [SEP]\n", "[CLS] Semantic segmentation metrics To evaluate the performance of photoFORMULA labels, we use the standard metrics from the Cityscapes benchmark\u00a0{{cite:b383ad7e-d8fb-4e55-bfbc-b88353c6b138}}, including per-pixel accuracy, per-class accuracy, and mean class Intersection-Over-Union (Class IOU)\u00a0{{cite:b383ad7e-d8fb-4e55-bfbc-b88353c6b138}}. [SEP]\n", "[CLS]   Baselines  \u00a0\u00a0\u00a0 CoGAN\u00a0{{cite:4e6d1845-2770-4991-8fdd-1d60d42365b8}} This method learns one GAN generator for domain FORMULA  and one for domain FORMULA , with tied weights on the first few layers for shared latent representations. [SEP]\n", "[CLS] Translation from FORMULA  to FORMULA  can be achieved by finding a latent representation that generates image FORMULA  and then rendering this latent representation into style FORMULA . [SEP]\n", "[CLS] SimGAN\u00a0{{cite:79dbe4ce-e956-45fb-816b-b0e3126a4a19}} Like our method, Shrivastava et al.{{cite:79dbe4ce-e956-45fb-816b-b0e3126a4a19}} uses an adversarial loss to train a translation from FORMULA  to FORMULA . [SEP]\n", "[CLS] The regularization term FORMULA   [SEP]\n", "[CLS] i s used to penalize making large changes at pixel level. [SEP]\n", "[CLS] Feature loss + GAN We also test a variant of SimGAN\u00a0{{cite:79dbe4ce-e956-45fb-816b-b0e3126a4a19}} where the L1 loss is computed over deep image features using a pretrained network (VGG-16 relu4_2\u00a0{{cite:61430e4e-8b5c-4368-b513-cd7537fe71f7}}), rather than over RGB pixel values. [SEP]\n", "[CLS] Computing distances in deep feature space, like this, is also sometimes referred to as using a \u201cperceptual loss\"\u00a0{{cite:f9b04987-016a-4362-aa62-680e433a7f8e}}, {{cite:774e6220-7987-445d-b2d3-661db45e701e}}. [SEP]\n", "[CLS] BiGAN/ALI\u00a0{{cite:4327d3d6-bca7-433e-9813-6cccc9097cdc}}, {{cite:a63a6b73-0d25-42b2-8292-3b5c379f0557}} Unconditional GANs\u00a0{{cite:161d5480-762b-4573-aef7-cce9f9398296}} learn a generator FORMULA , that maps a random noise FORMULA  to an image FORMULA . [SEP]\n", "[CLS] The BiGAN\u00a0{{cite:4327d3d6-bca7-433e-9813-6cccc9097cdc}} and ALI\u00a0{{cite:a63a6b73-0d25-42b2-8292-3b5c379f0557}} propose to also learn the inverse mapping function FORMULA . [SEP]\n", "[CLS] Though they were originally designed for mapping a latent vector FORMULA  to an image FORMULA , we implemented the same objective for mapping a source image FORMULA  to a target image FORMULA . [SEP]\n", "[CLS] pix2pix\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}} We also compare against pix2pix\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, which is trained on paired data, to see how close we can get to this \u201cupper bound\" without using any paired data. [SEP]\n", "[CLS] For a fair comparison, we implement all the baselines using the same architecture and details as our method, except for CoGAN\u00a0{{cite:4e6d1845-2770-4991-8fdd-1d60d42365b8}}. [SEP]\n", "[CLS] CoGAN builds on generators that produce images from a shared latent representation, which is incompatible with our image-to-image network. [SEP]\n", "[CLS] We use the public implementation of CoGAN instead. [SEP]\n", "[CLS] TABLE  TABLE  TABLE  FIGURE  TABLE [SEP]\n", "[CLS]  TABLE   Comparison against baselines As can be seen in Figure\u00a0REF  and Figure\u00a0REF , we were unable to achieve compelling results with any of the baselines. [SEP]\n", "[CLS] Our method, on the other hand, can produce translations that are often of similar quality to the fully supervised pix2pix. [SEP]\n", "[CLS] Table\u00a0REF  reports performance regarding the AMT perceptual realism task. [SEP]\n", "[CLS] Here, we see that our method can fool participants on around a quarter of trials, in both the mapsFORMULA aerial photos direction and the aerial photosFORMULA maps direction at FORMULA   [SEP]\n", "[CLS] resolutionWe also train CycleGAN and pix2pix at FORMULA  resolution, and observe the comparable performance: mapsFORMULA aerial photos: CycleGAN: FORMULA  and pix2pix: FORMULA ; aerial photosFORMULA maps: CycleGAN: FORMULA  and pix2pix:  FORMULA. [SEP]\n", "[CLS] All the baselines almost never fooled participants. [SEP]\n", "[CLS] Table\u00a0REF  assesses the performance of the labelsFORMULA photo task on the Cityscapes and Table\u00a0REF  evaluates the opposite mapping (photosFORMULA labels). [SEP]\n", "[CLS] In both cases, our method again outperforms the baselines. [SEP]\n", "[CLS]   Analysis of the loss function   [SEP]\n", "[CLS] In Table\u00a0REF  and Table\u00a0REF , we compare against ablations of our full loss. [SEP]\n", "[CLS] Removing the GAN loss substantially degrades results, as does removing the cycle-consistency loss. [SEP]\n", "[CLS] We therefore conclude that both terms are critical to our results. [SEP]\n", "[CLS] We also evaluate our method with the cycle loss in only one direction: GAN + forward cycle loss FORMULA , or GAN + backward cycle loss FORMULA  (Equation\u00a0REF ) and find that it often incurs training instability and causes mode collapse, especially for the direction of the mapping that was removed. [SEP]\n", "[CLS] Figure\u00a0REF  shows several qualitative examples. [SEP]\n", "[CLS]   Image reconstruction quality   [SEP]\n", "[CLS] In Figure\u00a0REF , we show a few random samples of the reconstructed images FORMULA . [SEP]\n", "[CLS] We observed that the reconstructed images were often close to the original inputs FORMULA , at both training and testing time, even in cases where one domain represents significantly more diverse information, such as mapFORMULA aerial photos. [SEP]\n", "[CLS] FIGURE     [SEP]\n", "[CLS] Additional results on paired datasets   [SEP]\n", "[CLS] Figure\u00a0REF  shows some example results on other paired datasets used in \u201cpix2pix\u201d\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}, such as architectural labelsFORMULA photos from the CMP Facade Database\u00a0{{cite:b2faed8b-2e67-4e57-9f5d-28f72e3028e2}}, and edgesFORMULA shoes from the UT Zappos50K dataset\u00a0{{cite:642f7077-cb3f-4b01-b0da-ae0aae3b3be1}}. [SEP]\n", "[CLS] The image quality of our results is close to those produced by the fully supervised pix2pix while our method learns the mapping without paired supervision. [SEP]\n", "[CLS]   Applications   [SEP]\n", "[CLS] We demonstrate our method on several applications where paired training data does not exist. [SEP]\n", "[CLS] Please refer to the appendix (Section\u00a0) for more details about the datasets. [SEP]\n", "[CLS] We observe that translations on training data are often more appealing than those on test data, and full results of all applications on both training and test data can be viewed on our project website. [SEP]\n", "[CLS] Collection style transfer (Figure\u00a0REF  and \u00a0Figure\u00a0REF ) We train the model on landscape photographs downloaded from Flickr and WikiArt. [SEP]\n", "[CLS] Unlike recent work on \u201cneural style transfer\"\u00a0{{cite:887d3bde-4015-4a81-9f7f-ca5d6049d45d}}, our method learns to mimic the style of an entire collection of artworks, rather than transferring the style of a single selected piece of art. [SEP]\n", "[CLS] Therefore, we can learn to generate photos in the style of, e.g., Van Gogh, rather than just in the style of Starry Night. [SEP]\n", "[CLS] The size of the dataset for each artist/style was 526, 1073, 400, and 563 for Cezanne, Monet, Van Gogh, and Ukiyo-e. Object transfiguration (Figure\u00a0REF ) The model is trained to translate one object class from ImageNet\u00a0{{cite:56bb345b-0a2a-401e-a361-95a834703bc5}} to another (each class contains around 1000 training images). [SEP]\n", "[CLS] Turmukhambetov et al.\u00a0{{cite:6f9acdf8-ddf0-4f4f-98dd-7718a8e9cb44}} propose a subspace model to translate one object into another object of the same category, while our method focuses on object transfiguration between two visually similar categories. [SEP]\n", "[CLS] Season transfer (Figure\u00a0REF ) The model is trained on 854 winter photos and 1273 summer photos of Yosemite downloaded from Flickr. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Photo generation from paintings (Figure\u00a0REF ) For paintingFORMULA photo, we find that it is helpful to introduce an additional loss to encourage the mapping to preserve color composition between the input and output. [SEP]\n", "[CLS] In particular, we adopt the technique of Taigman et al.\u00a0{{cite:7a1c34c9-d49f-48f4-b7d9-a5376ec44d1b}} and regularize the generator to be near an identity mapping when real samples of the target domain are provided as the input to the generator: i.e.,  FORMULA Without FORMULA , the generator FORMULA  and FORMULA  are free to change the tint of input images when there is no need to. [SEP]\n", "[CLS] For example, when learning the mapping between Monet's paintings and Flickr photographs, the generator often maps paintings of daytime to photographs taken during sunset, because such a mapping may be equally valid under the adversarial loss and cycle consistency loss. [SEP]\n", "[CLS] The effect of this identity mapping loss are shown in Figure\u00a0REF . [SEP]\n", "[CLS] In Figure\u00a0REF , we show additional results translating Monet's paintings to photographs. [SEP]\n", "[CLS] This figure and Figure\u00a0REF  show results on paintings that were included in the training set, whereas for all other experiments in the paper, we only evaluate and show test set results. [SEP]\n", "[CLS] Because the training set does not include paired data, coming up with a plausible translation for a training set painting is a nontrivial task. [SEP]\n", "[CLS] Indeed, since Monet is no longer able to create new paintings, generalization to unseen, \u201ctest set\", paintings is not a pressing problem. [SEP]\n", "[CLS] Photo enhancement (Figure\u00a0REF ) We show that our method can be used to generate photos with shallower depth of field. [SEP]\n", "[CLS] We train the model on flower photos downloaded from Flickr. [SEP]\n", "[CLS] The source domain consists of flower photos taken by smartphones, which usually have deep DoF due to a small aperture. [SEP]\n", "[CLS] The target contains photos captured by DSLRs with a larger aperture. [SEP]\n", "[CLS] Our model successfully generates photos with shallower depth of field from the photos taken by smartphones. [SEP]\n", "[CLS] Comparison with Gatys et al.\u00a0{{cite:887d3bde-4015-4a81-9f7f-ca5d6049d45d}} In \u00a0Figure\u00a0REF , we compare our results with neural style transfer\u00a0{{cite:887d3bde-4015-4a81-9f7f-ca5d6049d45d}} on photo stylization. [SEP]\n", "[CLS] For each row, we first use two representative artworks as the style images for \u00a0{{cite:887d3bde-4015-4a81-9f7f-ca5d6049d45d}}. [SEP]\n", "[CLS] Our method, on the other hand, can produce photos in the style of entire collection. [SEP]\n", "[CLS] To compare against neural style transfer of an entire collection, we compute the average Gram Matrix across the target domain and use this matrix to transfer the \u201caverage style\" with Gatys et al\u00a0{{cite:887d3bde-4015-4a81-9f7f-ca5d6049d45d}}. [SEP]\n", "[CLS] Figure\u00a0REF  demonstrates similar comparisons for other translation tasks. [SEP]\n", "[CLS] We observe that Gatys et al.\u00a0{{cite:887d3bde-4015-4a81-9f7f-ca5d6049d45d}} requires finding target style images that closely match the desired output, but still often fails to produce photorealistic results, while our method succeeds to generate natural-looking results, similar to the target domain. [SEP]\n", "[CLS]  Limitations and Discussion Although our method can achieve compelling results in many cases, the results are far from uniformly positive. [SEP]\n", "[CLS] Figure\u00a0REF  shows several typical failure cases. [SEP]\n", "[CLS] On translation tasks that involve color and texture changes, like many of those reported above, the method often succeeds. [SEP]\n", "[CLS] We have also explored tasks that require geometric changes, with little success. [SEP]\n", "[CLS] For example, on the task of dogFORMULA cat transfiguration, the learned translation degenerates into making minimal changes to the input (Figure\u00a0REF ). [SEP]\n", "[CLS] This failure might be caused by our generator architectures which are tailored for good performance on the appearance changes. [SEP]\n", "[CLS] Handling more varied and extreme transformations, especially geometric changes, is an important problem for future work. [SEP]\n", "[CLS] Some failure cases are caused by the distribution characteristics of the training datasets. [SEP]\n", "[CLS] For example, our method has got confused in the horse FORMULA  zebra example [SEP]\n", "[CLS] (Figure\u00a0REF , right), because our model was trained on the wild horse and zebra synsets of ImageNet, which does not contain images of a person riding a horse or zebra. [SEP]\n", "[CLS] We also observe a lingering gap between the results achievable with paired training data and those achieved by our unpaired method. [SEP]\n", "[CLS] In some cases, this gap may be very hard \u2013 or even impossible \u2013 to close: for example, our method sometimes permutes the labels for tree and building in the output of the photosFORMULA labels task. [SEP]\n", "[CLS] To resolve this ambiguity may require some form of weak semantic supervision. [SEP]\n", "[CLS] Integrating weak or semi-supervised data may lead to substantially more powerful translators, still at a fraction of the annotation cost of the fully-supervised systems. [SEP]\n", "[CLS] Nonetheless, in many cases completely unpaired data is plentifully available and should be made use of. [SEP]\n", "[CLS] This paper pushes the boundaries of what is possible in this \u201cunsupervised\" setting. [SEP]\n", "[CLS] Acknowledgments: We thank Aaron Hertzmann, Shiry Ginosar, Deepak Pathak, Bryan Russell, Eli Shechtman, Richard Zhang, and Tinghui Zhou for many helpful comments. [SEP]\n", "[CLS] This work was supported in part by NSF SMA-1514512, NSF IIS-1633310, a Google Research Award, Intel Corp, and hardware donations from NVIDIA. [SEP]\n", "[CLS] JYZ is supported by the Facebook Graduate Fellowship and TP is supported by the Samsung Scholarship. [SEP]\n", "[CLS] The photographs used for style transfer were taken by AE, mostly in France. [SEP]\n", "[CLS] FIGURE  FIGURE  FIGURE  FIGURE  FIGURE  FIGURE  FIGURE  FIGURE    [SEP]\n", "[CLS] Appendix Training details We train our networks from scratch, with a learning rate of FORMULA . [SEP]\n", "[CLS] In practice, we divide the objective by 2 while optimizing FORMULA , which slows down the rate at which FORMULA  learns, relative to the rate of FORMULA . [SEP]\n", "[CLS] We keep the same learning rate for the first 100 epochs and linearly decay the rate to zero over the next 100 epochs. [SEP]\n", "[CLS] Weights are initialized from a Gaussian distribution FORMULA . [SEP]\n", "[CLS] Cityscapes labelFORMULA Photo 2975 training images from the Cityscapes training set {{cite:b383ad7e-d8fb-4e55-bfbc-b88353c6b138}} with image size FORMULA . [SEP]\n", "[CLS] We used the Cityscapes val set for testing. [SEP]\n", "[CLS] MapsFORMULA aerial photograph 1096 training images were scraped from Google Maps\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}} with image size FORMULA . [SEP]\n", "[CLS] Images were sampled from in and around New York City. [SEP]\n", "[CLS] Data was then split into train and test about the median latitude of the sampling region (with a buffer region added to ensure that no training pixel appeared in the test set). [SEP]\n", "[CLS] Architectural facades labelsFORMULA photo 400 training images from the CMP Facade Database\u00a0{{cite:b2faed8b-2e67-4e57-9f5d-28f72e3028e2}}. [SEP]\n", "[CLS] EdgesFORMULA shoes around FORMULA  training images from UT Zappos50K dataset\u00a0{{cite:642f7077-cb3f-4b01-b0da-ae0aae3b3be1}}. [SEP]\n", "[CLS] The model was trained for 5 epochs. [SEP]\n", "[CLS] HorseFORMULA Zebra and AppleFORMULA Orange [SEP]\n", "[CLS] We downloaded the images from ImageNet\u00a0{{cite:56bb345b-0a2a-401e-a361-95a834703bc5}} using keywords wild horse, zebra, apple, and navel orange. [SEP]\n", "[CLS] The images were scaled to FORMULA  pixels. [SEP]\n", "[CLS] The training set size of each class: 939 (horse), 1177 (zebra), 996 (apple), and 1020 (orange). [SEP]\n", "[CLS] SummerFORMULA Winter Yosemite The images were downloaded using Flickr API with the tag yosemite and the datetaken field. [SEP]\n", "[CLS] Black-and-white photos were pruned. [SEP]\n", "[CLS] The images were scaled to FORMULA  pixels. [SEP]\n", "[CLS] The training size of each class: 1273 (summer) and 854 ( winter). [SEP]\n", "[CLS] PhotoFORMULA Art for style transfer The art images were downloaded from Wikiart.org. [SEP]\n", "[CLS] Some artworks that were sketches or too obscene were pruned by hand. [SEP]\n", "[CLS] The photos were downloaded from Flickr using the combination of tags landscape and landscapephotography. [SEP]\n", "[CLS] Black-and-white photos were pruned. [SEP]\n", "[CLS] The images were scaled to FORMULA  pixels. [SEP]\n", "[CLS] The training set size of each class was 1074 (Monet), 584 (Cezanne), 401 (Van Gogh), 1433 (Ukiyo-e), and 6853 (Photographs). [SEP]\n", "[CLS] The Monet dataset was particularly pruned to include only landscape paintings, and the Van Gogh dataset included only his later works that represent his most recognizable artistic style. [SEP]\n", "[CLS] Monet's paintingsFORMULA photos To achieve high resolution while conserving memory, we used random square crops of the original images for training. [SEP]\n", "[CLS] To generate results, we passed images of width 512 pixels with correct aspect ratio to the generator network as input. [SEP]\n", "[CLS] The weight for the identity mapping loss was FORMULA  where FORMULA  was the weight for cycle consistency loss. [SEP]\n", "[CLS] We set FORMULA . [SEP]\n", "[CLS] Flower photo enhancement Flower images taken on smartphones were downloaded from Flickr by searching for the photos taken by Apple iPhone 5, 5s, or 6, with search text flower. [SEP]\n", "[CLS] DSLR images with shallow DoF were also downloaded from Flickr by search tag flower, dof. [SEP]\n", "[CLS] The images were scaled to 360 pixels by width. [SEP]\n", "[CLS] The identity mapping loss of weight FORMULA  was used. [SEP]\n", "[CLS] The training set size of the smartphone and DSLR dataset were 1813 and 3326, respectively. [SEP]\n", "[CLS] We set FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Network architectures We provide both PyTorch and Torch implementations. [SEP]\n", "[CLS] Generator architectures We adopt our architectures from Johnson et al.\u00a0{{cite:774e6220-7987-445d-b2d3-661db45e701e}}. [SEP]\n", "[CLS] We use 6 residual blocks for FORMULA  training images, and 9 residual blocks for FORMULA  or higher-resolution training images. [SEP]\n", "[CLS] Below, we follow the naming convention used in the Johnson et al.'s [SEP]\n", "[CLS] Github repository. [SEP]\n", "[CLS] Let c7s1-k denote a FORMULA   [SEP]\n", "[CLS] Convolution-InstanceNorm-ReLU layer with FORMULA  filters and stride 1. [SEP]\n", "[CLS] dk denotes a FORMULA   [SEP]\n", "[CLS] Convolution-InstanceNorm-ReLU layer with FORMULA  filters and stride 2. [SEP]\n", "[CLS] Reflection padding was used to reduce artifacts. [SEP]\n", "[CLS] Rk denotes a residual block that contains two FORMULA  convolutional layers with the same number of filters on both layer. [SEP]\n", "[CLS] uk denotes a FORMULA  fractional-strided-Convolution-InstanceNorm-ReLU layer with FORMULA  filters and stride FORMULA . [SEP]\n", "[CLS] The network with 6 residual blocks consists of: c7s1-64,d128,d256,R256,R256,R256, R256,R256,R256,u128,u64,c7s1-3 The network with 9 residual blocks consists of: c7s1-64,d128,d256,R256,R256,R256, R256,R256,R256,R256,R256,R256,u128 u64,c7s1-3 Discriminator architectures For discriminator networks, we use FORMULA  PatchGAN\u00a0{{cite:904d36fb-ee48-4d0c-8c29-8e2682855ba7}}. [SEP]\n", "[CLS] Let Ck denote a FORMULA   [SEP]\n", "[CLS] Convolution-InstanceNorm-LeakyReLU layer with k filters and stride 2. [SEP]\n", "[CLS] After the last layer, we apply a convolution to produce a 1-dimensional output. [SEP]\n", "[CLS] We do not use InstanceNorm for the first C64 layer. [SEP]\n", "[CLS] We use leaky ReLUs with a slope of FORMULA . [SEP]\n", "[CLS] The discriminator architecture is: C64-C128-C256-C512   [SEP]\n"], "1511.06488": ["[CLS]   [SEP]\n", "[CLS] Resiliency of Deep Neural Networks under QuantizationWonyong\u00a0Sung, Sungho\u00a0Shin & Kyuyeon\u00a0Hwang Department of Electrical and Computer EngineeringSeoul National UniversitySeoul, 08826 Koreawysung@snu.ac.kr shshin@dsp.snu.ac.kr kyuyeon.hwang@gmail.com2020/09/12 00:39:23The complexity of deep neural network algorithms for hardware implementation can be much lowered by optimizing the word-length of weights and signals. [SEP]\n", "[CLS] Direct quantization of floating-point weights, however, does not show good performance when the number of bits assigned is small. [SEP]\n", "[CLS] Retraining of quantized networks has been developed to relieve this problem. [SEP]\n", "[CLS] In this work, the effects of quantization are analyzed for a feedforward deep neural network (FFDNN) and a convolutional neural network (CNN) when their network complexity is changed. [SEP]\n", "[CLS] The complexity of the FFDNN is controlled by varying the unit size in each hidden layer and the number of layers, while that of the CNN is done by modifying the feature map configuration. [SEP]\n", "[CLS] We find that some performance gap exists between the floating-point and the retrain-based ternary (+1, 0, -1) weight neural networks when the size is not large enough, but the discrepancy almost vanishes in fully complex networks whose capability is limited by the training data, rather than by the number of connections. [SEP]\n", "[CLS] This research shows that highly complex DNNs have the capability of absorbing the effects of severe weight quantization through retraining, but connection limited networks are less resilient. [SEP]\n", "[CLS] This paper also presents the effective compression ratio to guide the trade-off between the network size and the precision when the hardware resource is limited. [SEP]\n", "[CLS] Introduction Deep neural networks (DNNs) begin to find many real-time applications, such as speech recognition, autonomous driving, gesture recognition, and robotic control {{cite:37c0d91e-c7b9-4537-8397-431ba13a9b9d}}, {{cite:ff4a5d4f-ae83-4bf8-a1cd-ce05a950201d}}, {{cite:9108379c-2ee1-47ad-8912-27cca4e4fe32}}, {{cite:16932e0c-e628-4747-9f24-4cf08b91ebaa}}. [SEP]\n", "[CLS] Although most of deep neural networks are implemented using GPUs (Graphics Processing Units) in these days, their implementation in hardware can give many benefits in terms of power consumption and system size {{cite:ae6bba79-88df-45a4-9dce-a48ed5c3ebc5}}. [SEP]\n", "[CLS] FPGA based implementation examples of CNN show more than 10 times advantage in power consumption {{cite:ae6bba79-88df-45a4-9dce-a48ed5c3ebc5}}. [SEP]\n", "[CLS] Neural network algorithms employ many multiply and add (MAC) operations that mimic the operations of biological neurons. [SEP]\n", "[CLS] This suggests that reconfigurable hardware arrays that contain quite homogeneous hardware blocks, such as MAC units, can give very efficient solution to real-time neural network system design. [SEP]\n", "[CLS] Early studies on word-length determination of neural networks reported the needed precision of at least 8 bits {{cite:c9fc6901-b760-4416-9b69-77d86aad96a3}}. [SEP]\n", "[CLS] Our recent works show that the precision required for implementing FFDNN, CNN or RNN needs not be very high, especially when the quantized networks are trained again to learn the effects of lowered precision. [SEP]\n", "[CLS] In the fixed-point optimization examples shown in {{cite:f532f109-daa1-46e2-9ae9-78d7894a9305}}, {{cite:c3a6b783-186d-4325-8e97-3e604fbd7a1d}}, {{cite:d08ee522-8f21-461c-8093-45c99aa1709e}}, neural networks with ternary weights showed quite good performance which was close to that of floating-point arithmetic. [SEP]\n", "[CLS] In this work, we try to know if retraining can recover the performance of FFDNN and CNN under quantization with only ternary (+1, 0, -1) levels or 3 bits (+3, +2, +1, 0, -1, -2, -3) for weight representation. [SEP]\n", "[CLS] Note that bias values are not quantized. [SEP]\n", "[CLS] For this study, the network complexity is changed to analyze their effects on the performance gap between floating-point and retrained low-precision fixed-point deep neural networks. [SEP]\n", "[CLS] We conduct our experiments with a feed-forward deep neural network (FFDNN) for phoneme recognition and a convolutional neural network (CNN) for image classification. [SEP]\n", "[CLS] To control the network size, not only the number of units in each layer but also the number of hidden layers are varied in the FFDNN. [SEP]\n", "[CLS] For the CNN, the number of feature maps for each layer and the number of layers are both changed. [SEP]\n", "[CLS] The FFDNN uses the TIMIT corpus and the CNN employs the CIFAR-10 dataset. [SEP]\n", "[CLS] We also propose a metric called effective compression ratio (ECR) for comparing extremely quantized bigger networks with moderately quantized or floating-point networks with the smaller size. [SEP]\n", "[CLS] This analysis intends to find an insight to the knowledge representation capability of highly quantized networks, and also provides a guideline to network size and word-length determination for efficient hardware implementation of DNNs. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Related Work Fixed-point implementation of signal processing algorithms has long been of interest for VLSI based design of multimedia and communication systems. [SEP]\n", "[CLS] Some of early works used statistical modeling of quantization noise for application to linear digital filters. [SEP]\n", "[CLS] The simulation-based word-length optimization method utilized simulation tools to evaluate the fixed-point performance of a system, by which non-linear algorithms can be optimized {{cite:d13d0823-ee4a-4abf-b956-0df44ac95743}}. [SEP]\n", "[CLS] Ternary (+1, 0, -1) coefficients based digital filters were used to eliminate multiplications at the cost of higher quantization noise. [SEP]\n", "[CLS] The implementation of adaptive filters with ternary weights were developed, but it demanded oversampling to remove the quantization effects {{cite:2e05e781-2ea1-4614-b35c-759e80f871f7}}. [SEP]\n", "[CLS] Fixed-point neural network design also has been studied with the same purpose of reducing the hardware implementation cost {{cite:530874fd-5b1a-4ccd-a4fb-9d1b6fb84a66}}. [SEP]\n", "[CLS] In {{cite:c9fc6901-b760-4416-9b69-77d86aad96a3}}, back propagation simulation with 16-bit integer arithmetic was conducted for several problems, such as NetTalk, Parity, Protein and so on. [SEP]\n", "[CLS] This work conducted the experiments while changing the number of hidden units, which was, however, relatively small numbers. [SEP]\n", "[CLS] The integer simulations showed quite good results for NetTalk and Parity, but not for Protein benchmarks. [SEP]\n", "[CLS] With direct quantization of trained weights, this work also confirmed satisfactory operation of neural networks with 8-bit precision. [SEP]\n", "[CLS] An implementation with ternary weights were reported for neural network design with optical fiber networks {{cite:81cb620d-31e9-47af-bb60-ba5b748a8d91}}. [SEP]\n", "[CLS] In this ternary network design, the authors employed retraining after direct quantization to improve the performance of a shallow network. [SEP]\n", "[CLS] Recently, fixed-point design of DNNs is revisited, and FFDNN and CNN with ternary weights show quite good performances that are very close to the floating-point results. [SEP]\n", "[CLS] The ternary weight based FFDNN and CNN are used for VLSI and FPGA based implementations, by which the algorithms can operate with only on-chip memory consuming very low power {{cite:1b0c42ca-ca3c-4efd-8e79-d14c4ab51487}}. [SEP]\n", "[CLS] Binary weight based deep neural network design is also studied {{cite:eda126aa-a9e2-4589-949d-dcd07fe47191}}. [SEP]\n", "[CLS] Pruned floating-point weights are also utilized for efficient GPU based implementations, where small valued weights are forced to zero to reduce the number of arithmetic operations and the memory space for weight storage {{cite:111b31f7-8856-4621-9f39-be6b3f372bd7}}, {{cite:17fa37d8-8f29-442a-8571-1ca4ac5c7e6c}}. [SEP]\n", "[CLS] A network restructuring technique using singular value decomposition technique is also studied {{cite:0e4be80a-f877-4bb8-9144-9e1aff1f966f}}, {{cite:921ce8e1-c540-4499-8dcc-1e9a3f3c9540}}. [SEP]\n", "[CLS]  Fixed-point FFDNN and CNN Design [SEP]\n", "[CLS] This section explains the design of FFDNN and CNN with varying network complexity and, also, the fixed-point optimization procedure. [SEP]\n", "[CLS] FFDNN and CNN Design A feedforward deep neural network with multiple hidden layers are depicted in \u00a0REF . [SEP]\n", "[CLS] Each layer FORMULA  has a signal vector FORMULA , which is propagated to the next layer by multiplying the weight matrix FORMULA , adding biases FORMULA , and applying the activation function FORMULA  as follows: FORMULA    [SEP]\n", "[CLS] One of the most popular activation functions is the rectified linear unit defined as FORMULA  FIGURE   [SEP]\n", "[CLS] In this work, an FFDNN for phoneme recognition is used. [SEP]\n", "[CLS] The reference DNN has four hidden layers. [SEP]\n", "[CLS] Each of the hidden layers has FORMULA  units; the value of FORMULA  is changed to control the complexity of the network. [SEP]\n", "[CLS] We conduct experiments with the FORMULA  size of 32, 64, 128, 256, 512, and 1024. [SEP]\n", "[CLS] The number of hidden layers is also reduced. [SEP]\n", "[CLS] The input layer of the network has 1,353 units to accept 11 frames of a Fourier-transform-based filter-bank with 40 coefficients (FORMULA energy) distributed on a mel-scale, together with their first and second temporal derivatives. [SEP]\n", "[CLS] The output layer consists of 61 softmax units which correspond to 61 target phoneme labels. [SEP]\n", "[CLS] Phoneme recognition experiments were performed on the TIMIT corpus. [SEP]\n", "[CLS] The standard 462 speaker set with all SA records removed was used for training, and a separate development set of 50 speaker was used for early stopping. [SEP]\n", "[CLS] Results are reported for the 24-speaker core test set. [SEP]\n", "[CLS] The network was trained using a backpropagation algorithm with 128 mini-batch size. [SEP]\n", "[CLS] Initial learning rate was FORMULA  and it was decreased until FORMULA  during the training. [SEP]\n", "[CLS] Momentum was 0.9 and RMSProp was adopted for weights update {{cite:ec835368-b175-4431-a5f4-3d0094db6ce0}}. [SEP]\n", "[CLS] The dropout technique was employed with 0.2 dropout rate in each layer. [SEP]\n", "[CLS] The CNN used is for CIFAR-10 dataset. [SEP]\n", "[CLS] It contains a training set of 50,000 and a test set of 10,000 32FORMULA 32 RGB color images representing airplanes, automobiles, birds, cats, deers, dogs, frogs, horses, ships and trucks. [SEP]\n", "[CLS] We divided the training set to 40,000 images for training and 10,000 images for validation. [SEP]\n", "[CLS] This CNN has 3 convolution and pooling layers and a fully connected hidden layer with 64 units, and the output has 10 softmax units as shown in \u00a0REF . [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] We control the number of feature maps in each convolution layer. [SEP]\n", "[CLS] The reference size has 32-32-64 feature maps with 5 by 5 kernel size as used in\u00a0{{cite:7c8a22dc-92bb-4725-9e19-3bfe09735747}}. [SEP]\n", "[CLS] We did not perform any preprocessing and data augmentation such as ZCA whitening and global contrast normalization. [SEP]\n", "[CLS] To know the effects of network size variation, the number of feature maps is reduced or increased. [SEP]\n", "[CLS] The configurations of the feature maps used for the experiments are 8-8-16, 16-16-32, 32-32-64, 64-64-128, 96-96-192, and 128-128-256. [SEP]\n", "[CLS] The number of feature map layers is also changed, resulting in 32-32-64, 32-64, and 64 map configurations. [SEP]\n", "[CLS] Note that the fully connected layer in the CNN is not changed. [SEP]\n", "[CLS] The network was trained using a backpropagation algorithm with 128 mini-batch size. [SEP]\n", "[CLS] Initial learning rate was 0.001 and it was decreased to FORMULA  during the training procedure. [SEP]\n", "[CLS] Momentum was 0.8 and RMSProp was applied for weights update.   [SEP]\n", "[CLS] Fixed-point optimization of DNNs Reducing the word-length of weights brings several advantages in hardware based implementation of neural networks. [SEP]\n", "[CLS] First, it lowers the arithmetic precision, and thereby reduces the number of gates needed for multipliers. [SEP]\n", "[CLS] Second, the size of memory for storing weights is minimized, which would be a big advantage when keeping them on a chip, instead of external DRAM or NAND flash memory. [SEP]\n", "[CLS] Note that FFDNNs and recurrent neural networks demand a very large number of weights. [SEP]\n", "[CLS] Third, the reduced arithmetic precision or minimization of off-chip memory accesses leads to low power consumption. [SEP]\n", "[CLS] However, we need to concern the quantization effects that degrade the system performance. [SEP]\n", "[CLS] Direct quantization converts a floating-point value to the closest integer number, which is conventionally used in signal processing system design. [SEP]\n", "[CLS] However, direct quantization usually demands more than 8 bits, and does not show good performance when the number of bits is small. [SEP]\n", "[CLS] In fixed-point deep neural network design, retraining of quantized weights shows quite good performance. [SEP]\n", "[CLS] The fixed-point DNN algorithm design consists of three steps: floating-point training, direct quantization, and retraining of weights. [SEP]\n", "[CLS] The floating-point training procedure can be any of the state of the art techniques, which may include unsupervised learning and dropout. [SEP]\n", "[CLS] Note that fixed-point optimization needs to be based on the best performing floating-point weights. [SEP]\n", "[CLS] Thus, the floating-point weight optimization may need to be conducted several times with different initializations, and this step consumes the most of the time. [SEP]\n", "[CLS] After the floating-point training, direct quantization is followed. [SEP]\n", "[CLS] For direct quantization, uniform quantization function is employed and the function FORMULA  is defined as follows : FORMULA   where FORMULA  is a sign function, FORMULA  is a quantization step size, and FORMULA  represents the number of quantization levels. [SEP]\n", "[CLS] Note that FORMULA  needs to be an odd number since the weight values can be positive or negative. [SEP]\n", "[CLS] When FORMULA  is 7, the weights are represented by -3FORMULA , -2FORMULA , -1FORMULA , 0, +1FORMULA , +2FORMULA , +3FORMULA ,which can be represented in 3 bits. [SEP]\n", "[CLS] The quantization step size FORMULA  is determined to minimize the L2 error, FORMULA , depicted as follows. [SEP]\n", "[CLS] FORMULA   where FORMULA  is the number of weights in each weight group, FORMULA  is the FORMULA -th weight value represented in floating-point. [SEP]\n", "[CLS] This process needs some iterations, but does not take much time. [SEP]\n", "[CLS] For network retraining, we maintain both floating-point and quantized weights because the amount of weight updates in each training step is much smaller than the quantization step size FORMULA . [SEP]\n", "[CLS] The forward and backward propagation is conducted using quantized weights, but the weight update is applied to the floating-point weights and newly quantized values are generated at each iteration. [SEP]\n", "[CLS] This retraining procedure usually converges quickly and does not take much time when compared to the floating-point training. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Analysis of quantization effects Direct quantization [SEP]\n", "[CLS] The performance of the FFDNN and the CNN with directly quantized weights is analyzed while varying the number of units in each layer or the number of feature maps, respectively. [SEP]\n", "[CLS] In this analysis, the quantization is performed on each weight group, which is illustrated in \u00a0REF  and \u00a0REF , to know the sensitivity of word-length reduction. [SEP]\n", "[CLS] In this sub-section, we try to analyze the effects of direct quantization. [SEP]\n", "[CLS] The quantized weight can be represented as follows, FORMULA  where FORMULA  is the distortion of each weight due to quantization. [SEP]\n", "[CLS] In the direct quantization, we can assume that the distortion FORMULA  is not dependent each other. [SEP]\n", "[CLS] FIGURE  FIGURE  Consider a computation procedure for a unit in a hidden layer, the signal from the previous layer is summed up after multiplication with the weights as illustrated in \u00a0REF . [SEP]\n", "[CLS] We can also assemble a model for distortion, which is shown in \u00a0REF . [SEP]\n", "[CLS] In the distortion model, since FORMULA  is independent each other, we can assume that the effects of the summed distortion is reduced according to the random process theory. [SEP]\n", "[CLS] This analysis means that the quantization effects are reduced when the number of units in the anterior layer increases, but slowly. [SEP]\n", "[CLS] FIGURE  \u00a0REF  illustrates the performance of the FFDNN with floating-point arithmetic, 2-bit direct quantization of all the weights, and 2-bit direct quantization only on the weight group `In-h1', `h1-h2', and `h4-out'. [SEP]\n", "[CLS] Consider the quantization performance of the `In-h1' layer, the phone-error rate is higher than the floating-point result with an almost constant amount, about 10%. [SEP]\n", "[CLS] Note that the number of input to the `In-h1' layer is fixed, 1353, regardless of the hidden unit size. [SEP]\n", "[CLS] Thus, the amount of distortion delivered to each unit of the hidden layer 1 can be considered unchanged. [SEP]\n", "[CLS] \u00a0REF  also shows the quantization performance on `h1-h2' and `h4-out' layers, which informs the trend of reduced gap to the floating-point performance as the network size increases. [SEP]\n", "[CLS] This can be explained by the sum of increased number of independent distortions when the network size grows. [SEP]\n", "[CLS] The performance of all 2-bit quantization also shows the similar trend of reduced gap to the floating-point performance. [SEP]\n", "[CLS] But, apparently, the performance of 2-bit directly quantized networks is not satisfactory. [SEP]\n", "[CLS] In \u00a0REF , a similar analysis is conducted to the CNN with direct quantization when the number of feature maps increases or decreases. [SEP]\n", "[CLS] In the CNN, the number of input to each output is determined by the number of input feature maps and the kernel size. [SEP]\n", "[CLS] For example, at the first layer C1, the number of input signal for computing one output is only 75 (=3FORMULA 25) regardless of the network size, where the input map size is always 3 and the kernel size is 25. [SEP]\n", "[CLS] However, at the second layer C2, the number of input feature maps increases as the network size grows. [SEP]\n", "[CLS] When the feature map of 32-32-64 is considered, the number of input for the C2 layer grows to 800 (=32FORMULA 25). [SEP]\n", "[CLS] Thus, we can expect a reduced distortion as the number of feature maps increases. [SEP]\n", "[CLS] \u00a0REF  shows the performance of direct quantization with 2, 4, 6, and 8-bit precision when the network complexity varies. [SEP]\n", "[CLS] In the FFDNN, 6 bit direct quantization seems enough when the network size is larger than 128. [SEP]\n", "[CLS] But, small FFDNNs demand 8 bits for near floating-point performance. [SEP]\n", "[CLS] The CNN in \u00a0REF  also shows the similar trend. [SEP]\n", "[CLS] The direct quantization requires about 6 bits when the feature map configuration is 16-16-32 or larger. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Effects of retraining on quantized networks Retraining is conducted on the directly quantized networks using the same data for floating-point training. [SEP]\n", "[CLS] The fixed-point performance of the FFDNN is shown in \u00a0REF  when the number of hidden units in each layer varies. [SEP]\n", "[CLS] The performance of direct 2 bits (ternary levels), direct 3 bits (7-levels), retrain-based 2 bits, and retrain-based 3 bits are compared with the floating-point simulation. [SEP]\n", "[CLS] We can find that the performance gap between the floating-point and the retrain-based fixed-point networks converges very fast as the network size grows. [SEP]\n", "[CLS] Although the performance gap between the direct and the floating-point networks also converges, the rate of convergence is significantly different. [SEP]\n", "[CLS] In this figure, the performance of the floating-point network almost saturates when the network size is about 1024. [SEP]\n", "[CLS] Note that the TIMIT corpus that is used for training has only 3 hours of data. [SEP]\n", "[CLS] Thus, the network with 1024 hidden units can be considered in the `training-data limited region'. [SEP]\n", "[CLS] Here, the gap between the floating-point and fixed-point networks almost vanishes when the network is in the `training-data limited region'. [SEP]\n", "[CLS] However, when the network size is limited, such as 32, 64, 128, or 256, there is some performance gap between the floating-point and highly quantized networks even if retraining on the quantized networks is performed. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The similar experiments are conducted for the CNN with varying feature map sizes, and the results are shown in \u00a0REF . [SEP]\n", "[CLS] The configuration of the feature maps used for the experiments are 8-8-16, 16-16-32, 32-32-64, 64-64-128, 96-96-192, and 128-128-256. [SEP]\n", "[CLS] The size of the fully connected layer is not changed. [SEP]\n", "[CLS] In this figure, the floating-point and the fixed-point performances with retraining also converge very fast as the number of feature maps increases. [SEP]\n", "[CLS] The floating-point performance saturates when the feature map size is 128-128-256, and the gap is less than 1% when comparing the floating-point and the retrain-based 2-bit networks. [SEP]\n", "[CLS] However, also, there is some performance gap when the number of feature maps is reduced. [SEP]\n", "[CLS] This suggests that a fairly high performance feature extraction can be designed even using very low-precision weights if the number of feature maps can be increased. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Fixed-point performances when varying the depth It is well known that increasing the depth usually results in positive effects on the performance of a DNN {{cite:d912b43f-446d-43c5-950b-8fdd83621469}}. [SEP]\n", "[CLS] The network complexity of a DNN is changed by increasing or reducing the number of hidden layers or feature map levels. [SEP]\n", "[CLS] The result of fixed-point and floating-point performances when varying the number of hidden layers for the FFDNN is summarized in\u00a0\u00a0REF . [SEP]\n", "[CLS] The number of units in each hidden layer is 512. [SEP]\n", "[CLS] This table shows that both the floating-point and the fixed-point performances of the FFDNN increase when adding hidden layers from 0 to 4. [SEP]\n", "[CLS] The performance gap between the floating-point and the fixed-point networks shrinks as the number of levels increases. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] The network complexity of the CNN is also varied by reducing the level of feature maps as shown in\u00a0\u00a0REF . [SEP]\n", "[CLS] As expected, the performance of both the floating-point and retrain-based low-precision networks degrades as the number of levels is reduced. [SEP]\n", "[CLS] The performance gap between them is very small with 7-level quantization for all feature map levels. [SEP]\n", "[CLS] These results for the FFDNN and the CNN with varied number of levels also show that the effects of quantization can be much reduced by retraining when the network contains some redundant complexity. [SEP]\n", "[CLS] TABLE    [SEP]\n", "[CLS] Effective compression ratio So far we have examined the effect of direct and retraining-based quantization to the final classification error rates. [SEP]\n", "[CLS] As the number of quantization level decreases, more memory space can be saved at the cost of sacrificing the accuracy. [SEP]\n", "[CLS] Therefore, there is a trade-off between the total memory space for storing weights and the final classification accuracy. [SEP]\n", "[CLS] In practice, investigating this trade-off is important for deciding the optimal bit-widths for representing weights and implementing the most efficient neural network hardware. [SEP]\n", "[CLS] In this section, we propose a guideline for finding the optimal bit-widths in terms of the total number of bits consumed by the network weights when the desired accuracy or the network size is given. [SEP]\n", "[CLS] Note that we assume FORMULA  quantization levels are represented by FORMULA  bits (i.e. 2 bits are required for representing a ternary weight). [SEP]\n", "[CLS] For simplicity, all layers are quantized with the same number of quantization levels. [SEP]\n", "[CLS] However, the similar approach can be applied to the layer-wise quantization analysis. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The optimal combination of the bit-width and layer size can be found when the number of total bits or the accuracy is given as shown in \u00a0REF . [SEP]\n", "[CLS] The figure shows the framewise phoneme error rate on TIMIT with respect to the number of total bits, while varying the layer size of DNNs with various number of quantization bits from 2 to 8 bits. [SEP]\n", "[CLS] The network has 4 hidden layers with the uniform sizes. [SEP]\n", "[CLS] With direct quantization, the optimal hardware design can be achieved with about 5 bits. [SEP]\n", "[CLS] On the other hand, the weight representation with only 2 bits shows the best performance after retraining. [SEP]\n", "[CLS] FIGURE  FIGURE   [SEP]\n", "[CLS] The remaining question is how much memory space can be saved by quantization while maintaining the accuracy. [SEP]\n", "[CLS] To examine this, we introduce a metric called effective compression ratio (ECR), which is defined as follows: FORMULA    [SEP]\n", "[CLS] The compressed size is the total memory bits required for storing all weights with quantization. [SEP]\n", "[CLS] The effective uncompressed size is the total memory size with 32-bit floating point representation when the network achieves the same accuracy as that of the quantized network. [SEP]\n", "[CLS] \u00a0REF  describes how to obtain the effective number of parameters for uncompressed networks. [SEP]\n", "[CLS] Specifically, by varying the size, we find the number of total parameters of the floating-point network that shows the same accuracy as the quantized one. [SEP]\n", "[CLS] After that, the effective uncompressed size can be computed by multiplying 32 bits to the effective number of parameters. [SEP]\n", "[CLS] Once we get the corresponding effective uncompressed size for the specific network size and the number of quantization bits, the ECR can be computed by (REF ). [SEP]\n", "[CLS] The ECRs for the direct and retrain-based quantization for various network sizes and quantization bits are shown in \u00a0REF . [SEP]\n", "[CLS] For the direct quantization, 5 bit quantization shows the best ECR except for the layer size of 1024. [SEP]\n", "[CLS] On the other hand, even 2 bit quantization performs better than the others after retraining. [SEP]\n", "[CLS] That is, after retraining, a bigger network with extreme ternary (2 bit) quantization is more efficient in terms of the memory usage for weights than any other smaller networks with higher quantization bits when they are compared at the same accuracy. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Discussion [SEP]\n", "[CLS] In this study, we control the network size by changing the number of units in the hidden layers, the number of feature maps, or the number of levels. [SEP]\n", "[CLS] At any case, reduced complexity lowers the resiliency to quantization. [SEP]\n", "[CLS] We are now conducting similar experiments to the recurrent neural networks that are known to be more sensitive to quantization {{cite:d08ee522-8f21-461c-8093-45c99aa1709e}}. [SEP]\n", "[CLS] This work seems to be directly related to several network optimization methods, such as pruning, fault tolerance, and decomposition {{cite:111b31f7-8856-4621-9f39-be6b3f372bd7}}, {{cite:17fa37d8-8f29-442a-8571-1ca4ac5c7e6c}}, {{cite:0e4be80a-f877-4bb8-9144-9e1aff1f966f}}, {{cite:921ce8e1-c540-4499-8dcc-1e9a3f3c9540}}. [SEP]\n", "[CLS] In the pruning, retraining of weights is conducted after zeroing small valued weights. [SEP]\n", "[CLS] The effects of pruning, fault tolerance, and network decomposition efficiency would be dependent on the redundant representation capability of DNNs. [SEP]\n", "[CLS] This study can be applied to hardware efficient DNN design. [SEP]\n", "[CLS] For design with limited hardware resources, when the size of the reference DNN is relatively small, it is advised to employ a very low-precision arithmetic and, instead, increase the network complexity as much as the hardware capacity allows. [SEP]\n", "[CLS] But, when the DNNs are in the performance saturation region, this strategy does not always gain much because growing the `already-big' network size brings almost no performance advantages. [SEP]\n", "[CLS] This can be observed in \u00a0REF  and \u00a0REF  where 6 bit quantization performed best at the largest layer size (1,024). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusion We analyze the performance of fixed-point deep neural networks, an FFDNN for phoneme recognition and a CNN for image classification, while not only changing the arithmetic precision but also varying their network complexity. [SEP]\n", "[CLS] The low-precision networks for this analysis are obtained by using the retrain based quantization method, and the network complexity is controlled by changing the configurations of the hidden layers or feature maps. [SEP]\n", "[CLS] The performance gap between the floating-point and the fixed-point neural networks with ternary weights (+1, 0, -1) almost vanishes when the DNNs are in the performance saturation region for the given training data. [SEP]\n", "[CLS] However, when the complexity of DNNs are reduced, by lowering either the number of units, feature maps, or hidden layers, the performance gap between them increases. [SEP]\n", "[CLS] In other words, a large size network that may contain redundant representation capability for the given training data does not hurt by the lowered precision, but a very compact network does. [SEP]\n", "[CLS] Acknowledgments This work was supported in part by the Brain Korea 21 Plus Project and the National Research Foundation of Korea (NRF) grants funded by the Korea government (MSIP) (No. 2015R1A2A1A10056051). [SEP]\n"], "1612.06524": ["[CLS]  =1 3D Human Pose Estimation = 2D Pose Estimation + MatchingChing-Hang ChenCarnegie Mellon Universitychinghac@andrew.cmu.edu Deva RamananCarnegie Mellon Universitydeva@cs.cmu.edu 2020/09/11 [SEP]\n", "[CLS] 19:48:29We explore 3D human pose estimation from a single RGB image. [SEP]\n", "[CLS] While many approaches try to directly predict 3D pose from image measurements, we explore a simple architecture that reasons through intermediate 2D pose predictions. [SEP]\n", "[CLS] Our approach is based on two key observations (1) Deep neural nets have revolutionized 2D pose estimation, producing accurate 2D predictions even for poses with self-occlusions (2) \"Big-data\"sets of 3D mocap data are now readily available, making it tempting to \u201clift\" predicted 2D poses to 3D through simple memorization (e.g., nearest neighbors). [SEP]\n", "[CLS] The resulting architecture is straightforward to implement with off-the-shelf 2D pose estimation systems and 3D mocap libraries. [SEP]\n", "[CLS] Importantly, we demonstrate that such methods outperform almost all state-of-the-art 3D pose estimation systems, most of which directly try to regress 3D pose from 2D measurements. [SEP]\n", "[CLS] Introduction Inferring 3D human pose from image measurements is classic task in computer vision, dating back to the iconic work of Hogg\u00a0{{cite:374a22f5-932b-4b49-9075-dcc23e03814f}} and O'Rourke and Badler\u00a0{{cite:3400c74e-8250-44c0-8cb8-1aea48e8ad18}}. [SEP]\n", "[CLS] Such a technology has immediate applications in various tasks such as action understanding, surveillance, human-robot interaction, and motion capture, to name a few. [SEP]\n", "[CLS] As such, it has a long and storied history. [SEP]\n", "[CLS] We refer the reader to various surveys for a broad overview of the popular topic\u00a0{{cite:2e479f35-1ff3-473a-83c0-066baa705ed5}}, {{cite:7f914a73-51b8-4ad2-83a4-e5f47f78cad6}}. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Previous approaches often make use of a highly sensored environment, including video streams\u00a0{{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}}, {{cite:34ce34df-bfb8-4e72-b9b4-7508888d846d}}, multiview cameras\u00a0{{cite:dd94c956-16c7-48c5-9602-53a57531d9c1}}, {{cite:a46385ff-a160-4a8e-86cb-cfdc7247274c}}, depth images\u00a0{{cite:328961da-d368-47d7-8f5c-5bf4f587bc81}}, {{cite:91dbca51-d498-44c4-87ed-f1ac1a412443}}, {{cite:97582cdf-8bec-4df7-8e5a-5dbe31ed772e}}. [SEP]\n", "[CLS] In this work, we focus on the \"pure\" and challenging setting of recovering 3D body pose with a single 2D RGB image\u00a0{{cite:2131161f-bf76-4fdb-b363-9ddc8dd3a5fe}}, {{cite:b8fb3fe1-0036-4263-8728-80c4f2706ac0}}, {{cite:5d80ecea-0afc-4239-b85d-53476ef6fc21}}, {{cite:14090d35-3c57-4d61-af9c-06e9c74f97b8}}. [SEP]\n", "[CLS] Our key insight to the problem is leveraging recent advances in 2D image understanding, made possible through the undeniable impact of deep learning. [SEP]\n", "[CLS] While originally explored for coarse recognition tasks such as image classification, recent methods have extended such network architectures to \u201cfine-grained\" human pose estimation, where the task is formulated as one of 2D heatmap prediction\u00a0{{cite:36bb159f-459c-435d-a787-357c457a96c5}}, {{cite:1799bf14-342f-405f-8ca6-5fc435fc270c}}, {{cite:e9cc16f2-9265-4c20-91c4-94cf7fc4ec4a}}, {{cite:9daf4692-078a-4469-b361-878febccbdb0}}. [SEP]\n", "[CLS] One of the long standing challenges in 2D human pose estimation has been estimating poses under self-occlusions. [SEP]\n", "[CLS] Indeed, reasoning about occlusions has been one of the underlying motivations for working in a 3D coordinate frame rather than 2D. [SEP]\n", "[CLS] But one of our salient conclusions is that state-of-the-art methods do a surprisingly good job of 2D pose estimation even under occlusion. [SEP]\n", "[CLS] Given this observation, the remaining challenge is predicting depth values for the estimated 2D joints. [SEP]\n", "[CLS] Inferring 3D structure from 2D correspondences is also a well-studied problem in computer vision, often addressed in multiview setting as structure from motion. [SEP]\n", "[CLS] In the context of monocular human pose estimation, the relevant cues seem to be semantic rather than geometric. [SEP]\n", "[CLS] One can estimate 3D postures from a 2D skeleton based on high-level knowledge derived from anthropometric, kinematic, and dynamic constraints. [SEP]\n", "[CLS] Inspired by the success of data-driven architectures, we explore a simple non-parametric encoding of such high-level constraints: given a 3D pose library, we generate a large number of 2D projections (from virtual camera views). [SEP]\n", "[CLS] Given this training set of paired (2D,3D) data and predictions from a 2D pose estimation algorithm, we report back the depths from the 3D pose associated with the closest matching 2D example from our library. [SEP]\n", "[CLS] Our entire pipeline is summarized in Fig. [SEP]\n", "[CLS] \u00a0REF . [SEP]\n", "[CLS] Generalization: One desirable property of our two-stage approach is generalization. [SEP]\n", "[CLS] Due to the difficulty of annotation in 3D, training datasets with 3D labels are typically collected in a lab environment, while 2D datasets tend to be more diverse. [SEP]\n", "[CLS] Our two-stage pipeline makes use of different training sets for different stages, resulting a system that can predict 3D poses from \u201cin-the-wild\" images. [SEP]\n", "[CLS] Evaluation: Though we present qualitative results on in-the-wild-imagery, we also perform an extensive quantitative evaluation of our method on widely benchmarked 3D human-pose datasets, such as Human3.6M {{cite:cdf7cb8b-1195-418e-84fe-4ff690b35bef}}. [SEP]\n", "[CLS] We follow standard train/test protocol splits, but our analysis reveals that there has been inconsistent reporting in the literature, both in terms of test sets and evaluation criteria. [SEP]\n", "[CLS] To make our results as transparent as possible, we report performance for all metrics and splits we could find. [SEP]\n", "[CLS] One of our surprising findings is the impressive performance of our simple pipeline: we outperform essentially all prior work on all metrics. [SEP]\n", "[CLS] Our entire pipeline, even given the non-parametric matching step, returns a 3D pose given a 2D image in under 200ms (160ms for 2D estimation by a CNN, 26ms for exemplar matching with a training library of 200,000 poses). [SEP]\n", "[CLS] Finally, to promote future progress, we perform an exhaustive analysis of additional baselines with upper bounds that reveal the continued benefit of working with intermediate 2D representations and data-driven encoding of 3D constraints. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Related work Here we review related works on 3D human pose prediction most relevant to our approach. [SEP]\n", "[CLS] (Deep) Regression: Most existing work that makes use of deep features tends to formulate the problem as a direct 2D image to 3D pose regression task. [SEP]\n", "[CLS] Li et al. {{cite:2131161f-bf76-4fdb-b363-9ddc8dd3a5fe}} use deep learning to train a regression model to predict 3D pose directly from images. [SEP]\n", "[CLS] Tekin et al.\u00a0{{cite:34ce34df-bfb8-4e72-b9b4-7508888d846d}} integrate spatio-temporal features via an image sequence to learn regression model for 3D pose mapping. [SEP]\n", "[CLS] We provide both a theoretical and empirical analysis that suggests that 2D pose may be a useful intermediate representation. [SEP]\n", "[CLS] Intermediate 2D pose: Other approaches have explored pipelines that use 2D poses as an intermediate result. [SEP]\n", "[CLS] Most focus on the second-stage that lifts 2D estimates to 3D. This is classically treated as a constrained optimization problem who's objective minimizes the 2D reprojection error of an unknown 3D pose and unknown camera\u00a0{{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}}, {{cite:14090d35-3c57-4d61-af9c-06e9c74f97b8}}, {{cite:9485a822-970c-4fbd-8752-3c218e4b4e1f}}, {{cite:7325354f-a083-4e3c-902b-7d50dae253a6}}. [SEP]\n", "[CLS] The optimization problem is often subject to kinematic constraints\u00a0{{cite:f1dfceb3-4b7f-4e7b-822a-2474f2042b4e}}, {{cite:9dc99ea2-cbee-4885-afc5-c94f0e23b473}}, and sometimes 3D poses are assumed to live a in low-dimensional subspace to better condition the optimization\u00a0{{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}}. [SEP]\n", "[CLS] Such optimization-based approaches could be sensitive to initialization and local minima, and often require expensive constrained solvers. [SEP]\n", "[CLS] We use data-driven matching, that when combined with a simple closed-form warping algorithm, yields a fast and accurate 3D solution. [SEP]\n", "[CLS] Exemplar-based: Previous work has also explored example-based methods, dating back at least to\u00a0{{cite:bc071f3f-b94b-4f59-8737-a8273c992606}}. [SEP]\n", "[CLS] A central challenge is generalization to novel poses outside the training set. [SEP]\n", "[CLS] \u00a0{{cite:243bdf06-5b74-409d-a473-310fca035ddc}} propose matching upper and lower bodies individually, to allow for novel compositions at test-time. [SEP]\n", "[CLS] \u00a0{{cite:b8fb3fe1-0036-4263-8728-80c4f2706ac0}} adapt exemplars to better match image measurements with an energy minimization approach. [SEP]\n", "[CLS] {{cite:5d80ecea-0afc-4239-b85d-53476ef6fc21}} synthesize new 2D images with image-based rendering. [SEP]\n", "[CLS] Other methods also warp 3D exemplars to 2D image descriptors, often based on shape-context\u00a0{{cite:64dc88ec-0107-40f6-a889-a019366f36d1}}, {{cite:41d87982-5cb0-4105-887f-0aa15ac343c2}} or silhouette features\u00a0{{cite:12d45801-1ce6-47a1-81a4-40f686470b76}}. [SEP]\n", "[CLS] In our work, we show that a modest number of exemplars (200,000), combined with a simple closed-form algorithm for warping a 3D exemplar to exactly project to 2D pose estimates, outperforms more complex methods.   [SEP]\n", "[CLS] Approach [SEP]\n", "[CLS] In this section, we describe our method for estimating 3D human pose given a single RGB image. [SEP]\n", "[CLS] We make use of a probabilistic formulation over variables including the image FORMULA , the 3D pose FORMULA , and the 2D pose FORMULA , where FORMULA  is the number of articulated joints. [SEP]\n", "[CLS] We write the joint probability as: FORMULA  where the above makes no limiting assumptions by itself. [SEP]\n", "[CLS] Conditional independence: Let us now assume that the 3D pose FORMULA  is conditionally independent of image FORMULA  given the 2D pose FORMULA . [SEP]\n", "[CLS] This is equivalent to the implication that given a 2D skeleton, the prediction of its corresponding 3D skeleton would not be affected by 2D image measurements. [SEP]\n", "[CLS] While this is not quite true (we show a counter example in Fig.\u00a0REF ), it seems to be a reasonable first-order approximation. [SEP]\n", "[CLS] Moreover, this factorization still allows for FORMULA  to be arbitrarily complex, which is likely needed to accurately model complex interactions between 2D projections and image features during occlusions. [SEP]\n", "[CLS] Given this conditional Independence, one can write: FORMULA    [SEP]\n", "[CLS] We tackle the second term with a image-based CNN that predicts 2D keypoint heatmaps. [SEP]\n", "[CLS] We tackle the first term with a non-parametric nearest-neighbor (NN) model. [SEP]\n", "[CLS] We describe each term in turn below. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Image-Based 2D Pose Estimation Given the above Independence assumption, we would first like to predict 2D pose given image measurements. [SEP]\n", "[CLS] We model the conditional of 2D pose given an image as FORMULA  where we assume CNN is a nonlinear function that returns FORMULA  2D heatmaps (or marginal distributions over the location of individual joints). [SEP]\n", "[CLS] We make use of convolutional pose machines (CPMs)\u00a0{{cite:36bb159f-459c-435d-a787-357c457a96c5}}, which return precisely FORMULA  heatmaps for individual body joints. [SEP]\n", "[CLS] We normalize the heatmaps so that they can be interpreted as marginal distributions for each joint. [SEP]\n", "[CLS] CPM is a near-state-of-the-art pose estimation system (FORMULA  PCKh on MPII dataset {{cite:6a414193-dba2-4a98-ae65-e01b330fdcef}}, quite close to the state-of-the-art value of FORMULA  \u00a0{{cite:1799bf14-342f-405f-8ca6-5fc435fc270c}}). [SEP]\n", "[CLS] Note the off-the-shelf CPM model was trained on MPII dataset, which is a somewhat limited dataset in that annotations are provided through manual inspection. [SEP]\n", "[CLS] We fine-tune this model on the large scale Human3.6M {{cite:cdf7cb8b-1195-418e-84fe-4ff690b35bef}} training set, which contains annotations acquired by a mocap system (allowing for larger-scale labeling). [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Nonparametric 3D shape model We model FORMULA  with a non-parametric nearest neighbor model. [SEP]\n", "[CLS] We will follow a notational convention where FORMULA  and FORMULA . [SEP]\n", "[CLS] Assume that we have library of 3D poses FORMULA  paired with a particular camera projection matrix FORMULA , such that the associated 2D poses are given by FORMULA . [SEP]\n", "[CLS] If we want to consider multiple cameras for a single 3D pose, we add another copy of the 3D pose with a different camera matrix to our library. [SEP]\n", "[CLS] We define a distribution over 3D poses based on reprojection error: FORMULA  where the MAP estimate is given by the 1-nearest neighbor (1NN). [SEP]\n", "[CLS] We explore two extensions to the above basic framework. [SEP]\n", "[CLS] Virtual cameras: We can further reduce the squared reprojection error by searching over small perturbations of each camera. [SEP]\n", "[CLS] This involves solving a camera resectioning problem\u00a0{{cite:ec57aaa0-a559-4d33-8c71-968be7a11013}}, where an iterative solver can be initialized with FORMULA : FORMULA    [SEP]\n", "[CLS] In practice, we construct a shortlist of FORMULA  candidates that score well according to (REF ), and resort them according to optimal camera matrix. [SEP]\n", "[CLS] We found that optimizing over cameras produced a small but noticeable improvement in our experiments. [SEP]\n", "[CLS] Unless otherwise specified, we choose FORMULA  in our experiments. [SEP]\n", "[CLS] Warped exemplars: Much previous work on exemplars introduce methods for warping exemplars to better match the 2D pose estimates, often formulated as an inverse kinematics optimization problem. [SEP]\n", "[CLS] We describe an extremely lightweight method for doing so here. [SEP]\n", "[CLS] We first align the 3D exemplar to the camera-coordinate system used to compute the projection FORMULA . [SEP]\n", "[CLS] This is done with a 3D rigid transformation given by the camera extrinsics encoded in FORMULA  (or FORMULA ). [SEP]\n", "[CLS] In practice we use a training set FORMULA  where 3D exemplars are already aligned to their projections FORMULA , implying that extrinsics in FORMULA  reduce to an identity matrix (which is the case for the Human3.6M dataset\u00a0{{cite:cdf7cb8b-1195-418e-84fe-4ff690b35bef}}, since 3D poses are specified in camera coordinates of their associated image projections). [SEP]\n", "[CLS] Given this alignment, we simply replace the FORMULA  exemplar coordinates with their scaled 2D counterparts FORMULA  under a weak perspective camera model: FORMULA  where FORMULA  is the focal length of the camera (given by the intrinsics in FORMULA ) and average(FORMULA ) is the average depth of the 3D joints. [SEP]\n", "[CLS] Such weak-perspective approximations are commonly used to initialize algorithms for perspective (PnP) camera calibration\u00a0{{cite:7139c486-57c2-4fda-b682-ec82dcb79835}}, and will be reasonable when the depth variation of the human skeleton is small relative to the overall distance to the camera. [SEP]\n", "[CLS] Our results suggest that such closed-form solutions for 3D warping rival the accuracy of complex energy minimization methods (see Fig.\u00a0REF ). [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Experiments In our experiments, we test a variety of variations of our proposed pipeline. [SEP]\n", "[CLS] Qualitative results: We first present some qualitative results. [SEP]\n", "[CLS] Fig.\u00a0REF  shows results on challenging examples from subject S11 of Human3.6M. We choose examples with self-occlusions and sitting poses. [SEP]\n", "[CLS] To demonstrate the accuracy of the 3D predictions, we visualize novel viewpoints. [SEP]\n", "[CLS] We then apply the proposed method on Leeds Sports Pose(LSP) dataset {{cite:23cf9184-b26e-4153-b7d7-6a2530f6a63c}} to test cross-dataset generalization. [SEP]\n", "[CLS] We posit that our pipeline will generalize across image variation (due to the underlying robustness of our 2D pose estimation system) but maybe limited in the 3D estimates due to the library used (from Human3.6M). [SEP]\n", "[CLS] Importantly, our approach produces plausible 3D poses even when the activity class is not included in Human3.6M. [SEP]\n", "[CLS] This implies that our method can reliably estimate 3D poses in the wild! [SEP]\n", "[CLS] Evaluation protocols We use Human3.6M for quantitative evaluation and analysis. [SEP]\n", "[CLS] It appears that multiple train/test splits have been used in the literature, as well as different approaches to computing mean per joint position error (MPJPE), measured in millimeters. [SEP]\n", "[CLS] We summarize them here. [SEP]\n", "[CLS] Protocol 1: In\u00a0{{cite:b8fb3fe1-0036-4263-8728-80c4f2706ac0}}, {{cite:d1984047-0e98-45ea-9b5f-497e84a8427d}}, {{cite:5d80ecea-0afc-4239-b85d-53476ef6fc21}}, the entire dataset was partitioned into six training subjects (S1, S5, S6, S7, S8, S9), and one testing subject (S11). [SEP]\n", "[CLS] Evaluation is performed on every 64th frame of S11's video clips. [SEP]\n", "[CLS] In this configuration, there are total 1.8 million 3D poses available in the training set. [SEP]\n", "[CLS] MPJPE between the ground truth 3D pose and the estimated 3D pose is computed by first aligning poses with a rigid transformation\u00a0{{cite:d1984047-0e98-45ea-9b5f-497e84a8427d}}. [SEP]\n", "[CLS] Protocol 2: Others {{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}}, {{cite:34ce34df-bfb8-4e72-b9b4-7508888d846d}}, {{cite:2131161f-bf76-4fdb-b363-9ddc8dd3a5fe}} use five subjects (S1, S5, S6, S7, S8) for training, and two subjects (S9, S11) for testing. [SEP]\n", "[CLS] We follow {{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}}'s setup that downsamples the videos from 50 fps to 10 fps. [SEP]\n", "[CLS] Here, MPJPE is evaluated without a rigid transformation, following the original h36m protocol: both the ground-truth and predicted 3D pose is centered with respect to a root joint (ie. pelvis). [SEP]\n", "[CLS] In contrast to Protocol 1, this evaluation can be sensitive to a single poorly-predicted joint, particularly if it is the root\u00a0{{cite:cdf7cb8b-1195-418e-84fe-4ff690b35bef}}. [SEP]\n", "[CLS] To compare to published performance numbers, we use the appropriate protocol as needed. [SEP]\n", "[CLS] From our own experience, we find Protocol 1 to be simpler and more intuitive, and so focus on it for our diagnostic evaluations. [SEP]\n", "[CLS] TABLE  TABLE   Comparison to state-of-the-art (Protocol 1) Final system: Table\u00a0REF  compare MPJPE for each activity class. [SEP]\n", "[CLS] Our approach clearly outperforms {{cite:b8fb3fe1-0036-4263-8728-80c4f2706ac0}} and {{cite:5d80ecea-0afc-4239-b85d-53476ef6fc21}}. [SEP]\n", "[CLS] (\"Ours\" in the tables of comparison throughout the experiment refers to the warped exemplar FORMULA  described in Section\u00a0REF ) Performance given ground-truth 2D: A common diagnostic is evaluating performance given ground-truth 2D poses, written as FORMULA . [SEP]\n", "[CLS] Table\u00a0REF  shows that our simple matching + warping outperforms\u00a0{{cite:b8fb3fe1-0036-4263-8728-80c4f2706ac0}}, who use a complex iterative algorithm for matching and warping exemplars to image evidence. [SEP]\n", "[CLS] Our diagnostics will later show that even matching exemplars without warping outperforms prior art, indicating the remarkable power of a simple NN baseline. [SEP]\n", "[CLS] Size of trainset: Table\u00a0REF  shows the MPJPE versus the training data size. [SEP]\n", "[CLS] Since approaches deal with 2D and 3D sources differently, we list both sizes. [SEP]\n", "[CLS] Yasin et al. {{cite:b8fb3fe1-0036-4263-8728-80c4f2706ac0}} project multiple 2D poses from each 3D exemplar (with virtual cameras) to create 2D poses for matching, and Rogez et al. {{cite:5d80ecea-0afc-4239-b85d-53476ef6fc21}} directly synthesize 2D images for training. [SEP]\n", "[CLS] Our approach makes use of the default training data in Human3.6 [SEP]\n", "[CLS] M, where each 3D pose is paired with a single 2D projection. [SEP]\n", "[CLS] We max out performance with a modest pose library of 180k 3D-2D pairs, but produce competitive accuracy even for 18k. [SEP]\n", "[CLS] The slight increase in MPJPE for larger training sets seems to be related to noise from 2D pose estimation, since we observe a monotonically decrease when ground truth 2D poses are given (Fig.\u00a0REF ). [SEP]\n", "[CLS] TABLE  TABLE   Comparison to state-of-the-art (Protocol 2) Final system: Table\u00a0REF  provides the comparison to {{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}} and {{cite:34ce34df-bfb8-4e72-b9b4-7508888d846d}} using Protocol 2. [SEP]\n", "[CLS] Note that in both these works, temporal smoothness was exploited by taking a short image sequences as input. [SEP]\n", "[CLS] Even though we do not use temporal information, our system is quite close to state-of-the-art. [SEP]\n", "[CLS] A qualitative comparison to {{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}} is also provided in Fig.\u00a0REF . [SEP]\n", "[CLS] Performance given ground-truth 2D: Our strong performance in Fig. [SEP]\n", "[CLS] \u00a0REF  might be attributed to better 2D pose estimation. [SEP]\n", "[CLS] Therefore, we investigate the case given ground truth 2D pose, following Zhou's diagnostic protocol {{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}}: evaluate MPJPE up to a 3D rigid body transformation including scale, only on the first 30 seconds of the first camera in Human3.6M. For a fair comparison, we make use the same training set of 3D-2D training data for both methods. [SEP]\n", "[CLS] The results are shown in Table\u00a0REF . [SEP]\n", "[CLS] With a shortlist of FORMULA  matches, camera resectioning (REF ) and exemplar warping (REF ) produces a slightly lower error than {{cite:e71a4e72-997c-42b6-837a-25b9c7ee2c91}}'s approach without a 3D prior. [SEP]\n", "[CLS] Qualitative results are provided in Fig. [SEP]\n", "[CLS] \u00a0REF . [SEP]\n", "[CLS] Our approach produces lower 2D reprojection error, while Zhou's method appears to suffers from the restriction of 3D poses to a low-dimensional subspace. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] FIGURE  TABLE   Diagnostics We now perform an extensive set of diagnostics to reveal the strength of our individual components, as well as upper-bound analysis that is useful for guiding future work. [SEP]\n", "[CLS] For simplicity, we restrict ourselves to Protocol 1. [SEP]\n", "[CLS] Effect of warping: We evaluate the benefits of warping (FORMULA  vs FORMULA ) in Table\u00a0REF . [SEP]\n", "[CLS] It is clear that warping exemplars FORMULA  is a simple and effective approach to reducing error. [SEP]\n", "[CLS] Quite surprisingly, even without warping, simply matching to a set of 3D exemplar projections outperforms the state-of-the-art (see Table 1 & Table 6)! [SEP]\n", "[CLS] To analyze an upper-bound for our warping approach, we combine 2D estimates FORMULA  with depth values FORMULA  given by the ground-truth 3D pose FORMULA . [SEP]\n", "[CLS] In the last row, the performance of combining ground truth depth FORMULA  with FORMULA  is listed as a reference baseline. [SEP]\n", "[CLS] This suggests that one can still dramatically lower error by 2X even when continuing to use the output of current 2D pose estimation systems. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] Warping given ground-truth 2D: Next, we compute the error for the case that ground truth 2D pose is given, as shown in Table\u00a0REF . [SEP]\n", "[CLS] We write FORMULA  to emphasize that methods now have access to 2D ground-truth pose estimates. [SEP]\n", "[CLS] We first note that matching unwarped examples rivals the accuracy of state-of-the-art (see Table\u00a0REF  & Table\u00a0REF ). [SEP]\n", "[CLS] This again suggests the remarkable power a simple NN baseline based on matching 2D projections. [SEP]\n", "[CLS] That said, warping still improves results by a considerable margin. [SEP]\n", "[CLS] A qualitative example is provided in Fig. [SEP]\n", "[CLS] \u00a0REF . [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] Warping given optimal exemplar match: It is natural to ask what is the upper-bound on performance given our training set of (3D,2D) pairs. [SEP]\n", "[CLS] We first compute the optimal exemplar that minimizes 3D reprojection error (up to a rigid body transformation) to the true 3D test pose. [SEP]\n", "[CLS] We write the index of this best match from the training set as FORMULA . [SEP]\n", "[CLS] We would like to see the effect of warping given this optimal match. [SEP]\n", "[CLS] We analyze this combination in Table\u00a0REF . [SEP]\n", "[CLS] This suggests that, in principle, error can still be significantly reduced (by almost 2X) even given our fixed library of 3D poses. [SEP]\n", "[CLS] However, it is not clear that this is obtainable given our pipeline because it may require image evidence to select this optimal 3D exemplar (violating the conditional independence assumption from (REF )). [SEP]\n", "[CLS] TABLE  FIGURE  FIGURE   [SEP]\n", "[CLS] Effect of trainset size: An important aspect to investigate is the influence of database size. [SEP]\n", "[CLS] Here we investigate the error versus the number of exemplars in the database. [SEP]\n", "[CLS] Fig. [SEP]\n", "[CLS] \u00a0REF  evaluates performance versus a random fraction of our overall database. [SEP]\n", "[CLS] As expected, more data results in lower error, though diminishing results are observed (even in log scale). [SEP]\n", "[CLS] This is reasonable since training data is extracted from videos captured at 50 fps, implying that correlations over frames might limit the benefit of additional frames. [SEP]\n", "[CLS] We see that convergence is also effected by the quality of the 2D pose estimates: error given ground-truth 2D poses plateaus at FORMULA , while 2D pose estimates plateau even sooner at FORMULA . [SEP]\n", "[CLS] We posit that a more restricted 3D pose prior (implicitly enforced by a small randomly-sampled 3D library) helps given inaccurate 2D pose estimates. [SEP]\n", "[CLS] But in either case, exemplar-based 3D matching is effective even for modestly-size training sets (200,000). [SEP]\n", "[CLS] This analysis appears to suggest that better 2D pose estimates are needed to take advantage of \u201cbigger\" 3D datasets. [SEP]\n", "[CLS] Since the joint prediction error is not a normal distribution, we also plot median error in Fig.\u00a0REF . [SEP]\n", "[CLS] We see that the median is generally lower than mean error, and the difference between the two becomes smaller when ground truth 2D or 3D is given. [SEP]\n", "[CLS] This may suggest that errors are often due to a single incorrect joint prediction, which would significantly impact average error but not the median. [SEP]\n", "[CLS] Cross-dataset evaluation: To further examine generalization of exemplar-matching, Table\u00a0REF  quantitatively evaluates accuracy on HumanEva-I {{cite:c8c0a07e-3919-4c98-aeca-b01d5ee9141c}} given a model trained on Human3.6M. [SEP]\n", "[CLS] These results suggest that the 3D exemplars from HumanEva do generalize, and that generalization is significantly improved through our warping procedure. [SEP]\n", "[CLS] TABLE    [SEP]\n", "[CLS] Conclusion We present an simple approach to 3D human pose estimation by performing 2D pose estimation, followed by 3D exemplar matching. [SEP]\n", "[CLS] The simplicity and efficiency of our method, combined with its state-of-the-art performance on both benchmark datasets and unconstrained \u201cin-the-wild\" imagery, suggests that such simple baselines should be used for future benchmarking in 3D pose estimation. [SEP]\n", "[CLS] A notable advantage of intermediate 2D representations is modular training \u2013 2D datasets (which are typically larger and more diverse because of ease of annotation) can be used to train the initial-image processing module, while 3D motion capture data can be used to train the subsequent 3D-reasoning module. [SEP]\n", "[CLS] This allows our system to take immediate advantage of advances in 2D pose estimation, such as multi-body analysis\u00a0{{cite:ae754aba-0bfa-4fe1-9052-fd281eff1aaf}}. [SEP]\n", "[CLS] Our results also suggest that 3D inference is, in some sense, \u201call about 2D\", at least in the case of articulated objects. [SEP]\n", "[CLS] Indeed, one of our surprising findings was the high performance of 2D pose estimation systems even under occlusions, suggesting that 2D estimates can in fact be reliably estimated without directly reasoning about depth. [SEP]\n", "[CLS] Given such reliable 2D estimates, we show that one can efficiently impute depth through simple memorization and warping of a 3D pose library. [SEP]\n", "[CLS] Acknowledgements: This work was supported by NSF Grant 1618903, NSF Grant 1208598, the Intel Science and Technology Center for Visual Cloud Systems (ISTC-VCS), Google, and Amazon. [SEP]\n"], "1305.2460": ["[CLS]  Spatially Sparse Precoding in Millimeter Wave MIMO Systems\u00a0 [SEP]\n", "[CLS] This work was done while the first author was with Samsung Research America - Dallas. [SEP]\n", "[CLS] The authors at The University of Texas at Austin were supported in part by the Army Research Laboratory contract W911NF-10-1-0420 and National Science Foundation grant 1218338. [SEP]\n", "[CLS] This work has appeared in part at the 2012 IEEE International Communications Conference (ICC). [SEP]\n", "[CLS] Omar\u00a0El\u00a0Ayach, Sridhar Rajagopal, Shadi Abu-Surra, Zhouyue Pi, and Robert\u00a0W.\u00a0Heath, [SEP]\n", "[CLS] \u00a0Jr. [SEP]\n", "[CLS] Omar El Ayach and Robert Heath are with The University of Texas at Austin, Austin, TX 78712 USA (Email: oelayach, rheath@utexas.edu). [SEP]\n", "[CLS] Sridhar Rajagopal, Shadi Abu-Surra, and Zhouyue Pi are with Samsung Research America - Dallas, Richardson, TX, 75082 USA (Email: {sasurra, srajagop, zpi}@sta.samsung.com)   [SEP]\n", "[CLS] Millimeter wave (mmWave) signals experience orders-of-magnitude more pathloss than the microwave signals currently used in most wireless applications. [SEP]\n", "[CLS] MmWave systems must therefore leverage large antenna arrays, made possible by the decrease in wavelength, to combat pathloss with beamforming gain. [SEP]\n", "[CLS] Beamforming with multiple data streams, known as precoding, can be used to further improve mmWave spectral efficiency. [SEP]\n", "[CLS] Both beamforming and precoding are done digitally at baseband in traditional multi-antenna systems. [SEP]\n", "[CLS] The high cost and power consumption of mixed-signal devices in mmWave systems, however, make analog processing in the RF domain more attractive. [SEP]\n", "[CLS] This hardware limitation restricts the feasible set of precoders and combiners that can be applied by practical mmWave transceivers. [SEP]\n", "[CLS] In this paper, we consider transmit precoding and receiver combining in mmWave systems with large antenna arrays. [SEP]\n", "[CLS] We exploit the spatial structure of mmWave channels to formulate the precoding/combining problem as a sparse reconstruction problem. [SEP]\n", "[CLS] Using the principle of basis pursuit, we develop algorithms that accurately approximate optimal unconstrained precoders and combiners such that they can be implemented in low-cost RF hardware. [SEP]\n", "[CLS] We present numerical results on the performance of the proposed algorithms and show that they allow mmWave systems to approach their unconstrained performance limits, even when transceiver hardware constraints are considered. [SEP]\n", "[CLS] Introduction The capacity of wireless networks has thus far scaled with the increasing data traffic, primarily due to improved area spectral efficiency (bits/s/Hz/m2)\u00a0{{cite:eaed9610-e304-4f2e-8b77-0d99b7784b58}}. [SEP]\n", "[CLS] A number of physical layer enhancements such as multiple antennas, channel coding, and interference coordination, as well as the general trend toward network densification have all been instrumental in achieving this efficiency\u00a0{{cite:eaed9610-e304-4f2e-8b77-0d99b7784b58}}, {{cite:fd8e7325-6936-44d8-8369-c98701755232}}. [SEP]\n", "[CLS] Since there seems to be little scope for further gains at the physical layer, and since the widespread deployment of heterogeneous networks is not without challenges\u00a0{{cite:599d979c-003d-4d2b-8f01-8bfbbf10af9d}}, these techniques alone may not be sufficient to meet future traffic demands. [SEP]\n", "[CLS] As a result, increasing the spectrum available for commercial wireless systems, potentially by exploring new less-congested spectrum bands, is a promising solution to increase network capacity. [SEP]\n", "[CLS] Millimeter wave (mmWave) communication, for example, has enabled gigabit-per-second data rates in indoor wireless systems\u00a0{{cite:698cd55e-d92e-43a8-9066-9d8a32e2a309}}, {{cite:972849d6-fdd2-43af-914a-cad3d1989210}} and fixed outdoor systems\u00a0{{cite:9f2bbcb5-790a-4b29-afdc-d97449283810}}. [SEP]\n", "[CLS] More recently, advances in mmWave hardware {{cite:14d1527d-f262-422d-b43a-013e90000afc}} and the potential availability of spectrum has encouraged the wireless industry to consider mmWave for outdoor cellular systems\u00a0{{cite:2d363b0c-762b-4899-80ca-99ba6f6e081f}}, {{cite:60c32c51-e196-491b-8a1a-a97dd31e49c7}}. [SEP]\n", "[CLS] A main differentiating factor in mmWave communication is that the ten-fold increase in carrier frequency, compared to the current majority of wireless systems, implies that mmWave signals experience an orders-of-magnitude increase in free-space pathloss. [SEP]\n", "[CLS] An interesting redeeming feature in mmWave systems, however, is that the decrease in wavelength enables packing large antenna arrays at both the transmitter and receiver. [SEP]\n", "[CLS] Large arrays can provide the beamforming gain needed to overcome pathloss and establish links with reasonable signal-to-noise ratio (SNR). [SEP]\n", "[CLS] Further, large arrays may enable precoding multiple data streams which could improve spectral efficiency and allow systems to approach capacity\u00a0{{cite:8aa17970-9786-4f7d-ab61-899c85d754e6}}, {{cite:e3148a76-e1c2-481b-b3db-20b458f48260}}. [SEP]\n", "[CLS] While the fundamentals of precoding are the same regardless of carrier frequency, signal processing in mmWave systems is subject to a set of non-trivial practical constraints. [SEP]\n", "[CLS] For example, traditional multiple-input multiple-output (MIMO) processing is often performed digitally at baseband, which enables controlling both the signal's phase and amplitude. [SEP]\n", "[CLS] Digital processing, however, requires dedicated baseband and RF hardware for each antenna element. [SEP]\n", "[CLS] Unfortunately, the high cost and power consumption of mmWave mixed-signal hardware precludes such a transceiver architecture at present, and forces mmWave systems to rely heavily on analog or RF processing {{cite:14d1527d-f262-422d-b43a-013e90000afc}}, {{cite:2d363b0c-762b-4899-80ca-99ba6f6e081f}}. [SEP]\n", "[CLS] Analog precoding is often implemented using phase shifters\u00a0{{cite:2d363b0c-762b-4899-80ca-99ba6f6e081f}}, {{cite:14d1527d-f262-422d-b43a-013e90000afc}}, {{cite:4411c487-cee7-43af-bd65-dbee3b285fa5}} which places constant modulus constraints on the elements of the RF precoder. [SEP]\n", "[CLS] Several approaches have been considered for precoding in such low-complexity transceivers\u00a0{{cite:44338816-74f9-4779-bfc5-54f3b34aa0b6}}, {{cite:2217147f-959f-4744-9324-60b08a58c8ca}}, {{cite:4d463c62-6b5a-43de-a8b2-6817c0722d5f}}, {{cite:c6ea6532-ee0a-4ac0-b197-5ece69f280c6}}, {{cite:abe216ea-d0e2-46f1-a8bf-a0c63470902d}}, {{cite:ead3b8dd-0adb-44d4-a047-05cb02db7453}}, {{cite:7f4e3768-f18b-4c47-88eb-6bb451cc7b6f}}, {{cite:0ae52dcc-a15d-4cd6-b539-71bc0cb6f10e}}, {{cite:7d596b5f-1a8d-4598-922f-190747091f4e}}, {{cite:35e741e7-66cc-435d-8c2c-f536a39aff9a}}, {{cite:59da8c32-bc26-4a2d-97a9-3203e64c41b4}}, {{cite:afb7bb50-3759-42da-a8f1-89eb62225caf}}, {{cite:c2e51cf4-7588-4468-af40-12f62f02302f}}, {{cite:66d065e0-e1e3-4520-84bc-14c53c0350dd}}, {{cite:37bdad85-cd1a-48f7-b85f-a2ccc3806d49}}, {{cite:a548aadb-de12-4230-a715-c75c1429abef}}. [SEP]\n", "[CLS] The work in {{cite:44338816-74f9-4779-bfc5-54f3b34aa0b6}}, {{cite:2217147f-959f-4744-9324-60b08a58c8ca}}, {{cite:4d463c62-6b5a-43de-a8b2-6817c0722d5f}} considers antenna (or antenna subset) selection which has the advantage of replacing phase shifters with even simpler analog switches. [SEP]\n", "[CLS] Selection, however, provides limited array gain and performs poorly in correlated channels such as those experienced in mmWave\u00a0{{cite:c6ea6532-ee0a-4ac0-b197-5ece69f280c6}}. [SEP]\n", "[CLS] To improve performance over correlated channels, the work {{cite:abe216ea-d0e2-46f1-a8bf-a0c63470902d}}, {{cite:ead3b8dd-0adb-44d4-a047-05cb02db7453}}, {{cite:7f4e3768-f18b-4c47-88eb-6bb451cc7b6f}}, {{cite:0ae52dcc-a15d-4cd6-b539-71bc0cb6f10e}} considers beam steering solutions in which phase shifters or discrete lens arrays are used to optimally orient an array's response in space, potentially based on statistical channel knowledge. [SEP]\n", "[CLS] The strategies in {{cite:abe216ea-d0e2-46f1-a8bf-a0c63470902d}}, {{cite:ead3b8dd-0adb-44d4-a047-05cb02db7453}}, {{cite:7f4e3768-f18b-4c47-88eb-6bb451cc7b6f}}, {{cite:0ae52dcc-a15d-4cd6-b539-71bc0cb6f10e}}, however, are in general suboptimal since beam steering alone cannot perfectly capture the channels dominant eigenmodes. [SEP]\n", "[CLS] The work in {{cite:7d596b5f-1a8d-4598-922f-190747091f4e}}, {{cite:35e741e7-66cc-435d-8c2c-f536a39aff9a}}, {{cite:59da8c32-bc26-4a2d-97a9-3203e64c41b4}}, {{cite:afb7bb50-3759-42da-a8f1-89eb62225caf}}, {{cite:c2e51cf4-7588-4468-af40-12f62f02302f}}, {{cite:66d065e0-e1e3-4520-84bc-14c53c0350dd}} develops iterative precoding algorithms for systems that leverage analog processing, and {{cite:37bdad85-cd1a-48f7-b85f-a2ccc3806d49}} further proposes simple analytical solutions. [SEP]\n", "[CLS] Further hardware limitations have also been considered in {{cite:a548aadb-de12-4230-a715-c75c1429abef}}, for example, which focuses on analog receiver processing with only quantized phase control and finite-precision analog-to-digital converters. [SEP]\n", "[CLS] The work in {{cite:7d596b5f-1a8d-4598-922f-190747091f4e}}, {{cite:35e741e7-66cc-435d-8c2c-f536a39aff9a}}, {{cite:59da8c32-bc26-4a2d-97a9-3203e64c41b4}}, {{cite:afb7bb50-3759-42da-a8f1-89eb62225caf}}, {{cite:c2e51cf4-7588-4468-af40-12f62f02302f}}, {{cite:66d065e0-e1e3-4520-84bc-14c53c0350dd}}, {{cite:37bdad85-cd1a-48f7-b85f-a2ccc3806d49}}, {{cite:a548aadb-de12-4230-a715-c75c1429abef}}, however, is not specialized to mmWave MIMO systems with large antenna arrays. [SEP]\n", "[CLS] Namely, the work in {{cite:7d596b5f-1a8d-4598-922f-190747091f4e}}, {{cite:35e741e7-66cc-435d-8c2c-f536a39aff9a}}, {{cite:59da8c32-bc26-4a2d-97a9-3203e64c41b4}}, {{cite:afb7bb50-3759-42da-a8f1-89eb62225caf}}, {{cite:c2e51cf4-7588-4468-af40-12f62f02302f}}, {{cite:66d065e0-e1e3-4520-84bc-14c53c0350dd}}, {{cite:37bdad85-cd1a-48f7-b85f-a2ccc3806d49}}, {{cite:a548aadb-de12-4230-a715-c75c1429abef}} does not leverage the structure present in mmWave MIMO channels and adopts models that do not fully capture the effect of limited mmWave scattering and large tightly-packed arrays\u00a0{{cite:66cf682e-0515-4e55-8ef4-9ea791a7b0a2}}, {{cite:00bbd661-0ef4-490a-8062-c3f0959c99ca}}, {{cite:5fd2d74a-d114-4145-a352-acb3a555b853}}. [SEP]\n", "[CLS] In this paper, we focus on the precoding insight and solutions that can be derived from jointly considering the following three factors: (i) precoding with RF hardware constraints, (ii) the use of large antenna arrays, and (iii) the limited scattering nature of mmWave channels. [SEP]\n", "[CLS] We consider single-user precoding for a practical transceiver architecture in which a large antenna array is driven by a limited number of transmit/receive chains\u00a0{{cite:2d363b0c-762b-4899-80ca-99ba6f6e081f}}, {{cite:8aa17970-9786-4f7d-ab61-899c85d754e6}}, {{cite:e3148a76-e1c2-481b-b3db-20b458f48260}}, {{cite:87994e5a-5d99-471e-bd06-b8f87493e230}}. [SEP]\n", "[CLS] In such a system, transmitters have the ability to apply high-dimensional (tall) RF precoders, implemented via analog phase shifters, followed by low-dimensional (small) digital precoders that can be implemented at baseband. [SEP]\n", "[CLS] We adopt a realistic clustered channel model that captures both the limited scattering at high frequency and the antenna correlation present in large tightly-packed arrays\u00a0{{cite:66cf682e-0515-4e55-8ef4-9ea791a7b0a2}}, {{cite:5fd2d74a-d114-4145-a352-acb3a555b853}}, {{cite:00bbd661-0ef4-490a-8062-c3f0959c99ca}}. [SEP]\n", "[CLS] We exploit the sparse-scattering structure of mmWave channels to formulate the design of hybrid RF/baseband precoders as a sparsity constrained matrix reconstruction problem\u00a0{{cite:e6c6eaf4-c240-491c-aaf2-08c04b14e9c5}}, {{cite:ea3eb4f3-42d8-4bcb-8d7d-951c1727f316}}, {{cite:31036dbd-5054-49b0-a7c9-ffd1f7f492f3}}, {{cite:197bf33d-c54b-4ed4-912b-f16f6b88e18a}}, {{cite:2d0f09d5-f5d2-4a3e-a8fb-2757efc75eac}}, {{cite:5591595b-33a6-4651-a7d3-76a654a7dd18}}. [SEP]\n", "[CLS] Initial results on this precoding approach were presented in {{cite:11fcc201-775a-4d66-bec3-e969a6de9cc4}}. [SEP]\n", "[CLS] In this paper, we formalize the mmWave precoding problem and show that, instead of directly maximizing mutual information, near-optimal hybrid precoders can be found via an optimization that resembles the problem of sparse signal recovery with multiple measurement vectors, also known as the simultaneously sparse approximation problem\u00a0{{cite:dd319f94-3694-48f6-b390-12b28d64412a}}, {{cite:8266b750-f4bc-4fa5-b08f-4c294b99e91d}}, {{cite:032c6203-8e01-4cb2-9e84-17a2d3ea9b9c}}, {{cite:8e3dffb7-c8f1-432a-b5a6-303a0c3650a5}}. [SEP]\n", "[CLS] We thus provide an algorithmic precoding solution based on the concept of orthogonal matching pursuit\u00a0{{cite:197bf33d-c54b-4ed4-912b-f16f6b88e18a}}, {{cite:ea3eb4f3-42d8-4bcb-8d7d-951c1727f316}}, {{cite:084f6762-625d-416d-8b10-deb32a6fcd91}}. [SEP]\n", "[CLS] The algorithm takes an optimal unconstrained precoder as input and approximates it as linear combination of beam steering vectors that can be applied at RF (and combined digitally at baseband). [SEP]\n", "[CLS] Further, we extend this sparse precoding approach to receiver-side processing and show that designing hybrid minimum mean-square error (MMSE) combiners can again be cast as a simultaneously sparse approximation problem and solved via basis pursuit\u00a0{{cite:99da2b9b-931a-47e1-8269-3fa138c2d994}}, {{cite:2dc35a6f-d96c-4039-948c-37c310f6fa2a}}. [SEP]\n", "[CLS] We argue that, in addition to providing practical near-optimal precoders, the proposed framework is particularly amenable for limited feedback operation and is thus not limited to genie-aided systems with perfect transmitter channel knowledge\u00a0{{cite:2b75f029-0594-4341-815b-bd101721eace}}. [SEP]\n", "[CLS] The generated precoders can be efficiently compressed using simple scalar quantizers (for the arguments of the beam steering vectors) and low-dimensional Grassmannian subspace quantizers (used to quantize the baseband precoder)\u00a0{{cite:2b75f029-0594-4341-815b-bd101721eace}}, {{cite:893ce582-a094-4625-8568-e860fa8b0433}}, {{cite:522ca8bc-8ce2-4d61-8182-df6921f15538}}. [SEP]\n", "[CLS] We briefly describe the construction of the limited feedback codebooks required, but defer the analysis of limited feedback performance to future work. [SEP]\n", "[CLS] Finally, we present simulation results on the performance of the proposed strategy and show that it allows mmWave systems to approach their unconstrained performance limits even when practical transceiver constraints are considered. [SEP]\n", "[CLS] We use the following notation throughout this paper: FORMULA  is a matrix; FORMULA  is a vector; FORMULA  is a scalar; FORMULA  is the FORMULA  column of FORMULA ; FORMULA  and FORMULA  denote transpose and conjugate transpose respectively; FORMULA  is the Frobenius norm of FORMULA , FORMULA  is its trace and FORMULA  is its determinant; FORMULA  is the FORMULA -norm of FORMULA ; FORMULA  denotes horizontal concatenation; FORMULA  is a vector formed by the diagonal elements of FORMULA ; FORMULA  is the FORMULA  identity matrix; FORMULA  is the FORMULA  all-zeros matrix; FORMULA  is a complex Gaussian vector with mean FORMULA  and covariance matrix FORMULA . [SEP]\n", "[CLS] Expectation is denoted by FORMULA  and the real part of a variable is denoted by FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] System Model [SEP]\n", "[CLS] In this section, we present the mmWave signal and channel model considered in this paper. [SEP]\n", "[CLS] System Model Consider the single-user mmWave system shown in Fig. REF  in which a transmitter with FORMULA  antennas communicates FORMULA  data streams to a receiver with FORMULA  antennas\u00a0{{cite:87994e5a-5d99-471e-bd06-b8f87493e230}}. [SEP]\n", "[CLS] To enable multi-stream communication, the transmitter is equipped with FORMULA  transmit chains such that FORMULA . [SEP]\n", "[CLS] This hardware architecture enables the transmitter to apply an FORMULA  baseband precoder FORMULA  using its FORMULA  transmit chains, followed by an FORMULA  RF precoder FORMULA  using analog circuitry. [SEP]\n", "[CLS] The discrete-time transmitted signal is therefore given by FORMULA  where FORMULA  is the FORMULA  symbol vector such that FORMULA . [SEP]\n", "[CLS] Since FORMULA  is implemented using analog phase shifters, its elements are constrained to satisfy FORMULA , where FORMULA  denotes the FORMULA  diagonal element of a matrix, i.e., all elements of FORMULA  have equal norm. [SEP]\n", "[CLS] The transmitter's total power constraint is enforced by normalizing FORMULA  such that FORMULA ; no other hardware-related constraints are placed on the baseband precoder. [SEP]\n", "[CLS] For simplicity, we consider a narrowband block-fading propagation channel as in {{cite:8aa17970-9786-4f7d-ab61-899c85d754e6}}, {{cite:7f4e3768-f18b-4c47-88eb-6bb451cc7b6f}}, {{cite:66d065e0-e1e3-4520-84bc-14c53c0350dd}}, {{cite:87994e5a-5d99-471e-bd06-b8f87493e230}}, which yields a received signal FORMULA  where FORMULA  is the FORMULA  received vector, FORMULA  is the FORMULA  channel matrix such that FORMULA , FORMULA  represents the average received power, and FORMULA  is the vector of i.i.d FORMULA  noise. [SEP]\n", "[CLS] In writing (REF ), we implicitly assume perfect timing and frequency recovery. [SEP]\n", "[CLS] Moreover, to enable precoding, we assume that the channel FORMULA  is known perfectly and instantaneously to both the transmitter and receiver. [SEP]\n", "[CLS] In practical systems, channel state information (CSI) at the receiver can be obtained via training\u00a0{{cite:abe216ea-d0e2-46f1-a8bf-a0c63470902d}}, {{cite:85493e22-13b4-4e04-bd85-099578c07b31}} and subsequently shared with the transmitter via limited feedback\u00a0{{cite:2b75f029-0594-4341-815b-bd101721eace}}; an efficient limited feedback strategy is presented in Section . [SEP]\n", "[CLS] Techniques for efficient mmWave channel estimation, and a rigorous treatment of frequency selective mmWave channels, are still an ongoing topic of research. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The receiver uses its FORMULA  RF chains and its analog phase shifters to obtain the post-processing received signal FORMULA  where FORMULA  is the FORMULA   [SEP]\n", "[CLS] RF combining matrix and FORMULA  is the FORMULA  baseband combining matrix. [SEP]\n", "[CLS] Similarly to the RF precoder, FORMULA  is implemented using phase shifters and therefore is such that FORMULA . [SEP]\n", "[CLS] When Gaussian symbols are transmitted over the mmWave channel, the spectral efficiency achieved is given by\u00a0{{cite:a2058890-5227-4dba-a9b8-7335e3353709}} FORMULA   where FORMULA  is the noise covariance matrix after combining.   [SEP]\n", "[CLS] Channel Model [SEP]\n", "[CLS] The high free-space pathloss that is a characteristic of mmWave propagation leads to limited spatial selectivity or scattering. [SEP]\n", "[CLS] Similarly, the large tightly-packed antenna arrays that are characteristic of mmWave transceivers lead to high levels of antenna correlation. [SEP]\n", "[CLS] This combination of tightly packed arrays in sparse scattering environments makes many of the statistical fading distributions used in traditional MIMO analysis inaccurate for mmWave channel modeling. [SEP]\n", "[CLS] For this reason, we adopt a narrowband clustered channel representation, based on the extended Saleh-Valenzuela model, which allows us to accurately capture the mathematical structure present in mmWave channels\u00a0{{cite:00bbd661-0ef4-490a-8062-c3f0959c99ca}}, {{cite:66cf682e-0515-4e55-8ef4-9ea791a7b0a2}}, {{cite:3774d1a5-dfcd-4d33-a380-5a2afe603719}}, {{cite:8bcc471d-baf7-4dae-8c8c-3ab24f766fe8}}. [SEP]\n", "[CLS] Using the clustered channel model, the matrix channel FORMULA  is assumed to be a sum of the contributions of FORMULA  scattering clusters, each of which contribute FORMULA  propagation paths to the channel matrix FORMULA . [SEP]\n", "[CLS] Therefore, the discrete-time narrowband channel FORMULA  can be written as FORMULA  where FORMULA  is the complex gain of the FORMULA  ray in the FORMULA  scattering cluster, whereas FORMULA  (FORMULA ) and FORMULA  (FORMULA ) are its azimuth (elevation) angles of arrival and departure respectively. [SEP]\n", "[CLS] The functions FORMULA  and FORMULA  represent the transmit and receive antenna element gain at the corresponding angles of departure and arrival. [SEP]\n", "[CLS] Finally, the vectors FORMULA  and FORMULA  represent the normalized receive and transmit array response vectors at an azimuth (elevation) angle of FORMULA  (FORMULA ) and FORMULA  (FORMULA ) respectively. [SEP]\n", "[CLS] In Section , we assume that FORMULA  are i.i.d. [SEP]\n", "[CLS] FORMULA  where FORMULA  represents the average power of the FORMULA  cluster. [SEP]\n", "[CLS] The average cluster powers are such [SEP]\n", "[CLS] that FORMULA  where FORMULA  is a normalization constant that satisfies FORMULA \u00a0{{cite:00bbd661-0ef4-490a-8062-c3f0959c99ca}}. [SEP]\n", "[CLS] The FORMULA  azimuth and elevation angles of departure, FORMULA  and FORMULA , within the cluster FORMULA  are assumed to be randomly distributed with a uniformly-random mean cluster angle of FORMULA  and FORMULA  respectively, and a constant angular spread (standard deviation) of FORMULA  and FORMULA  respectively. [SEP]\n", "[CLS] The azimuth and elevation angles of arrival, FORMULA  and FORMULA , are again randomly distributed with mean cluster angles of FORMULA  and angular spreads FORMULA . [SEP]\n", "[CLS] While a variety of distributions have been proposed for the angles of arrival and departure in clustered channel models, the Laplacian distribution has been found to be a good fit for a variety of propagation scenarios\u00a0{{cite:3f2628c9-1fdb-4826-8aa9-37430540a1c0}}, and will thus be adopted in the numerical results of Section\u00a0. [SEP]\n", "[CLS] Similarly, a number of parametrized mathematical models have been proposed for the functions FORMULA  and FORMULA . [SEP]\n", "[CLS] For example, if the transmitter's antenna elements are modeled as being ideal sectored elements\u00a0{{cite:0d1e3fc6-ad3e-4321-ae59-d4610f531649}}, FORMULA  would be given by FORMULA  where we have assumed unit gain over the sector defined by FORMULA  and FORMULA  without loss of generality. [SEP]\n", "[CLS] The receive antenna element gain FORMULA  is defined similarly over the azimuth sector FORMULA  and elevation sector FORMULA . [SEP]\n", "[CLS] The array response vectors FORMULA  and FORMULA  are a function of the transmit and receiver antenna array structure only, and are thus independent of the antenna element properties. [SEP]\n", "[CLS] While the algorithms and results derived in the remainder of this paper can be applied to arbitrary antenna arrays, we give the following two illustrative examples of commonly-used antenna arrays for completeness. [SEP]\n", "[CLS] For an FORMULA -element uniform linear array (ULA) on the FORMULA -axis, the array response vector can be written as\u00a0{{cite:f7a2ee64-68d3-402f-916b-5bb4d79aaa13}} FORMULA  where FORMULA  and FORMULA  is the inter-element spacing. [SEP]\n", "[CLS] Note that we do not include FORMULA  in the arguments of FORMULA  as the array's response is invariant in the elevation domain. [SEP]\n", "[CLS] In the case of a uniform planar array (UPA) in the FORMULA -plane with FORMULA  and FORMULA  elements on the FORMULA  and FORMULA  axes respectively, the array response vector is given by {{cite:f7a2ee64-68d3-402f-916b-5bb4d79aaa13}} FORMULA   where FORMULA  and FORMULA  are the FORMULA  and FORMULA  indices of an antenna element respectively and the antenna array size is FORMULA . [SEP]\n", "[CLS] Considering uniform planar arrays is of interest in mmWave beamforming since they (i) yield smaller antenna array dimensions, (ii) facilitate packing more antenna elements in a reasonably-sized array, and (iii) enable beamforming in the elevation domain (also known as 3D beamforming). [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Spatially Sparse Precoding for the Single User mmWave Channel [SEP]\n", "[CLS] We seek to design hybrid mmWave precoders FORMULA  that maximize the spectral efficiency expression in (REF ). [SEP]\n", "[CLS] Directly maximizing (REF ), however, requires a joint optimization over the four matrix variables FORMULA . [SEP]\n", "[CLS] Unfortunately, finding global optima for similar constrained joint optimization problems is often found to be intractable\u00a0{{cite:704d30f1-bddd-4ec2-b419-3475480700d1}}, {{cite:2f4408bf-6f81-4731-8910-5097d695f9a9}}. [SEP]\n", "[CLS] In the case of mmWave precoding, the non-convex constraints on FORMULA  and FORMULA  makes finding an exact solution unlikely. [SEP]\n", "[CLS] To simplify transceiver design, we temporarily decouple the joint transmitter-receiver optimization problem and focus on the design of the hybrid precoders FORMULA . [SEP]\n", "[CLS] Therefore, in lieu of maximizing spectral efficiency, we design FORMULA  to maximize the mutual information achieved by Gaussian signaling over the mmWave channel FORMULA   [SEP]\n", "[CLS] We note here that abstracting receiver operation, and focusing on mutual information instead of the spectral efficiency expression in (REF ), effectively amounts to assuming that the receiver can perform optimal nearest-neighbor decoding based on the FORMULA -dimensional received signal FORMULA . [SEP]\n", "[CLS] Unfortunately, such a decoder is impossible to realize with practical mmWave systems in which decoders do not have access to the FORMULA -dimensional signal. [SEP]\n", "[CLS] In practical mmWave systems, received signals must be combined in the analog domain, and possibly in the digital domain, before any detection or decoding is performed. [SEP]\n", "[CLS] For this reason, we revisit the problem of designing practical mmWave receivers in Section . [SEP]\n", "[CLS] Proceeding with the design of FORMULA , the precoder optimization problem can be stated as FORMULA   where FORMULA  is the set of feasible RF precoders, i.e., the set of FORMULA  matrices with constant-magnitude entries. [SEP]\n", "[CLS] To the extent of the authors' knowledge, no general solutions to (REF ) are known in the presence of the non-convex feasibility constraint FORMULA . [SEP]\n", "[CLS] Therefore, we propose to solve an approximation of (REF ) in order to find practical near-optimal precoders that can be implemented in the system of Fig. REF . [SEP]\n", "[CLS] We start by examining the mutual information achieved by the hybrid precoders FORMULA  and rewriting (REF ) in terms of the \u201cdistance\u201d between FORMULA  and the channel's optimal unconstrained precoder FORMULA . [SEP]\n", "[CLS] To do so, define the channel's ordered singular value decomposition (SVD) to be FORMULA  where FORMULA  is an FORMULA  unitary matrix, FORMULA  is a FORMULA  diagonal matrix of singular values arranged in decreasing order, and FORMULA  is a FORMULA  unitary matrix. [SEP]\n", "[CLS] Using the SVD of FORMULA  and standard mathematical manipulation, (REF ) can be rewritten as FORMULA   [SEP]\n", "[CLS] Further, defining the following two partitions of the matrices FORMULA  and FORMULA  as FORMULA   where FORMULA  is of dimension FORMULA  and FORMULA  is of dimension FORMULA , we note that the optimal unconstrained unitary precoder for FORMULA  is simply given by FORMULA . [SEP]\n", "[CLS] Further note that the precoder FORMULA  cannot in general be expressed as FORMULA  with FORMULA , and thus cannot be realized in the mmWave architecture of interest. [SEP]\n", "[CLS] If the hybrid precoder FORMULA  can be made sufficiently \u201cclose\u201d to the optimal precoder FORMULA , however, the mutual information resulting from FORMULA  and FORMULA  can be made comparable. [SEP]\n", "[CLS] In fact, to simplify the forthcoming treatment of FORMULA , we make the following system assumption. [SEP]\n", "[CLS] Approximation 1 We assume that the mmWave system parameters FORMULA , as well as the parameters of the mmWave propagation channel FORMULA , are such that the hybrid precoders FORMULA  can be made sufficiently \u201cclose\u201d to the optimal unitary precoder FORMULA . [SEP]\n", "[CLS] Mathematically, this \u201ccloseness\u201d is defined by the following two equivalent approximations:   [SEP]\n", "[CLS] The eigenvalues of the matrix FORMULA  are small. [SEP]\n", "[CLS] In the case of mmWave precoding, this can be equivalently stated as FORMULA .For [SEP]\n", "[CLS] the eigenvalues of FORMULA  to be small, we need FORMULA  where FORMULA  is any FORMULA  unitary matrix (not necessarily FORMULA ). [SEP]\n", "[CLS] However, if FORMULA  is a valid precoder with FORMULA , then so is the rotated precoder FORMULA  for which we have FORMULA . [SEP]\n", "[CLS] Since FORMULA  can be arbitrarily rotated, the conditions FORMULA  and FORMULA  can be considered equivalent in this case without loss of generality. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The singular values of the matrix FORMULA  are small; alternatively FORMULA . [SEP]\n", "[CLS]   This approximation is similar to the high-resolution approximation used to simplify the analysis of limited feedback MIMO systems by assuming that codebooks are large enough such that they contain codewords that are sufficiently close to the optimal unquantized precoder\u00a0{{cite:522ca8bc-8ce2-4d61-8182-df6921f15538}}. [SEP]\n", "[CLS] In the case of mmWave precoding, this approximation is expected to be tight in systems of interest which include: (i) a reasonably large number of antennas FORMULA , (ii) a number of transmit chains FORMULA , and (iii) correlated channel matrices FORMULA . [SEP]\n", "[CLS] Functionally, Approximation REF  allows us further simplify FORMULA . [SEP]\n", "[CLS] To do so, we use the partitions defined in (REF ) and further define the following partition of FORMULA  as FORMULA  which allows us to approximate the mutual information achieved by FORMULA  as FORMULA   where FORMULA  is a result of using the Schur complement identity for matrix determinants and FORMULA  follows from invoking Approximation REF  which implies that FORMULA , FORMULA  and FORMULA  are approximately zero. [SEP]\n", "[CLS] Using (REF ), mutual information can be further simplified by writing FORMULA   where we note that FORMULA  is exact given (REF ), and FORMULA  follows from Approximation REF  which implies that the eigenvalues of the matrix FORMULA  are small and thus allows us to use the following approximation FORMULA . [SEP]\n", "[CLS] Finally FORMULA  follows from adopting a high effective-SNR approximation which implies that FORMULA  and yields the final result in ().Note here that it is not the nominal SNR FORMULA  that is assumed to be high. [SEP]\n", "[CLS] This would be a problematic assumption in mmWave systems. [SEP]\n", "[CLS] It is, however, only the effective-SNRs in the channel's dominant FORMULA  subspaces that are assumed to be sufficiently high. [SEP]\n", "[CLS] This is a reasonable assumption since these effective SNRs include the large array gain from mmWave beamforming. [SEP]\n", "[CLS] We notice that the first term in () is the mutual information achieved by the optimal precoder FORMULA  and that the dependence of FORMULA  on the hybrid precoder FORMULA  is now captured in the second and final term of (REF ) and (). [SEP]\n", "[CLS] Assuming FORMULA  is made exactly unitary, we note that the second term in (REF ) and () is nothing but the squared chordal distance between the two points FORMULA  and FORMULA  on the Grassmann manifold. [SEP]\n", "[CLS] Since Approximation REF  states the these two points are \u201cclose\u201d, we can exploit the manifold's locally Euclidean property to replace the chordal distance by the Euclidean distance FORMULA  . [SEP]\n", "[CLS] Therefore, near-optimal hybrid precoders that approximately maximize FORMULA  can be found by instead minimizing FORMULA . [SEP]\n", "[CLS] In fact, even without treating FORMULA  as a point on the Grassmann manifold, Approximation REF  implies that FORMULA , and consequently (), can be approximately maximized by instead maximizing FORMULA .This [SEP]\n", "[CLS] is since the magnitude of FORMULA 's off-diagonal entries is negligible and all FORMULA 's diagonals must be made close to one. [SEP]\n", "[CLS] Thus FORMULA , i.e., the FORMULA  norm of FORMULA 's diagonals, can be maximized by optimizing FORMULA , i.e., the FORMULA  norm of the diagonals\u00a0{{cite:b59fbae5-3ef5-4b60-9a1a-02cf3406eda2}}, {{cite:9b2f3e72-35f7-4c55-a73e-3cc53629e99d}}, {{cite:5591595b-33a6-4651-a7d3-76a654a7dd18}}. [SEP]\n", "[CLS] Since maximizing FORMULA  is again equivalent to minimizing FORMULA , the precoder design problem can be rewritten as FORMULA   which can now be summarized as finding the projection of FORMULA  onto the set of hybrid precoders of the form FORMULA  with FORMULA . [SEP]\n", "[CLS] Further, this projection is defined with respect to the standard Frobenius norm FORMULA . [SEP]\n", "[CLS] Unfortunately, the complex non-convex nature of the feasible set FORMULA  makes finding such a projection both analytically (in closed form) and algorithmically intractable\u00a0{{cite:cd26ad19-7368-44ce-8d1e-55bf4edbff77}}, {{cite:8929e239-1e09-4347-91ef-20225c9bfbe9}}, {{cite:ee075b25-7802-4543-a45d-009e9ce4c1dc}}, {{cite:3cea9aba-498e-41c8-817b-811b100fa482}}. [SEP]\n", "[CLS] To provide near-optimal solutions to the problem in (REF ), we propose to exploit the structure of the mmWave MIMO channels generated by the clustered channel model in Section REF . [SEP]\n", "[CLS] Namely, we leverage the following observations on mmWave precoding:  Structure of optimal precoder: Recall that the optimal unitary precoder is FORMULA , and that the columns of the unitary matrix FORMULA  form an orthonormal basis for the channel's row space. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Structure of clustered mmWave channels: Examining the channel model in (REF ), we note that the array response vectors FORMULA  also form a finite spanning set for the channel's row space. [SEP]\n", "[CLS] In fact, when FORMULA , we note that the array response vectors FORMULA  will be linearly independent with probability one and will thus form another minimal basis for the channel's row space when FORMULA . [SEP]\n", "[CLS] Note: To establish the linear independence of the vectors FORMULA , consider the case of uniform linear arrays. [SEP]\n", "[CLS] When ULAs are considered, the FORMULA  matrix formed by the collection of vectors FORMULA  will be a Vandermonde matrix which has full rank whenever the angles FORMULA  are distinct. [SEP]\n", "[CLS] This event occurs with probability one when FORMULA  are generated from a continuous distribution. [SEP]\n", "[CLS] Linear independence can be established in the case of UPAs by writing their response vectors as a Kronecker product of two ULA response vectors\u00a0{{cite:78e19981-f433-4b84-afa0-586909b0e976}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Connection between FORMULA  and  FORMULA: Regardless of whether FORMULA  or not, observation 1 implies that the columns of the optimal precoder FORMULA  are related to the vectors FORMULA  through a linear transformation. [SEP]\n", "[CLS] As a result, the columns of FORMULA  can be written as linear combinations of FORMULA . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Vectors FORMULA  as columns of  FORMULA: Recall that the vectors FORMULA  are constant-magnitude phase-only vectors which can be applied at RF using analog phase shifters. [SEP]\n", "[CLS] Therefore, the mmWave transmitter can apply FORMULA  of the vectors FORMULA  at RF (via the RF precoder FORMULA ), and form arbitrary linear combinations of them using its digital precoder FORMULA . [SEP]\n", "[CLS] Namely, it can construct the linear combination that minimizes FORMULA .   [SEP]\n", "[CLS] Therefore, by exploiting the structure of FORMULA , we notice that near-optimal hybrid precoders can be found by further restricting FORMULA  to be the set of vectors of the form FORMULA  and solving FORMULA   which amounts to finding the best low dimensional representation of FORMULA  using the basis vectors FORMULA . [SEP]\n", "[CLS] We note here that the set of basis vectors can be extended to include array response vectors FORMULA  in directions other than FORMULA , though the effect of this basis extension is typically negligible. [SEP]\n", "[CLS] In any case, the precoding problem consists of selecting the \u201cbest\u201d FORMULA  array response vectors and finding their optimal baseband combination. [SEP]\n", "[CLS] Finally, we note that the constraint of FORMULA  can be embedded directly into the optimization objective to obtain the following equivalent problem FORMULA   where FORMULA  is an FORMULA  matrix of array response vectors and FORMULA  is an FORMULA  matrix. [SEP]\n", "[CLS] The matrices FORMULA  and FORMULA  act as auxiliary variables from which we obtain FORMULA  and FORMULA  respectively. [SEP]\n", "[CLS] Namely, the sparsity constraint FORMULA  states that FORMULA  cannot have more than FORMULA  non-zero rows. [SEP]\n", "[CLS] When only FORMULA  rows of FORMULA  are non zero, only FORMULA  columns of the matrix FORMULA  are effectively \u201cselected\u201d. [SEP]\n", "[CLS] As a result, the baseband precoder FORMULA  will be given by the FORMULA  non-zero rows of FORMULA  and the RF precoder FORMULA  will be given by the corresponding FORMULA  columns of FORMULA . [SEP]\n", "[CLS] Essentially, we have reformulated the problem of jointly designing FORMULA  and FORMULA  into a sparsity constrained matrix reconstruction problem with one variable. [SEP]\n", "[CLS] Although the underlying motivation differs, and so does the interpretation of the different variables involved in (REF ), the resulting problem formulation is identical to the optimization problem encountered in the literature on sparse signal recovery. [SEP]\n", "[CLS] Thus, the extensive literature on sparse reconstruction can now be used for hybrid precoder design\u00a0{{cite:197bf33d-c54b-4ed4-912b-f16f6b88e18a}}, {{cite:ea3eb4f3-42d8-4bcb-8d7d-951c1727f316}}. [SEP]\n", "[CLS] To see this more clearly, note that in the simplest case of single stream beamforming, (REF ) simplifies to FORMULA   in which the sparsity constraint is now on the vector FORMULA . [SEP]\n", "[CLS] This beamforming problem can be solved, for example, by relaxing the sparsity constraint and using convex optimization to solve its FORMULA  relaxation. [SEP]\n", "[CLS] Alternatively, (REF ) can be solved using tools from {{cite:31036dbd-5054-49b0-a7c9-ffd1f7f492f3}}, {{cite:084f6762-625d-416d-8b10-deb32a6fcd91}}, {{cite:197bf33d-c54b-4ed4-912b-f16f6b88e18a}}, {{cite:2d0f09d5-f5d2-4a3e-a8fb-2757efc75eac}}, {{cite:ea3eb4f3-42d8-4bcb-8d7d-951c1727f316}}. [SEP]\n", "[CLS] [t!] Spatially Sparse Precoding via Orthogonal Matching Pursuit [1] FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA   FORMULA In the more general case of FORMULA , the problem in (REF ) is equivalent to the problem of sparse signal recovery with multiple measurement vectors, also known as the simultaneously sparse approximation problem\u00a0{{cite:dd319f94-3694-48f6-b390-12b28d64412a}}, {{cite:8266b750-f4bc-4fa5-b08f-4c294b99e91d}}, {{cite:032c6203-8e01-4cb2-9e84-17a2d3ea9b9c}}, {{cite:8e3dffb7-c8f1-432a-b5a6-303a0c3650a5}}. [SEP]\n", "[CLS] So, for the general case of FORMULA , we present an algorithmic solution based on the well-known concept of orthogonal matching pursuit\u00a0{{cite:197bf33d-c54b-4ed4-912b-f16f6b88e18a}}, {{cite:ea3eb4f3-42d8-4bcb-8d7d-951c1727f316}}, {{cite:084f6762-625d-416d-8b10-deb32a6fcd91}}. [SEP]\n", "[CLS] The pseudo-code for the precoder solution is given in Algorithm . [SEP]\n", "[CLS] In summary, the precoding algorithm starts by finding the vector FORMULA  along which the optimal precoder has the maximum projection. [SEP]\n", "[CLS] It then appends the selected column vector FORMULA  to the RF precoder FORMULA . [SEP]\n", "[CLS] After the dominant vector is found, and the least squares solution to FORMULA  is calculated in step 7, the contribution of the selected vector is removed in step 8 and the algorithm proceeds to find the column along which the \u201cresidual precoding matrix\u201d FORMULA  has the largest projection. [SEP]\n", "[CLS] The process continues until all FORMULA  beamforming vectors have been selected. [SEP]\n", "[CLS] At the end of the FORMULA  iterations, the algorithm would have (i) constructed an FORMULA  RF precoding matrix FORMULA , and (ii) found the optimal FORMULA  baseband precoder FORMULA  which minimizes FORMULA . [SEP]\n", "[CLS] Step 10 ensures that the transmit power constraint is exactly satisfied. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] To gain more intuition about the proposed precoding framework, Fig. REF  plots the beam patterns generated by a transmitter with a 256-element planar array for an example channel realization using (i) the channel's optimal unconstrained precoder, (ii) the proposed precoding strategy with FORMULA , and (ii) the beam steering vector in the channel's dominant physical direction. [SEP]\n", "[CLS] We observe that in practical mmWave channels, optimal precoders do in fact generate spatially sparse beam patterns and thus may be accurately approximated by a finite combination of array response vectors. [SEP]\n", "[CLS] Further, Fig. REF  indicates that Algorithm  succeeds in generating beam patterns which closely resemble those generated by FORMULA . [SEP]\n", "[CLS] Therefore, Algorithm  succeeds in selecting the best FORMULA  steering directions and forming appropriate linear combinations of the selected response vectors. [SEP]\n", "[CLS] This beam pattern similarity will ultimately result in favorable spectral efficiency performance as shown in Section . [SEP]\n", "[CLS] Having presented the proposed precoding framework, we conclude this section with the following design remarks. [SEP]\n", "[CLS] Remark 2 [SEP]\n", "[CLS] We note that the mmWave terminals need not know the exact angles FORMULA  that make up the channel matrix FORMULA , and need not use the matrix FORMULA  as defined earlier. [SEP]\n", "[CLS] We have only used this finite basis for simplicity of exposition. [SEP]\n", "[CLS] In general, the mmWave terminals can instead select basis vectors of the form FORMULA  using any finite set of representative azimuth and elevation directions (such as a set of equally spaced angles for example). [SEP]\n", "[CLS] This approach avoids having to decompose FORMULA  into its geometric representation and is naturally suited for limited feedback operation. [SEP]\n", "[CLS] This approach will be discussed further in Section . [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Remark 3 [SEP]\n", "[CLS] It may be advantageous in some cases to impose the additional constraint that FORMULA  be unitary. [SEP]\n", "[CLS] Unitary precoders can be more efficiently quantized and are thus more attractive in limited feedback systems. [SEP]\n", "[CLS] With this additional constraint, (REF ) can be solved again via Algorithm  by replacing the least squares solution for FORMULA  in step 7, by the solution to the corresponding orthogonal Procrustes problem\u00a0{{cite:5c4b4311-8d52-4354-b6eb-26517733bce0}}. [SEP]\n", "[CLS] This is given by FORMULA  where FORMULA  and FORMULA  are unitary matrices defined by the singular value decomposition of FORMULA , i.e., FORMULA \u00a0{{cite:5c4b4311-8d52-4354-b6eb-26517733bce0}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Remark 4 [SEP]\n", "[CLS] In the limit of large antenna arrays (FORMULA ) in very poor scattering environments for which FORMULA , the results of {{cite:78e19981-f433-4b84-afa0-586909b0e976}}, {{cite:ead3b8dd-0adb-44d4-a047-05cb02db7453}} indicate that simple RF-only beam steering becomes optimal, i.e., it becomes optimal to simply transmit each stream along one of the FORMULA  most dominant vectors FORMULA . [SEP]\n", "[CLS] For arrays of practical sizes, however, Section  shows that there can be significant gains from more involved precoding strategies such as the one presented in this section. [SEP]\n", "[CLS]   Practical Millimeter Wave Receiver Design In Section , we abstracted receiver-side processing and focused on designing practical mmWave precoders that maximize mutual information. [SEP]\n", "[CLS] Effectively, we assumed that the mmWave receiver can optimally decode data using it FORMULA -dimensional received signal. [SEP]\n", "[CLS] Such a decoder can be of prohibitively high complexity in multi-antenna systems, making lower-complexity receivers such as the commonly used linear MMSE receiver more appealing for practical implementation. [SEP]\n", "[CLS] In fact, in mmWave architectures such as the one shown in Fig. REF , such optimal decoders are impossible to realize since received signals must be linearly combined in the analog domain before any detection or decoding is performed. [SEP]\n", "[CLS] In this section, we address the problem of designing linear combiners for the mmWave receiver in Fig. REF , which uses both analog and digital processing before detection. [SEP]\n", "[CLS] Assuming the hybrid precoders FORMULA  are fixed, we seek to design hybrid combiners FORMULA  that minimize the mean-squared-error (MSE) between the transmitted and processed received signals. [SEP]\n", "[CLS] The combiner design problem can therefore be stated as FORMULA   where FORMULA  is the set of feasible RF combiners, i.e., FORMULA  is the set of FORMULA  matrices with constant-gain phase-only entries. [SEP]\n", "[CLS] In the absence of any hardware limitations that restrict the set of feasible linear receivers, the exact solution to (REF ) is well known\u00a0{{cite:f46545ca-d6e0-4e59-9be8-a39ce7b503b7}} to be FORMULA   where FORMULA  follows from applying the matrix inversion lemma. [SEP]\n", "[CLS] Just as in the precoding case, however, this optimal unconstrained MMSE combiner FORMULA  need not be decomposable into a product of RF and baseband combiners FORMULA  with FORMULA . [SEP]\n", "[CLS] Therefore FORMULA  cannot be realized in the system of Fig. REF . [SEP]\n", "[CLS] Further, just as in the precoding case, the complex non-convex constraint FORMULA  makes solving (REF ) analytically impossible and algorithmically non-trivial. [SEP]\n", "[CLS] To overcome this difficulty, we leverage the methodology used in {{cite:99da2b9b-931a-47e1-8269-3fa138c2d994}}, {{cite:2dc35a6f-d96c-4039-948c-37c310f6fa2a}} to find linear MMSE estimators with complex structural constraints. [SEP]\n", "[CLS] We start by reformulating the problem in (REF ) by expanding MSE as follows FORMULA   We now note that since the optimization problem in (REF ) is over the variables FORMULA  and FORMULA , we can add any term that is independent of FORMULA  and FORMULA  to its objective function without changing the outcome of the optimization. [SEP]\n", "[CLS] Thus, we choose to add the constant term FORMULA  and minimize the equivalent objective function FORMULA   where FORMULA  follows from noticing that FORMULA  which implies that the second term can be rewritten as FORMULA . [SEP]\n", "[CLS] As a result of (REF ), the MMSE estimation problem is equivalent to finding hybrid combiners that solve FORMULA   which amounts to finding the projection of the unconstrained MMSE combiner FORMULA  onto the set of hybrid combiners of the form FORMULA  with FORMULA . [SEP]\n", "[CLS] Thus, the design of MMSE receivers for the mmWave system of interest closely resembles the design of its hybrid precoders. [SEP]\n", "[CLS] Unlike in the precoding case however, the projection now is not with respect to the standard norm FORMULA  and is instead an FORMULA -weighted Frobenius norm. [SEP]\n", "[CLS] Unfortunately, as in the case of the precoding problem in (REF ), the non-convex constraint on FORMULA  precludes us from practically solving the projection problem in (REF ). [SEP]\n", "[CLS] The same observations that allowed us to leverage the structure of mmWave channels to solve the precoding problem in Section , however, can be translated to the receiver side to solve the combiner problem as well. [SEP]\n", "[CLS] Namely, because of the structure of clustered mmWave channels, near-optimal receivers can be found by further constraining FORMULA  to have columns of the form FORMULA  and instead solving FORMULA   where FORMULA  is an FORMULA  matrix of array response vectors and FORMULA  is an FORMULA  matrix; the quantities FORMULA  and FORMULA  act as auxiliary variables from which we obtain FORMULA  and FORMULA  in a manner similar to Section .As noted in Section  the receiver need not know the exact angles FORMULA  and can instead use any set of representative azimuth and elevation angles of arrival to construct the matrix of basis vectors FORMULA . [SEP]\n", "[CLS] As a result, the MMSE estimation problem is again equivalent to the problem of sparse signal recovery with multiple measurement vectors and can thus be solved via the orthogonal matching pursuit concept used in Section . [SEP]\n", "[CLS] For completeness the pseudo code is given in Algorithm . [SEP]\n", "[CLS] [t!] Spatially Sparse MMSE [SEP]\n", "[CLS] Combining via Orthogonal Matching Pursuit [1] FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA  FORMULA   FORMULA Remark 5 [SEP]\n", "[CLS] This section relaxes the perfect-receiver assumption of Section  and proposes practical methods to find low-complexity linear receivers. [SEP]\n", "[CLS] The design of precoders and combiners, however, remains decoupled as we have assumed that the precoders FORMULA  are fixed while designing FORMULA  (and that receivers are optimal while designing FORMULA ). [SEP]\n", "[CLS] This decoupled approach simplifies mmWave transceiver design, and will be shown to perform well in Section , however, some simple \u201cjoint decisions\u201d may be both practical and beneficial. [SEP]\n", "[CLS] For example, consider the case where a receiver only has a single RF chain and thus is restricted to applying a single response vector FORMULA . [SEP]\n", "[CLS] In such a situation, designing FORMULA  to radiate power in FORMULA  different directions may lead to a loss in actual received power (since the receiver can only form a beam in one direction). [SEP]\n", "[CLS] As a result, it is beneficial to account for the limitations of the more-constrained terminal when designing either precoders or combiners. [SEP]\n", "[CLS] To do so, we propose to run Algorithms  and  in succession according to the following rules [SEP]\n", "[CLS] FORMULA    [SEP]\n", "[CLS] In summary, starting with the more constrained side, the hybrid precoder or combiner is found using Algorithm  or . [SEP]\n", "[CLS] Then, given the output, the remaining processing matrix is found by appropriately updating the effective mmWave channel. [SEP]\n", "[CLS] Finally, we note that while the numerical results of Section  indicate that this decoupled approach to mmWave transceiver design yields near-optimal spectral efficiency, a more direct joint optimization of FORMULA  is an interesting topic for future investigation. [SEP]\n", "[CLS] Similarly, while we have solved the sparse formulation of the precoding and combining problems via orthogonal matching pursuit, the problems in (REF ) and (REF ) can be solved by leveraging other algorithms for simultaneously sparse approximation\u00a0{{cite:032c6203-8e01-4cb2-9e84-17a2d3ea9b9c}}. [SEP]\n", "[CLS]  Limited Feedback Spatially Sparse Precoding Section  implicitly assumed that the transmitter has perfect knowledge of the channel matrix FORMULA  and is thus able to calculate FORMULA  and approximate it as a hybrid RF/baseband precoder FORMULA . [SEP]\n", "[CLS] Since such transmitter channel knowledge may not be available in practical systems, we propose to fulfill this channel knowledge requirement via limited feedback\u00a0{{cite:7d596b5f-1a8d-4598-922f-190747091f4e}}, {{cite:893ce582-a094-4625-8568-e860fa8b0433}}, {{cite:2b75f029-0594-4341-815b-bd101721eace}}, {{cite:522ca8bc-8ce2-4d61-8182-df6921f15538}}. [SEP]\n", "[CLS] Namely, we assume that the receiver (i) acquires perfect knowledge of FORMULA , (ii) calculates FORMULA  and a corresponding hybrid approximation FORMULA , then (iii) feeds back information about FORMULA  to the transmitter. [SEP]\n", "[CLS] Since hybrid precoders are naturally decomposed into an RF and baseband component, we propose to quantize FORMULA  and FORMULA  separately while exploiting the mathematical structure present in each of them. [SEP]\n", "[CLS] Quantizing the RF Precoder Recall that the precoder FORMULA  calculated Section  has FORMULA  columns of the form FORMULA . [SEP]\n", "[CLS] Therefore, FORMULA  admits a natural parametrization in terms of the FORMULA  azimuth and elevation angles that it uses. [SEP]\n", "[CLS] Thus, FORMULA  can be efficiently encoded by quantizing its FORMULA  free variables. [SEP]\n", "[CLS] For simplicity, we propose to uniformly quantize the FORMULA  azimuth and elevation angles using FORMULA  and FORMULA  bits respectively. [SEP]\n", "[CLS] Therefore, the quantized azimuth and elevation angles are such that FORMULA   where we recall that FORMULA  and FORMULA  are the sectors over which FORMULA . [SEP]\n", "[CLS] The receiver can then quantize FORMULA  by simply selecting the entries of FORMULA  and FORMULA  that are closest in Euclidean distance to FORMULA 's angles. [SEP]\n", "[CLS] Alternatively, as stated in Remark REF , Algorithm  can be run directly using the FORMULA  matrix of \u201cquantized response vectors\u201d FORMULA  and the index of the selected angles can be fed back to the transmitter. [SEP]\n", "[CLS] While this latter approach has higher search complexity, it has the advantage of (i) \u201cjointly quantizing\u201d all FORMULA  angles, and (ii) automatically matching the baseband precoder FORMULA  to the quantized angles.   [SEP]\n", "[CLS] Quantizing the Baseband Precoder To efficiently quantize FORMULA , we begin by highlighting its mathematical structure in mmWave systems of interest. [SEP]\n", "[CLS] Namely, we note that for systems with large antenna arrays, we typically have that FORMULA . [SEP]\n", "[CLS] When coupled with Approximation REF , we have that FORMULA , i.e., FORMULA  is approximately unitary. [SEP]\n", "[CLS] In fact, FORMULA  can be made exactly unitary as discussed in Remark REF . [SEP]\n", "[CLS] Further, we recall that the spectral efficiency expression in (REF ) is invariant to FORMULA  unitary transformations of the baseband precoder. [SEP]\n", "[CLS] Therefore, FORMULA  is a subspace quantity that can be quantized on the Grassmann manifold\u00a0{{cite:893ce582-a094-4625-8568-e860fa8b0433}}, {{cite:2b75f029-0594-4341-815b-bd101721eace}}. [SEP]\n", "[CLS] Suitable codebooks for FORMULA  can be designed using Lloyd's algorithm on a training set of baseband precoders and using the chordal distance as a distance measure\u00a0{{cite:6ced230a-c1cd-49f7-bb9b-760195249f4f}}. [SEP]\n", "[CLS] Since such codebook construction is well-studied in the literature on limited feedback MIMO, we omit its details for brevity and refer the reader to {{cite:82fb1dcb-b735-4d91-9a22-ba837abc71c5}} for an in-depth description of the process. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Simulation Results [SEP]\n", "[CLS] In this section, we present simulation results to demonstrate the performance of the spatially sparse precoding algorithm presented in Section  when combined with the sparse MMSE combining solution presented in Section . [SEP]\n", "[CLS] We model the propagation environment as a FORMULA  cluster environment with FORMULA  rays per cluster with Laplacian distributed azimuth and elevation angles of arrival and departure\u00a0{{cite:00bbd661-0ef4-490a-8062-c3f0959c99ca}}, {{cite:3f2628c9-1fdb-4826-8aa9-37430540a1c0}}. [SEP]\n", "[CLS] For simplicity of exposition, we assume all clusters are of equal power, i.e., FORMULA , and that the angle spread at both the transmitter and receiver are equal in the azimuth and elevation domain, i.e., FORMULA . [SEP]\n", "[CLS] Since outdoor deployments are likely to use sectorized transmitters to decrease interference and increase beamforming gain, we consider arrays of directional antenna elements with a response given in (REF )\u00a0{{cite:2d363b0c-762b-4899-80ca-99ba6f6e081f}}, {{cite:60c32c51-e196-491b-8a1a-a97dd31e49c7}}. [SEP]\n", "[CLS] The transmitter's sector angle is assumed to be FORMULA -wide in the azimuth domain and FORMULA -wide in elevation\u00a0{{cite:2d363b0c-762b-4899-80ca-99ba6f6e081f}}. [SEP]\n", "[CLS] In contrast, we assume that the receivers have relatively smaller antenna arrays of omni-directional elements; this is since receivers must be able to steer beams in any direction since their location and orientation in real systems is random. [SEP]\n", "[CLS] The inter-element spacing FORMULA  is assumed to be half-wavelength. [SEP]\n", "[CLS] We compare the performance of the proposed strategy to optimal unconstrained precoding in which streams are sent along the channel's dominant eigenmodes. [SEP]\n", "[CLS] We also compare with a simple beam steering solution in which data streams are steered onto the channel's best propagation paths. [SEP]\n", "[CLS] Note that, when FORMULA , the best propagation paths in terms of spectral efficiency may not be the ones with the highest gains. [SEP]\n", "[CLS] This is since, with no receiver baseband processing, different paths must be sufficiently separated so as they do not interfere. [SEP]\n", "[CLS] In this case, the best paths are chosen via a costly exhaustive search. [SEP]\n", "[CLS] Further, when power allocation is considered in Fig. REF , the same waterfilling power allocation is applied to the beam steering solution. [SEP]\n", "[CLS] For fairness, the same total power constraint is enforced on all precoding solutions and signal-to-noise ratio is defined as FORMULA . [SEP]\n", "[CLS] FIGURE  FIGURE   [SEP]\n", "[CLS] Fig. REF  shows the spectral efficiency achieved in a FORMULA  system with square planar arrays at both transmitter and receiver. [SEP]\n", "[CLS] For the proposed precoding strategy, both transmitter and receiver are assumed to have four transceiver chains with which they transmit FORMULA  or 2 streams. [SEP]\n", "[CLS] Fig. REF  shows that the proposed framework achieves spectral efficiencies that are essentially equal to those achieved by the optimal unconstrained solution in the case FORMULA  and are within a small gap from optimality in the case of FORMULA . [SEP]\n", "[CLS] This implies that the proposed strategy can very accurately approximate the channel's dominant singular vectors as a combination of four steering vectors. [SEP]\n", "[CLS] When compared to traditional beam steering, Fig. REF  shows that there is a non-negligible improvement to be had from more sophisticated precoding strategies in mmWave systems with practical array sizes. [SEP]\n", "[CLS] To explore performance in mmWave systems with larger antenna arrays, Fig. REF  plots the performance achieved in a FORMULA  system with FORMULA  RF chains. [SEP]\n", "[CLS] Fig. REF  shows that the proposed precoding/combining solution achieves almost-perfect performance in both FORMULA  and FORMULA  cases. [SEP]\n", "[CLS] Further, we note that although beam steering is expected to be optimal in the limit of large arrays, as discussed in Remark REF , the proposed solution still outperforms beam steering by approximately 5 dB in this larger mmWave system. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] While Section  focused on the design of fixed-rank precoders with equal power allocation across streams, the same framework can be applied to systems in which FORMULA  is determined dynamically and streams are sent with unequal power. [SEP]\n", "[CLS] This configuration allows us to compare the rates achieved by the proposed precoding/combining framework to the mmWave channel's waterfilling capacity. [SEP]\n", "[CLS] To do so, Algorithm  is simply set to approximate FORMULA  where FORMULA  is a diagonal matrix resulting from the waterfilling power allocation. [SEP]\n", "[CLS] Fig. REF  demonstrates the performance achieved when Algorithms  and  are used to approximate the channel's capacity-achieving precoders and combiners in a FORMULA  mmWave system with FORMULA . [SEP]\n", "[CLS] Fig. REF  shows that the proposed framework allows systems to approach channel capacity and provides large gains over simple beam steering. [SEP]\n", "[CLS] Since the multiplexing gain of the mmWave system is limited by FORMULA , capacity cannot be approached at very high SNR when the optimal FORMULA  exceeds FORMULA . [SEP]\n", "[CLS] Fig. REF  indicates, however, that even at an SNR of 0 dB where we observe that FORMULA  streams are sent over most channel realizations, the proposed strategy is still within a small gap from capacity. [SEP]\n", "[CLS] Finally, we note that although the derivation leading up to () does not account for unequal power allocation across streams, Fig. REF  indicates that Algorithm  is nevertheless a sensible approach to designing such precoders. [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] The proposed precoding/combining framework leverages the mathematical structure of large mmWave channels with relatively limited scattering. [SEP]\n", "[CLS] To examine performance in propagation environments with varying levels of scattering, Fig. REF  plots spectral efficiency as a function of the channel's angle spread for a number of mmWave system configurations. [SEP]\n", "[CLS] Fig. REF  indicates that when the angle spread is low, i.e., the scattering is rather limited, the performance of the proposed algorithm is within a small gap from the performance of unconstrained precoding. [SEP]\n", "[CLS] As angle spread increases, the rates achieved by the proposed solutions slowly degrade. [SEP]\n", "[CLS] However, Fig REF  indicates that in the two FORMULA  cases shown, the rate gap remains below FORMULA  at a significant angle spread of FORMULA  and is negligible for more reasonable angle spreads of around FORMULA . [SEP]\n", "[CLS] In the case of FORMULA  with smaller arrays, spectral efficiency degrades more rapidly with angle spread. [SEP]\n", "[CLS] This can be seen by examining the FORMULA  system with FORMULA  and FORMULA . [SEP]\n", "[CLS] If possible, the effect of increased scattering can be mitigated by increasing the number of RF chains at the mmWave terminals which enables them to generate more flexible precoders/combiners. [SEP]\n", "[CLS] This can be seen by examining the same FORMULA  system with FORMULA . [SEP]\n", "[CLS] FIGURE   [SEP]\n", "[CLS] Finally, we examine the performance of the proposed precoding strategy in systems without channel state information at the transmitter. [SEP]\n", "[CLS] For this performance characterization, we assume that the receiver calculates FORMULA  and FORMULA  with full knowledge of the channel and feeds back their parameters as described in Section . [SEP]\n", "[CLS] We assume that the receiver uses four and six bits to quantize FORMULA  in the case of FORMULA  and FORMULA  respectively, and constructs codebooks as described in Section REF . [SEP]\n", "[CLS] The receiver uses a variable number of bits to quantize the azimuth and elevation angles used in FORMULA . [SEP]\n", "[CLS] For simplicity of exposition, we assume that FORMULA . [SEP]\n", "[CLS] Fig. REF  indicates that similar performance can be expected in limited feedback systems and that the performance degradation due to quantization is limited. [SEP]\n", "[CLS] Namely, Fig. REF  indicates that no more than 3 bits are needed to quantize each steering angle in practical systems, and even 2 bits yields almost-perfect performance for a FORMULA  systems with FORMULA . [SEP]\n", "[CLS] In general the number of bits needed to properly quantize the steering angles grows slowly with array size since larger arrays generate narrower beams and require finer steering. [SEP]\n", "[CLS] Since beam width is inversely proportional to the antenna array dimensions, a reasonable rule-of-thumb is to add 1 bit per azimuth (or elevation) steering angle whenever the array's width (or height) doubles. [SEP]\n", "[CLS] Fig. [SEP]\n", "[CLS] REF  is promising as it indicates that it takes no more than 20 bits to quantize a FORMULA  precoder and about 22 bits for a FORMULA  precoder. [SEP]\n", "[CLS] When considering the fact that practical mmWave systems will use twenty to fifty times more antennas compared to traditional MIMO systems, which use about 4 to 6 bits of feedback\u00a0{{cite:2b75f029-0594-4341-815b-bd101721eace}}, we see that exploiting spatial sparsity in precoding helps dramatically compress feedback and keep its overhead manageable. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Conclusion [SEP]\n", "[CLS] In this paper we considered single user precoding and combing in mmWave systems where traditional MIMO solutions are made infeasible by the heavy reliance on RF precoding. [SEP]\n", "[CLS] By leveraging the structure of realistic mmWave channels, we developed a low hardware-complexity precoding solution. [SEP]\n", "[CLS] We formulated the problem of mmWave precoder design as a sparsity-constrained signal recovery problem and presented an algorithmic solution using orthogonal matching pursuit. [SEP]\n", "[CLS] We showed that the same framework can be applied to the problem of designing practical MMSE combiners for mmWave systems. [SEP]\n", "[CLS] We showed that the proposed precoders can be efficiently quantized and that the precoding strategy is well-suited for limited feedback systems. [SEP]\n", "[CLS] Finally, we presented numerical results on the performance of spatially sparse mmWave processing and showed that it allows systems to approach their theoretical limits on spectral efficiency. [SEP]\n", "[CLS] Future work related to such mmWave precoding includes relaxing the assumptions made throughout this paper such as (i) perfect channel state information at the receiver, (ii) knowledge of the antenna array structure, and (iii) the specialization to narrowband channels. [SEP]\n"], "1810.04805": ["[CLS]  compat=1.14 BERT: Pre-training of Deep Bidirectional Transformers for Language UnderstandingJacob Devlin \u00a0\u00a0\u00a0Ming-Wei Chang \u00a0\u00a0\u00a0 [SEP]\n", "[CLS] Kenton Lee \u00a0\u00a0\u00a0 [SEP]\n", "[CLS] Kristina Toutanova Google AI Language {jacobdevlin,mingweichang,kentonl,kristout}@google.com We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. [SEP]\n", "[CLS] Unlike recent language representation models\u00a0{{cite:61500747-002c-41e5-821d-e7b34b67d6fb}}, {{cite:3b4254ec-35a4-4b5c-ada6-f40eef22f36e}}, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. [SEP]\n", "[CLS] As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. [SEP]\n", "[CLS] BERT is conceptually simple and empirically powerful. [SEP]\n", "[CLS] It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement). [SEP]\n", "[CLS] Introduction Language model pre-training has been shown to be effective for improving many natural language processing tasks\u00a0{{cite:0327c5df-0749-4ab1-ad56-f5241d895496}}, {{cite:61500747-002c-41e5-821d-e7b34b67d6fb}}, {{cite:3b4254ec-35a4-4b5c-ada6-f40eef22f36e}}, {{cite:2263c000-9580-4fda-988d-980483386aae}}. [SEP]\n", "[CLS] These include sentence-level tasks such as natural language inference\u00a0{{cite:7f664e41-503b-424c-ab17-b80a4de67921}}, {{cite:32b1a4e1-a50d-47c2-9872-ddeeb2e0b97b}} and paraphrasing\u00a0{{cite:456ab9d2-aab7-4810-a574-5542d76182fe}}, which aim to predict the relationships between sentences by analyzing them holistically, as well as token-level tasks such as named entity recognition and question answering, where models are required to produce fine-grained output at the token level\u00a0{{cite:99421d9f-755e-4013-a782-a3b9be83f76c}}, {{cite:d1450ea3-b522-4ce5-a9e1-38a8c17d5a10}}. [SEP]\n", "[CLS] There are two existing strategies for applying pre-trained language representations to downstream tasks: feature-based and fine-tuning. [SEP]\n", "[CLS] The feature-based approach, such as ELMo\u00a0{{cite:61500747-002c-41e5-821d-e7b34b67d6fb}}, uses task-specific architectures that include the pre-trained representations as additional features. [SEP]\n", "[CLS] The fine-tuning approach, such as the Generative Pre-trained Transformer (OpenAI GPT)\u00a0{{cite:3b4254ec-35a4-4b5c-ada6-f40eef22f36e}}, introduces minimal task-specific parameters, and is trained on the downstream tasks by simply fine-tuning all pre-trained parameters. [SEP]\n", "[CLS] The two approaches share the same objective function during pre-training, where they use unidirectional language models to learn general language representations. [SEP]\n", "[CLS] We argue that current techniques restrict the power of the pre-trained representations, especially for the fine-tuning approaches. [SEP]\n", "[CLS] The major limitation is that standard language models are unidirectional, and this limits the choice of architectures that can be used during pre-training. [SEP]\n", "[CLS] For example, in OpenAI GPT, the authors use a left-to-right architecture, where every token can only attend to previous tokens in the self-attention layers of the Transformer\u00a0{{cite:61b78031-c3d7-449a-9e2c-9e20fb81a97c}}. [SEP]\n", "[CLS] Such restrictions are sub-optimal for sentence-level tasks, and could be very harmful when applying fine-tuning based approaches to token-level tasks such as question answering, where it is crucial to incorporate context from both directions. [SEP]\n", "[CLS] In this paper, we improve the fine-tuning based approaches by proposing BERT: Bidirectional Encoder Representations from Transformers. [SEP]\n", "[CLS] BERT alleviates the previously mentioned unidirectionality constraint by using a \u201cmasked language model\u201d\u00a0(MLM) pre-training objective, inspired by the Cloze task\u00a0{{cite:ac7a83cd-d0b4-4e57-847d-9347e2a239ad}}. [SEP]\n", "[CLS] The masked language model randomly masks some of the tokens from the input, and the objective is to predict the original vocabulary id of the masked word based only on its context. [SEP]\n", "[CLS] Unlike left-to-right language model pre-training, the MLM objective enables the representation to fuse the left and the right context, which allows us to pre-train a deep bidirectional Transformer. [SEP]\n", "[CLS] In addition to the masked language model, we also use a \u201cnext sentence prediction\u201d task that jointly pre-trains text-pair representations. [SEP]\n", "[CLS] The contributions of our paper are as follows: [leftmargin=1em] We demonstrate the importance of bidirectional pre-training for language representations. [SEP]\n", "[CLS] Unlike {{cite:3b4254ec-35a4-4b5c-ada6-f40eef22f36e}}, which uses unidirectional language models for pre-training, BERT uses masked language models to enable pre-trained deep bidirectional representations. [SEP]\n", "[CLS] This is also in contrast to {{cite:61500747-002c-41e5-821d-e7b34b67d6fb}}, which uses a shallow concatenation of independently trained left-to-right and right-to-left LMs. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] We show that pre-trained representations reduce the need for many heavily-engineered task-specific architectures. [SEP]\n", "[CLS] BERT is the first fine-tuning based representation model that achieves state-of-the-art performance on a large suite of sentence-level and token-level tasks, outperforming many task-specific architectures. [SEP]\n", "[CLS]  BERT advances the state of the art for eleven NLP tasks. [SEP]\n", "[CLS] The code and pre-trained models are available at https://github.com/google-research/bert. [SEP]\n", "[CLS]   Related Work There is a long history of pre-training general language representations, and we briefly review the most widely-used approaches in this section. [SEP]\n", "[CLS] Unsupervised Feature-based Approaches Learning widely applicable representations of words has been an active area of research for decades, including non-neural\u00a0{{cite:bc2aff1f-2720-4e25-afa1-36845867951f}}, {{cite:e947ca58-ffe8-4ec6-be37-dae2bc65f63d}}, {{cite:c6545860-8c9e-4df0-87f9-0fc360dfbdfd}} and neural\u00a0{{cite:9a4a86f6-ba68-4ee6-8064-66f0824db560}}, {{cite:79272621-ed13-413b-bdc5-1bcefb3a2fcd}} methods. [SEP]\n", "[CLS] Pre-trained word embeddings are an integral part of modern NLP systems, offering significant improvements over embeddings learned from scratch\u00a0{{cite:9fbcbe0d-ee41-4cb3-9c8a-96df6d5db832}}. [SEP]\n", "[CLS] To pre-train word embedding vectors, left-to-right language modeling objectives have been used\u00a0{{cite:d4dda1f4-d51b-402c-9861-6885d1c1a791}}, as well as objectives to discriminate correct from incorrect words in left and right context\u00a0{{cite:9a4a86f6-ba68-4ee6-8064-66f0824db560}}. [SEP]\n", "[CLS] These approaches have been generalized to coarser granularities, such as sentence embeddings\u00a0{{cite:fee029c3-b803-4d6a-8c4f-d899922f0d41}}, {{cite:97d3ecb3-3bc0-49f3-ba11-270b6ce9119f}} or paragraph embeddings\u00a0{{cite:ca40fe8a-67d6-4a62-86b1-5e19895d0957}}. [SEP]\n", "[CLS] To train sentence representations, prior work has used objectives to rank candidate next sentences {{cite:8f279fa7-3c11-4f56-b5b7-f5832f40139d}}, {{cite:97d3ecb3-3bc0-49f3-ba11-270b6ce9119f}}, left-to-right generation of next sentence words given a representation of the previous sentence\u00a0{{cite:fee029c3-b803-4d6a-8c4f-d899922f0d41}}, or denoising auto-encoder derived objectives\u00a0{{cite:b781f490-05d4-466e-bcf1-d5ebe0308ccc}}. [SEP]\n", "[CLS] FIGURE  ELMo and its predecessor\u00a0{{cite:dde1fa1e-d648-43b5-86b2-363d2865b006}}, {{cite:61500747-002c-41e5-821d-e7b34b67d6fb}} generalize traditional word embedding research along a different dimension. [SEP]\n", "[CLS] They extract context-sensitive features from a left-to-right and a right-to-left language model. [SEP]\n", "[CLS] The contextual representation of each token is the concatenation of the left-to-right and right-to-left representations. [SEP]\n", "[CLS] When integrating contextual word embeddings with existing task-specific architectures, ELMo advances the state of the art for several major NLP benchmarks\u00a0{{cite:61500747-002c-41e5-821d-e7b34b67d6fb}} including question answering\u00a0{{cite:d1450ea3-b522-4ce5-a9e1-38a8c17d5a10}}, sentiment analysis\u00a0{{cite:ada010eb-5ae6-4a5a-9fb7-ac04bfb23ae0}}, and named entity recognition\u00a0{{cite:99421d9f-755e-4013-a782-a3b9be83f76c}}. [SEP]\n", "[CLS] {{cite:1fb4b747-c3de-4647-a5c6-ce341ae9e829}} proposed learning contextual representations through a task to predict a single word from both left and right context using LSTMs. [SEP]\n", "[CLS] Similar to ELMo, their model is feature-based and not deeply bidirectional. [SEP]\n", "[CLS] {{cite:d3d00207-995c-423d-9f13-5f458a5f48d5}} shows that the cloze task can be used to improve the robustness of text generation models. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Unsupervised Fine-tuning Approaches As with the feature-based approaches, the first works in this direction only pre-trained word embedding parameters from unlabeled text \u00a0{{cite:673be00f-0e8e-4bfe-b378-e85edd94eeb1}}. [SEP]\n", "[CLS] More recently, sentence or document encoders which produce contextual token representations have been pre-trained from unlabeled text and fine-tuned for a supervised downstream task\u00a0{{cite:0327c5df-0749-4ab1-ad56-f5241d895496}}, {{cite:2263c000-9580-4fda-988d-980483386aae}}, {{cite:3b4254ec-35a4-4b5c-ada6-f40eef22f36e}}. [SEP]\n", "[CLS] The advantage of these approaches is that few parameters need to be learned from scratch. [SEP]\n", "[CLS] At least partly due to this advantage, OpenAI GPT\u00a0{{cite:3b4254ec-35a4-4b5c-ada6-f40eef22f36e}} achieved previously state-of-the-art results on many sentence-level tasks from the GLUE benchmark\u00a0{{cite:8acdc454-0345-474c-86e3-2a50cb521644}}. [SEP]\n", "[CLS] Left-to-right language modeling and auto-encoder objectives have been used for pre-training such models\u00a0{{cite:2263c000-9580-4fda-988d-980483386aae}}, {{cite:3b4254ec-35a4-4b5c-ada6-f40eef22f36e}}, {{cite:0327c5df-0749-4ab1-ad56-f5241d895496}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Transfer Learning from Supervised Data There has also been work showing effective transfer from supervised tasks with large datasets, such as natural language inference\u00a0{{cite:b8234837-90f8-40bf-9849-c5138c49340e}} and machine translation\u00a0{{cite:61972435-1651-4b2b-a30b-9ffa32840034}}. [SEP]\n", "[CLS] Computer vision research has also demonstrated the importance of transfer learning from large pre-trained models, where an effective recipe is to fine-tune models pre-trained with ImageNet\u00a0{{cite:c3ac947f-0ec5-498f-8df6-81da0e4f3d9d}}, {{cite:47db27d3-cf1a-4584-96b8-76322025e903}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] BERT We introduce BERT and its detailed implementation in this section. [SEP]\n", "[CLS] There are two steps in our framework: pre-training and fine-tuning. [SEP]\n", "[CLS] During pre-training, the model is trained on unlabeled data over different pre-training tasks. [SEP]\n", "[CLS] For fine-tuning, the BERT model is first initialized with the pre-trained parameters, and all of the parameters are fine-tuned using labeled data from the downstream tasks. [SEP]\n", "[CLS] Each downstream task has separate fine-tuned models, even though they are initialized with the same pre-trained parameters. [SEP]\n", "[CLS] The question-answering example in Figure\u00a0REF  will serve as a running example for this section. [SEP]\n", "[CLS] A distinctive feature of BERT is its unified architecture across different tasks. [SEP]\n", "[CLS] There is minimal difference between the pre-trained architecture and the final downstream architecture. [SEP]\n", "[CLS] Model Architecture BERT's model architecture is a multi-layer bidirectional Transformer encoder based on the original implementation described in {{cite:61b78031-c3d7-449a-9e2c-9e20fb81a97c}} and released in the tensor2tensor library.https://github.com/tensorflow/tensor2tensor Because the use of Transformers has become common and our implementation is almost identical to the original, we will omit an exhaustive background description of the model architecture and refer readers to {{cite:61b78031-c3d7-449a-9e2c-9e20fb81a97c}} as well as excellent guides such as \u201cThe Annotated Transformer. [SEP]\n", "[CLS] \u201dhttp://nlp.seas.harvard.edu/2018/04/03/attention.html [SEP]\n", "[CLS] In this work, we denote the number of layers (i.e., Transformer blocks) as FORMULA , the hidden size as FORMULA , and the number of self-attention heads as FORMULA .In [SEP]\n", "[CLS] all cases we set the feed-forward/filter size to be FORMULA , i.e., 3072 for the FORMULA  and 4096 for the FORMULA . [SEP]\n", "[CLS] We primarily report results on two model sizes: BERT FORMULA (L=12, H=768, A=12, Total Parameters=110M) and BERT FORMULA (L=24, H=1024, A=16, Total Parameters=340M). [SEP]\n", "[CLS] BERTFORMULA  was chosen to have the same model size as OpenAI GPT for comparison purposes. [SEP]\n", "[CLS] Critically, however, the BERT Transformer uses bidirectional self-attention, while the GPT Transformer uses constrained self-attention where every token can only attend to context to its left. [SEP]\n", "[CLS] We note that in the literature the bidirectional Transformer is often referred to as a \u201cTransformer encoder\u201d while the left-context-only version is referred to as a \u201cTransformer decoder\u201d since it can be used for text generation. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Input/Output Representations To make BERT handle a variety of down-stream tasks, our input representation is able to unambiguously represent both a single sentence and a pair of sentences (e.g., FORMULA   [SEP]\n", "[CLS] Question, Answer FORMULA ) in one token sequence. [SEP]\n", "[CLS] Throughout this work, a \u201csentence\u201d can be an arbitrary span of contiguous text, rather than an actual linguistic sentence. [SEP]\n", "[CLS] A \u201csequence\u201d refers to the input token sequence to BERT, which may be a single sentence or two sentences packed together. [SEP]\n", "[CLS] We use WordPiece embeddings {{cite:66d22194-902d-4aac-a41e-8b2e76deddc1}} with a 30,000 token vocabulary. [SEP]\n", "[CLS] The first token of every sequence is always a special classification token [SEP]\n", "[CLS] ([CLS]). [SEP]\n", "[CLS] The final hidden state corresponding to this token is used as the aggregate sequence representation for classification tasks. [SEP]\n", "[CLS] Sentence pairs are packed together into a single sequence. [SEP]\n", "[CLS] We differentiate the sentences in two ways. [SEP]\n", "[CLS] First, we separate them with a special token ([SEP]). [SEP]\n", "[CLS] Second, we add a learned embedding to every token indicating whether it belongs to sentence A or sentence B. [SEP]\n", "[CLS] As shown in Figure\u00a0REF , we denote input embedding as FORMULA , the final hidden vector of the special [CLS] token as FORMULA , and the final hidden vector for the FORMULA  input token as FORMULA . [SEP]\n", "[CLS] For a given token, its input representation is constructed by summing the corresponding token, segment, and position embeddings. [SEP]\n", "[CLS] A visualization of this construction can be seen in Figure\u00a0REF . [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Pre-training BERT Unlike {{cite:61500747-002c-41e5-821d-e7b34b67d6fb}} and {{cite:3b4254ec-35a4-4b5c-ada6-f40eef22f36e}} [SEP]\n", "[CLS] , we do not use traditional left-to-right or right-to-left language models to pre-train BERT. [SEP]\n", "[CLS] Instead, we pre-train BERT using two unsupervised tasks, described in this section. [SEP]\n", "[CLS] This step is presented in the left part of Figure\u00a0REF . [SEP]\n", "[CLS] Task #1: Masked LM [SEP]\n", "[CLS] Intuitively, it is reasonable to believe that a deep bidirectional model is strictly more powerful than either a left-to-right model or the shallow concatenation of a left-to-right and a right-to-left model. [SEP]\n", "[CLS] Unfortunately, standard conditional language models can only be trained left-to-right or right-to-left, since bidirectional conditioning would allow each word to indirectly \u201csee itself\u201d, and the model could trivially predict the target word in a multi-layered context. [SEP]\n", "[CLS] In order to train a deep bidirectional representation, we simply mask some percentage of the input tokens at random, and then predict those masked tokens. [SEP]\n", "[CLS] We refer to this procedure as a \u201cmasked LM\u201d (MLM), although it is often referred to as a Cloze task in the literature\u00a0{{cite:ac7a83cd-d0b4-4e57-847d-9347e2a239ad}}. [SEP]\n", "[CLS] In this case, the final hidden vectors corresponding to the mask tokens are fed into an output softmax over the vocabulary, as in a standard LM. [SEP]\n", "[CLS] In all of our experiments, we mask 15% of all WordPiece tokens in each sequence at random. [SEP]\n", "[CLS] In contrast to denoising auto-encoders {{cite:1be61ea0-8db0-4fb3-a3e2-abf6fec864f1}}, we only predict the masked words rather than reconstructing the entire input. [SEP]\n", "[CLS] Although this allows us to obtain a bidirectional pre-trained model, a downside is that we are creating a mismatch between pre-training and fine-tuning, since the [MASK] token does not appear during fine-tuning. [SEP]\n", "[CLS] To mitigate this, we do not always replace \u201cmasked\u201d words with the actual [MASK] token. [SEP]\n", "[CLS] The training data generator chooses 15% of the token positions at random for prediction. [SEP]\n", "[CLS] If the FORMULA -th token is chosen, we replace the FORMULA -th token with (1) the [MASK] token 80% of the time (2) a random token 10% of the time (3) the unchanged FORMULA -th token 10% of the time. [SEP]\n", "[CLS] Then, FORMULA  will be used to predict the original token with cross entropy loss. [SEP]\n", "[CLS] We compare variations of this procedure in Appendix\u00a0REF . [SEP]\n", "[CLS]   Task #2: Next Sentence Prediction (NSP) Many important downstream tasks such as Question Answering (QA) and Natural Language Inference (NLI) are based on understanding the relationship between two sentences, which is not directly captured by language modeling. [SEP]\n", "[CLS] In order to train a model that understands sentence relationships, we pre-train for a binarized next sentence prediction task that can be trivially generated from any monolingual corpus. [SEP]\n", "[CLS] Specifically, when choosing the sentences A and B for each pre-training example, 50% of the time B is the actual next sentence that follows A (labeled as IsNext), and 50% of the time it is a random sentence from the corpus (labeled as NotNext). [SEP]\n", "[CLS] As we show in Figure\u00a0REF , FORMULA  is used for next sentence prediction (NSP).The final model achieves 97%-98% accuracy on NSP. [SEP]\n", "[CLS] Despite its simplicity, we demonstrate in Section\u00a0REF  that pre-training towards this task is very beneficial to both QA and NLI. [SEP]\n", "[CLS] The vector FORMULA  is not a meaningful sentence representation without fine-tuning, since it was trained with NSP. [SEP]\n", "[CLS] The NSP task is closely related to representation-learning objectives used in {{cite:8f279fa7-3c11-4f56-b5b7-f5832f40139d}} and {{cite:97d3ecb3-3bc0-49f3-ba11-270b6ce9119f}}. [SEP]\n", "[CLS] However, in prior work, only sentence embeddings are transferred to down-stream tasks, where BERT transfers all parameters to initialize end-task model parameters. [SEP]\n", "[CLS]  Pre-training data The pre-training procedure largely follows the existing literature on language model pre-training. [SEP]\n", "[CLS] For the pre-training corpus we use the BooksCorpus (800M words)\u00a0{{cite:843b9598-f224-4916-ad3b-404c171589ae}} and English Wikipedia (2,500M words). [SEP]\n", "[CLS] For Wikipedia we extract only the text passages and ignore lists, tables, and headers. [SEP]\n", "[CLS] It is critical to use a document-level corpus rather than a shuffled sentence-level corpus such as the Billion Word Benchmark {{cite:0957d518-0d42-4e4e-be80-eea699e8eef2}} in order to extract long contiguous sequences. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Fine-tuning BERT Fine-tuning is straightforward since the self-attention mechanism in the Transformer allows BERT to model many downstream tasks\u2014whether they involve single text or text pairs\u2014by swapping out the appropriate inputs and outputs. [SEP]\n", "[CLS] For applications involving text pairs, a common pattern is to independently encode text pairs before applying bidirectional cross attention, such as\u00a0parikh-etal:2016, bidaf. [SEP]\n", "[CLS] BERT instead uses the self-attention mechanism to unify these two stages, as encoding a concatenated text pair with self-attention effectively includes bidirectional cross attention between two sentences. [SEP]\n", "[CLS] For each task, we simply plug in the task-specific inputs and outputs into BERT and fine-tune all the parameters end-to-end. [SEP]\n", "[CLS] At the input, sentence A and sentence B from pre-training are analogous to (1) sentence pairs in paraphrasing, (2) hypothesis-premise pairs in entailment, (3) question-passage pairs in question answering, and (4) a degenerate text-FORMULA  pair in text classification or sequence tagging. [SEP]\n", "[CLS] At the output, the token representations are fed into an output layer for token-level tasks, such as sequence tagging or question answering, and the [CLS] representation is fed into an output layer for classification, such as entailment or sentiment analysis. [SEP]\n", "[CLS] Compared to pre-training, fine-tuning is relatively inexpensive. [SEP]\n", "[CLS] All of the results in the paper can be replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU, starting from the exact same pre-trained model. [SEP]\n", "[CLS] For example, the BERT SQuAD model can be trained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of 91.0%. [SEP]\n", "[CLS] We describe the task-specific details in the corresponding subsections of Section\u00a0. [SEP]\n", "[CLS] More details can be found in Appendix\u00a0REF . [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] See (10) in https://gluebenchmark.com/faq.   [SEP]\n", "[CLS] Experiments [SEP]\n", "[CLS] In this section, we present BERT fine-tuning results on 11 NLP tasks. [SEP]\n", "[CLS] GLUE The General Language Understanding Evaluation (GLUE) benchmark\u00a0{{cite:8acdc454-0345-474c-86e3-2a50cb521644}} is a collection of diverse natural language understanding tasks. [SEP]\n", "[CLS] Detailed descriptions of GLUE datasets are included in Appendix\u00a0REF . [SEP]\n", "[CLS] To fine-tune on GLUE, we represent the input sequence (for single sentence or sentence pairs) as described in Section\u00a0, and use the final hidden vector FORMULA  corresponding to the first input token [SEP]\n", "[CLS] ([CLS]) as the aggregate representation. [SEP]\n", "[CLS] The only new parameters introduced during fine-tuning are classification layer weights FORMULA , where FORMULA  is the number of labels. [SEP]\n", "[CLS] We compute a standard classification loss with FORMULA  and FORMULA , i.e., FORMULA . [SEP]\n", "[CLS] We use a batch size of 32 and fine-tune for 3 epochs over the data for all GLUE tasks. [SEP]\n", "[CLS] For each task, we selected the best fine-tuning learning rate (among 5e-5, 4e-5, 3e-5, and 2e-5) on the Dev set. [SEP]\n", "[CLS] Additionally, for BERTFORMULA  we found that fine-tuning was sometimes unstable on small datasets, so we ran several random restarts and selected the best model on the Dev set. [SEP]\n", "[CLS] With random restarts, we use the same pre-trained checkpoint but perform different fine-tuning data shuffling and classifier layer initialization. [SEP]\n", "[CLS] The GLUE data set distribution does not include the Test labels, and we only made a single GLUE evaluation server submission for each of BERTFORMULA  and BERTFORMULA . [SEP]\n", "[CLS] Results are presented in Table\u00a0REF . [SEP]\n", "[CLS] Both BERTFORMULA  and BERTFORMULA  outperform all systems on all tasks by a substantial margin, obtaining 4.5% and 7.0% respective average accuracy improvement over the prior state of the art. [SEP]\n", "[CLS] Note that BERTFORMULA  and OpenAI GPT are nearly identical in terms of model architecture apart from the attention masking. [SEP]\n", "[CLS] For the largest and most widely reported GLUE task, MNLI, BERT obtains a 4.6% absolute accuracy improvement. [SEP]\n", "[CLS] On the official GLUE leaderboardhttps://gluebenchmark.com/leaderboard, BERTFORMULA  obtains a score of 80.5, compared to OpenAI GPT, which obtains 72.8 as of the date of writing. [SEP]\n", "[CLS] We find that BERTFORMULA  significantly outperforms BERTFORMULA  across all tasks, especially those with very little training data. [SEP]\n", "[CLS] The effect of model size is explored more thoroughly in Section\u00a0REF . [SEP]\n", "[CLS]  SQuAD v1.1 [SEP]\n", "[CLS] The Stanford Question Answering Dataset (SQuAD v1.1) is a collection of 100k crowdsourced question/answer pairs\u00a0{{cite:d1450ea3-b522-4ce5-a9e1-38a8c17d5a10}}. [SEP]\n", "[CLS] Given a question and a passage from Wikipedia containing the answer, the task is to predict the answer text span in the passage. [SEP]\n", "[CLS] As shown in Figure\u00a0REF , in the question answering task, we represent the input question and passage as a single packed sequence, with the question using the A embedding and the passage using the B embedding. [SEP]\n", "[CLS] We only introduce a start vector FORMULA  and an end vector FORMULA  during fine-tuning. [SEP]\n", "[CLS] The probability of word FORMULA  being the start of the answer span is computed as a dot product between FORMULA  and FORMULA  followed by a softmax over all of the words in the paragraph: FORMULA . [SEP]\n", "[CLS] The analogous formula is used for the end of the answer span. [SEP]\n", "[CLS] The score of a candidate span from position FORMULA  to position FORMULA  is defined as FORMULA , and the maximum scoring span where FORMULA  is used as a prediction. [SEP]\n", "[CLS] The training objective is the sum of the log-likelihoods of the correct start and end positions. [SEP]\n", "[CLS] We fine-tune for 3 epochs with a learning rate of 5e-5 and a batch size of 32. TABLE [SEP]\n", "[CLS]  TABLE  Table\u00a0REF  shows top leaderboard entries as well as results from top published systems\u00a0{{cite:e0271a1b-f7d0-4ecf-b0dd-f0d88dc53edb}}, {{cite:cd0dfa0a-7e75-4fe1-af54-8a3514ef5a63}}, {{cite:61500747-002c-41e5-821d-e7b34b67d6fb}}, {{cite:39d1a915-c840-4f86-9cce-d9ada6751034}}. [SEP]\n", "[CLS] The top results from the SQuAD leaderboard do not have up-to-date public system descriptions available,QANet is described in yu-etal:2018:qanet, but the system has improved substantially after publication. and are allowed to use any public data when training their systems. [SEP]\n", "[CLS] We therefore use modest data augmentation in our system by first fine-tuning on TriviaQA\u00a0{{cite:6b06c914-a8a1-4617-aefd-c886e9281313}} befor fine-tuning on SQuAD. [SEP]\n", "[CLS] Our best performing system outperforms the top leaderboard system by +1.5 F1 in ensembling and +1.3 F1 as a single system. [SEP]\n", "[CLS] In fact, our single BERT model outperforms the top ensemble system in terms of F1 score. [SEP]\n", "[CLS] Without TriviaQA fine-tuning data, we only lose 0.1-0.4 F1, still outperforming all existing systems by a wide margin. [SEP]\n", "[CLS] The TriviaQA data we used consists of paragraphs from TriviaQA-Wiki formed of the first 400 tokens in documents, that contain at least one of the provided possible answers. [SEP]\n", "[CLS]  SQuAD v2.0 The SQuAD 2.0 task extends the SQuAD 1.1 problem definition by allowing for the possibility that no short answer exists in the provided paragraph, making the problem more realistic. [SEP]\n", "[CLS] We use a simple approach to extend the SQuAD v1.1 BERT model for this task. [SEP]\n", "[CLS] We treat questions that do not have an answer as having an answer span with start and end at the [CLS] token. [SEP]\n", "[CLS] The probability space for the start and end answer span positions is extended to include the position of the [CLS] token. [SEP]\n", "[CLS] For prediction, we compare the score of the no-answer span: FORMULA  to the score of the best non-null span FORMULA   [SEP]\n", "[CLS] = FORMULA . [SEP]\n", "[CLS] We predict a non-null answer when FORMULA , where the threshold FORMULA  is selected on the dev set to maximize F1. [SEP]\n", "[CLS] We did not use TriviaQA data for this model. [SEP]\n", "[CLS] We fine-tuned for 2 epochs with a learning rate of 5e-5 and a batch size of 48. [SEP]\n", "[CLS] The results compared to prior leaderboard entries and top published work {{cite:848fc550-e792-4540-b8e2-18b01abf2c80}}, {{cite:e54acc4b-c8af-4c0b-8702-60cfbf661bee}} are shown in Table\u00a0REF , excluding systems that use BERT as one of their components. [SEP]\n", "[CLS] We observe a +5.1 F1 improvement over the previous best system. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] SWAG The Situations With Adversarial Generations (SWAG) dataset contains 113k sentence-pair completion examples that evaluate grounded commonsense inference\u00a0{{cite:2a8fd915-d208-46c6-a4c3-49a4e2261adc}}. [SEP]\n", "[CLS] Given a sentence, the task is to choose the most plausible continuation among four choices. [SEP]\n", "[CLS] When fine-tuning on the SWAG dataset, we construct four input sequences, each containing the concatenation of the given sentence (sentence A) and a possible continuation (sentence B). [SEP]\n", "[CLS] The only task-specific parameters introduced is a vector whose dot product with the [CLS] token representation FORMULA  denotes a score for each choice which is normalized with a softmax layer. [SEP]\n", "[CLS] We fine-tune the model for 3 epochs with a learning rate of 2e-5 and a batch size of 16. [SEP]\n", "[CLS] Results are presented in Table\u00a0REF . [SEP]\n", "[CLS] BERTFORMULA  outperforms the authors' baseline ESIM+ELMo system by +27.1% and OpenAI GPT by 8.3%. [SEP]\n", "[CLS] TABLE   Ablation Studies In this section, we perform ablation experiments over a number of facets of BERT in order to better understand their relative importance. [SEP]\n", "[CLS] Additional ablation studies can be found in Appendix\u00a0. [SEP]\n", "[CLS] Effect of Pre-training Tasks We demonstrate the importance of the deep bidirectionality of BERT by evaluating two pre-training objectives using exactly the same pre-training data, fine-tuning scheme, and hyperparameters as BERTFORMULA :   [SEP]\n", "[CLS] No NSP: A bidirectional model which is trained using the \u201cmasked LM\u201d (MLM) but without the \u201cnext sentence prediction\u201d (NSP) task. [SEP]\n", "[CLS] LTR & No NSP: A left-context-only model which is trained using a standard Left-to-Right (LTR) LM, rather than an MLM. [SEP]\n", "[CLS] The left-only constraint was also applied at fine-tuning, because removing it introduced a pre-train/fine-tune mismatch that degraded downstream performance. [SEP]\n", "[CLS] Additionally, this model was pre-trained without the NSP task. [SEP]\n", "[CLS] This is directly comparable to OpenAI GPT, but using our larger training dataset, our input representation, and our fine-tuning scheme. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] We first examine the impact brought by the NSP task. [SEP]\n", "[CLS] In Table\u00a0REF , we show that removing NSP hurts performance significantly on QNLI, MNLI, and SQuAD 1.1. [SEP]\n", "[CLS] Next, we evaluate the impact of training bidirectional representations by comparing \u201cNo NSP\u201d to \u201cLTR & No NSP\u201d. [SEP]\n", "[CLS] The LTR model performs worse than the MLM model on all tasks, with large drops on MRPC and SQuAD. [SEP]\n", "[CLS] For SQuAD it is intuitively clear that a LTR model will perform poorly at token predictions, since the token-level hidden states have no right-side context. [SEP]\n", "[CLS] In order to make a good faith attempt at strengthening the LTR system, we added a randomly initialized BiLSTM on top. [SEP]\n", "[CLS] This does significantly improve results on SQuAD, but the results are still far worse than those of the pre-trained bidirectional models. [SEP]\n", "[CLS] The BiLSTM hurts performance on the GLUE tasks. [SEP]\n", "[CLS] We recognize that it would also be possible to train separate LTR and RTL models and represent each token as the concatenation of the two models, as ELMo does. [SEP]\n", "[CLS] However: (a) this is twice as expensive as a single bidirectional model; (b) this is non-intuitive for tasks like QA, since the RTL model would not be able to condition the answer on the question; (c) this it is strictly less powerful than a deep bidirectional model, since it can use both left and right context at every layer. [SEP]\n", "[CLS]  Effect of Model Size In this section, we explore the effect of model size on fine-tuning task accuracy. [SEP]\n", "[CLS] We trained a number of BERT models with a differing number of layers, hidden units, and attention heads, while otherwise using the same hyperparameters and training procedure as described previously. [SEP]\n", "[CLS] Results on selected GLUE tasks are shown in Table\u00a0REF . [SEP]\n", "[CLS] In this table, we report the average Dev Set accuracy from 5 random restarts of fine-tuning. [SEP]\n", "[CLS] We can see that larger models lead to a strict accuracy improvement across all four datasets, even for MRPC which only has 3,600 labeled training examples, and is substantially different from the pre-training tasks. [SEP]\n", "[CLS] It is also perhaps surprising that we are able to achieve such significant improvements on top of models which are already quite large relative to the existing literature. [SEP]\n", "[CLS] For example, the largest Transformer explored in {{cite:61b78031-c3d7-449a-9e2c-9e20fb81a97c}} is (L=6, H=1024, A=16) with 100M parameters for the encoder, and the largest Transformer we have found in the literature is (L=64, H=512, A=2) with 235M parameters {{cite:fff265de-0c84-4a29-be31-e80da1fa5f5b}}. [SEP]\n", "[CLS] By contrast, BERTFORMULA  contains 110M parameters and BERTFORMULA  contains 340M parameters. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] It has long been known that increasing the model size will lead to continual improvements on large-scale tasks such as machine translation and language modeling, which is demonstrated by the LM perplexity of held-out training data shown in Table\u00a0REF . [SEP]\n", "[CLS] However, we believe that this is the first work to demonstrate convincingly that scaling to extreme model sizes also leads to large improvements on very small scale tasks, provided that the model has been sufficiently pre-trained. [SEP]\n", "[CLS] {{cite:f3bf079a-0d40-4713-8ea0-47e39b35f7f7}} presented mixed results on the downstream task impact of increasing the pre-trained bi-LM size from two to four layers and {{cite:1fb4b747-c3de-4647-a5c6-ce341ae9e829}} mentioned in passing that increasing hidden dimension size from 200 to 600 helped, but increasing further to 1,000 did not bring further improvements. [SEP]\n", "[CLS] Both of these prior works used a feature-based approach \u2014 we hypothesize that when the model is fine-tuned directly on the downstream tasks and uses only a very small number of randomly initialized additional parameters, the task-specific models can benefit from the larger, more expressive pre-trained representations even when downstream task data is very small.   [SEP]\n", "[CLS] Feature-based Approach with BERT All of the BERT results presented so far have used the fine-tuning approach, where a simple classification layer is added to the pre-trained model, and all parameters are jointly fine-tuned on a downstream task. [SEP]\n", "[CLS] However, the feature-based approach, where fixed features are extracted from the pre-trained model, has certain advantages. [SEP]\n", "[CLS] First, not all tasks can be easily represented by a Transformer encoder architecture, and therefore require a task-specific model architecture to be added. [SEP]\n", "[CLS] Second, there are major computational benefits to pre-compute an expensive representation of the training data once and then run many experiments with cheaper models on top of this representation. [SEP]\n", "[CLS] In this section, we compare the two approaches by applying BERT to the CoNLL-2003 Named Entity Recognition (NER) task\u00a0{{cite:99421d9f-755e-4013-a782-a3b9be83f76c}}. [SEP]\n", "[CLS] In the input to BERT, we use a case-preserving WordPiece model, and we include the maximal document context provided by the data. [SEP]\n", "[CLS] Following standard practice, we formulate this as a tagging task but do not use a CRF layer in the output. [SEP]\n", "[CLS] We use the representation of the first sub-token as the input to the token-level classifier over the NER label set. [SEP]\n", "[CLS] To ablate the fine-tuning approach, we apply the feature-based approach by extracting the activations from one or more layers without fine-tuning any parameters of BERT. [SEP]\n", "[CLS] These contextual embeddings are used as input to a randomly initialized two-layer 768-dimensional BiLSTM before the classification layer. [SEP]\n", "[CLS] Results are presented in Table\u00a0REF . [SEP]\n", "[CLS] BERTFORMULA  performs competitively with state-of-the-art methods. [SEP]\n", "[CLS] The best performing method concatenates the token representations from the top four hidden layers of the pre-trained Transformer, which is only 0.3 F1 behind fine-tuning the entire model. [SEP]\n", "[CLS] This demonstrates that BERT is effective for both fine-tuning and feature-based approaches. [SEP]\n", "[CLS] TABLE    [SEP]\n", "[CLS] Conclusion Recent empirical improvements due to transfer learning with language models have demonstrated that rich, unsupervised pre-training is an integral part of many language understanding systems. [SEP]\n", "[CLS] In particular, these results enable even low-resource tasks to benefit from deep unidirectional architectures. [SEP]\n", "[CLS] Our major contribution is further generalizing these findings to deep bidirectional architectures, allowing the same pre-trained model to successfully tackle a broad set of NLP tasks. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Appendix for \u201cBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u201d We organize the appendix into three sections:   [SEP]\n", "[CLS] Additional implementation details for BERT are presented in Appendix\u00a0;  Additional details for our experiments are presented in Appendix\u00a0; and  Additional ablation studies are presented in Appendix\u00a0. [SEP]\n", "[CLS] We present additional ablation studies for BERT including:  Effect of Number of Training Steps; and  Ablation for Different Masking Procedures.     [SEP]\n", "[CLS] Additional Details for BERT FIGURE   [SEP]\n", "[CLS] Illustration of the Pre-training Tasks We provide examples of the pre-training tasks in the following. [SEP]\n", "[CLS] Masked LM and the Masking Procedure Assuming the unlabeled sentence is my dog is hairy, and during the random masking procedure we chose the 4-th token (which corresponding to hairy), our masking procedure can be further illustrated by  80% of the time: Replace the word with the [MASK] token, e.g., my dog is hairy FORMULA   [SEP]\n", "[CLS] my dog is [MASK]  10% of the time: Replace the word with a random word, e.g., my dog is hairy FORMULA   [SEP]\n", "[CLS] my dog is apple  10% of the time: Keep the word unchanged, e.g., my dog is hairy FORMULA   [SEP]\n", "[CLS] my dog is hairy. [SEP]\n", "[CLS] The purpose of this is to bias the representation towards the actual observed word. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] The advantage of this procedure is that the Transformer encoder does not know which words it will be asked to predict or which have been replaced by random words, so it is forced to keep a distributional contextual representation of every input token. [SEP]\n", "[CLS] Additionally, because random replacement only occurs for 1.5% of all tokens (i.e., 10% of 15%), this does not seem to harm the model's language understanding capability. [SEP]\n", "[CLS] In Section\u00a0REF , we evaluate the impact this procedure. [SEP]\n", "[CLS] Compared to standard langauge model training, the masked LM only make predictions on 15% of tokens in each batch, which suggests that more pre-training steps may be required for the model to converge. [SEP]\n", "[CLS] In Section\u00a0REF  we demonstrate that MLM does converge marginally slower than a left-to-right model (which predicts every token), but the empirical improvements of the MLM model far outweigh the increased training cost. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Next Sentence Prediction The next sentence prediction task can be illustrated in the following examples. [SEP]\n", "[CLS] FORMULA   Pre-training Procedure To generate each training input sequence, we sample two spans of text from the corpus, which we refer to as \u201csentences\u201d even though they are typically much longer than single sentences (but can be shorter also). [SEP]\n", "[CLS] The first sentence receives the A embedding and the second receives the B embedding. [SEP]\n", "[CLS] 50% of the time B is the actual next sentence that follows A and 50% of the time it is a random sentence, which is done for the \u201cnext sentence prediction\u201d task. [SEP]\n", "[CLS] They are sampled such that the combined length is FORMULA  512 tokens. [SEP]\n", "[CLS] The LM masking is applied after WordPiece tokenization with a uniform masking rate of 15%, and no special consideration given to partial word pieces. [SEP]\n", "[CLS] We train with batch size of 256 sequences (256 sequences * 512 tokens = 128,000 tokens/batch) for 1,000,000 steps, which is approximately 40 epochs over the 3.3 billion word corpus. [SEP]\n", "[CLS] We use Adam with learning rate of 1e-4, FORMULA , FORMULA , L2 weight decay of FORMULA , learning rate warmup over the first 10,000 steps, and linear decay of the learning rate. [SEP]\n", "[CLS] We use a dropout probability of 0.1 on all layers. [SEP]\n", "[CLS] We use a gelu activation {{cite:8a5d3042-bdb7-4ab0-8737-1f2c30a2b986}} rather than the standard relu, following OpenAI GPT. [SEP]\n", "[CLS] The training loss is the sum of the mean masked LM likelihood and the mean next sentence prediction likelihood. [SEP]\n", "[CLS] Training of BERTFORMULA  was performed on 4 Cloud TPUs in Pod configuration (16 TPU chips total).https://cloudplatform.googleblog.com/2018/06/Cloud-TPU-now-offers-preemptible-pricing-and-global-availability.html Training of BERTFORMULA  was performed on 16 Cloud TPUs (64 TPU chips total). [SEP]\n", "[CLS] Each pre-training took 4 days to complete. [SEP]\n", "[CLS] Longer sequences are disproportionately expensive because attention is quadratic to the sequence length. [SEP]\n", "[CLS] To speed up pretraing in our experiments, we pre-train the model with sequence length of 128 for 90% of the steps. [SEP]\n", "[CLS] Then, we train the rest 10% of the steps of sequence of 512 to learn the positional embeddings. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Fine-tuning Procedure For fine-tuning [SEP]\n", "[CLS] , most model hyperparameters are the same as in pre-training, with the exception of the batch size, learning rate, and number of training epochs. [SEP]\n", "[CLS] The dropout probability was always kept at 0.1. [SEP]\n", "[CLS] The optimal hyperparameter values are task-specific, but we found the following range of possible values to work well across all tasks: [noitemsep] Batch size: 16, 32  Learning rate (Adam): 5e-5, 3e-5, 2e-5  Number of epochs: 2, 3, 4   [SEP]\n", "[CLS] We also observed that large data sets (e.g., 100k+ labeled training examples) were far less sensitive to hyperparameter choice than small data sets. [SEP]\n", "[CLS] Fine-tuning is typically very fast, so it is reasonable to simply run an exhaustive search over the above parameters and choose the model that performs best on the development set.   [SEP]\n", "[CLS] Comparison of BERT, ELMo ,and OpenAI GPT Here we studies the differences in recent popular representation learning models including ELMo, OpenAI GPT and BERT. [SEP]\n", "[CLS] The comparisons between the model architectures are shown visually in Figure\u00a0REF . [SEP]\n", "[CLS] Note that in addition to the architecture differences, BERT and OpenAI GPT are fine-tuning approaches, while ELMo is a feature-based approach. [SEP]\n", "[CLS] The most comparable existing pre-training method to BERT is OpenAI GPT, which trains a left-to-right Transformer LM on a large text corpus. [SEP]\n", "[CLS] In fact, many of the design decisions in BERT were intentionally made to make it as close to GPT as possible so that the two methods could be minimally compared. [SEP]\n", "[CLS] The core argument of this work is that the bi-directionality and the two pre-training tasks presented in Section\u00a0REF  account for the majority of the empirical improvements, but we do note that there are several other differences between how BERT and GPT were trained:  GPT is trained on the BooksCorpus (800M words); BERT is trained on the BooksCorpus (800M words) and Wikipedia (2,500M words). [SEP]\n", "[CLS]  GPT uses a sentence separator ([SEP]) and classifier token [SEP]\n", "[CLS] ([CLS]) which are only introduced at fine-tuning time; BERT learns [SEP], [CLS] and sentence A/B embeddings during pre-training. [SEP]\n", "[CLS]  GPT was trained for 1M steps with a batch size of 32,000 words; BERT was trained for 1M steps with a batch size of 128,000 words. [SEP]\n", "[CLS]  GPT used the same learning rate of 5e-5 for all fine-tuning experiments; BERT chooses a task-specific fine-tuning learning rate which performs the best on the development set. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] To isolate the effect of these differences, we perform ablation experiments in Section\u00a0REF  which demonstrate that the majority of the improvements are in fact coming from the two pre-training tasks and the bidirectionality they enable. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Illustrations of Fine-tuning on Different Tasks The illustration of fine-tuning BERT on different tasks can be seen in Figure\u00a0REF . [SEP]\n", "[CLS] Our task-specific models are formed by incorporating BERT with one additional output layer, so a minimal number of parameters need to be learned from scratch. [SEP]\n", "[CLS] Among the tasks, (a) and (b) are sequence-level tasks while (c) and (d) are token-level tasks. [SEP]\n", "[CLS] In the figure, FORMULA  represents the input embedding, FORMULA  represents the contextual representation of token FORMULA , [CLS] is the special symbol for classification output, and [SEP] is the special symbol to separate non-consecutive token sequences. [SEP]\n", "[CLS] FIGURE    [SEP]\n", "[CLS] Detailed Experimental Setup Detailed Descriptions for the GLUE Benchmark Experiments. [SEP]\n", "[CLS] Our GLUE results in TableREF  are obtained from https://gluebenchmark.com/leaderboard and https://blog.openai.com/language-unsupervised. [SEP]\n", "[CLS] The GLUE benchmark includes the following datasets, the descriptions of which were originally summarized in {{cite:8acdc454-0345-474c-86e3-2a50cb521644}}: MNLI Multi-Genre Natural Language Inference is a large-scale, crowdsourced entailment classification task\u00a0{{cite:32b1a4e1-a50d-47c2-9872-ddeeb2e0b97b}}. [SEP]\n", "[CLS] Given a pair of sentences, the goal is to predict whether the second sentence is an entailment, contradiction, or neutral with respect to the first one.   [SEP]\n", "[CLS] QQP Quora Question Pairs is a binary classification task where the goal is to determine if two questions asked on Quora are semantically equivalent\u00a0{{cite:a2bbd4cd-11cf-48fb-b67a-80fd404f9668}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] QNLI Question Natural Language Inference is a version of the Stanford Question Answering Dataset\u00a0{{cite:d1450ea3-b522-4ce5-a9e1-38a8c17d5a10}} which has been converted to a binary classification task\u00a0{{cite:8acdc454-0345-474c-86e3-2a50cb521644}}. [SEP]\n", "[CLS] The positive examples are (question, sentence) pairs which do contain the correct answer, and the negative examples are (question, sentence) from the same paragraph which do not contain the answer. [SEP]\n", "[CLS]  SST-2 [SEP]\n", "[CLS] The Stanford Sentiment Treebank is a binary single-sentence classification task consisting of sentences extracted from movie reviews with human annotations of their sentiment\u00a0{{cite:ada010eb-5ae6-4a5a-9fb7-ac04bfb23ae0}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] CoLA The Corpus of Linguistic Acceptability is a binary single-sentence classification task, where the goal is to predict whether an English sentence is linguistically \u201cacceptable\u201d or not\u00a0{{cite:939c17f9-e5ec-470e-9fe9-2c8ab2823410}}. [SEP]\n", "[CLS]  STS-B The Semantic Textual Similarity Benchmark is a collection of sentence pairs drawn from news headlines and other sources\u00a0{{cite:e92b6a53-65c4-41ac-a8ce-09843e7e09a6}}. [SEP]\n", "[CLS] They were annotated with a score from 1 to 5 denoting how similar the two sentences are in terms of semantic meaning. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] MRPC Microsoft Research Paraphrase Corpus consists of sentence pairs automatically extracted from online news sources, with human annotations for whether the sentences in the pair are semantically equivalent\u00a0{{cite:456ab9d2-aab7-4810-a574-5542d76182fe}}. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] RTE Recognizing Textual Entailment is a binary entailment task similar to MNLI, but with much less training data\u00a0{{cite:e9eaa1b4-38bf-40f7-b0b7-a799ddb04c4e}}.Note that we only report single-task fine-tuning results in this paper. [SEP]\n", "[CLS] A multitask fine-tuning approach could potentially push the performance even further. [SEP]\n", "[CLS] For example, we did observe substantial improvements on RTE from multi-task training with MNLI. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] WNLI Winograd NLI is a small natural language inference dataset {{cite:562dbfc1-6df8-4ca3-a547-ecfe236c34b0}}. [SEP]\n", "[CLS] The GLUE webpage notes that there are issues with the construction of this dataset,\u00a0https://gluebenchmark.com/faq and every trained system that's been submitted to GLUE has performed worse than the 65.1 baseline accuracy of predicting the majority class. [SEP]\n", "[CLS] We therefore exclude this set to be fair to OpenAI GPT. [SEP]\n", "[CLS] For our GLUE submission, we always predicted the majority class. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Additional Ablation Studies Effect of Number of Training Steps Figure\u00a0REF  presents MNLI Dev accuracy after fine-tuning from a checkpoint that has been pre-trained for FORMULA  steps. [SEP]\n", "[CLS] This allows us to answer the following questions: FIGURE   Question: Does BERT really need such a large amount of pre-training (128,000 words/batch * 1,000,000 steps) to achieve high fine-tuning accuracy? [SEP]\n", "[CLS] Answer: Yes, BERTFORMULA  achieves almost 1.0% additional accuracy on MNLI when trained on 1M steps compared to 500k steps. [SEP]\n", "[CLS]   [SEP]\n", "[CLS] Question: Does MLM pre-training converge slower than LTR pre-training, since only 15% of words are predicted in each batch rather than every word? [SEP]\n", "[CLS] Answer: The MLM model does converge slightly slower than the LTR model. [SEP]\n", "[CLS] However, in terms of absolute accuracy the MLM model begins to outperform the LTR model almost immediately. [SEP]\n", "[CLS]   Ablation for Different Masking Procedures In Section\u00a0REF , we mention that BERT uses a mixed strategy for masking the target tokens when pre-training with the masked language model (MLM) objective. [SEP]\n", "[CLS] The following is an ablation study to evaluate the effect of different masking strategies. [SEP]\n", "[CLS] Note that the purpose of the masking strategies is to reduce the mismatch between pre-training and fine-tuning, as the [MASK] symbol never appears during the fine-tuning stage. [SEP]\n", "[CLS] We report the Dev results for both MNLI and NER. [SEP]\n", "[CLS] For NER, we report both fine-tuning and feature-based approaches, as we expect the mismatch will be amplified for the feature-based approach as the model will not have the chance to adjust the representations. [SEP]\n", "[CLS] TABLE   [SEP]\n", "[CLS] The results are presented in Table\u00a0REF . [SEP]\n", "[CLS] In the table, Mask means that we replace the target token with the [MASK] symbol for MLM; Same means that we keep the target token as is; Rnd means that we replace the target token with another random token. [SEP]\n", "[CLS] The numbers in the left part of the table represent the probabilities of the specific strategies used during MLM pre-training (BERT uses 80%, 10%, 10%). [SEP]\n", "[CLS] The right part of the paper represents the Dev set results. [SEP]\n", "[CLS] For the feature-based approach, we concatenate the last 4 layers of BERT as the features, which was shown to be the best approach in Section\u00a0REF . [SEP]\n", "[CLS] From the table it can be seen that fine-tuning is surprisingly robust to different masking strategies. [SEP]\n", "[CLS] However, as expected, using only the Mask strategy was problematic when applying the feature-based approach to NER. [SEP]\n", "[CLS] Interestingly, using only the Rnd strategy performs much worse than our strategy as well. [SEP]\n"]}